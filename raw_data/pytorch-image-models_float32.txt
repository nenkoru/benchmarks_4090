Running bulk validation on these pretrained models: bat_resnext26ts.ch_in1k, beit_base_patch16_224.in22k_ft_in22k, beit_base_patch16_224.in22k_ft_in22k_in1k, beit_base_patch16_384.in22k_ft_in22k_in1k, beit_large_patch16_224.in22k_ft_in22k, beit_large_patch16_224.in22k_ft_in22k_in1k, beit_large_patch16_384.in22k_ft_in22k_in1k, beit_large_patch16_512.in22k_ft_in22k_in1k, beitv2_base_patch16_224.in1k_ft_in1k, beitv2_base_patch16_224.in1k_ft_in22k, beitv2_base_patch16_224.in1k_ft_in22k_in1k, beitv2_large_patch16_224.in1k_ft_in1k, beitv2_large_patch16_224.in1k_ft_in22k, beitv2_large_patch16_224.in1k_ft_in22k_in1k, botnet26t_256.c1_in1k, caformer_b36.sail_in1k, caformer_b36.sail_in1k_384, caformer_b36.sail_in22k, caformer_b36.sail_in22k_ft_in1k, caformer_b36.sail_in22k_ft_in1k_384, caformer_m36.sail_in1k, caformer_m36.sail_in1k_384, caformer_m36.sail_in22k, caformer_m36.sail_in22k_ft_in1k, caformer_m36.sail_in22k_ft_in1k_384, caformer_s18.sail_in1k, caformer_s18.sail_in1k_384, caformer_s18.sail_in22k, caformer_s18.sail_in22k_ft_in1k, caformer_s18.sail_in22k_ft_in1k_384, caformer_s36.sail_in1k, caformer_s36.sail_in1k_384, caformer_s36.sail_in22k, caformer_s36.sail_in22k_ft_in1k, caformer_s36.sail_in22k_ft_in1k_384, cait_m36_384.fb_dist_in1k, cait_m48_448.fb_dist_in1k, cait_s24_224.fb_dist_in1k, cait_s24_384.fb_dist_in1k, cait_s36_384.fb_dist_in1k, cait_xs24_384.fb_dist_in1k, cait_xxs24_224.fb_dist_in1k, cait_xxs24_384.fb_dist_in1k, cait_xxs36_224.fb_dist_in1k, cait_xxs36_384.fb_dist_in1k, coat_lite_medium.in1k, coat_lite_medium_384.in1k, coat_lite_mini.in1k, coat_lite_small.in1k, coat_lite_tiny.in1k, coat_mini.in1k, coat_small.in1k, coat_tiny.in1k, coatnet_0_rw_224.sw_in1k, coatnet_1_rw_224.sw_in1k, coatnet_2_rw_224.sw_in12k, coatnet_2_rw_224.sw_in12k_ft_in1k, coatnet_3_rw_224.sw_in12k, coatnet_bn_0_rw_224.sw_in1k, coatnet_nano_rw_224.sw_in1k, coatnet_rmlp_1_rw2_224.sw_in12k, coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k, coatnet_rmlp_1_rw_224.sw_in1k, coatnet_rmlp_2_rw_224.sw_in1k, coatnet_rmlp_2_rw_224.sw_in12k, coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k, coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k, coatnet_rmlp_nano_rw_224.sw_in1k, coatnext_nano_rw_224.sw_in1k, convformer_b36.sail_in1k, convformer_b36.sail_in1k_384, convformer_b36.sail_in22k, convformer_b36.sail_in22k_ft_in1k, convformer_b36.sail_in22k_ft_in1k_384, convformer_m36.sail_in1k, convformer_m36.sail_in1k_384, convformer_m36.sail_in22k, convformer_m36.sail_in22k_ft_in1k, convformer_m36.sail_in22k_ft_in1k_384, convformer_s18.sail_in1k, convformer_s18.sail_in1k_384, convformer_s18.sail_in22k, convformer_s18.sail_in22k_ft_in1k, convformer_s18.sail_in22k_ft_in1k_384, convformer_s36.sail_in1k, convformer_s36.sail_in1k_384, convformer_s36.sail_in22k, convformer_s36.sail_in22k_ft_in1k, convformer_s36.sail_in22k_ft_in1k_384, convit_base.fb_in1k, convit_small.fb_in1k, convit_tiny.fb_in1k, convmixer_768_32.in1k, convmixer_1024_20_ks9_p14.in1k, convmixer_1536_20.in1k, convnext_atto.d2_in1k, convnext_atto_ols.a2_in1k, convnext_base.clip_laion2b, convnext_base.clip_laion2b_augreg, convnext_base.clip_laion2b_augreg_ft_in1k, convnext_base.clip_laion2b_augreg_ft_in12k, convnext_base.clip_laion2b_augreg_ft_in12k_in1k, convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384, convnext_base.clip_laiona, convnext_base.clip_laiona_320, convnext_base.clip_laiona_augreg_320, convnext_base.clip_laiona_augreg_ft_in1k_384, convnext_base.fb_in1k, convnext_base.fb_in22k, convnext_base.fb_in22k_ft_in1k, convnext_base.fb_in22k_ft_in1k_384, convnext_femto.d1_in1k, convnext_femto_ols.d1_in1k, convnext_large.fb_in1k, convnext_large.fb_in22k, convnext_large.fb_in22k_ft_in1k, convnext_large.fb_in22k_ft_in1k_384, convnext_large_mlp.clip_laion2b_augreg, convnext_large_mlp.clip_laion2b_augreg_ft_in1k, convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384, convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384, convnext_large_mlp.clip_laion2b_ft_320, convnext_large_mlp.clip_laion2b_ft_soup_320, convnext_large_mlp.clip_laion2b_soup_ft_in12k_320, convnext_large_mlp.clip_laion2b_soup_ft_in12k_384, convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320, convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384, convnext_nano.d1h_in1k, convnext_nano.in12k, convnext_nano.in12k_ft_in1k, convnext_nano_ols.d1h_in1k, convnext_pico.d1_in1k, convnext_pico_ols.d1_in1k, convnext_small.fb_in1k, convnext_small.fb_in22k, convnext_small.fb_in22k_ft_in1k, convnext_small.fb_in22k_ft_in1k_384, convnext_small.in12k, convnext_small.in12k_ft_in1k, convnext_small.in12k_ft_in1k_384, convnext_tiny.fb_in1k, convnext_tiny.fb_in22k, convnext_tiny.fb_in22k_ft_in1k, convnext_tiny.fb_in22k_ft_in1k_384, convnext_tiny.in12k, convnext_tiny.in12k_ft_in1k, convnext_tiny.in12k_ft_in1k_384, convnext_tiny_hnf.a2h_in1k, convnext_xlarge.fb_in22k, convnext_xlarge.fb_in22k_ft_in1k, convnext_xlarge.fb_in22k_ft_in1k_384, convnext_xxlarge.clip_laion2b_rewind, convnext_xxlarge.clip_laion2b_soup, convnext_xxlarge.clip_laion2b_soup_ft_in1k, convnextv2_atto.fcmae, convnextv2_atto.fcmae_ft_in1k, convnextv2_base.fcmae, convnextv2_base.fcmae_ft_in1k, convnextv2_base.fcmae_ft_in22k_in1k, convnextv2_base.fcmae_ft_in22k_in1k_384, convnextv2_femto.fcmae, convnextv2_femto.fcmae_ft_in1k, convnextv2_huge.fcmae, convnextv2_huge.fcmae_ft_in1k, convnextv2_huge.fcmae_ft_in22k_in1k_384, convnextv2_huge.fcmae_ft_in22k_in1k_512, convnextv2_large.fcmae, convnextv2_large.fcmae_ft_in1k, convnextv2_large.fcmae_ft_in22k_in1k, convnextv2_large.fcmae_ft_in22k_in1k_384, convnextv2_nano.fcmae, convnextv2_nano.fcmae_ft_in1k, convnextv2_nano.fcmae_ft_in22k_in1k, convnextv2_nano.fcmae_ft_in22k_in1k_384, convnextv2_pico.fcmae, convnextv2_pico.fcmae_ft_in1k, convnextv2_tiny.fcmae, convnextv2_tiny.fcmae_ft_in1k, convnextv2_tiny.fcmae_ft_in22k_in1k, convnextv2_tiny.fcmae_ft_in22k_in1k_384, crossvit_9_240.in1k, crossvit_9_dagger_240.in1k, crossvit_15_240.in1k, crossvit_15_dagger_240.in1k, crossvit_15_dagger_408.in1k, crossvit_18_240.in1k, crossvit_18_dagger_240.in1k, crossvit_18_dagger_408.in1k, crossvit_base_240.in1k, crossvit_small_240.in1k, crossvit_tiny_240.in1k, cs3darknet_focus_l.c2ns_in1k, cs3darknet_focus_m.c2ns_in1k, cs3darknet_l.c2ns_in1k, cs3darknet_m.c2ns_in1k, cs3darknet_x.c2ns_in1k, cs3edgenet_x.c2_in1k, cs3se_edgenet_x.c2ns_in1k, cs3sedarknet_l.c2ns_in1k, cs3sedarknet_x.c2ns_in1k, cspdarknet53.ra_in1k, cspresnet50.ra_in1k, cspresnext50.ra_in1k, darknet53.c2ns_in1k, darknetaa53.c2ns_in1k, davit_base.msft_in1k, davit_small.msft_in1k, davit_tiny.msft_in1k, deit3_base_patch16_224.fb_in1k, deit3_base_patch16_224.fb_in22k_ft_in1k, deit3_base_patch16_384.fb_in1k, deit3_base_patch16_384.fb_in22k_ft_in1k, deit3_huge_patch14_224.fb_in1k, deit3_huge_patch14_224.fb_in22k_ft_in1k, deit3_large_patch16_224.fb_in1k, deit3_large_patch16_224.fb_in22k_ft_in1k, deit3_large_patch16_384.fb_in1k, deit3_large_patch16_384.fb_in22k_ft_in1k, deit3_medium_patch16_224.fb_in1k, deit3_medium_patch16_224.fb_in22k_ft_in1k, deit3_small_patch16_224.fb_in1k, deit3_small_patch16_224.fb_in22k_ft_in1k, deit3_small_patch16_384.fb_in1k, deit3_small_patch16_384.fb_in22k_ft_in1k, deit_base_distilled_patch16_224.fb_in1k, deit_base_distilled_patch16_384.fb_in1k, deit_base_patch16_224.fb_in1k, deit_base_patch16_384.fb_in1k, deit_small_distilled_patch16_224.fb_in1k, deit_small_patch16_224.fb_in1k, deit_tiny_distilled_patch16_224.fb_in1k, deit_tiny_patch16_224.fb_in1k, densenet121.ra_in1k, densenet121.tv_in1k, densenet161.tv_in1k, densenet169.tv_in1k, densenet201.tv_in1k, densenetblur121d.ra_in1k, dla34.in1k, dla46_c.in1k, dla46x_c.in1k, dla60.in1k, dla60_res2net.in1k, dla60_res2next.in1k, dla60x.in1k, dla60x_c.in1k, dla102.in1k, dla102x2.in1k, dla102x.in1k, dla169.in1k, dm_nfnet_f0.dm_in1k, dm_nfnet_f1.dm_in1k, dm_nfnet_f2.dm_in1k, dm_nfnet_f3.dm_in1k, dm_nfnet_f4.dm_in1k, dm_nfnet_f5.dm_in1k, dm_nfnet_f6.dm_in1k, dpn68.mx_in1k, dpn68b.mx_in1k, dpn68b.ra_in1k, dpn92.mx_in1k, dpn98.mx_in1k, dpn107.mx_in1k, dpn131.mx_in1k, eca_botnext26ts_256.c1_in1k, eca_halonext26ts.c1_in1k, eca_nfnet_l0.ra2_in1k, eca_nfnet_l1.ra2_in1k, eca_nfnet_l2.ra3_in1k, eca_resnet33ts.ra2_in1k, eca_resnext26ts.ch_in1k, ecaresnet26t.ra2_in1k, ecaresnet50d.miil_in1k, ecaresnet50d_pruned.miil_in1k, ecaresnet50t.a1_in1k, ecaresnet50t.a2_in1k, ecaresnet50t.a3_in1k, ecaresnet50t.ra2_in1k, ecaresnet101d.miil_in1k, ecaresnet101d_pruned.miil_in1k, ecaresnet269d.ra2_in1k, ecaresnetlight.miil_in1k, edgenext_base.in21k_ft_in1k, edgenext_base.usi_in1k, edgenext_small.usi_in1k, edgenext_small_rw.sw_in1k, edgenext_x_small.in1k, edgenext_xx_small.in1k, efficientformer_l1.snap_dist_in1k, efficientformer_l3.snap_dist_in1k, efficientformer_l7.snap_dist_in1k, efficientformerv2_l.snap_dist_in1k, efficientformerv2_s0.snap_dist_in1k, efficientformerv2_s1.snap_dist_in1k, efficientformerv2_s2.snap_dist_in1k, efficientnet_b0.ra_in1k, efficientnet_b1.ft_in1k, efficientnet_b1_pruned.in1k, efficientnet_b2.ra_in1k, efficientnet_b2_pruned.in1k, efficientnet_b3.ra2_in1k, efficientnet_b3_pruned.in1k, efficientnet_b4.ra2_in1k, efficientnet_b5.sw_in12k, efficientnet_b5.sw_in12k_ft_in1k, efficientnet_el.ra_in1k, efficientnet_el_pruned.in1k, efficientnet_em.ra2_in1k, efficientnet_es.ra_in1k, efficientnet_es_pruned.in1k, efficientnet_lite0.ra_in1k, efficientnetv2_rw_m.agc_in1k, efficientnetv2_rw_s.ra2_in1k, efficientnetv2_rw_t.ra2_in1k, ese_vovnet19b_dw.ra_in1k, ese_vovnet39b.ra_in1k, eva02_base_patch14_224.mim_in22k, eva02_base_patch14_448.mim_in22k_ft_in1k, eva02_base_patch14_448.mim_in22k_ft_in22k, eva02_base_patch14_448.mim_in22k_ft_in22k_in1k, eva02_base_patch16_clip_224.merged2b, eva02_enormous_patch14_clip_224.laion2b, eva02_enormous_patch14_clip_224.laion2b_plus, eva02_large_patch14_224.mim_in22k, eva02_large_patch14_224.mim_m38m, eva02_large_patch14_448.mim_in22k_ft_in1k, eva02_large_patch14_448.mim_in22k_ft_in22k, eva02_large_patch14_448.mim_in22k_ft_in22k_in1k, eva02_large_patch14_448.mim_m38m_ft_in1k, eva02_large_patch14_448.mim_m38m_ft_in22k, eva02_large_patch14_448.mim_m38m_ft_in22k_in1k, eva02_large_patch14_clip_224.merged2b, eva02_large_patch14_clip_336.merged2b, eva02_small_patch14_224.mim_in22k, eva02_small_patch14_336.mim_in22k_ft_in1k, eva02_tiny_patch14_224.mim_in22k, eva02_tiny_patch14_336.mim_in22k_ft_in1k, eva_giant_patch14_224.clip_ft_in1k, eva_giant_patch14_336.clip_ft_in1k, eva_giant_patch14_336.m30m_ft_in22k_in1k, eva_giant_patch14_560.m30m_ft_in22k_in1k, eva_giant_patch14_clip_224.laion400m, eva_giant_patch14_clip_224.merged2b, eva_large_patch14_196.in22k_ft_in1k, eva_large_patch14_196.in22k_ft_in22k_in1k, eva_large_patch14_336.in22k_ft_in1k, eva_large_patch14_336.in22k_ft_in22k_in1k, fbnetc_100.rmsp_in1k, fbnetv3_b.ra2_in1k, fbnetv3_d.ra2_in1k, fbnetv3_g.ra2_in1k, flexivit_base.300ep_in1k, flexivit_base.600ep_in1k, flexivit_base.1200ep_in1k, flexivit_large.300ep_in1k, flexivit_large.600ep_in1k, flexivit_large.1200ep_in1k, flexivit_small.300ep_in1k, flexivit_small.600ep_in1k, flexivit_small.1200ep_in1k, focalnet_base_lrf.ms_in1k, focalnet_base_srf.ms_in1k, focalnet_huge_fl3.ms_in22k, focalnet_huge_fl4.ms_in22k, focalnet_large_fl3.ms_in22k, focalnet_large_fl4.ms_in22k, focalnet_small_lrf.ms_in1k, focalnet_small_srf.ms_in1k, focalnet_tiny_lrf.ms_in1k, focalnet_tiny_srf.ms_in1k, focalnet_xlarge_fl3.ms_in22k, focalnet_xlarge_fl4.ms_in22k, gc_efficientnetv2_rw_t.agc_in1k, gcresnet33ts.ra2_in1k, gcresnet50t.ra2_in1k, gcresnext26ts.ch_in1k, gcresnext50ts.ch_in1k, gcvit_base.in1k, gcvit_small.in1k, gcvit_tiny.in1k, gcvit_xtiny.in1k, gcvit_xxtiny.in1k, gernet_l.idstcv_in1k, gernet_m.idstcv_in1k, gernet_s.idstcv_in1k, ghostnet_100.in1k, gmixer_24_224.ra3_in1k, gmlp_s16_224.ra3_in1k, halo2botnet50ts_256.a1h_in1k, halonet26t.a1h_in1k, halonet50ts.a1h_in1k, haloregnetz_b.ra3_in1k, hardcorenas_a.miil_green_in1k, hardcorenas_b.miil_green_in1k, hardcorenas_c.miil_green_in1k, hardcorenas_d.miil_green_in1k, hardcorenas_e.miil_green_in1k, hardcorenas_f.miil_green_in1k, hrnet_w18.ms_aug_in1k, hrnet_w18.ms_in1k, hrnet_w18_small.ms_in1k, hrnet_w18_small_v2.ms_in1k, hrnet_w18_ssld.paddle_in1k, hrnet_w30.ms_in1k, hrnet_w32.ms_in1k, hrnet_w40.ms_in1k, hrnet_w44.ms_in1k, hrnet_w48.ms_in1k, hrnet_w48_ssld.paddle_in1k, hrnet_w64.ms_in1k, inception_resnet_v2.tf_ens_adv_in1k, inception_resnet_v2.tf_in1k, inception_v3.gluon_in1k, inception_v3.tf_adv_in1k, inception_v3.tf_in1k, inception_v3.tv_in1k, inception_v4.tf_in1k, lambda_resnet26rpt_256.c1_in1k, lambda_resnet26t.c1_in1k, lambda_resnet50ts.a1h_in1k, lamhalobotnet50ts_256.a1h_in1k, lcnet_050.ra2_in1k, lcnet_075.ra2_in1k, lcnet_100.ra2_in1k, legacy_senet154.in1k, legacy_seresnet18.in1k, legacy_seresnet34.in1k, legacy_seresnet50.in1k, legacy_seresnet101.in1k, legacy_seresnet152.in1k, legacy_seresnext26_32x4d.in1k, legacy_seresnext50_32x4d.in1k, legacy_seresnext101_32x4d.in1k, legacy_xception.tf_in1k, levit_128.fb_dist_in1k, levit_128s.fb_dist_in1k, levit_192.fb_dist_in1k, levit_256.fb_dist_in1k, levit_384.fb_dist_in1k, levit_conv_128.fb_dist_in1k, levit_conv_128s.fb_dist_in1k, levit_conv_192.fb_dist_in1k, levit_conv_256.fb_dist_in1k, levit_conv_384.fb_dist_in1k, maxvit_base_tf_224.in1k, maxvit_base_tf_384.in1k, maxvit_base_tf_384.in21k_ft_in1k, maxvit_base_tf_512.in1k, maxvit_base_tf_512.in21k_ft_in1k, maxvit_large_tf_224.in1k, maxvit_large_tf_384.in1k, maxvit_large_tf_384.in21k_ft_in1k, maxvit_large_tf_512.in1k, maxvit_large_tf_512.in21k_ft_in1k, maxvit_nano_rw_256.sw_in1k, maxvit_rmlp_base_rw_224.sw_in12k, maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k, maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k, maxvit_rmlp_nano_rw_256.sw_in1k, maxvit_rmlp_pico_rw_256.sw_in1k, maxvit_rmlp_small_rw_224.sw_in1k, maxvit_rmlp_tiny_rw_256.sw_in1k, maxvit_small_tf_224.in1k, maxvit_small_tf_384.in1k, maxvit_small_tf_512.in1k, maxvit_tiny_rw_224.sw_in1k, maxvit_tiny_tf_224.in1k, maxvit_tiny_tf_384.in1k, maxvit_tiny_tf_512.in1k, maxvit_xlarge_tf_384.in21k_ft_in1k, maxvit_xlarge_tf_512.in21k_ft_in1k, maxxvit_rmlp_nano_rw_256.sw_in1k, maxxvit_rmlp_small_rw_256.sw_in1k, maxxvitv2_nano_rw_256.sw_in1k, maxxvitv2_rmlp_base_rw_224.sw_in12k, maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k, maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k, mixer_b16_224.goog_in21k_ft_in1k, mixer_b16_224.miil_in21k_ft_in1k, mixer_l16_224.goog_in21k_ft_in1k, mixnet_l.ft_in1k, mixnet_m.ft_in1k, mixnet_s.ft_in1k, mixnet_xl.ra_in1k, mnasnet_100.rmsp_in1k, mnasnet_small.lamb_in1k, mobilenetv2_050.lamb_in1k, mobilenetv2_100.ra_in1k, mobilenetv2_110d.ra_in1k, mobilenetv2_120d.ra_in1k, mobilenetv2_140.ra_in1k, mobilenetv3_large_100.miil_in21k_ft_in1k, mobilenetv3_large_100.ra_in1k, mobilenetv3_rw.rmsp_in1k, mobilenetv3_small_050.lamb_in1k, mobilenetv3_small_075.lamb_in1k, mobilenetv3_small_100.lamb_in1k, mobilevit_s.cvnets_in1k, mobilevit_xs.cvnets_in1k, mobilevit_xxs.cvnets_in1k, mobilevitv2_050.cvnets_in1k, mobilevitv2_075.cvnets_in1k, mobilevitv2_100.cvnets_in1k, mobilevitv2_125.cvnets_in1k, mobilevitv2_150.cvnets_in1k, mobilevitv2_150.cvnets_in22k_ft_in1k, mobilevitv2_150.cvnets_in22k_ft_in1k_384, mobilevitv2_175.cvnets_in1k, mobilevitv2_175.cvnets_in22k_ft_in1k, mobilevitv2_175.cvnets_in22k_ft_in1k_384, mobilevitv2_200.cvnets_in1k, mobilevitv2_200.cvnets_in22k_ft_in1k, mobilevitv2_200.cvnets_in22k_ft_in1k_384, mvitv2_base.fb_in1k, mvitv2_base_cls.fb_inw21k, mvitv2_huge_cls.fb_inw21k, mvitv2_large.fb_in1k, mvitv2_large_cls.fb_inw21k, mvitv2_small.fb_in1k, mvitv2_tiny.fb_in1k, nasnetalarge.tf_in1k, nest_base_jx.goog_in1k, nest_small_jx.goog_in1k, nest_tiny_jx.goog_in1k, nf_regnet_b1.ra2_in1k, nf_resnet50.ra2_in1k, nfnet_l0.ra2_in1k, pit_b_224.in1k, pit_b_distilled_224.in1k, pit_s_224.in1k, pit_s_distilled_224.in1k, pit_ti_224.in1k, pit_ti_distilled_224.in1k, pit_xs_224.in1k, pit_xs_distilled_224.in1k, pnasnet5large.tf_in1k, poolformer_m36.sail_in1k, poolformer_m48.sail_in1k, poolformer_s12.sail_in1k, poolformer_s24.sail_in1k, poolformer_s36.sail_in1k, poolformerv2_m36.sail_in1k, poolformerv2_m48.sail_in1k, poolformerv2_s12.sail_in1k, poolformerv2_s24.sail_in1k, poolformerv2_s36.sail_in1k, pvt_v2_b0.in1k, pvt_v2_b1.in1k, pvt_v2_b2.in1k, pvt_v2_b2_li.in1k, pvt_v2_b3.in1k, pvt_v2_b4.in1k, pvt_v2_b5.in1k, regnetv_040.ra3_in1k, regnetv_064.ra3_in1k, regnetx_002.pycls_in1k, regnetx_004.pycls_in1k, regnetx_004_tv.tv2_in1k, regnetx_006.pycls_in1k, regnetx_008.pycls_in1k, regnetx_008.tv2_in1k, regnetx_016.pycls_in1k, regnetx_016.tv2_in1k, regnetx_032.pycls_in1k, regnetx_032.tv2_in1k, regnetx_040.pycls_in1k, regnetx_064.pycls_in1k, regnetx_080.pycls_in1k, regnetx_080.tv2_in1k, regnetx_120.pycls_in1k, regnetx_160.pycls_in1k, regnetx_160.tv2_in1k, regnetx_320.pycls_in1k, regnetx_320.tv2_in1k, regnety_002.pycls_in1k, regnety_004.pycls_in1k, regnety_004.tv2_in1k, regnety_006.pycls_in1k, regnety_008.pycls_in1k, regnety_008_tv.tv2_in1k, regnety_016.pycls_in1k, regnety_016.tv2_in1k, regnety_032.pycls_in1k, regnety_032.ra_in1k, regnety_032.tv2_in1k, regnety_040.pycls_in1k, regnety_040.ra3_in1k, regnety_064.pycls_in1k, regnety_064.ra3_in1k, regnety_080.pycls_in1k, regnety_080.ra3_in1k, regnety_080_tv.tv2_in1k, regnety_120.pycls_in1k, regnety_120.sw_in12k, regnety_120.sw_in12k_ft_in1k, regnety_160.deit_in1k, regnety_160.lion_in12k_ft_in1k, regnety_160.pycls_in1k, regnety_160.sw_in12k, regnety_160.sw_in12k_ft_in1k, regnety_160.swag_ft_in1k, regnety_160.swag_lc_in1k, regnety_160.tv2_in1k, regnety_320.pycls_in1k, regnety_320.seer, regnety_320.seer_ft_in1k, regnety_320.swag_ft_in1k, regnety_320.swag_lc_in1k, regnety_320.tv2_in1k, regnety_640.seer, regnety_640.seer_ft_in1k, regnety_1280.seer, regnety_1280.seer_ft_in1k, regnety_1280.swag_ft_in1k, regnety_1280.swag_lc_in1k, regnety_2560.seer_ft_in1k, regnetz_040.ra3_in1k, regnetz_040_h.ra3_in1k, regnetz_b16.ra3_in1k, regnetz_c16.ra3_in1k, regnetz_c16_evos.ch_in1k, regnetz_d8.ra3_in1k, regnetz_d8_evos.ch_in1k, regnetz_d32.ra3_in1k, regnetz_e8.ra3_in1k, repvgg_a2.rvgg_in1k, repvgg_b0.rvgg_in1k, repvgg_b1.rvgg_in1k, repvgg_b1g4.rvgg_in1k, repvgg_b2.rvgg_in1k, repvgg_b2g4.rvgg_in1k, repvgg_b3.rvgg_in1k, repvgg_b3g4.rvgg_in1k, res2net50_14w_8s.in1k, res2net50_26w_4s.in1k, res2net50_26w_6s.in1k, res2net50_26w_8s.in1k, res2net50_48w_2s.in1k, res2net50d.in1k, res2net101_26w_4s.in1k, res2net101d.in1k, res2next50.in1k, resmlp_12_224.fb_dino, resmlp_12_224.fb_distilled_in1k, resmlp_12_224.fb_in1k, resmlp_24_224.fb_dino, resmlp_24_224.fb_distilled_in1k, resmlp_24_224.fb_in1k, resmlp_36_224.fb_distilled_in1k, resmlp_36_224.fb_in1k, resmlp_big_24_224.fb_distilled_in1k, resmlp_big_24_224.fb_in1k, resmlp_big_24_224.fb_in22k_ft_in1k, resnest14d.gluon_in1k, resnest26d.gluon_in1k, resnest50d.in1k, resnest50d_1s4x24d.in1k, resnest50d_4s2x40d.in1k, resnest101e.in1k, resnest200e.in1k, resnest269e.in1k, resnet10t.c3_in1k, resnet14t.c3_in1k, resnet18.a1_in1k, resnet18.a2_in1k, resnet18.a3_in1k, resnet18.fb_ssl_yfcc100m_ft_in1k, resnet18.fb_swsl_ig1b_ft_in1k, resnet18.gluon_in1k, resnet18.tv_in1k, resnet18d.ra2_in1k, resnet26.bt_in1k, resnet26d.bt_in1k, resnet26t.ra2_in1k, resnet32ts.ra2_in1k, resnet33ts.ra2_in1k, resnet34.a1_in1k, resnet34.a2_in1k, resnet34.a3_in1k, resnet34.bt_in1k, resnet34.gluon_in1k, resnet34.tv_in1k, resnet34d.ra2_in1k, resnet50.a1_in1k, resnet50.a1h_in1k, resnet50.a2_in1k, resnet50.a3_in1k, resnet50.am_in1k, resnet50.b1k_in1k, resnet50.b2k_in1k, resnet50.bt_in1k, resnet50.c1_in1k, resnet50.c2_in1k, resnet50.d_in1k, resnet50.fb_ssl_yfcc100m_ft_in1k, resnet50.fb_swsl_ig1b_ft_in1k, resnet50.gluon_in1k, resnet50.ra_in1k, resnet50.ram_in1k, resnet50.tv2_in1k, resnet50.tv_in1k, resnet50_gn.a1h_in1k, resnet50c.gluon_in1k, resnet50d.a1_in1k, resnet50d.a2_in1k, resnet50d.a3_in1k, resnet50d.gluon_in1k, resnet50d.ra2_in1k, resnet50s.gluon_in1k, resnet51q.ra2_in1k, resnet61q.ra2_in1k, resnet101.a1_in1k, resnet101.a1h_in1k, resnet101.a2_in1k, resnet101.a3_in1k, resnet101.gluon_in1k, resnet101.tv2_in1k, resnet101.tv_in1k, resnet101c.gluon_in1k, resnet101d.gluon_in1k, resnet101d.ra2_in1k, resnet101s.gluon_in1k, resnet152.a1_in1k, resnet152.a1h_in1k, resnet152.a2_in1k, resnet152.a3_in1k, resnet152.gluon_in1k, resnet152.tv2_in1k, resnet152.tv_in1k, resnet152c.gluon_in1k, resnet152d.gluon_in1k, resnet152d.ra2_in1k, resnet152s.gluon_in1k, resnet200d.ra2_in1k, resnetaa50.a1h_in1k, resnetaa50d.d_in12k, resnetaa50d.sw_in12k, resnetaa50d.sw_in12k_ft_in1k, resnetaa101d.sw_in12k, resnetaa101d.sw_in12k_ft_in1k, resnetblur50.bt_in1k, resnetrs50.tf_in1k, resnetrs101.tf_in1k, resnetrs152.tf_in1k, resnetrs200.tf_in1k, resnetrs270.tf_in1k, resnetrs350.tf_in1k, resnetrs420.tf_in1k, resnetv2_50.a1h_in1k, resnetv2_50d_evos.ah_in1k, resnetv2_50d_gn.ah_in1k, resnetv2_50x1_bit.goog_distilled_in1k, resnetv2_50x1_bit.goog_in21k_ft_in1k, resnetv2_50x3_bit.goog_in21k_ft_in1k, resnetv2_101.a1h_in1k, resnetv2_101x1_bit.goog_in21k_ft_in1k, resnetv2_101x3_bit.goog_in21k_ft_in1k, resnetv2_152x2_bit.goog_in21k_ft_in1k, resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k, resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384, resnetv2_152x4_bit.goog_in21k_ft_in1k, resnext26ts.ra2_in1k, resnext50_32x4d.a1_in1k, resnext50_32x4d.a1h_in1k, resnext50_32x4d.a2_in1k, resnext50_32x4d.a3_in1k, resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k, resnext50_32x4d.fb_swsl_ig1b_ft_in1k, resnext50_32x4d.gluon_in1k, resnext50_32x4d.ra_in1k, resnext50_32x4d.tv2_in1k, resnext50_32x4d.tv_in1k, resnext50d_32x4d.bt_in1k, resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k, resnext101_32x4d.fb_swsl_ig1b_ft_in1k, resnext101_32x4d.gluon_in1k, resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k, resnext101_32x8d.fb_swsl_ig1b_ft_in1k, resnext101_32x8d.fb_wsl_ig1b_ft_in1k, resnext101_32x8d.tv2_in1k, resnext101_32x8d.tv_in1k, resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k, resnext101_32x16d.fb_swsl_ig1b_ft_in1k, resnext101_32x16d.fb_wsl_ig1b_ft_in1k, resnext101_32x32d.fb_wsl_ig1b_ft_in1k, resnext101_64x4d.c1_in1k, resnext101_64x4d.gluon_in1k, resnext101_64x4d.tv_in1k, rexnet_100.nav_in1k, rexnet_130.nav_in1k, rexnet_150.nav_in1k, rexnet_200.nav_in1k, rexnet_300.nav_in1k, rexnetr_200.sw_in12k, rexnetr_200.sw_in12k_ft_in1k, rexnetr_300.sw_in12k, rexnetr_300.sw_in12k_ft_in1k, samvit_base_patch16.sa1b, samvit_huge_patch16.sa1b, samvit_large_patch16.sa1b, sebotnet33ts_256.a1h_in1k, sehalonet33ts.ra2_in1k, SelecSls42b.in1k, SelecSls60.in1k, SelecSls60b.in1k, semnasnet_075.rmsp_in1k, semnasnet_100.rmsp_in1k, senet154.gluon_in1k, sequencer2d_l.in1k, sequencer2d_m.in1k, sequencer2d_s.in1k, seresnet33ts.ra2_in1k, seresnet50.a1_in1k, seresnet50.a2_in1k, seresnet50.a3_in1k, seresnet50.ra2_in1k, seresnet152d.ra2_in1k, seresnext26d_32x4d.bt_in1k, seresnext26t_32x4d.bt_in1k, seresnext26ts.ch_in1k, seresnext50_32x4d.gluon_in1k, seresnext50_32x4d.racm_in1k, seresnext101_32x4d.gluon_in1k, seresnext101_32x8d.ah_in1k, seresnext101_64x4d.gluon_in1k, seresnext101d_32x8d.ah_in1k, seresnextaa101d_32x8d.ah_in1k, seresnextaa101d_32x8d.sw_in12k, seresnextaa101d_32x8d.sw_in12k_ft_in1k, seresnextaa101d_32x8d.sw_in12k_ft_in1k_288, skresnet18.ra_in1k, skresnet34.ra_in1k, skresnext50_32x4d.ra_in1k, spnasnet_100.rmsp_in1k, swin_base_patch4_window7_224.ms_in1k, swin_base_patch4_window7_224.ms_in22k, swin_base_patch4_window7_224.ms_in22k_ft_in1k, swin_base_patch4_window12_384.ms_in1k, swin_base_patch4_window12_384.ms_in22k, swin_base_patch4_window12_384.ms_in22k_ft_in1k, swin_large_patch4_window7_224.ms_in22k, swin_large_patch4_window7_224.ms_in22k_ft_in1k, swin_large_patch4_window12_384.ms_in22k, swin_large_patch4_window12_384.ms_in22k_ft_in1k, swin_s3_base_224.ms_in1k, swin_s3_small_224.ms_in1k, swin_s3_tiny_224.ms_in1k, swin_small_patch4_window7_224.ms_in1k, swin_small_patch4_window7_224.ms_in22k, swin_small_patch4_window7_224.ms_in22k_ft_in1k, swin_tiny_patch4_window7_224.ms_in1k, swin_tiny_patch4_window7_224.ms_in22k, swin_tiny_patch4_window7_224.ms_in22k_ft_in1k, swinv2_base_window8_256.ms_in1k, swinv2_base_window12_192.ms_in22k, swinv2_base_window12to16_192to256.ms_in22k_ft_in1k, swinv2_base_window12to24_192to384.ms_in22k_ft_in1k, swinv2_base_window16_256.ms_in1k, swinv2_cr_small_224.sw_in1k, swinv2_cr_small_ns_224.sw_in1k, swinv2_cr_tiny_ns_224.sw_in1k, swinv2_large_window12_192.ms_in22k, swinv2_large_window12to16_192to256.ms_in22k_ft_in1k, swinv2_large_window12to24_192to384.ms_in22k_ft_in1k, swinv2_small_window8_256.ms_in1k, swinv2_small_window16_256.ms_in1k, swinv2_tiny_window8_256.ms_in1k, swinv2_tiny_window16_256.ms_in1k, tf_efficientnet_b0.aa_in1k, tf_efficientnet_b0.ap_in1k, tf_efficientnet_b0.in1k, tf_efficientnet_b0.ns_jft_in1k, tf_efficientnet_b1.aa_in1k, tf_efficientnet_b1.ap_in1k, tf_efficientnet_b1.in1k, tf_efficientnet_b1.ns_jft_in1k, tf_efficientnet_b2.aa_in1k, tf_efficientnet_b2.ap_in1k, tf_efficientnet_b2.in1k, tf_efficientnet_b2.ns_jft_in1k, tf_efficientnet_b3.aa_in1k, tf_efficientnet_b3.ap_in1k, tf_efficientnet_b3.in1k, tf_efficientnet_b3.ns_jft_in1k, tf_efficientnet_b4.aa_in1k, tf_efficientnet_b4.ap_in1k, tf_efficientnet_b4.in1k, tf_efficientnet_b4.ns_jft_in1k, tf_efficientnet_b5.aa_in1k, tf_efficientnet_b5.ap_in1k, tf_efficientnet_b5.in1k, tf_efficientnet_b5.ns_jft_in1k, tf_efficientnet_b5.ra_in1k, tf_efficientnet_b6.aa_in1k, tf_efficientnet_b6.ap_in1k, tf_efficientnet_b6.ns_jft_in1k, tf_efficientnet_b7.aa_in1k, tf_efficientnet_b7.ap_in1k, tf_efficientnet_b7.ns_jft_in1k, tf_efficientnet_b7.ra_in1k, tf_efficientnet_b8.ap_in1k, tf_efficientnet_b8.ra_in1k, tf_efficientnet_cc_b0_4e.in1k, tf_efficientnet_cc_b0_8e.in1k, tf_efficientnet_cc_b1_8e.in1k, tf_efficientnet_el.in1k, tf_efficientnet_em.in1k, tf_efficientnet_es.in1k, tf_efficientnet_l2.ns_jft_in1k, tf_efficientnet_l2.ns_jft_in1k_475, tf_efficientnet_lite0.in1k, tf_efficientnet_lite1.in1k, tf_efficientnet_lite2.in1k, tf_efficientnet_lite3.in1k, tf_efficientnet_lite4.in1k, tf_efficientnetv2_b0.in1k, tf_efficientnetv2_b1.in1k, tf_efficientnetv2_b2.in1k, tf_efficientnetv2_b3.in1k, tf_efficientnetv2_b3.in21k_ft_in1k, tf_efficientnetv2_l.in1k, tf_efficientnetv2_l.in21k_ft_in1k, tf_efficientnetv2_m.in1k, tf_efficientnetv2_m.in21k_ft_in1k, tf_efficientnetv2_s.in1k, tf_efficientnetv2_s.in21k_ft_in1k, tf_efficientnetv2_xl.in21k_ft_in1k, tf_mixnet_l.in1k, tf_mixnet_m.in1k, tf_mixnet_s.in1k, tf_mobilenetv3_large_075.in1k, tf_mobilenetv3_large_100.in1k, tf_mobilenetv3_large_minimal_100.in1k, tf_mobilenetv3_small_075.in1k, tf_mobilenetv3_small_100.in1k, tf_mobilenetv3_small_minimal_100.in1k, tinynet_a.in1k, tinynet_b.in1k, tinynet_c.in1k, tinynet_d.in1k, tinynet_e.in1k, tnt_s_patch16_224, tresnet_l.miil_in1k, tresnet_l.miil_in1k_448, tresnet_m.miil_in1k, tresnet_m.miil_in1k_448, tresnet_m.miil_in21k_ft_in1k, tresnet_v2_l.miil_in21k_ft_in1k, tresnet_xl.miil_in1k, tresnet_xl.miil_in1k_448, twins_pcpvt_base.in1k, twins_pcpvt_large.in1k, twins_pcpvt_small.in1k, twins_svt_base.in1k, twins_svt_large.in1k, twins_svt_small.in1k, vgg11.tv_in1k, vgg11_bn.tv_in1k, vgg13.tv_in1k, vgg13_bn.tv_in1k, vgg16.tv_in1k, vgg16_bn.tv_in1k, vgg19.tv_in1k, vgg19_bn.tv_in1k, visformer_small.in1k, visformer_tiny.in1k, vit_base_patch8_224.augreg2_in21k_ft_in1k, vit_base_patch8_224.augreg_in21k_ft_in1k, vit_base_patch8_224.dino, vit_base_patch14_dinov2.lvd142m, vit_base_patch16_224.augreg2_in21k_ft_in1k, vit_base_patch16_224.augreg_in1k, vit_base_patch16_224.augreg_in21k_ft_in1k, vit_base_patch16_224.dino, vit_base_patch16_224.mae, vit_base_patch16_224.orig_in21k_ft_in1k, vit_base_patch16_224.sam_in1k, vit_base_patch16_224_miil.in21k_ft_in1k, vit_base_patch16_384.augreg_in1k, vit_base_patch16_384.augreg_in21k_ft_in1k, vit_base_patch16_384.orig_in21k_ft_in1k, vit_base_patch16_clip_224.datacompxl, vit_base_patch16_clip_224.laion2b, vit_base_patch16_clip_224.laion2b_ft_in1k, vit_base_patch16_clip_224.laion2b_ft_in12k, vit_base_patch16_clip_224.laion2b_ft_in12k_in1k, vit_base_patch16_clip_224.openai, vit_base_patch16_clip_224.openai_ft_in1k, vit_base_patch16_clip_224.openai_ft_in12k, vit_base_patch16_clip_224.openai_ft_in12k_in1k, vit_base_patch16_clip_384.laion2b_ft_in1k, vit_base_patch16_clip_384.laion2b_ft_in12k_in1k, vit_base_patch16_clip_384.openai_ft_in1k, vit_base_patch16_clip_384.openai_ft_in12k_in1k, vit_base_patch16_rpn_224.sw_in1k, vit_base_patch32_224.augreg_in1k, vit_base_patch32_224.augreg_in21k_ft_in1k, vit_base_patch32_224.sam_in1k, vit_base_patch32_384.augreg_in1k, vit_base_patch32_384.augreg_in21k_ft_in1k, vit_base_patch32_clip_224.laion2b, vit_base_patch32_clip_224.laion2b_ft_in1k, vit_base_patch32_clip_224.laion2b_ft_in12k_in1k, vit_base_patch32_clip_224.openai, vit_base_patch32_clip_224.openai_ft_in1k, vit_base_patch32_clip_384.laion2b_ft_in12k_in1k, vit_base_patch32_clip_384.openai_ft_in12k_in1k, vit_base_patch32_clip_448.laion2b_ft_in12k_in1k, vit_base_r50_s16_384.orig_in21k_ft_in1k, vit_giant_patch14_clip_224.laion2b, vit_giant_patch14_dinov2.lvd142m, vit_gigantic_patch14_clip_224.laion2b, vit_gigantic_patch16_224_ijepa.in22k, vit_huge_patch14_224.mae, vit_huge_patch14_224_ijepa.in1k, vit_huge_patch14_224_ijepa.in22k, vit_huge_patch14_clip_224.laion2b, vit_huge_patch14_clip_224.laion2b_ft_in1k, vit_huge_patch14_clip_224.laion2b_ft_in12k, vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k, vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k, vit_huge_patch16_448_ijepa.in1k, vit_large_patch14_clip_224.datacompxl, vit_large_patch14_clip_224.laion2b, vit_large_patch14_clip_224.laion2b_ft_in1k, vit_large_patch14_clip_224.laion2b_ft_in12k, vit_large_patch14_clip_224.laion2b_ft_in12k_in1k, vit_large_patch14_clip_224.openai, vit_large_patch14_clip_224.openai_ft_in1k, vit_large_patch14_clip_224.openai_ft_in12k, vit_large_patch14_clip_224.openai_ft_in12k_in1k, vit_large_patch14_clip_336.laion2b_ft_in1k, vit_large_patch14_clip_336.laion2b_ft_in12k_in1k, vit_large_patch14_clip_336.openai, vit_large_patch14_clip_336.openai_ft_in12k_in1k, vit_large_patch14_dinov2.lvd142m, vit_large_patch16_224.augreg_in21k_ft_in1k, vit_large_patch16_224.mae, vit_large_patch16_384.augreg_in21k_ft_in1k, vit_large_patch32_384.orig_in21k_ft_in1k, vit_large_r50_s32_224.augreg_in21k_ft_in1k, vit_large_r50_s32_384.augreg_in21k_ft_in1k, vit_medium_patch16_gap_240.sw_in12k, vit_medium_patch16_gap_256.sw_in12k_ft_in1k, vit_medium_patch16_gap_384.sw_in12k_ft_in1k, vit_relpos_base_patch16_224.sw_in1k, vit_relpos_base_patch16_clsgap_224.sw_in1k, vit_relpos_base_patch32_plus_rpn_256.sw_in1k, vit_relpos_medium_patch16_224.sw_in1k, vit_relpos_medium_patch16_cls_224.sw_in1k, vit_relpos_medium_patch16_rpn_224.sw_in1k, vit_relpos_small_patch16_224.sw_in1k, vit_small_patch8_224.dino, vit_small_patch14_dinov2.lvd142m, vit_small_patch16_224.augreg_in1k, vit_small_patch16_224.augreg_in21k_ft_in1k, vit_small_patch16_224.dino, vit_small_patch16_384.augreg_in1k, vit_small_patch16_384.augreg_in21k_ft_in1k, vit_small_patch32_224.augreg_in21k_ft_in1k, vit_small_patch32_384.augreg_in21k_ft_in1k, vit_small_r26_s32_224.augreg_in21k_ft_in1k, vit_small_r26_s32_384.augreg_in21k_ft_in1k, vit_srelpos_medium_patch16_224.sw_in1k, vit_srelpos_small_patch16_224.sw_in1k, vit_tiny_patch16_224.augreg_in21k_ft_in1k, vit_tiny_patch16_384.augreg_in21k_ft_in1k, vit_tiny_r_s16_p8_224.augreg_in21k_ft_in1k, vit_tiny_r_s16_p8_384.augreg_in21k_ft_in1k, volo_d1_224.sail_in1k, volo_d1_384.sail_in1k, volo_d2_224.sail_in1k, volo_d2_384.sail_in1k, volo_d3_224.sail_in1k, volo_d3_448.sail_in1k, volo_d4_224.sail_in1k, volo_d4_448.sail_in1k, volo_d5_224.sail_in1k, volo_d5_448.sail_in1k, volo_d5_512.sail_in1k, wide_resnet50_2.racm_in1k, wide_resnet50_2.tv2_in1k, wide_resnet50_2.tv_in1k, wide_resnet101_2.tv2_in1k, wide_resnet101_2.tv_in1k, xception41.tf_in1k, xception41p.ra3_in1k, xception65.ra3_in1k, xception65.tf_in1k, xception65p.ra3_in1k, xception71.tf_in1k, xcit_large_24_p8_224.fb_dist_in1k, xcit_large_24_p8_224.fb_in1k, xcit_large_24_p8_384.fb_dist_in1k, xcit_large_24_p16_224.fb_dist_in1k, xcit_large_24_p16_224.fb_in1k, xcit_large_24_p16_384.fb_dist_in1k, xcit_medium_24_p8_224.fb_dist_in1k, xcit_medium_24_p8_224.fb_in1k, xcit_medium_24_p8_384.fb_dist_in1k, xcit_medium_24_p16_224.fb_dist_in1k, xcit_medium_24_p16_224.fb_in1k, xcit_medium_24_p16_384.fb_dist_in1k, xcit_nano_12_p8_224.fb_dist_in1k, xcit_nano_12_p8_224.fb_in1k, xcit_nano_12_p8_384.fb_dist_in1k, xcit_nano_12_p16_224.fb_dist_in1k, xcit_nano_12_p16_224.fb_in1k, xcit_nano_12_p16_384.fb_dist_in1k, xcit_small_12_p8_224.fb_dist_in1k, xcit_small_12_p8_224.fb_in1k, xcit_small_12_p8_384.fb_dist_in1k, xcit_small_12_p16_224.fb_dist_in1k, xcit_small_12_p16_224.fb_in1k, xcit_small_12_p16_384.fb_dist_in1k, xcit_small_24_p8_224.fb_dist_in1k, xcit_small_24_p8_224.fb_in1k, xcit_small_24_p8_384.fb_dist_in1k, xcit_small_24_p16_224.fb_dist_in1k, xcit_small_24_p16_224.fb_in1k, xcit_small_24_p16_384.fb_dist_in1k, xcit_tiny_12_p8_224.fb_dist_in1k, xcit_tiny_12_p8_224.fb_in1k, xcit_tiny_12_p8_384.fb_dist_in1k, xcit_tiny_12_p16_224.fb_dist_in1k, xcit_tiny_12_p16_224.fb_in1k, xcit_tiny_12_p16_384.fb_dist_in1k, xcit_tiny_24_p8_224.fb_dist_in1k, xcit_tiny_24_p8_224.fb_in1k, xcit_tiny_24_p8_384.fb_dist_in1k, xcit_tiny_24_p16_224.fb_dist_in1k, xcit_tiny_24_p16_224.fb_in1k, xcit_tiny_24_p16_384.fb_dist_in1k
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model bat_resnext26ts.ch_in1k created, param count: 10731200
Running inference benchmark on bat_resnext26ts.ch_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2413.86 samples/sec. 106.054 ms/step.
Infer [16/40]. 2413.19 samples/sec. 106.084 ms/step.
Infer [24/40]. 2412.98 samples/sec. 106.093 ms/step.
Infer [32/40]. 2412.82 samples/sec. 106.100 ms/step.
Infer [40/40]. 2412.61 samples/sec. 106.109 ms/step.
Inference benchmark of bat_resnext26ts.ch_in1k done. 2411.96 samples/sec, 106.11 ms/step
Model bat_resnext26ts.ch_in1k created, param count: 10731200
Running train benchmark on bat_resnext26ts.ch_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.15 GiB is allocated by PyTorch, and 19.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model bat_resnext26ts.ch_in1k created, param count: 10731200
Running train benchmark on bat_resnext26ts.ch_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.12 GiB is allocated by PyTorch, and 35.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model bat_resnext26ts.ch_in1k created, param count: 10731200
Running train benchmark on bat_resnext26ts.ch_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 680.29 samples/sec. 188.155 ms/step.
Train [16/40]. 680.27 samples/sec. 188.161 ms/step.
Train [24/40]. 680.26 samples/sec. 188.163 ms/step.
Train [32/40]. 680.28 samples/sec. 188.157 ms/step.
Train [40/40]. 680.27 samples/sec. 188.160 ms/step.
Train benchmark of bat_resnext26ts.ch_in1k done. 676.27 samples/sec, 188.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
/home/nenkoru/miniconda3/envs/starcoder/lib/python3.10/site-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3491.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model beit_base_patch16_224.in22k_ft_in22k created, param count: 102557713
Running inference benchmark on beit_base_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1148.95 samples/sec. 222.812 ms/step.
Infer [16/40]. 1149.02 samples/sec. 222.798 ms/step.
Infer [24/40]. 1149.04 samples/sec. 222.795 ms/step.
Infer [32/40]. 1149.06 samples/sec. 222.790 ms/step.
Infer [40/40]. 1149.07 samples/sec. 222.790 ms/step.
Inference benchmark of beit_base_patch16_224.in22k_ft_in22k done. 1148.86 samples/sec, 222.79 ms/step
Model beit_base_patch16_224.in22k_ft_in22k created, param count: 102557713
Running train benchmark on beit_base_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 121.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_base_patch16_224.in22k_ft_in22k created, param count: 102557713
Running train benchmark on beit_base_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 272.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_base_patch16_224.in22k_ft_in22k created, param count: 102557713
Running train benchmark on beit_base_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 375.80 samples/sec. 340.605 ms/step.
Train [16/40]. 375.81 samples/sec. 340.599 ms/step.
Train [24/40]. 375.81 samples/sec. 340.596 ms/step.
Train [32/40]. 375.81 samples/sec. 340.597 ms/step.
Train [40/40]. 375.81 samples/sec. 340.598 ms/step.
Train benchmark of beit_base_patch16_224.in22k_ft_in22k done. 374.41 samples/sec, 340.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beit_base_patch16_224.in22k_ft_in22k_in1k created, param count: 86530984
Running inference benchmark on beit_base_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1149.54 samples/sec. 222.698 ms/step.
Infer [16/40]. 1149.52 samples/sec. 222.701 ms/step.
Infer [24/40]. 1149.52 samples/sec. 222.701 ms/step.
Infer [32/40]. 1149.54 samples/sec. 222.699 ms/step.
Infer [40/40]. 1149.53 samples/sec. 222.700 ms/step.
Inference benchmark of beit_base_patch16_224.in22k_ft_in22k_in1k done. 1149.33 samples/sec, 222.70 ms/step
Model beit_base_patch16_224.in22k_ft_in22k_in1k created, param count: 86530984
Running train benchmark on beit_base_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 118.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_base_patch16_224.in22k_ft_in22k_in1k created, param count: 86530984
Running train benchmark on beit_base_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 269.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_base_patch16_224.in22k_ft_in22k_in1k created, param count: 86530984
Running train benchmark on beit_base_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 377.06 samples/sec. 339.468 ms/step.
Train [16/40]. 377.06 samples/sec. 339.465 ms/step.
Train [24/40]. 377.07 samples/sec. 339.462 ms/step.
Train [32/40]. 377.07 samples/sec. 339.461 ms/step.
Train [40/40]. 377.07 samples/sec. 339.456 ms/step.
Train benchmark of beit_base_patch16_224.in22k_ft_in22k_in1k done. 375.64 samples/sec, 339.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running inference benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 296.95 samples/sec. 862.098 ms/step.
Infer [16/40]. 296.93 samples/sec. 862.161 ms/step.
Infer [24/40]. 296.87 samples/sec. 862.341 ms/step.
Infer [32/40]. 296.84 samples/sec. 862.420 ms/step.
Infer [40/40]. 296.79 samples/sec. 862.559 ms/step.
Inference benchmark of beit_base_patch16_384.in22k_ft_in22k_in1k done. 296.78 samples/sec, 862.56 ms/step
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running train benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.81 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.27 GiB is free. Including non-PyTorch memory, this process has 20.37 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 473.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running train benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.15 GiB is free. Including non-PyTorch memory, this process has 21.49 GiB memory in use. Of the allocated memory 20.68 GiB is allocated by PyTorch, and 330.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running train benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 22.01 GiB memory in use. Of the allocated memory 21.32 GiB is allocated by PyTorch, and 208.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running train benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 488.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 474.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 440.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running train benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 976.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 334.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running train benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 732.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 270.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 242.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model beit_base_patch16_384.in22k_ft_in22k_in1k created, param count: 86744104
Running train benchmark on beit_base_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 96.42 samples/sec. 331.875 ms/step.
Train [16/40]. 96.42 samples/sec. 331.874 ms/step.
Train [24/40]. 96.42 samples/sec. 331.871 ms/step.
Train [32/40]. 96.42 samples/sec. 331.889 ms/step.
Train [40/40]. 96.41 samples/sec. 331.907 ms/step.
Train benchmark of beit_base_patch16_384.in22k_ft_in22k_in1k done. 96.03 samples/sec, 331.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beit_large_patch16_224.in22k_ft_in22k created, param count: 325792593
Running inference benchmark on beit_large_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 379.06 samples/sec. 675.347 ms/step.
Infer [16/40]. 379.05 samples/sec. 675.372 ms/step.
Infer [24/40]. 379.05 samples/sec. 675.366 ms/step.
Infer [32/40]. 379.07 samples/sec. 675.346 ms/step.
Infer [40/40]. 379.07 samples/sec. 675.331 ms/step.
Inference benchmark of beit_large_patch16_224.in22k_ft_in22k done. 379.05 samples/sec, 675.33 ms/step
Model beit_large_patch16_224.in22k_ft_in22k created, param count: 325792593
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 96.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_large_patch16_224.in22k_ft_in22k created, param count: 325792593
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 117.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_large_patch16_224.in22k_ft_in22k created, param count: 325792593
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 393.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beit_large_patch16_224.in22k_ft_in22k created, param count: 325792593
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 133.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beit_large_patch16_224.in22k_ft_in22k created, param count: 325792593
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 179.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beit_large_patch16_224.in22k_ft_in22k created, param count: 325792593
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 121.21 samples/sec. 396.012 ms/step.
Train [16/40]. 121.21 samples/sec. 396.000 ms/step.
Train [24/40]. 121.21 samples/sec. 396.008 ms/step.
Train [32/40]. 121.20 samples/sec. 396.039 ms/step.
Train [40/40]. 121.19 samples/sec. 396.058 ms/step.
Train benchmark of beit_large_patch16_224.in22k_ft_in22k done. 120.57 samples/sec, 396.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beit_large_patch16_224.in22k_ft_in22k_in1k created, param count: 304430568
Running inference benchmark on beit_large_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 379.20 samples/sec. 675.102 ms/step.
Infer [16/40]. 379.19 samples/sec. 675.125 ms/step.
Infer [24/40]. 379.15 samples/sec. 675.193 ms/step.
Infer [32/40]. 379.12 samples/sec. 675.256 ms/step.
Infer [40/40]. 379.10 samples/sec. 675.292 ms/step.
Inference benchmark of beit_large_patch16_224.in22k_ft_in22k_in1k done. 379.07 samples/sec, 675.29 ms/step
Model beit_large_patch16_224.in22k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 112.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_large_patch16_224.in22k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 137.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_large_patch16_224.in22k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 442.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beit_large_patch16_224.in22k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 142.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beit_large_patch16_224.in22k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 140.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beit_large_patch16_224.in22k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beit_large_patch16_224.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 121.58 samples/sec. 394.806 ms/step.
Train [16/40]. 121.58 samples/sec. 394.807 ms/step.
Train [24/40]. 121.58 samples/sec. 394.815 ms/step.
Train [32/40]. 121.58 samples/sec. 394.814 ms/step.
Train [40/40]. 121.58 samples/sec. 394.817 ms/step.
Train benchmark of beit_large_patch16_224.in22k_ft_in22k_in1k done. 120.92 samples/sec, 394.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running inference benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 99.52 samples/sec. 2572.373 ms/step.
Infer [16/40]. 99.52 samples/sec. 2572.358 ms/step.
Infer [24/40]. 99.51 samples/sec. 2572.596 ms/step.
Infer [32/40]. 99.50 samples/sec. 2572.749 ms/step.
Infer [40/40]. 99.50 samples/sec. 2572.950 ms/step.
Inference benchmark of beit_large_patch16_384.in22k_ft_in22k_in1k done. 99.49 samples/sec, 2572.95 ms/step
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.08 GiB. GPU 0 has a total capacty of 23.65 GiB of which 608.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 610.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.81 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 20.94 GiB memory in use. Of the allocated memory 20.16 GiB is allocated by PyTorch, and 296.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 180.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 23.65 GiB of which 664.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.12 GiB is allocated by PyTorch, and 398.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 204.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 192.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 976.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 530.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 395.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 393.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 436.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 473.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model beit_large_patch16_384.in22k_ft_in22k_in1k created, param count: 304998888
Running train benchmark on beit_large_patch16_384.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 32.40 samples/sec. 370.374 ms/step.
Train [16/40]. 32.40 samples/sec. 370.383 ms/step.
Train [24/40]. 32.40 samples/sec. 370.384 ms/step.
Train [32/40]. 32.40 samples/sec. 370.375 ms/step.
Train [40/40]. 32.40 samples/sec. 370.380 ms/step.
Train benchmark of beit_large_patch16_384.in22k_ft_in22k_in1k done. 32.22 samples/sec, 370.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running inference benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.97 GiB is free. Including non-PyTorch memory, this process has 12.67 GiB memory in use. Of the allocated memory 11.17 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running inference benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.29 GiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 373.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running inference benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
Infer [8/40]. 41.44 samples/sec. 3088.830 ms/step.
Infer [16/40]. 41.43 samples/sec. 3089.582 ms/step.
Infer [24/40]. 41.43 samples/sec. 3089.546 ms/step.
Infer [32/40]. 41.42 samples/sec. 3089.995 ms/step.
Infer [40/40]. 41.42 samples/sec. 3090.241 ms/step.
Inference benchmark of beit_large_patch16_512.in22k_ft_in22k_in1k done. 41.42 samples/sec, 3090.24 ms/step
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.97 GiB is free. Including non-PyTorch memory, this process has 12.67 GiB memory in use. Of the allocated memory 11.17 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.79 GiB is free. Including non-PyTorch memory, this process has 20.85 GiB memory in use. Of the allocated memory 20.00 GiB is allocated by PyTorch, and 374.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 255.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.86 GiB is free. Including non-PyTorch memory, this process has 18.78 GiB memory in use. Of the allocated memory 17.84 GiB is allocated by PyTorch, and 464.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.11 GiB is free. Including non-PyTorch memory, this process has 21.53 GiB memory in use. Of the allocated memory 20.87 GiB is allocated by PyTorch, and 172.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 420.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 361.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.17 GiB is free. Including non-PyTorch memory, this process has 22.47 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 459.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.28 GiB is free. Including non-PyTorch memory, this process has 22.36 GiB memory in use. Of the allocated memory 21.48 GiB is allocated by PyTorch, and 400.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 660.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.11 GiB is allocated by PyTorch, and 407.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 686.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 434.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 317.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 272.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model beit_large_patch16_512.in22k_ft_in22k_in1k created, param count: 305674728
Running train benchmark on beit_large_patch16_512.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 512, 512) and batch size 4.
Train [8/40]. 12.88 samples/sec. 310.576 ms/step.
Train [16/40]. 12.88 samples/sec. 310.615 ms/step.
Train [24/40]. 12.88 samples/sec. 310.672 ms/step.
Train [32/40]. 12.87 samples/sec. 310.699 ms/step.
Train [40/40]. 12.87 samples/sec. 310.722 ms/step.
Train benchmark of beit_large_patch16_512.in22k_ft_in22k_in1k done. 12.79 samples/sec, 310.72 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beitv2_base_patch16_224.in1k_ft_in1k created, param count: 86530984
Running inference benchmark on beitv2_base_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1149.32 samples/sec. 222.741 ms/step.
Infer [16/40]. 1149.33 samples/sec. 222.738 ms/step.
Infer [24/40]. 1149.37 samples/sec. 222.730 ms/step.
Infer [32/40]. 1149.43 samples/sec. 222.720 ms/step.
Infer [40/40]. 1149.41 samples/sec. 222.723 ms/step.
Inference benchmark of beitv2_base_patch16_224.in1k_ft_in1k done. 1149.19 samples/sec, 222.72 ms/step
Model beitv2_base_patch16_224.in1k_ft_in1k created, param count: 86530984
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 118.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beitv2_base_patch16_224.in1k_ft_in1k created, param count: 86530984
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 269.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beitv2_base_patch16_224.in1k_ft_in1k created, param count: 86530984
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 377.06 samples/sec. 339.469 ms/step.
Train [16/40]. 377.06 samples/sec. 339.467 ms/step.
Train [24/40]. 377.05 samples/sec. 339.475 ms/step.
Train [32/40]. 377.04 samples/sec. 339.490 ms/step.
Train [40/40]. 377.01 samples/sec. 339.516 ms/step.
Train benchmark of beitv2_base_patch16_224.in1k_ft_in1k done. 375.51 samples/sec, 339.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beitv2_base_patch16_224.in1k_ft_in22k created, param count: 102557713
Running inference benchmark on beitv2_base_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1148.44 samples/sec. 222.912 ms/step.
Infer [16/40]. 1148.53 samples/sec. 222.894 ms/step.
Infer [24/40]. 1148.57 samples/sec. 222.886 ms/step.
Infer [32/40]. 1148.57 samples/sec. 222.886 ms/step.
Infer [40/40]. 1148.54 samples/sec. 222.892 ms/step.
Inference benchmark of beitv2_base_patch16_224.in1k_ft_in22k done. 1148.33 samples/sec, 222.89 ms/step
Model beitv2_base_patch16_224.in1k_ft_in22k created, param count: 102557713
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 121.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beitv2_base_patch16_224.in1k_ft_in22k created, param count: 102557713
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 306.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 494.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beitv2_base_patch16_224.in1k_ft_in22k created, param count: 102557713
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 375.79 samples/sec. 340.614 ms/step.
Train [16/40]. 375.79 samples/sec. 340.620 ms/step.
Train [24/40]. 375.79 samples/sec. 340.619 ms/step.
Train [32/40]. 375.79 samples/sec. 340.620 ms/step.
Train [40/40]. 375.75 samples/sec. 340.651 ms/step.
Train benchmark of beitv2_base_patch16_224.in1k_ft_in22k done. 374.23 samples/sec, 340.65 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beitv2_base_patch16_224.in1k_ft_in22k_in1k created, param count: 86530984
Running inference benchmark on beitv2_base_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1149.29 samples/sec. 222.747 ms/step.
Infer [16/40]. 1149.39 samples/sec. 222.728 ms/step.
Infer [24/40]. 1149.39 samples/sec. 222.728 ms/step.
Infer [32/40]. 1149.32 samples/sec. 222.740 ms/step.
Infer [40/40]. 1149.30 samples/sec. 222.744 ms/step.
Inference benchmark of beitv2_base_patch16_224.in1k_ft_in22k_in1k done. 1149.08 samples/sec, 222.74 ms/step
Model beitv2_base_patch16_224.in1k_ft_in22k_in1k created, param count: 86530984
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 118.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beitv2_base_patch16_224.in1k_ft_in22k_in1k created, param count: 86530984
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 269.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beitv2_base_patch16_224.in1k_ft_in22k_in1k created, param count: 86530984
Running train benchmark on beitv2_base_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 376.98 samples/sec. 339.539 ms/step.
Train [16/40]. 376.92 samples/sec. 339.591 ms/step.
Train [24/40]. 376.92 samples/sec. 339.595 ms/step.
Train [32/40]. 376.91 samples/sec. 339.606 ms/step.
Train [40/40]. 376.90 samples/sec. 339.609 ms/step.
Train benchmark of beitv2_base_patch16_224.in1k_ft_in22k_in1k done. 375.40 samples/sec, 339.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beitv2_large_patch16_224.in1k_ft_in1k created, param count: 304430568
Running inference benchmark on beitv2_large_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 379.01 samples/sec. 675.442 ms/step.
Infer [16/40]. 379.01 samples/sec. 675.442 ms/step.
Infer [24/40]. 379.01 samples/sec. 675.441 ms/step.
Infer [32/40]. 379.01 samples/sec. 675.446 ms/step.
Infer [40/40]. 379.01 samples/sec. 675.441 ms/step.
Inference benchmark of beitv2_large_patch16_224.in1k_ft_in1k done. 378.99 samples/sec, 675.44 ms/step
Model beitv2_large_patch16_224.in1k_ft_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 112.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beitv2_large_patch16_224.in1k_ft_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 137.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beitv2_large_patch16_224.in1k_ft_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 442.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beitv2_large_patch16_224.in1k_ft_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 142.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beitv2_large_patch16_224.in1k_ft_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 140.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beitv2_large_patch16_224.in1k_ft_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 121.58 samples/sec. 394.801 ms/step.
Train [16/40]. 121.58 samples/sec. 394.811 ms/step.
Train [24/40]. 121.58 samples/sec. 394.816 ms/step.
Train [32/40]. 121.58 samples/sec. 394.817 ms/step.
Train [40/40]. 121.58 samples/sec. 394.815 ms/step.
Train benchmark of beitv2_large_patch16_224.in1k_ft_in1k done. 120.94 samples/sec, 394.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beitv2_large_patch16_224.in1k_ft_in22k created, param count: 325792593
Running inference benchmark on beitv2_large_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 379.02 samples/sec. 675.425 ms/step.
Infer [16/40]. 379.01 samples/sec. 675.442 ms/step.
Infer [24/40]. 379.01 samples/sec. 675.444 ms/step.
Infer [32/40]. 379.01 samples/sec. 675.444 ms/step.
Infer [40/40]. 379.00 samples/sec. 675.457 ms/step.
Inference benchmark of beitv2_large_patch16_224.in1k_ft_in22k done. 378.98 samples/sec, 675.46 ms/step
Model beitv2_large_patch16_224.in1k_ft_in22k created, param count: 325792593
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 96.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k created, param count: 325792593
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 117.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k created, param count: 325792593
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 393.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k created, param count: 325792593
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 133.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k created, param count: 325792593
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 179.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k created, param count: 325792593
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 121.22 samples/sec. 395.982 ms/step.
Train [16/40]. 121.22 samples/sec. 395.973 ms/step.
Train [24/40]. 121.22 samples/sec. 395.975 ms/step.
Train [32/40]. 121.22 samples/sec. 395.978 ms/step.
Train [40/40]. 121.22 samples/sec. 395.981 ms/step.
Train benchmark of beitv2_large_patch16_224.in1k_ft_in22k done. 120.59 samples/sec, 395.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model beitv2_large_patch16_224.in1k_ft_in22k_in1k created, param count: 304430568
Running inference benchmark on beitv2_large_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 379.03 samples/sec. 675.408 ms/step.
Infer [16/40]. 379.02 samples/sec. 675.426 ms/step.
Infer [24/40]. 379.01 samples/sec. 675.436 ms/step.
Infer [32/40]. 379.02 samples/sec. 675.432 ms/step.
Infer [40/40]. 378.97 samples/sec. 675.510 ms/step.
Inference benchmark of beitv2_large_patch16_224.in1k_ft_in22k_in1k done. 378.94 samples/sec, 675.51 ms/step
Model beitv2_large_patch16_224.in1k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 112.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 137.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 442.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 142.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 140.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model beitv2_large_patch16_224.in1k_ft_in22k_in1k created, param count: 304430568
Running train benchmark on beitv2_large_patch16_224.in1k_ft_in22k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 121.58 samples/sec. 394.794 ms/step.
Train [16/40]. 121.58 samples/sec. 394.795 ms/step.
Train [24/40]. 121.58 samples/sec. 394.792 ms/step.
Train [32/40]. 121.58 samples/sec. 394.797 ms/step.
Train [40/40]. 121.58 samples/sec. 394.802 ms/step.
Train benchmark of beitv2_large_patch16_224.in1k_ft_in22k_in1k done. 120.94 samples/sec, 394.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model botnet26t_256.c1_in1k created, param count: 12488672
Running inference benchmark on botnet26t_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2393.58 samples/sec. 106.953 ms/step.
Infer [16/40]. 2393.47 samples/sec. 106.958 ms/step.
Infer [24/40]. 2393.40 samples/sec. 106.961 ms/step.
Infer [32/40]. 2393.42 samples/sec. 106.960 ms/step.
Infer [40/40]. 2393.46 samples/sec. 106.958 ms/step.
Inference benchmark of botnet26t_256.c1_in1k done. 2392.80 samples/sec, 106.96 ms/step
Model botnet26t_256.c1_in1k created, param count: 12488672
Running train benchmark on botnet26t_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Train [8/40]. 737.04 samples/sec. 347.335 ms/step.
Train [16/40]. 737.12 samples/sec. 347.299 ms/step.
Train [24/40]. 737.16 samples/sec. 347.281 ms/step.
Train [32/40]. 737.13 samples/sec. 347.294 ms/step.
Train [40/40]. 737.13 samples/sec. 347.293 ms/step.
Train benchmark of botnet26t_256.c1_in1k done. 735.35 samples/sec, 347.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_b36.sail_in1k created, param count: 98753614
Running inference benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 445.20 samples/sec. 575.019 ms/step.
Infer [16/40]. 445.20 samples/sec. 575.025 ms/step.
Infer [24/40]. 445.20 samples/sec. 575.024 ms/step.
Infer [32/40]. 445.20 samples/sec. 575.026 ms/step.
Infer [40/40]. 445.20 samples/sec. 575.027 ms/step.
Inference benchmark of caformer_b36.sail_in1k done. 445.16 samples/sec, 575.03 ms/step
Model caformer_b36.sail_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 656.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 127.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_b36.sail_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 388.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 139.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_b36.sail_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 239.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_b36.sail_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 541.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_b36.sail_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 158.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_b36.sail_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 54.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_b36.sail_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 100.90 samples/sec. 317.137 ms/step.
Train [16/40]. 100.87 samples/sec. 317.233 ms/step.
Train [24/40]. 100.81 samples/sec. 317.415 ms/step.
Train [32/40]. 100.78 samples/sec. 317.508 ms/step.
Train [40/40]. 100.77 samples/sec. 317.561 ms/step.
Train benchmark of caformer_b36.sail_in1k done. 100.16 samples/sec, 317.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running inference benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 142.69 samples/sec. 1794.127 ms/step.
Infer [16/40]. 142.69 samples/sec. 1794.123 ms/step.
Infer [24/40]. 142.69 samples/sec. 1794.107 ms/step.
Infer [32/40]. 142.68 samples/sec. 1794.195 ms/step.
Infer [40/40]. 142.68 samples/sec. 1794.260 ms/step.
Inference benchmark of caformer_b36.sail_in1k_384 done. 142.67 samples/sec, 1794.26 ms/step
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.14 GiB is free. Including non-PyTorch memory, this process has 20.50 GiB memory in use. Of the allocated memory 19.99 GiB is allocated by PyTorch, and 21.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 222.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.60 GiB is free. Including non-PyTorch memory, this process has 22.04 GiB memory in use. Of the allocated memory 21.45 GiB is allocated by PyTorch, and 96.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.61 GiB is free. Including non-PyTorch memory, this process has 22.03 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 294.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 816.06 MiB is free. Including non-PyTorch memory, this process has 22.84 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 180.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 276.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 255.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 339.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 202.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model caformer_b36.sail_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 32.00 samples/sec. 374.949 ms/step.
Train [16/40]. 32.00 samples/sec. 374.949 ms/step.
Train [24/40]. 32.00 samples/sec. 374.952 ms/step.
Train [32/40]. 32.00 samples/sec. 374.954 ms/step.
Train [40/40]. 32.00 samples/sec. 374.957 ms/step.
Train benchmark of caformer_b36.sail_in1k_384 done. 31.83 samples/sec, 374.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_b36.sail_in22k created, param count: 162798007
Running inference benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 444.70 samples/sec. 575.671 ms/step.
Infer [16/40]. 444.71 samples/sec. 575.662 ms/step.
Infer [24/40]. 444.66 samples/sec. 575.719 ms/step.
Infer [32/40]. 444.63 samples/sec. 575.755 ms/step.
Infer [40/40]. 444.62 samples/sec. 575.771 ms/step.
Inference benchmark of caformer_b36.sail_in22k done. 444.58 samples/sec, 575.77 ms/step
Model caformer_b36.sail_in22k created, param count: 162798007
Running train benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 408.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 129.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_b36.sail_in22k created, param count: 162798007
Running train benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 254.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 27.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_b36.sail_in22k created, param count: 162798007
Running train benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 251.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_b36.sail_in22k created, param count: 162798007
Running train benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 340.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_b36.sail_in22k created, param count: 162798007
Running train benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 289.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_b36.sail_in22k created, param count: 162798007
Running train benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 125.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_b36.sail_in22k created, param count: 162798007
Running train benchmark on caformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 99.43 samples/sec. 321.836 ms/step.
Train [16/40]. 99.42 samples/sec. 321.874 ms/step.
Train [24/40]. 99.41 samples/sec. 321.890 ms/step.
Train [32/40]. 99.41 samples/sec. 321.899 ms/step.
Train [40/40]. 99.41 samples/sec. 321.906 ms/step.
Train benchmark of caformer_b36.sail_in22k done. 98.80 samples/sec, 321.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running inference benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 445.00 samples/sec. 575.283 ms/step.
Infer [16/40]. 444.99 samples/sec. 575.294 ms/step.
Infer [24/40]. 444.98 samples/sec. 575.309 ms/step.
Infer [32/40]. 444.97 samples/sec. 575.316 ms/step.
Infer [40/40]. 444.97 samples/sec. 575.321 ms/step.
Inference benchmark of caformer_b36.sail_in22k_ft_in1k done. 444.93 samples/sec, 575.32 ms/step
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 654.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 127.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 37.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 191.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 359.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 132.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 127.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_b36.sail_in22k_ft_in1k created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 100.71 samples/sec. 317.754 ms/step.
Train [16/40]. 100.71 samples/sec. 317.759 ms/step.
Train [24/40]. 100.70 samples/sec. 317.774 ms/step.
Train [32/40]. 100.70 samples/sec. 317.772 ms/step.
Train [40/40]. 100.70 samples/sec. 317.769 ms/step.
Train benchmark of caformer_b36.sail_in22k_ft_in1k done. 100.08 samples/sec, 317.77 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running inference benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 142.73 samples/sec. 1793.644 ms/step.
Infer [16/40]. 142.71 samples/sec. 1793.828 ms/step.
Infer [24/40]. 142.71 samples/sec. 1793.887 ms/step.
Infer [32/40]. 142.70 samples/sec. 1793.923 ms/step.
Infer [40/40]. 142.70 samples/sec. 1793.934 ms/step.
Inference benchmark of caformer_b36.sail_in22k_ft_in1k_384 done. 142.70 samples/sec, 1793.93 ms/step
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.14 GiB is free. Including non-PyTorch memory, this process has 20.50 GiB memory in use. Of the allocated memory 19.99 GiB is allocated by PyTorch, and 21.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 268.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.56 GiB is free. Including non-PyTorch memory, this process has 22.08 GiB memory in use. Of the allocated memory 21.45 GiB is allocated by PyTorch, and 141.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.60 GiB is free. Including non-PyTorch memory, this process has 22.04 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 306.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 790.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 205.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 366.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 206.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 127.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 319.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 244.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model caformer_b36.sail_in22k_ft_in1k_384 created, param count: 98753614
Running train benchmark on caformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 31.98 samples/sec. 375.187 ms/step.
Train [16/40]. 31.98 samples/sec. 375.229 ms/step.
Train [24/40]. 31.98 samples/sec. 375.226 ms/step.
Train [32/40]. 31.98 samples/sec. 375.231 ms/step.
Train [40/40]. 31.98 samples/sec. 375.231 ms/step.
Train benchmark of caformer_b36.sail_in22k_ft_in1k_384 done. 31.80 samples/sec, 375.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_m36.sail_in1k created, param count: 56204878
Running inference benchmark on caformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 616.58 samples/sec. 415.192 ms/step.
Infer [16/40]. 616.57 samples/sec. 415.201 ms/step.
Infer [24/40]. 616.57 samples/sec. 415.201 ms/step.
Infer [32/40]. 616.56 samples/sec. 415.205 ms/step.
Infer [40/40]. 616.56 samples/sec. 415.205 ms/step.
Inference benchmark of caformer_m36.sail_in1k done. 616.49 samples/sec, 415.20 ms/step
Model caformer_m36.sail_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 636.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 10.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_m36.sail_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 126.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 245.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_m36.sail_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 156.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 105.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_m36.sail_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 486.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_m36.sail_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 312.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_m36.sail_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 140.88 samples/sec. 340.713 ms/step.
Train [16/40]. 140.88 samples/sec. 340.718 ms/step.
Train [24/40]. 140.87 samples/sec. 340.733 ms/step.
Train [32/40]. 140.87 samples/sec. 340.739 ms/step.
Train [40/40]. 140.88 samples/sec. 340.724 ms/step.
Train benchmark of caformer_m36.sail_in1k done. 140.21 samples/sec, 340.72 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running inference benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 195.42 samples/sec. 1310.024 ms/step.
Infer [16/40]. 195.41 samples/sec. 1310.053 ms/step.
Infer [24/40]. 195.38 samples/sec. 1310.277 ms/step.
Infer [32/40]. 195.36 samples/sec. 1310.424 ms/step.
Infer [40/40]. 195.34 samples/sec. 1310.511 ms/step.
Inference benchmark of caformer_m36.sail_in1k_384 done. 195.34 samples/sec, 1310.51 ms/step
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.34 GiB is free. Including non-PyTorch memory, this process has 22.30 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 19.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 267.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 300.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 540.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 364.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 196.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 442.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 341.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 164.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 232.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model caformer_m36.sail_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 44.27 samples/sec. 361.406 ms/step.
Train [16/40]. 44.28 samples/sec. 361.372 ms/step.
Train [24/40]. 44.28 samples/sec. 361.374 ms/step.
Train [32/40]. 44.28 samples/sec. 361.371 ms/step.
Train [40/40]. 44.28 samples/sec. 361.373 ms/step.
Train benchmark of caformer_m36.sail_in1k_384 done. 44.08 samples/sec, 361.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_m36.sail_in22k created, param count: 104243383
Running inference benchmark on caformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 616.15 samples/sec. 415.483 ms/step.
Infer [16/40]. 616.15 samples/sec. 415.481 ms/step.
Infer [24/40]. 616.15 samples/sec. 415.482 ms/step.
Infer [32/40]. 616.15 samples/sec. 415.486 ms/step.
Infer [40/40]. 616.14 samples/sec. 415.493 ms/step.
Inference benchmark of caformer_m36.sail_in22k done. 616.06 samples/sec, 415.49 ms/step
Model caformer_m36.sail_in22k created, param count: 104243383
Running train benchmark on caformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 442.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 18.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_m36.sail_in22k created, param count: 104243383
Running train benchmark on caformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 302.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_m36.sail_in22k created, param count: 104243383
Running train benchmark on caformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 228.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 150.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_m36.sail_in22k created, param count: 104243383
Running train benchmark on caformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 562.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_m36.sail_in22k created, param count: 104243383
Running train benchmark on caformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 312.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_m36.sail_in22k created, param count: 104243383
Running train benchmark on caformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 139.63 samples/sec. 343.763 ms/step.
Train [16/40]. 139.62 samples/sec. 343.779 ms/step.
Train [24/40]. 139.63 samples/sec. 343.765 ms/step.
Train [32/40]. 139.63 samples/sec. 343.774 ms/step.
Train [40/40]. 139.62 samples/sec. 343.794 ms/step.
Train benchmark of caformer_m36.sail_in22k done. 138.95 samples/sec, 343.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_m36.sail_in22k_ft_in1k created, param count: 56204878
Running inference benchmark on caformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 616.64 samples/sec. 415.151 ms/step.
Infer [16/40]. 616.66 samples/sec. 415.141 ms/step.
Infer [24/40]. 616.65 samples/sec. 415.144 ms/step.
Infer [32/40]. 616.65 samples/sec. 415.146 ms/step.
Infer [40/40]. 616.65 samples/sec. 415.145 ms/step.
Inference benchmark of caformer_m36.sail_in22k_ft_in1k done. 616.59 samples/sec, 415.14 ms/step
Model caformer_m36.sail_in22k_ft_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 634.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 10.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_m36.sail_in22k_ft_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 218.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_m36.sail_in22k_ft_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 135.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_m36.sail_in22k_ft_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 474.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_m36.sail_in22k_ft_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 356.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_m36.sail_in22k_ft_in1k created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 140.81 samples/sec. 340.884 ms/step.
Train [16/40]. 140.83 samples/sec. 340.843 ms/step.
Train [24/40]. 140.81 samples/sec. 340.873 ms/step.
Train [32/40]. 140.81 samples/sec. 340.895 ms/step.
Train [40/40]. 140.81 samples/sec. 340.884 ms/step.
Train benchmark of caformer_m36.sail_in22k_ft_in1k done. 140.11 samples/sec, 340.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running inference benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 195.40 samples/sec. 1310.107 ms/step.
Infer [16/40]. 195.40 samples/sec. 1310.123 ms/step.
Infer [24/40]. 195.40 samples/sec. 1310.127 ms/step.
Infer [32/40]. 195.40 samples/sec. 1310.130 ms/step.
Infer [40/40]. 195.40 samples/sec. 1310.137 ms/step.
Inference benchmark of caformer_m36.sail_in22k_ft_in1k_384 done. 195.39 samples/sec, 1310.14 ms/step
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.34 GiB is free. Including non-PyTorch memory, this process has 22.30 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 19.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 126.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 287.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 300.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 540.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 364.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 422.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 294.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 164.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 251.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model caformer_m36.sail_in22k_ft_in1k_384 created, param count: 56204878
Running train benchmark on caformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 44.24 samples/sec. 361.653 ms/step.
Train [16/40]. 44.24 samples/sec. 361.678 ms/step.
Train [24/40]. 44.23 samples/sec. 361.705 ms/step.
Train [32/40]. 44.24 samples/sec. 361.693 ms/step.
Train [40/40]. 44.24 samples/sec. 361.689 ms/step.
Train benchmark of caformer_m36.sail_in22k_ft_in1k_384 done. 44.04 samples/sec, 361.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s18.sail_in1k created, param count: 26341656
Running inference benchmark on caformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1612.46 samples/sec. 158.763 ms/step.
Infer [16/40]. 1612.45 samples/sec. 158.765 ms/step.
Infer [24/40]. 1612.47 samples/sec. 158.763 ms/step.
Infer [32/40]. 1612.50 samples/sec. 158.760 ms/step.
Infer [40/40]. 1612.50 samples/sec. 158.760 ms/step.
Inference benchmark of caformer_s18.sail_in1k done. 1612.15 samples/sec, 158.76 ms/step
Model caformer_s18.sail_in1k created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 343.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s18.sail_in1k created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 60.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s18.sail_in1k created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 405.12 samples/sec. 315.958 ms/step.
Train [16/40]. 404.96 samples/sec. 316.080 ms/step.
Train [24/40]. 404.86 samples/sec. 316.162 ms/step.
Train [32/40]. 404.77 samples/sec. 316.233 ms/step.
Train [40/40]. 404.73 samples/sec. 316.264 ms/step.
Train benchmark of caformer_s18.sail_in1k done. 403.37 samples/sec, 316.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s18.sail_in1k_384 created, param count: 26341656
Running inference benchmark on caformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 509.27 samples/sec. 502.677 ms/step.
Infer [16/40]. 509.27 samples/sec. 502.683 ms/step.
Infer [24/40]. 509.26 samples/sec. 502.687 ms/step.
Infer [32/40]. 509.26 samples/sec. 502.687 ms/step.
Infer [40/40]. 509.26 samples/sec. 502.690 ms/step.
Inference benchmark of caformer_s18.sail_in1k_384 done. 509.21 samples/sec, 502.69 ms/step
Model caformer_s18.sail_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 22.01 GiB memory in use. Of the allocated memory 21.44 GiB is allocated by PyTorch, and 80.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s18.sail_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 145.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s18.sail_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 908.06 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 223.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_s18.sail_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 213.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_s18.sail_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 62.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_s18.sail_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 125.67 samples/sec. 381.949 ms/step.
Train [16/40]. 125.61 samples/sec. 382.125 ms/step.
Train [24/40]. 125.59 samples/sec. 382.191 ms/step.
Train [32/40]. 125.57 samples/sec. 382.255 ms/step.
Train [40/40]. 125.56 samples/sec. 382.278 ms/step.
Train benchmark of caformer_s18.sail_in1k_384 done. 125.23 samples/sec, 382.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s18.sail_in22k created, param count: 69044865
Running inference benchmark on caformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1609.09 samples/sec. 159.096 ms/step.
Infer [16/40]. 1609.12 samples/sec. 159.093 ms/step.
Infer [24/40]. 1609.08 samples/sec. 159.097 ms/step.
Infer [32/40]. 1609.10 samples/sec. 159.095 ms/step.
Infer [40/40]. 1609.12 samples/sec. 159.093 ms/step.
Inference benchmark of caformer_s18.sail_in22k done. 1608.79 samples/sec, 159.09 ms/step
Model caformer_s18.sail_in22k created, param count: 69044865
Running train benchmark on caformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 353.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s18.sail_in22k created, param count: 69044865
Running train benchmark on caformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 184.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s18.sail_in22k created, param count: 69044865
Running train benchmark on caformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 400.84 samples/sec. 319.333 ms/step.
Train [16/40]. 400.81 samples/sec. 319.356 ms/step.
Train [24/40]. 400.81 samples/sec. 319.353 ms/step.
Train [32/40]. 400.80 samples/sec. 319.364 ms/step.
Train [40/40]. 400.79 samples/sec. 319.369 ms/step.
Train benchmark of caformer_s18.sail_in22k done. 399.43 samples/sec, 319.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s18.sail_in22k_ft_in1k created, param count: 26341656
Running inference benchmark on caformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1612.60 samples/sec. 158.750 ms/step.
Infer [16/40]. 1612.58 samples/sec. 158.752 ms/step.
Infer [24/40]. 1612.60 samples/sec. 158.750 ms/step.
Infer [32/40]. 1612.58 samples/sec. 158.751 ms/step.
Infer [40/40]. 1612.60 samples/sec. 158.750 ms/step.
Inference benchmark of caformer_s18.sail_in22k_ft_in1k done. 1612.28 samples/sec, 158.75 ms/step
Model caformer_s18.sail_in22k_ft_in1k created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 343.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s18.sail_in22k_ft_in1k created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 170.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s18.sail_in22k_ft_in1k created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 404.56 samples/sec. 316.395 ms/step.
Train [16/40]. 404.56 samples/sec. 316.396 ms/step.
Train [24/40]. 404.56 samples/sec. 316.392 ms/step.
Train [32/40]. 404.55 samples/sec. 316.398 ms/step.
Train [40/40]. 404.56 samples/sec. 316.395 ms/step.
Train benchmark of caformer_s18.sail_in22k_ft_in1k done. 403.19 samples/sec, 316.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s18.sail_in22k_ft_in1k_384 created, param count: 26341656
Running inference benchmark on caformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 509.24 samples/sec. 502.710 ms/step.
Infer [16/40]. 509.24 samples/sec. 502.708 ms/step.
Infer [24/40]. 509.24 samples/sec. 502.709 ms/step.
Infer [32/40]. 509.24 samples/sec. 502.708 ms/step.
Infer [40/40]. 509.24 samples/sec. 502.709 ms/step.
Inference benchmark of caformer_s18.sail_in22k_ft_in1k_384 done. 509.20 samples/sec, 502.71 ms/step
Model caformer_s18.sail_in22k_ft_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 22.01 GiB memory in use. Of the allocated memory 21.44 GiB is allocated by PyTorch, and 80.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s18.sail_in22k_ft_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 145.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s18.sail_in22k_ft_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 868.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 263.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_s18.sail_in22k_ft_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 193.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_s18.sail_in22k_ft_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 204.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_s18.sail_in22k_ft_in1k_384 created, param count: 26341656
Running train benchmark on caformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 125.57 samples/sec. 382.265 ms/step.
Train [16/40]. 125.58 samples/sec. 382.241 ms/step.
Train [24/40]. 125.58 samples/sec. 382.233 ms/step.
Train [32/40]. 125.58 samples/sec. 382.240 ms/step.
Train [40/40]. 125.58 samples/sec. 382.240 ms/step.
Train benchmark of caformer_s18.sail_in22k_ft_in1k_384 done. 125.23 samples/sec, 382.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s36.sail_in1k created, param count: 39297102
Running inference benchmark on caformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 849.57 samples/sec. 301.328 ms/step.
Infer [16/40]. 849.57 samples/sec. 301.328 ms/step.
Infer [24/40]. 849.57 samples/sec. 301.327 ms/step.
Infer [32/40]. 849.58 samples/sec. 301.327 ms/step.
Infer [40/40]. 849.57 samples/sec. 301.330 ms/step.
Inference benchmark of caformer_s36.sail_in1k done. 849.45 samples/sec, 301.33 ms/step
Model caformer_s36.sail_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 293.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s36.sail_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 342.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s36.sail_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 456.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_s36.sail_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 202.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_s36.sail_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 203.57 samples/sec. 314.395 ms/step.
Train [16/40]. 203.56 samples/sec. 314.397 ms/step.
Train [24/40]. 203.57 samples/sec. 314.389 ms/step.
Train [32/40]. 203.57 samples/sec. 314.381 ms/step.
Train [40/40]. 203.58 samples/sec. 314.376 ms/step.
Train benchmark of caformer_s36.sail_in1k done. 202.52 samples/sec, 314.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running inference benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 268.17 samples/sec. 954.619 ms/step.
Infer [16/40]. 268.17 samples/sec. 954.618 ms/step.
Infer [24/40]. 268.17 samples/sec. 954.622 ms/step.
Infer [32/40]. 268.15 samples/sec. 954.684 ms/step.
Infer [40/40]. 268.14 samples/sec. 954.723 ms/step.
Inference benchmark of caformer_s36.sail_in1k_384 done. 268.13 samples/sec, 954.72 ms/step
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 22.06 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 81.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 188.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 838.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 244.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 172.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 299.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 284.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 381.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model caformer_s36.sail_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 62.99 samples/sec. 381.010 ms/step.
Train [16/40]. 62.99 samples/sec. 381.037 ms/step.
Train [24/40]. 62.99 samples/sec. 381.012 ms/step.
Train [32/40]. 62.99 samples/sec. 381.018 ms/step.
Train [40/40]. 62.99 samples/sec. 381.019 ms/step.
Train benchmark of caformer_s36.sail_in1k_384 done. 62.72 samples/sec, 381.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s36.sail_in22k created, param count: 82000311
Running inference benchmark on caformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 848.59 samples/sec. 301.679 ms/step.
Infer [16/40]. 848.61 samples/sec. 301.671 ms/step.
Infer [24/40]. 848.60 samples/sec. 301.673 ms/step.
Infer [32/40]. 848.62 samples/sec. 301.668 ms/step.
Infer [40/40]. 848.63 samples/sec. 301.662 ms/step.
Inference benchmark of caformer_s36.sail_in22k done. 848.51 samples/sec, 301.66 ms/step
Model caformer_s36.sail_in22k created, param count: 82000311
Running train benchmark on caformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 126.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 106.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s36.sail_in22k created, param count: 82000311
Running train benchmark on caformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 484.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s36.sail_in22k created, param count: 82000311
Running train benchmark on caformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 466.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_s36.sail_in22k created, param count: 82000311
Running train benchmark on caformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 107.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_s36.sail_in22k created, param count: 82000311
Running train benchmark on caformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 202.00 samples/sec. 316.826 ms/step.
Train [16/40]. 202.01 samples/sec. 316.820 ms/step.
Train [24/40]. 202.02 samples/sec. 316.799 ms/step.
Train [32/40]. 202.01 samples/sec. 316.809 ms/step.
Train [40/40]. 202.01 samples/sec. 316.820 ms/step.
Train benchmark of caformer_s36.sail_in22k done. 200.94 samples/sec, 316.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s36.sail_in22k_ft_in1k created, param count: 39297102
Running inference benchmark on caformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 849.41 samples/sec. 301.385 ms/step.
Infer [16/40]. 849.43 samples/sec. 301.379 ms/step.
Infer [24/40]. 849.43 samples/sec. 301.379 ms/step.
Infer [32/40]. 849.44 samples/sec. 301.376 ms/step.
Infer [40/40]. 849.43 samples/sec. 301.377 ms/step.
Inference benchmark of caformer_s36.sail_in22k_ft_in1k done. 849.31 samples/sec, 301.38 ms/step
Model caformer_s36.sail_in22k_ft_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 293.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s36.sail_in22k_ft_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 342.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s36.sail_in22k_ft_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 456.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_s36.sail_in22k_ft_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 191.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_s36.sail_in22k_ft_in1k created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 203.53 samples/sec. 314.457 ms/step.
Train [16/40]. 203.53 samples/sec. 314.448 ms/step.
Train [24/40]. 203.53 samples/sec. 314.444 ms/step.
Train [32/40]. 203.52 samples/sec. 314.472 ms/step.
Train [40/40]. 203.52 samples/sec. 314.458 ms/step.
Train benchmark of caformer_s36.sail_in22k_ft_in1k done. 202.44 samples/sec, 314.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running inference benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 268.18 samples/sec. 954.592 ms/step.
Infer [16/40]. 268.15 samples/sec. 954.690 ms/step.
Infer [24/40]. 268.14 samples/sec. 954.742 ms/step.
Infer [32/40]. 268.13 samples/sec. 954.768 ms/step.
Infer [40/40]. 268.12 samples/sec. 954.785 ms/step.
Inference benchmark of caformer_s36.sail_in22k_ft_in1k_384 done. 268.11 samples/sec, 954.78 ms/step
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 22.06 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 81.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 188.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 838.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 244.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 172.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 299.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 284.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 357.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model caformer_s36.sail_in22k_ft_in1k_384 created, param count: 39297102
Running train benchmark on caformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 63.02 samples/sec. 380.813 ms/step.
Train [16/40]. 63.02 samples/sec. 380.826 ms/step.
Train [24/40]. 63.02 samples/sec. 380.840 ms/step.
Train [32/40]. 63.02 samples/sec. 380.839 ms/step.
Train [40/40]. 63.02 samples/sec. 380.839 ms/step.
Train benchmark of caformer_s36.sail_in22k_ft_in1k_384 done. 62.75 samples/sec, 380.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running inference benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 41.67 samples/sec. 6143.303 ms/step.
Infer [16/40]. 41.67 samples/sec. 6143.172 ms/step.
Infer [24/40]. 41.67 samples/sec. 6143.263 ms/step.
Infer [32/40]. 41.67 samples/sec. 6143.116 ms/step.
Infer [40/40]. 41.67 samples/sec. 6143.162 ms/step.
Inference benchmark of cait_m36_384.fb_dist_in1k done. 41.67 samples/sec, 6143.16 ms/step
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.04 GiB is free. Including non-PyTorch memory, this process has 20.60 GiB memory in use. Of the allocated memory 20.01 GiB is allocated by PyTorch, and 98.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.71 GiB is free. Including non-PyTorch memory, this process has 19.93 GiB memory in use. Of the allocated memory 19.06 GiB is allocated by PyTorch, and 387.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 22.63 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 233.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 468.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 212.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 285.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 546.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 232.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 364.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 251.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 380.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 263.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 448.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model cait_m36_384.fb_dist_in1k created, param count: 271221352
Running train benchmark on cait_m36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 4.
Train [8/40]. 15.40 samples/sec. 259.732 ms/step.
Train [16/40]. 15.40 samples/sec. 259.743 ms/step.
Train [24/40]. 15.40 samples/sec. 259.738 ms/step.
Train [32/40]. 15.40 samples/sec. 259.734 ms/step.
Train [40/40]. 15.40 samples/sec. 259.734 ms/step.
Train benchmark of cait_m36_384.fb_dist_in1k done. 15.23 samples/sec, 259.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running inference benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.25 GiB is free. Including non-PyTorch memory, this process has 15.39 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 154.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running inference benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 7.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.28 GiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.43 GiB is allocated by PyTorch, and 442.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running inference benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
Infer [8/40]. 18.07 samples/sec. 7084.117 ms/step.
Infer [16/40]. 18.07 samples/sec. 7084.232 ms/step.
Infer [24/40]. 18.07 samples/sec. 7084.238 ms/step.
Infer [32/40]. 18.07 samples/sec. 7084.254 ms/step.
Infer [40/40]. 18.07 samples/sec. 7084.283 ms/step.
Inference benchmark of cait_m48_448.fb_dist_in1k done. 18.07 samples/sec, 7084.28 ms/step
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.11 GiB is free. Including non-PyTorch memory, this process has 16.54 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 153.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 7.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.42 GiB is free. Including non-PyTorch memory, this process has 20.22 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 441.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 309.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 3.52 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 21.23 GiB is allocated by PyTorch, and 849.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, and 443.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 684.06 MiB is free. Including non-PyTorch memory, this process has 22.97 GiB memory in use. Of the allocated memory 22.02 GiB is allocated by PyTorch, and 473.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 502.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 379.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 902.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 300.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 443.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 602.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 388.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 425.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 264.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 456.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 295.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 568.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 725.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model cait_m48_448.fb_dist_in1k created, param count: 356460520
Running train benchmark on cait_m48_448.fb_dist_in1k for 40 steps w/ input size (3, 448, 448) and batch size 2.
Train [8/40]. 6.59 samples/sec. 303.540 ms/step.
Train [16/40]. 6.59 samples/sec. 303.558 ms/step.
Train [24/40]. 6.59 samples/sec. 303.554 ms/step.
Train [32/40]. 6.59 samples/sec. 303.558 ms/step.
Train [40/40]. 6.59 samples/sec. 303.669 ms/step.
Train benchmark of cait_m48_448.fb_dist_in1k done. 6.50 samples/sec, 303.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_s24_224.fb_dist_in1k created, param count: 46916200
Running inference benchmark on cait_s24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 824.60 samples/sec. 310.452 ms/step.
Infer [16/40]. 824.45 samples/sec. 310.510 ms/step.
Infer [24/40]. 824.41 samples/sec. 310.526 ms/step.
Infer [32/40]. 824.38 samples/sec. 310.535 ms/step.
Infer [40/40]. 824.37 samples/sec. 310.540 ms/step.
Inference benchmark of cait_s24_224.fb_dist_in1k done. 824.26 samples/sec, 310.54 ms/step
Model cait_s24_224.fb_dist_in1k created, param count: 46916200
Running train benchmark on cait_s24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 239.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_s24_224.fb_dist_in1k created, param count: 46916200
Running train benchmark on cait_s24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 188.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_s24_224.fb_dist_in1k created, param count: 46916200
Running train benchmark on cait_s24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 464.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_s24_224.fb_dist_in1k created, param count: 46916200
Running train benchmark on cait_s24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 398.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_s24_224.fb_dist_in1k created, param count: 46916200
Running train benchmark on cait_s24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 286.60 samples/sec. 223.311 ms/step.
Train [16/40]. 286.59 samples/sec. 223.313 ms/step.
Train [24/40]. 286.60 samples/sec. 223.306 ms/step.
Train [32/40]. 286.60 samples/sec. 223.304 ms/step.
Train [40/40]. 286.60 samples/sec. 223.307 ms/step.
Train benchmark of cait_s24_224.fb_dist_in1k done. 283.78 samples/sec, 223.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running inference benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 135.12 samples/sec. 1894.573 ms/step.
Infer [16/40]. 135.10 samples/sec. 1894.857 ms/step.
Infer [24/40]. 135.09 samples/sec. 1894.981 ms/step.
Infer [32/40]. 135.09 samples/sec. 1895.030 ms/step.
Infer [40/40]. 135.09 samples/sec. 1895.045 ms/step.
Inference benchmark of cait_s24_384.fb_dist_in1k done. 135.09 samples/sec, 1895.05 ms/step
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.85 GiB is free. Including non-PyTorch memory, this process has 21.79 GiB memory in use. Of the allocated memory 21.29 GiB is allocated by PyTorch, and 14.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 285.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1006.06 MiB is free. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 33.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 143.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 88.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 162.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 150.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 161.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model cait_s24_384.fb_dist_in1k created, param count: 47062120
Running train benchmark on cait_s24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 47.73 samples/sec. 335.247 ms/step.
Train [16/40]. 47.73 samples/sec. 335.240 ms/step.
Train [24/40]. 47.73 samples/sec. 335.231 ms/step.
Train [32/40]. 47.73 samples/sec. 335.233 ms/step.
Train [40/40]. 47.73 samples/sec. 335.230 ms/step.
Train benchmark of cait_s24_384.fb_dist_in1k done. 47.38 samples/sec, 335.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running inference benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 90.27 samples/sec. 2836.075 ms/step.
Infer [16/40]. 90.26 samples/sec. 2836.280 ms/step.
Infer [24/40]. 90.24 samples/sec. 2836.731 ms/step.
Infer [32/40]. 90.24 samples/sec. 2836.946 ms/step.
Infer [40/40]. 90.23 samples/sec. 2837.079 ms/step.
Inference benchmark of cait_s36_384.fb_dist_in1k done. 90.23 samples/sec, 2837.08 ms/step
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.76 GiB is free. Including non-PyTorch memory, this process has 21.88 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 20.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 126.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 291.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 888.06 MiB is free. Including non-PyTorch memory, this process has 22.77 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 70.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 150.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 89.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 132.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 90.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 219.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 126.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 276.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model cait_s36_384.fb_dist_in1k created, param count: 68366632
Running train benchmark on cait_s36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 32.94 samples/sec. 242.849 ms/step.
Train [16/40]. 32.94 samples/sec. 242.845 ms/step.
Train [24/40]. 32.94 samples/sec. 242.837 ms/step.
Train [32/40]. 32.95 samples/sec. 242.819 ms/step.
Train [40/40]. 32.95 samples/sec. 242.817 ms/step.
Train benchmark of cait_s36_384.fb_dist_in1k done. 32.55 samples/sec, 242.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running inference benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 186.06 samples/sec. 1375.906 ms/step.
Infer [16/40]. 186.06 samples/sec. 1375.910 ms/step.
Infer [24/40]. 186.04 samples/sec. 1376.055 ms/step.
Infer [32/40]. 186.03 samples/sec. 1376.142 ms/step.
Infer [40/40]. 186.02 samples/sec. 1376.197 ms/step.
Inference benchmark of cait_xs24_384.fb_dist_in1k done. 186.01 samples/sec, 1376.20 ms/step
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 400.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 67.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 198.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 212.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 198.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 142.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 730.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 510.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 160.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 79.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 236.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 230.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 149.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 249.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model cait_xs24_384.fb_dist_in1k created, param count: 26670088
Running train benchmark on cait_xs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 67.42 samples/sec. 237.320 ms/step.
Train [16/40]. 67.42 samples/sec. 237.308 ms/step.
Train [24/40]. 67.42 samples/sec. 237.303 ms/step.
Train [32/40]. 67.42 samples/sec. 237.310 ms/step.
Train [40/40]. 67.42 samples/sec. 237.315 ms/step.
Train benchmark of cait_xs24_384.fb_dist_in1k done. 66.80 samples/sec, 237.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_xxs24_224.fb_dist_in1k created, param count: 11956264
Running inference benchmark on cait_xxs24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1714.78 samples/sec. 149.291 ms/step.
Infer [16/40]. 1714.77 samples/sec. 149.291 ms/step.
Infer [24/40]. 1714.81 samples/sec. 149.288 ms/step.
Infer [32/40]. 1714.82 samples/sec. 149.287 ms/step.
Infer [40/40]. 1714.77 samples/sec. 149.291 ms/step.
Inference benchmark of cait_xxs24_224.fb_dist_in1k done. 1714.41 samples/sec, 149.29 ms/step
Model cait_xxs24_224.fb_dist_in1k created, param count: 11956264
Running train benchmark on cait_xxs24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 446.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_xxs24_224.fb_dist_in1k created, param count: 11956264
Running train benchmark on cait_xxs24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 362.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_xxs24_224.fb_dist_in1k created, param count: 11956264
Running train benchmark on cait_xxs24_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 538.40 samples/sec. 237.740 ms/step.
Train [16/40]. 538.36 samples/sec. 237.759 ms/step.
Train [24/40]. 538.39 samples/sec. 237.748 ms/step.
Train [32/40]. 538.39 samples/sec. 237.748 ms/step.
Train [40/40]. 538.38 samples/sec. 237.749 ms/step.
Train benchmark of cait_xxs24_224.fb_dist_in1k done. 533.34 samples/sec, 237.75 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running inference benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 269.96 samples/sec. 948.301 ms/step.
Infer [16/40]. 269.93 samples/sec. 948.391 ms/step.
Infer [24/40]. 269.92 samples/sec. 948.424 ms/step.
Infer [32/40]. 269.92 samples/sec. 948.438 ms/step.
Infer [40/40]. 269.91 samples/sec. 948.448 ms/step.
Inference benchmark of cait_xxs24_384.fb_dist_in1k done. 269.90 samples/sec, 948.45 ms/step
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running train benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 928.06 MiB is free. Including non-PyTorch memory, this process has 22.73 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 25.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running train benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 94.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running train benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 270.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 36.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running train benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 138.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running train benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 38.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running train benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 177.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model cait_xxs24_384.fb_dist_in1k created, param count: 12029224
Running train benchmark on cait_xxs24_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 86.18 samples/sec. 371.333 ms/step.
Train [16/40]. 86.18 samples/sec. 371.316 ms/step.
Train [24/40]. 86.18 samples/sec. 371.325 ms/step.
Train [32/40]. 86.18 samples/sec. 371.319 ms/step.
Train [40/40]. 86.18 samples/sec. 371.318 ms/step.
Train benchmark of cait_xxs24_384.fb_dist_in1k done. 85.64 samples/sec, 371.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_xxs36_224.fb_dist_in1k created, param count: 17299720
Running inference benchmark on cait_xxs36_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1147.75 samples/sec. 223.045 ms/step.
Infer [16/40]. 1147.76 samples/sec. 223.043 ms/step.
Infer [24/40]. 1147.78 samples/sec. 223.040 ms/step.
Infer [32/40]. 1147.77 samples/sec. 223.042 ms/step.
Infer [40/40]. 1147.75 samples/sec. 223.044 ms/step.
Inference benchmark of cait_xxs36_224.fb_dist_in1k done. 1147.58 samples/sec, 223.04 ms/step
Model cait_xxs36_224.fb_dist_in1k created, param count: 17299720
Running train benchmark on cait_xxs36_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 444.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_xxs36_224.fb_dist_in1k created, param count: 17299720
Running train benchmark on cait_xxs36_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 355.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_xxs36_224.fb_dist_in1k created, param count: 17299720
Running train benchmark on cait_xxs36_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 535.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_xxs36_224.fb_dist_in1k created, param count: 17299720
Running train benchmark on cait_xxs36_224.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 376.75 samples/sec. 254.811 ms/step.
Train [16/40]. 376.75 samples/sec. 254.814 ms/step.
Train [24/40]. 376.74 samples/sec. 254.819 ms/step.
Train [32/40]. 376.74 samples/sec. 254.816 ms/step.
Train [40/40]. 376.74 samples/sec. 254.819 ms/step.
Train benchmark of cait_xxs36_224.fb_dist_in1k done. 372.35 samples/sec, 254.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running inference benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 180.36 samples/sec. 1419.352 ms/step.
Infer [16/40]. 180.37 samples/sec. 1419.315 ms/step.
Infer [24/40]. 180.37 samples/sec. 1419.314 ms/step.
Infer [32/40]. 180.36 samples/sec. 1419.368 ms/step.
Infer [40/40]. 180.34 samples/sec. 1419.549 ms/step.
Inference benchmark of cait_xxs36_384.fb_dist_in1k done. 180.33 samples/sec, 1419.55 ms/step
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 906.06 MiB is free. Including non-PyTorch memory, this process has 22.76 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 27.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 101.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 37.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 152.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 39.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 191.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 80.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 302.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model cait_xxs36_384.fb_dist_in1k created, param count: 17372680
Running train benchmark on cait_xxs36_384.fb_dist_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 59.00 samples/sec. 271.199 ms/step.
Train [16/40]. 59.00 samples/sec. 271.194 ms/step.
Train [24/40]. 59.00 samples/sec. 271.203 ms/step.
Train [32/40]. 58.99 samples/sec. 271.218 ms/step.
Train [40/40]. 58.99 samples/sec. 271.226 ms/step.
Train benchmark of cait_xxs36_384.fb_dist_in1k done. 58.36 samples/sec, 271.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_lite_medium.in1k created, param count: 44571048
Running inference benchmark on coat_lite_medium.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 810.42 samples/sec. 315.886 ms/step.
Infer [16/40]. 810.42 samples/sec. 315.885 ms/step.
Infer [24/40]. 810.41 samples/sec. 315.888 ms/step.
Infer [32/40]. 810.41 samples/sec. 315.888 ms/step.
Infer [40/40]. 810.40 samples/sec. 315.892 ms/step.
Inference benchmark of coat_lite_medium.in1k done. 810.30 samples/sec, 315.89 ms/step
Model coat_lite_medium.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 942.06 MiB is free. Including non-PyTorch memory, this process has 22.72 GiB memory in use. Of the allocated memory 21.82 GiB is allocated by PyTorch, and 419.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coat_lite_medium.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 364.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coat_lite_medium.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 346.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coat_lite_medium.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 144.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coat_lite_medium.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 205.14 samples/sec. 311.984 ms/step.
Train [16/40]. 205.13 samples/sec. 312.004 ms/step.
Train [24/40]. 205.14 samples/sec. 311.975 ms/step.
Train [32/40]. 205.15 samples/sec. 311.969 ms/step.
Train [40/40]. 205.15 samples/sec. 311.959 ms/step.
Train benchmark of coat_lite_medium.in1k done. 203.60 samples/sec, 311.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_lite_medium_384.in1k created, param count: 44571048
Running inference benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 251.11 samples/sec. 1019.493 ms/step.
Infer [16/40]. 251.11 samples/sec. 1019.474 ms/step.
Infer [24/40]. 251.11 samples/sec. 1019.476 ms/step.
Infer [32/40]. 251.10 samples/sec. 1019.504 ms/step.
Infer [40/40]. 251.10 samples/sec. 1019.523 ms/step.
Inference benchmark of coat_lite_medium_384.in1k done. 251.09 samples/sec, 1019.52 ms/step
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.11 GiB is free. Including non-PyTorch memory, this process has 22.53 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.27 GiB is free. Including non-PyTorch memory, this process has 22.38 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, and 235.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 492.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 293.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 264.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 288.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 467.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 370.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 445.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 423.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model coat_lite_medium_384.in1k created, param count: 44571048
Running train benchmark on coat_lite_medium_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 67.73 samples/sec. 354.370 ms/step.
Train [16/40]. 67.71 samples/sec. 354.455 ms/step.
Train [24/40]. 67.71 samples/sec. 354.448 ms/step.
Train [32/40]. 67.71 samples/sec. 354.444 ms/step.
Train [40/40]. 67.71 samples/sec. 354.449 ms/step.
Train benchmark of coat_lite_medium_384.in1k done. 67.23 samples/sec, 354.45 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_lite_mini.in1k created, param count: 11011560
Running inference benchmark on coat_lite_mini.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2815.29 samples/sec. 90.932 ms/step.
Infer [16/40]. 2815.38 samples/sec. 90.929 ms/step.
Infer [24/40]. 2815.22 samples/sec. 90.934 ms/step.
Infer [32/40]. 2815.29 samples/sec. 90.932 ms/step.
Infer [40/40]. 2815.23 samples/sec. 90.934 ms/step.
Inference benchmark of coat_lite_mini.in1k done. 2814.43 samples/sec, 90.93 ms/step
Model coat_lite_mini.in1k created, param count: 11011560
Running train benchmark on coat_lite_mini.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 719.29 samples/sec. 355.907 ms/step.
Train [16/40]. 719.29 samples/sec. 355.909 ms/step.
Train [24/40]. 719.27 samples/sec. 355.918 ms/step.
Train [32/40]. 719.31 samples/sec. 355.898 ms/step.
Train [40/40]. 719.30 samples/sec. 355.903 ms/step.
Train benchmark of coat_lite_mini.in1k done. 716.88 samples/sec, 355.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_lite_small.in1k created, param count: 19838504
Running inference benchmark on coat_lite_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1582.51 samples/sec. 161.768 ms/step.
Infer [16/40]. 1582.61 samples/sec. 161.758 ms/step.
Infer [24/40]. 1582.63 samples/sec. 161.756 ms/step.
Infer [32/40]. 1582.66 samples/sec. 161.753 ms/step.
Infer [40/40]. 1582.67 samples/sec. 161.752 ms/step.
Inference benchmark of coat_lite_small.in1k done. 1582.38 samples/sec, 161.75 ms/step
Model coat_lite_small.in1k created, param count: 19838504
Running train benchmark on coat_lite_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 786.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 432.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 322.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coat_lite_small.in1k created, param count: 19838504
Running train benchmark on coat_lite_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 92.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coat_lite_small.in1k created, param count: 19838504
Running train benchmark on coat_lite_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 414.06 samples/sec. 309.131 ms/step.
Train [16/40]. 414.02 samples/sec. 309.165 ms/step.
Train [24/40]. 413.98 samples/sec. 309.195 ms/step.
Train [32/40]. 413.97 samples/sec. 309.204 ms/step.
Train [40/40]. 413.98 samples/sec. 309.191 ms/step.
Train benchmark of coat_lite_small.in1k done. 411.61 samples/sec, 309.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_lite_tiny.in1k created, param count: 5721960
Running inference benchmark on coat_lite_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3004.31 samples/sec. 85.211 ms/step.
Infer [16/40]. 3004.28 samples/sec. 85.212 ms/step.
Infer [24/40]. 3004.28 samples/sec. 85.212 ms/step.
Infer [32/40]. 3004.14 samples/sec. 85.216 ms/step.
Infer [40/40]. 3004.06 samples/sec. 85.218 ms/step.
Inference benchmark of coat_lite_tiny.in1k done. 3003.17 samples/sec, 85.22 ms/step
Model coat_lite_tiny.in1k created, param count: 5721960
Running train benchmark on coat_lite_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 768.96 samples/sec. 332.919 ms/step.
Train [16/40]. 768.95 samples/sec. 332.921 ms/step.
Train [24/40]. 768.92 samples/sec. 332.937 ms/step.
Train [32/40]. 768.91 samples/sec. 332.937 ms/step.
Train [40/40]. 768.90 samples/sec. 332.943 ms/step.
Train benchmark of coat_lite_tiny.in1k done. 766.16 samples/sec, 332.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_mini.in1k created, param count: 10337004
Running inference benchmark on coat_mini.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 873.28 samples/sec. 293.149 ms/step.
Infer [16/40]. 873.27 samples/sec. 293.153 ms/step.
Infer [24/40]. 873.28 samples/sec. 293.147 ms/step.
Infer [32/40]. 873.28 samples/sec. 293.147 ms/step.
Infer [40/40]. 873.28 samples/sec. 293.146 ms/step.
Inference benchmark of coat_mini.in1k done. 873.17 samples/sec, 293.15 ms/step
Model coat_mini.in1k created, param count: 10337004
Running train benchmark on coat_mini.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 223.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coat_mini.in1k created, param count: 10337004
Running train benchmark on coat_mini.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 130.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coat_mini.in1k created, param count: 10337004
Running train benchmark on coat_mini.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 224.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coat_mini.in1k created, param count: 10337004
Running train benchmark on coat_mini.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 227.27 samples/sec. 422.406 ms/step.
Train [16/40]. 227.34 samples/sec. 422.284 ms/step.
Train [24/40]. 227.40 samples/sec. 422.158 ms/step.
Train [32/40]. 227.39 samples/sec. 422.181 ms/step.
Train [40/40]. 227.37 samples/sec. 422.225 ms/step.
Train benchmark of coat_mini.in1k done. 226.14 samples/sec, 422.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_small.in1k created, param count: 21693908
Running inference benchmark on coat_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 635.90 samples/sec. 402.580 ms/step.
Infer [16/40]. 635.92 samples/sec. 402.568 ms/step.
Infer [24/40]. 635.91 samples/sec. 402.570 ms/step.
Infer [32/40]. 635.91 samples/sec. 402.575 ms/step.
Infer [40/40]. 635.90 samples/sec. 402.582 ms/step.
Inference benchmark of coat_small.in1k done. 635.83 samples/sec, 402.58 ms/step
Model coat_small.in1k created, param count: 21693908
Running train benchmark on coat_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 257.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coat_small.in1k created, param count: 21693908
Running train benchmark on coat_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 736.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 288.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 244.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coat_small.in1k created, param count: 21693908
Running train benchmark on coat_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 303.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coat_small.in1k created, param count: 21693908
Running train benchmark on coat_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 368.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 196.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 233.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coat_small.in1k created, param count: 21693908
Running train benchmark on coat_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 162.50 samples/sec. 393.837 ms/step.
Train [16/40]. 162.50 samples/sec. 393.857 ms/step.
Train [24/40]. 162.51 samples/sec. 393.818 ms/step.
Train [32/40]. 162.51 samples/sec. 393.812 ms/step.
Train [40/40]. 162.52 samples/sec. 393.804 ms/step.
Train benchmark of coat_small.in1k done. 161.60 samples/sec, 393.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coat_tiny.in1k created, param count: 5498540
Running inference benchmark on coat_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1115.32 samples/sec. 229.532 ms/step.
Infer [16/40]. 1115.34 samples/sec. 229.526 ms/step.
Infer [24/40]. 1115.31 samples/sec. 229.533 ms/step.
Infer [32/40]. 1115.32 samples/sec. 229.531 ms/step.
Infer [40/40]. 1115.37 samples/sec. 229.519 ms/step.
Inference benchmark of coat_tiny.in1k done. 1115.21 samples/sec, 229.52 ms/step
Model coat_tiny.in1k created, param count: 5498540
Running train benchmark on coat_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 468.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 295.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coat_tiny.in1k created, param count: 5498540
Running train benchmark on coat_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 133.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coat_tiny.in1k created, param count: 5498540
Running train benchmark on coat_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 352.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coat_tiny.in1k created, param count: 5498540
Running train benchmark on coat_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 292.74 samples/sec. 327.934 ms/step.
Train [16/40]. 292.84 samples/sec. 327.825 ms/step.
Train [24/40]. 292.78 samples/sec. 327.893 ms/step.
Train [32/40]. 292.82 samples/sec. 327.849 ms/step.
Train [40/40]. 292.79 samples/sec. 327.881 ms/step.
Train benchmark of coat_tiny.in1k done. 290.79 samples/sec, 327.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_0_rw_224.sw_in1k created, param count: 27435562
Running inference benchmark on coatnet_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1569.12 samples/sec. 163.149 ms/step.
Infer [16/40]. 1569.19 samples/sec. 163.142 ms/step.
Infer [24/40]. 1569.19 samples/sec. 163.142 ms/step.
Infer [32/40]. 1569.18 samples/sec. 163.143 ms/step.
Infer [40/40]. 1569.18 samples/sec. 163.143 ms/step.
Inference benchmark of coatnet_0_rw_224.sw_in1k done. 1568.85 samples/sec, 163.14 ms/step
Model coatnet_0_rw_224.sw_in1k created, param count: 27435562
Running train benchmark on coatnet_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 170.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_0_rw_224.sw_in1k created, param count: 27435562
Running train benchmark on coatnet_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 199.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_0_rw_224.sw_in1k created, param count: 27435562
Running train benchmark on coatnet_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 482.70 samples/sec. 265.174 ms/step.
Train [16/40]. 482.70 samples/sec. 265.173 ms/step.
Train [24/40]. 482.70 samples/sec. 265.176 ms/step.
Train [32/40]. 482.70 samples/sec. 265.174 ms/step.
Train [40/40]. 482.70 samples/sec. 265.174 ms/step.
Train benchmark of coatnet_0_rw_224.sw_in1k done. 480.56 samples/sec, 265.17 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_1_rw_224.sw_in1k created, param count: 41721502
Running inference benchmark on coatnet_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 871.77 samples/sec. 293.656 ms/step.
Infer [16/40]. 871.77 samples/sec. 293.656 ms/step.
Infer [24/40]. 871.76 samples/sec. 293.660 ms/step.
Infer [32/40]. 871.75 samples/sec. 293.662 ms/step.
Infer [40/40]. 871.75 samples/sec. 293.661 ms/step.
Inference benchmark of coatnet_1_rw_224.sw_in1k done. 871.63 samples/sec, 293.66 ms/step
Model coatnet_1_rw_224.sw_in1k created, param count: 41721502
Running train benchmark on coatnet_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 214.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_1_rw_224.sw_in1k created, param count: 41721502
Running train benchmark on coatnet_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 104.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_1_rw_224.sw_in1k created, param count: 41721502
Running train benchmark on coatnet_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 220.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 339.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_1_rw_224.sw_in1k created, param count: 41721502
Running train benchmark on coatnet_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 546.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_1_rw_224.sw_in1k created, param count: 41721502
Running train benchmark on coatnet_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 276.13 samples/sec. 231.774 ms/step.
Train [16/40]. 276.13 samples/sec. 231.778 ms/step.
Train [24/40]. 276.13 samples/sec. 231.777 ms/step.
Train [32/40]. 276.12 samples/sec. 231.780 ms/step.
Train [40/40]. 276.12 samples/sec. 231.783 ms/step.
Train benchmark of coatnet_1_rw_224.sw_in1k done. 274.32 samples/sec, 231.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_2_rw_224.sw_in12k created, param count: 84959925
Running inference benchmark on coatnet_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 584.28 samples/sec. 438.149 ms/step.
Infer [16/40]. 584.27 samples/sec. 438.154 ms/step.
Infer [24/40]. 584.26 samples/sec. 438.160 ms/step.
Infer [32/40]. 584.25 samples/sec. 438.168 ms/step.
Infer [40/40]. 584.25 samples/sec. 438.170 ms/step.
Inference benchmark of coatnet_2_rw_224.sw_in12k done. 584.19 samples/sec, 438.17 ms/step
Model coatnet_2_rw_224.sw_in12k created, param count: 84959925
Running train benchmark on coatnet_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.75 GiB is free. Including non-PyTorch memory, this process has 20.89 GiB memory in use. Of the allocated memory 20.01 GiB is allocated by PyTorch, and 406.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_2_rw_224.sw_in12k created, param count: 84959925
Running train benchmark on coatnet_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 844.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 352.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_2_rw_224.sw_in12k created, param count: 84959925
Running train benchmark on coatnet_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 286.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_2_rw_224.sw_in12k created, param count: 84959925
Running train benchmark on coatnet_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 150.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_2_rw_224.sw_in12k created, param count: 84959925
Running train benchmark on coatnet_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 202.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coatnet_2_rw_224.sw_in12k created, param count: 84959925
Running train benchmark on coatnet_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 180.76 samples/sec. 265.552 ms/step.
Train [16/40]. 180.76 samples/sec. 265.545 ms/step.
Train [24/40]. 180.76 samples/sec. 265.551 ms/step.
Train [32/40]. 180.75 samples/sec. 265.556 ms/step.
Train [40/40]. 180.75 samples/sec. 265.559 ms/step.
Train benchmark of coatnet_2_rw_224.sw_in12k done. 179.70 samples/sec, 265.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_2_rw_224.sw_in12k_ft_in1k created, param count: 73868400
Running inference benchmark on coatnet_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 584.71 samples/sec. 437.825 ms/step.
Infer [16/40]. 584.56 samples/sec. 437.935 ms/step.
Infer [24/40]. 584.50 samples/sec. 437.984 ms/step.
Infer [32/40]. 584.46 samples/sec. 438.010 ms/step.
Infer [40/40]. 584.44 samples/sec. 438.025 ms/step.
Inference benchmark of coatnet_2_rw_224.sw_in12k_ft_in1k done. 584.38 samples/sec, 438.02 ms/step
Model coatnet_2_rw_224.sw_in12k_ft_in1k created, param count: 73868400
Running train benchmark on coatnet_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.79 GiB is free. Including non-PyTorch memory, this process has 20.85 GiB memory in use. Of the allocated memory 19.96 GiB is allocated by PyTorch, and 400.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_2_rw_224.sw_in12k_ft_in1k created, param count: 73868400
Running train benchmark on coatnet_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 868.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 368.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_2_rw_224.sw_in12k_ft_in1k created, param count: 73868400
Running train benchmark on coatnet_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 261.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_2_rw_224.sw_in12k_ft_in1k created, param count: 73868400
Running train benchmark on coatnet_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 278.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 228.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_2_rw_224.sw_in12k_ft_in1k created, param count: 73868400
Running train benchmark on coatnet_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 211.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coatnet_2_rw_224.sw_in12k_ft_in1k created, param count: 73868400
Running train benchmark on coatnet_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 181.22 samples/sec. 264.873 ms/step.
Train [16/40]. 181.23 samples/sec. 264.864 ms/step.
Train [24/40]. 181.22 samples/sec. 264.866 ms/step.
Train [32/40]. 181.22 samples/sec. 264.868 ms/step.
Train [40/40]. 181.22 samples/sec. 264.875 ms/step.
Train benchmark of coatnet_2_rw_224.sw_in12k_ft_in1k done. 180.19 samples/sec, 264.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running inference benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "Expected canUse32BitIndexMath(input) && canUse32BitIndexMath(output) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running inference benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Infer [8/40]. 353.97 samples/sec. 542.418 ms/step.
Infer [16/40]. 353.94 samples/sec. 542.464 ms/step.
Infer [24/40]. 353.93 samples/sec. 542.487 ms/step.
Infer [32/40]. 353.92 samples/sec. 542.501 ms/step.
Infer [40/40]. 353.91 samples/sec. 542.508 ms/step.
Inference benchmark of coatnet_3_rw_224.sw_in12k done. 353.88 samples/sec, 542.51 ms/step
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 22.06 GiB memory in use. Of the allocated memory 20.94 GiB is allocated by PyTorch, and 637.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.69 GiB is free. Including non-PyTorch memory, this process has 16.95 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 585.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 344.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 516.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 360.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 294.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 363.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 403.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 658.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model coatnet_3_rw_224.sw_in12k created, param count: 181805305
Running train benchmark on coatnet_3_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 108.09 samples/sec. 222.028 ms/step.
Train [16/40]. 108.10 samples/sec. 222.021 ms/step.
Train [24/40]. 108.10 samples/sec. 222.021 ms/step.
Train [32/40]. 108.10 samples/sec. 222.019 ms/step.
Train [40/40]. 108.10 samples/sec. 222.019 ms/step.
Train benchmark of coatnet_3_rw_224.sw_in12k done. 107.34 samples/sec, 222.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_bn_0_rw_224.sw_in1k created, param count: 27435562
Running inference benchmark on coatnet_bn_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1423.59 samples/sec. 179.827 ms/step.
Infer [16/40]. 1423.54 samples/sec. 179.833 ms/step.
Infer [24/40]. 1423.54 samples/sec. 179.833 ms/step.
Infer [32/40]. 1423.54 samples/sec. 179.834 ms/step.
Infer [40/40]. 1423.54 samples/sec. 179.833 ms/step.
Inference benchmark of coatnet_bn_0_rw_224.sw_in1k done. 1423.24 samples/sec, 179.83 ms/step
Model coatnet_bn_0_rw_224.sw_in1k created, param count: 27435562
Running train benchmark on coatnet_bn_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 237.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_bn_0_rw_224.sw_in1k created, param count: 27435562
Running train benchmark on coatnet_bn_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 137.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_bn_0_rw_224.sw_in1k created, param count: 27435562
Running train benchmark on coatnet_bn_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 179.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_bn_0_rw_224.sw_in1k created, param count: 27435562
Running train benchmark on coatnet_bn_0_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 418.64 samples/sec. 229.313 ms/step.
Train [16/40]. 418.65 samples/sec. 229.310 ms/step.
Train [24/40]. 418.65 samples/sec. 229.310 ms/step.
Train [32/40]. 418.64 samples/sec. 229.314 ms/step.
Train [40/40]. 418.64 samples/sec. 229.313 ms/step.
Train benchmark of coatnet_bn_0_rw_224.sw_in1k done. 416.71 samples/sec, 229.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_nano_rw_224.sw_in1k created, param count: 15141244
Running inference benchmark on coatnet_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1970.04 samples/sec. 129.946 ms/step.
Infer [16/40]. 1969.98 samples/sec. 129.951 ms/step.
Infer [24/40]. 1970.04 samples/sec. 129.947 ms/step.
Infer [32/40]. 1970.06 samples/sec. 129.945 ms/step.
Infer [40/40]. 1970.03 samples/sec. 129.947 ms/step.
Inference benchmark of coatnet_nano_rw_224.sw_in1k done. 1969.57 samples/sec, 129.95 ms/step
Model coatnet_nano_rw_224.sw_in1k created, param count: 15141244
Running train benchmark on coatnet_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 344.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 101.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_nano_rw_224.sw_in1k created, param count: 15141244
Running train benchmark on coatnet_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 93.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_nano_rw_224.sw_in1k created, param count: 15141244
Running train benchmark on coatnet_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 583.69 samples/sec. 219.294 ms/step.
Train [16/40]. 583.72 samples/sec. 219.282 ms/step.
Train [24/40]. 583.71 samples/sec. 219.288 ms/step.
Train [32/40]. 583.71 samples/sec. 219.287 ms/step.
Train [40/40]. 583.71 samples/sec. 219.288 ms/step.
Train benchmark of coatnet_nano_rw_224.sw_in1k done. 580.68 samples/sec, 219.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_1_rw2_224.sw_in12k created, param count: 50045971
Running inference benchmark on coatnet_rmlp_1_rw2_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 871.13 samples/sec. 293.871 ms/step.
Infer [16/40]. 871.16 samples/sec. 293.863 ms/step.
Infer [24/40]. 871.18 samples/sec. 293.855 ms/step.
Infer [32/40]. 871.17 samples/sec. 293.856 ms/step.
Infer [40/40]. 871.17 samples/sec. 293.859 ms/step.
Inference benchmark of coatnet_rmlp_1_rw2_224.sw_in12k done. 871.03 samples/sec, 293.86 ms/step
Model coatnet_rmlp_1_rw2_224.sw_in12k created, param count: 50045971
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 217.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k created, param count: 50045971
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 140.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k created, param count: 50045971
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 136.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 391.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k created, param count: 50045971
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 557.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k created, param count: 50045971
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 274.02 samples/sec. 233.556 ms/step.
Train [16/40]. 274.04 samples/sec. 233.542 ms/step.
Train [24/40]. 274.04 samples/sec. 233.541 ms/step.
Train [32/40]. 274.04 samples/sec. 233.543 ms/step.
Train [40/40]. 274.04 samples/sec. 233.539 ms/step.
Train benchmark of coatnet_rmlp_1_rw2_224.sw_in12k done. 272.14 samples/sec, 233.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k created, param count: 41724622
Running inference benchmark on coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 870.88 samples/sec. 293.955 ms/step.
Infer [16/40]. 870.88 samples/sec. 293.956 ms/step.
Infer [24/40]. 870.87 samples/sec. 293.958 ms/step.
Infer [32/40]. 870.87 samples/sec. 293.960 ms/step.
Infer [40/40]. 870.87 samples/sec. 293.960 ms/step.
Inference benchmark of coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k done. 870.74 samples/sec, 293.96 ms/step
Model coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k created, param count: 41724622
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 213.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k created, param count: 41724622
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 98.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k created, param count: 41724622
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 228.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 331.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k created, param count: 41724622
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 569.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k created, param count: 41724622
Running train benchmark on coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 274.78 samples/sec. 232.911 ms/step.
Train [16/40]. 274.79 samples/sec. 232.908 ms/step.
Train [24/40]. 274.78 samples/sec. 232.909 ms/step.
Train [32/40]. 274.78 samples/sec. 232.910 ms/step.
Train [40/40]. 274.78 samples/sec. 232.916 ms/step.
Train benchmark of coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k done. 272.84 samples/sec, 232.92 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_1_rw_224.sw_in1k created, param count: 41691982
Running inference benchmark on coatnet_rmlp_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 935.65 samples/sec. 273.607 ms/step.
Infer [16/40]. 935.65 samples/sec. 273.608 ms/step.
Infer [24/40]. 935.65 samples/sec. 273.606 ms/step.
Infer [32/40]. 935.65 samples/sec. 273.607 ms/step.
Infer [40/40]. 935.65 samples/sec. 273.608 ms/step.
Inference benchmark of coatnet_rmlp_1_rw_224.sw_in1k done. 935.49 samples/sec, 273.61 ms/step
Model coatnet_rmlp_1_rw_224.sw_in1k created, param count: 41691982
Running train benchmark on coatnet_rmlp_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 72.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_1_rw_224.sw_in1k created, param count: 41691982
Running train benchmark on coatnet_rmlp_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 274.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 113.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_1_rw_224.sw_in1k created, param count: 41691982
Running train benchmark on coatnet_rmlp_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 273.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_1_rw_224.sw_in1k created, param count: 41691982
Running train benchmark on coatnet_rmlp_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 723.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_rmlp_1_rw_224.sw_in1k created, param count: 41691982
Running train benchmark on coatnet_rmlp_1_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 301.03 samples/sec. 212.602 ms/step.
Train [16/40]. 301.04 samples/sec. 212.599 ms/step.
Train [24/40]. 301.03 samples/sec. 212.606 ms/step.
Train [32/40]. 301.02 samples/sec. 212.609 ms/step.
Train [40/40]. 301.02 samples/sec. 212.611 ms/step.
Train benchmark of coatnet_rmlp_1_rw_224.sw_in1k done. 298.77 samples/sec, 212.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_2_rw_224.sw_in1k created, param count: 73881264
Running inference benchmark on coatnet_rmlp_2_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 575.70 samples/sec. 444.675 ms/step.
Infer [16/40]. 575.70 samples/sec. 444.679 ms/step.
Infer [24/40]. 575.70 samples/sec. 444.678 ms/step.
Infer [32/40]. 575.69 samples/sec. 444.680 ms/step.
Infer [40/40]. 575.69 samples/sec. 444.684 ms/step.
Inference benchmark of coatnet_rmlp_2_rw_224.sw_in1k done. 575.63 samples/sec, 444.68 ms/step
Model coatnet_rmlp_2_rw_224.sw_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.79 GiB is free. Including non-PyTorch memory, this process has 20.85 GiB memory in use. Of the allocated memory 19.96 GiB is allocated by PyTorch, and 400.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_2_rw_224.sw_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 878.06 MiB is free. Including non-PyTorch memory, this process has 22.78 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 358.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_2_rw_224.sw_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 252.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_2_rw_224.sw_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 292.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 214.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_rmlp_2_rw_224.sw_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 166.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coatnet_rmlp_2_rw_224.sw_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 178.54 samples/sec. 268.846 ms/step.
Train [16/40]. 178.49 samples/sec. 268.915 ms/step.
Train [24/40]. 178.47 samples/sec. 268.945 ms/step.
Train [32/40]. 178.46 samples/sec. 268.961 ms/step.
Train [40/40]. 178.46 samples/sec. 268.965 ms/step.
Train benchmark of coatnet_rmlp_2_rw_224.sw_in1k done. 177.26 samples/sec, 268.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_2_rw_224.sw_in12k created, param count: 84972789
Running inference benchmark on coatnet_rmlp_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 575.28 samples/sec. 444.997 ms/step.
Infer [16/40]. 575.28 samples/sec. 444.997 ms/step.
Infer [24/40]. 575.29 samples/sec. 444.996 ms/step.
Infer [32/40]. 575.28 samples/sec. 444.998 ms/step.
Infer [40/40]. 575.28 samples/sec. 444.999 ms/step.
Inference benchmark of coatnet_rmlp_2_rw_224.sw_in12k done. 575.23 samples/sec, 445.00 ms/step
Model coatnet_rmlp_2_rw_224.sw_in12k created, param count: 84972789
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.75 GiB is free. Including non-PyTorch memory, this process has 20.89 GiB memory in use. Of the allocated memory 20.01 GiB is allocated by PyTorch, and 406.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k created, param count: 84972789
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 854.06 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 341.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k created, param count: 84972789
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 278.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k created, param count: 84972789
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 280.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 186.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k created, param count: 84972789
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 178.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k created, param count: 84972789
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 178.13 samples/sec. 269.462 ms/step.
Train [16/40]. 178.12 samples/sec. 269.483 ms/step.
Train [24/40]. 178.12 samples/sec. 269.486 ms/step.
Train [32/40]. 178.11 samples/sec. 269.490 ms/step.
Train [40/40]. 178.12 samples/sec. 269.488 ms/step.
Train benchmark of coatnet_rmlp_2_rw_224.sw_in12k done. 176.94 samples/sec, 269.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k created, param count: 73881264
Running inference benchmark on coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 575.88 samples/sec. 444.538 ms/step.
Infer [16/40]. 575.85 samples/sec. 444.562 ms/step.
Infer [24/40]. 575.73 samples/sec. 444.653 ms/step.
Infer [32/40]. 575.68 samples/sec. 444.694 ms/step.
Infer [40/40]. 575.64 samples/sec. 444.720 ms/step.
Inference benchmark of coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k done. 575.58 samples/sec, 444.72 ms/step
Model coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.79 GiB is free. Including non-PyTorch memory, this process has 20.85 GiB memory in use. Of the allocated memory 19.96 GiB is allocated by PyTorch, and 400.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 878.06 MiB is free. Including non-PyTorch memory, this process has 22.78 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 358.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 252.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 292.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 214.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 166.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 178.58 samples/sec. 268.788 ms/step.
Train [16/40]. 178.58 samples/sec. 268.793 ms/step.
Train [24/40]. 178.58 samples/sec. 268.789 ms/step.
Train [32/40]. 178.58 samples/sec. 268.787 ms/step.
Train [40/40]. 178.58 samples/sec. 268.787 ms/step.
Train benchmark of coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k done. 177.39 samples/sec, 268.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running inference benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 11.13 GiB is free. Including non-PyTorch memory, this process has 12.51 GiB memory in use. Of the allocated memory 10.88 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running inference benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.69 GiB is free. Including non-PyTorch memory, this process has 19.95 GiB memory in use. Of the allocated memory 18.37 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running inference benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "Expected canUse32BitIndexMath(input) && canUse32BitIndexMath(output) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running inference benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
Infer [8/40]. 155.52 samples/sec. 617.287 ms/step.
Infer [16/40]. 155.53 samples/sec. 617.252 ms/step.
Infer [24/40]. 155.53 samples/sec. 617.262 ms/step.
Infer [32/40]. 155.51 samples/sec. 617.313 ms/step.
Infer [40/40]. 155.50 samples/sec. 617.345 ms/step.
Inference benchmark of coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k done. 155.49 samples/sec, 617.35 ms/step
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.38 GiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 17.63 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.37 GiB is free. Including non-PyTorch memory, this process has 18.27 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 21.46 GiB memory in use. Of the allocated memory 20.23 GiB is allocated by PyTorch, and 761.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 416.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 757.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 22.54 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 532.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 119.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 360.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 160.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 280.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k created, param count: 73881264
Running train benchmark on coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 50.13 samples/sec. 239.372 ms/step.
Train [16/40]. 50.12 samples/sec. 239.413 ms/step.
Train [24/40]. 50.12 samples/sec. 239.445 ms/step.
Train [32/40]. 50.11 samples/sec. 239.465 ms/step.
Train [40/40]. 50.11 samples/sec. 239.479 ms/step.
Train benchmark of coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k done. 49.74 samples/sec, 239.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnet_rmlp_nano_rw_224.sw_in1k created, param count: 15145116
Running inference benchmark on coatnet_rmlp_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1714.65 samples/sec. 149.301 ms/step.
Infer [16/40]. 1714.64 samples/sec. 149.302 ms/step.
Infer [24/40]. 1714.66 samples/sec. 149.301 ms/step.
Infer [32/40]. 1714.67 samples/sec. 149.300 ms/step.
Infer [40/40]. 1714.65 samples/sec. 149.302 ms/step.
Inference benchmark of coatnet_rmlp_nano_rw_224.sw_in1k done. 1714.27 samples/sec, 149.30 ms/step
Model coatnet_rmlp_nano_rw_224.sw_in1k created, param count: 15145116
Running train benchmark on coatnet_rmlp_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 101.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model coatnet_rmlp_nano_rw_224.sw_in1k created, param count: 15145116
Running train benchmark on coatnet_rmlp_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 204.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 186.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model coatnet_rmlp_nano_rw_224.sw_in1k created, param count: 15145116
Running train benchmark on coatnet_rmlp_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 129.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model coatnet_rmlp_nano_rw_224.sw_in1k created, param count: 15145116
Running train benchmark on coatnet_rmlp_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 501.67 samples/sec. 191.359 ms/step.
Train [16/40]. 501.69 samples/sec. 191.353 ms/step.
Train [24/40]. 501.68 samples/sec. 191.356 ms/step.
Train [32/40]. 501.69 samples/sec. 191.354 ms/step.
Train [40/40]. 501.69 samples/sec. 191.352 ms/step.
Train benchmark of coatnet_rmlp_nano_rw_224.sw_in1k done. 498.63 samples/sec, 191.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model coatnext_nano_rw_224.sw_in1k created, param count: 14701244
Running inference benchmark on coatnext_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2438.23 samples/sec. 104.994 ms/step.
Infer [16/40]. 2438.43 samples/sec. 104.986 ms/step.
Infer [24/40]. 2438.52 samples/sec. 104.982 ms/step.
Infer [32/40]. 2438.56 samples/sec. 104.980 ms/step.
Infer [40/40]. 2438.57 samples/sec. 104.979 ms/step.
Inference benchmark of coatnext_nano_rw_224.sw_in1k done. 2437.91 samples/sec, 104.98 ms/step
Model coatnext_nano_rw_224.sw_in1k created, param count: 14701244
Running train benchmark on coatnext_nano_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 683.98 samples/sec. 374.282 ms/step.
Train [16/40]. 683.88 samples/sec. 374.337 ms/step.
Train [24/40]. 683.88 samples/sec. 374.335 ms/step.
Train [32/40]. 683.84 samples/sec. 374.355 ms/step.
Train [40/40]. 683.87 samples/sec. 374.337 ms/step.
Train benchmark of coatnext_nano_rw_224.sw_in1k done. 681.80 samples/sec, 374.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_b36.sail_in1k created, param count: 99882616
Running inference benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 442.63 samples/sec. 578.367 ms/step.
Infer [16/40]. 442.63 samples/sec. 578.364 ms/step.
Infer [24/40]. 442.62 samples/sec. 578.377 ms/step.
Infer [32/40]. 442.61 samples/sec. 578.381 ms/step.
Infer [40/40]. 442.61 samples/sec. 578.389 ms/step.
Inference benchmark of convformer_b36.sail_in1k done. 442.57 samples/sec, 578.39 ms/step
Model convformer_b36.sail_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 644.06 MiB is free. Including non-PyTorch memory, this process has 23.01 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 132.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_b36.sail_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 404.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 119.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_b36.sail_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 286.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_b36.sail_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 371.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_b36.sail_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 578.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_b36.sail_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 394.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_b36.sail_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 90.91 samples/sec. 351.988 ms/step.
Train [16/40]. 90.91 samples/sec. 351.985 ms/step.
Train [24/40]. 90.91 samples/sec. 351.978 ms/step.
Train [32/40]. 90.92 samples/sec. 351.977 ms/step.
Train [40/40]. 90.91 samples/sec. 351.978 ms/step.
Train benchmark of convformer_b36.sail_in1k done. 90.39 samples/sec, 351.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running inference benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 151.83 samples/sec. 1686.077 ms/step.
Infer [16/40]. 151.83 samples/sec. 1686.117 ms/step.
Infer [24/40]. 151.83 samples/sec. 1686.115 ms/step.
Infer [32/40]. 151.83 samples/sec. 1686.104 ms/step.
Infer [40/40]. 151.83 samples/sec. 1686.109 ms/step.
Inference benchmark of convformer_b36.sail_in1k_384 done. 151.82 samples/sec, 1686.11 ms/step
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.13 GiB is free. Including non-PyTorch memory, this process has 20.51 GiB memory in use. Of the allocated memory 19.99 GiB is allocated by PyTorch, and 27.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 996.06 MiB is free. Including non-PyTorch memory, this process has 22.67 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 344.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 22.17 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 221.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 391.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 540.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 448.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 377.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 258.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 354.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 406.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 234.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convformer_b36.sail_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 30.65 samples/sec. 391.566 ms/step.
Train [16/40]. 30.65 samples/sec. 391.574 ms/step.
Train [24/40]. 30.64 samples/sec. 391.586 ms/step.
Train [32/40]. 30.65 samples/sec. 391.580 ms/step.
Train [40/40]. 30.64 samples/sec. 391.617 ms/step.
Train benchmark of convformer_b36.sail_in1k_384 done. 30.48 samples/sec, 391.62 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_b36.sail_in22k created, param count: 163927009
Running inference benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 442.68 samples/sec. 578.298 ms/step.
Infer [16/40]. 442.51 samples/sec. 578.513 ms/step.
Infer [24/40]. 442.45 samples/sec. 578.598 ms/step.
Infer [32/40]. 442.41 samples/sec. 578.643 ms/step.
Infer [40/40]. 442.40 samples/sec. 578.667 ms/step.
Inference benchmark of convformer_b36.sail_in22k done. 442.36 samples/sec, 578.67 ms/step
Model convformer_b36.sail_in22k created, param count: 163927009
Running train benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 400.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 131.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_b36.sail_in22k created, param count: 163927009
Running train benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 107.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_b36.sail_in22k created, param count: 163927009
Running train benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 346.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_b36.sail_in22k created, param count: 163927009
Running train benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 353.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_b36.sail_in22k created, param count: 163927009
Running train benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.34 GiB is allocated by PyTorch, and 737.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_b36.sail_in22k created, param count: 163927009
Running train benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 389.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_b36.sail_in22k created, param count: 163927009
Running train benchmark on convformer_b36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 90.00 samples/sec. 355.545 ms/step.
Train [16/40]. 90.01 samples/sec. 355.531 ms/step.
Train [24/40]. 90.00 samples/sec. 355.543 ms/step.
Train [32/40]. 90.00 samples/sec. 355.546 ms/step.
Train [40/40]. 89.96 samples/sec. 355.698 ms/step.
Train benchmark of convformer_b36.sail_in22k done. 89.45 samples/sec, 355.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running inference benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 442.86 samples/sec. 578.061 ms/step.
Infer [16/40]. 442.77 samples/sec. 578.183 ms/step.
Infer [24/40]. 442.73 samples/sec. 578.227 ms/step.
Infer [32/40]. 442.72 samples/sec. 578.245 ms/step.
Infer [40/40]. 442.71 samples/sec. 578.257 ms/step.
Inference benchmark of convformer_b36.sail_in22k_ft_in1k done. 442.67 samples/sec, 578.26 ms/step
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 644.06 MiB is free. Including non-PyTorch memory, this process has 23.01 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 132.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 404.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 119.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 286.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 371.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 578.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 394.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_b36.sail_in22k_ft_in1k created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 91.03 samples/sec. 351.548 ms/step.
Train [16/40]. 91.03 samples/sec. 351.541 ms/step.
Train [24/40]. 91.03 samples/sec. 351.542 ms/step.
Train [32/40]. 90.98 samples/sec. 351.735 ms/step.
Train [40/40]. 90.95 samples/sec. 351.855 ms/step.
Train benchmark of convformer_b36.sail_in22k_ft_in1k done. 90.41 samples/sec, 351.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running inference benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 151.85 samples/sec. 1685.927 ms/step.
Infer [16/40]. 151.85 samples/sec. 1685.919 ms/step.
Infer [24/40]. 151.85 samples/sec. 1685.927 ms/step.
Infer [32/40]. 151.84 samples/sec. 1686.003 ms/step.
Infer [40/40]. 151.83 samples/sec. 1686.083 ms/step.
Inference benchmark of convformer_b36.sail_in22k_ft_in1k_384 done. 151.83 samples/sec, 1686.08 ms/step
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.13 GiB is free. Including non-PyTorch memory, this process has 20.51 GiB memory in use. Of the allocated memory 19.99 GiB is allocated by PyTorch, and 27.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 996.06 MiB is free. Including non-PyTorch memory, this process has 22.67 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 344.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 22.17 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 221.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 391.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 540.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 448.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 377.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 258.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 354.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 406.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 250.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convformer_b36.sail_in22k_ft_in1k_384 created, param count: 99882616
Running train benchmark on convformer_b36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 30.62 samples/sec. 391.926 ms/step.
Train [16/40]. 30.62 samples/sec. 391.934 ms/step.
Train [24/40]. 30.62 samples/sec. 391.933 ms/step.
Train [32/40]. 30.62 samples/sec. 391.927 ms/step.
Train [40/40]. 30.62 samples/sec. 391.930 ms/step.
Train benchmark of convformer_b36.sail_in22k_ft_in1k_384 done. 30.46 samples/sec, 391.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_m36.sail_in1k created, param count: 57051640
Running inference benchmark on convformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 616.55 samples/sec. 415.214 ms/step.
Infer [16/40]. 616.45 samples/sec. 415.284 ms/step.
Infer [24/40]. 616.33 samples/sec. 415.360 ms/step.
Infer [32/40]. 616.29 samples/sec. 415.391 ms/step.
Infer [40/40]. 616.25 samples/sec. 415.414 ms/step.
Inference benchmark of convformer_m36.sail_in1k done. 616.19 samples/sec, 415.41 ms/step
Model convformer_m36.sail_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 622.06 MiB is free. Including non-PyTorch memory, this process has 23.03 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 18.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_m36.sail_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 232.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_m36.sail_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 96.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_m36.sail_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 504.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_m36.sail_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 625.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_m36.sail_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 127.73 samples/sec. 375.779 ms/step.
Train [16/40]. 127.73 samples/sec. 375.788 ms/step.
Train [24/40]. 127.73 samples/sec. 375.807 ms/step.
Train [32/40]. 127.73 samples/sec. 375.787 ms/step.
Train [40/40]. 127.73 samples/sec. 375.789 ms/step.
Train benchmark of convformer_m36.sail_in1k done. 127.15 samples/sec, 375.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running inference benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 209.24 samples/sec. 1223.504 ms/step.
Infer [16/40]. 209.23 samples/sec. 1223.509 ms/step.
Infer [24/40]. 209.23 samples/sec. 1223.510 ms/step.
Infer [32/40]. 209.23 samples/sec. 1223.516 ms/step.
Infer [40/40]. 209.23 samples/sec. 1223.515 ms/step.
Inference benchmark of convformer_m36.sail_in1k_384 done. 209.22 samples/sec, 1223.52 ms/step
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.32 GiB is free. Including non-PyTorch memory, this process has 22.32 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 27.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 281.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 280.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 337.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 242.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 392.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 273.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 136.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 357.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convformer_m36.sail_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 42.64 samples/sec. 375.192 ms/step.
Train [16/40]. 42.63 samples/sec. 375.284 ms/step.
Train [24/40]. 42.61 samples/sec. 375.508 ms/step.
Train [32/40]. 42.60 samples/sec. 375.603 ms/step.
Train [40/40]. 42.59 samples/sec. 375.684 ms/step.
Train benchmark of convformer_m36.sail_in1k_384 done. 42.39 samples/sec, 375.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_m36.sail_in22k created, param count: 105090145
Running inference benchmark on convformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 615.91 samples/sec. 415.646 ms/step.
Infer [16/40]. 615.80 samples/sec. 415.722 ms/step.
Infer [24/40]. 615.69 samples/sec. 415.797 ms/step.
Infer [32/40]. 615.64 samples/sec. 415.828 ms/step.
Infer [40/40]. 615.61 samples/sec. 415.847 ms/step.
Inference benchmark of convformer_m36.sail_in22k done. 615.54 samples/sec, 415.85 ms/step
Model convformer_m36.sail_in22k created, param count: 105090145
Running train benchmark on convformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 430.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 27.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_m36.sail_in22k created, param count: 105090145
Running train benchmark on convformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 316.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_m36.sail_in22k created, param count: 105090145
Running train benchmark on convformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 128.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_m36.sail_in22k created, param count: 105090145
Running train benchmark on convformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 204.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 592.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_m36.sail_in22k created, param count: 105090145
Running train benchmark on convformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 643.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_m36.sail_in22k created, param count: 105090145
Running train benchmark on convformer_m36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 126.81 samples/sec. 378.526 ms/step.
Train [16/40]. 126.81 samples/sec. 378.519 ms/step.
Train [24/40]. 126.72 samples/sec. 378.796 ms/step.
Train [32/40]. 126.67 samples/sec. 378.947 ms/step.
Train [40/40]. 126.64 samples/sec. 379.025 ms/step.
Train benchmark of convformer_m36.sail_in22k done. 126.07 samples/sec, 379.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_m36.sail_in22k_ft_in1k created, param count: 57051640
Running inference benchmark on convformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 616.19 samples/sec. 415.454 ms/step.
Infer [16/40]. 616.16 samples/sec. 415.478 ms/step.
Infer [24/40]. 616.14 samples/sec. 415.493 ms/step.
Infer [32/40]. 616.13 samples/sec. 415.499 ms/step.
Infer [40/40]. 616.12 samples/sec. 415.501 ms/step.
Inference benchmark of convformer_m36.sail_in22k_ft_in1k done. 616.05 samples/sec, 415.50 ms/step
Model convformer_m36.sail_in22k_ft_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 622.06 MiB is free. Including non-PyTorch memory, this process has 23.03 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 18.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_m36.sail_in22k_ft_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 232.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_m36.sail_in22k_ft_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 96.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_m36.sail_in22k_ft_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 504.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_m36.sail_in22k_ft_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 661.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_m36.sail_in22k_ft_in1k created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 127.70 samples/sec. 375.871 ms/step.
Train [16/40]. 127.69 samples/sec. 375.904 ms/step.
Train [24/40]. 127.70 samples/sec. 375.877 ms/step.
Train [32/40]. 127.71 samples/sec. 375.857 ms/step.
Train [40/40]. 127.71 samples/sec. 375.848 ms/step.
Train benchmark of convformer_m36.sail_in22k_ft_in1k done. 127.14 samples/sec, 375.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running inference benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 209.24 samples/sec. 1223.462 ms/step.
Infer [16/40]. 209.24 samples/sec. 1223.477 ms/step.
Infer [24/40]. 209.24 samples/sec. 1223.482 ms/step.
Infer [32/40]. 209.24 samples/sec. 1223.491 ms/step.
Infer [40/40]. 209.24 samples/sec. 1223.492 ms/step.
Inference benchmark of convformer_m36.sail_in22k_ft_in1k_384 done. 209.23 samples/sec, 1223.49 ms/step
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.32 GiB is free. Including non-PyTorch memory, this process has 22.32 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 27.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 281.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 280.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 337.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 242.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 392.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 273.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 136.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 349.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convformer_m36.sail_in22k_ft_in1k_384 created, param count: 57051640
Running train benchmark on convformer_m36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 42.57 samples/sec. 375.827 ms/step.
Train [16/40]. 42.57 samples/sec. 375.852 ms/step.
Train [24/40]. 42.57 samples/sec. 375.865 ms/step.
Train [32/40]. 42.57 samples/sec. 375.859 ms/step.
Train [40/40]. 42.57 samples/sec. 375.848 ms/step.
Train benchmark of convformer_m36.sail_in22k_ft_in1k_384 done. 42.38 samples/sec, 375.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s18.sail_in1k created, param count: 26774448
Running inference benchmark on convformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1601.38 samples/sec. 159.862 ms/step.
Infer [16/40]. 1601.38 samples/sec. 159.862 ms/step.
Infer [24/40]. 1601.37 samples/sec. 159.863 ms/step.
Infer [32/40]. 1601.38 samples/sec. 159.862 ms/step.
Infer [40/40]. 1601.38 samples/sec. 159.862 ms/step.
Inference benchmark of convformer_s18.sail_in1k done. 1601.04 samples/sec, 159.86 ms/step
Model convformer_s18.sail_in1k created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 236.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s18.sail_in1k created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 110.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s18.sail_in1k created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 350.91 samples/sec. 364.766 ms/step.
Train [16/40]. 350.87 samples/sec. 364.808 ms/step.
Train [24/40]. 350.85 samples/sec. 364.830 ms/step.
Train [32/40]. 350.85 samples/sec. 364.829 ms/step.
Train [40/40]. 350.84 samples/sec. 364.843 ms/step.
Train benchmark of convformer_s18.sail_in1k done. 349.77 samples/sec, 364.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s18.sail_in1k_384 created, param count: 26774448
Running inference benchmark on convformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 545.65 samples/sec. 469.165 ms/step.
Infer [16/40]. 545.65 samples/sec. 469.169 ms/step.
Infer [24/40]. 545.64 samples/sec. 469.171 ms/step.
Infer [32/40]. 545.64 samples/sec. 469.170 ms/step.
Infer [40/40]. 545.64 samples/sec. 469.173 ms/step.
Inference benchmark of convformer_s18.sail_in1k_384 done. 545.59 samples/sec, 469.17 ms/step
Model convformer_s18.sail_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.62 GiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.44 GiB is allocated by PyTorch, and 89.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s18.sail_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 145.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s18.sail_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 868.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 261.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_s18.sail_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 205.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_s18.sail_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 161.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_s18.sail_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 117.52 samples/sec. 408.428 ms/step.
Train [16/40]. 117.53 samples/sec. 408.399 ms/step.
Train [24/40]. 117.53 samples/sec. 408.399 ms/step.
Train [32/40]. 117.53 samples/sec. 408.394 ms/step.
Train [40/40]. 117.53 samples/sec. 408.397 ms/step.
Train benchmark of convformer_s18.sail_in1k_384 done. 117.21 samples/sec, 408.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s18.sail_in22k created, param count: 69477657
Running inference benchmark on convformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1597.72 samples/sec. 160.228 ms/step.
Infer [16/40]. 1597.81 samples/sec. 160.220 ms/step.
Infer [24/40]. 1597.81 samples/sec. 160.219 ms/step.
Infer [32/40]. 1597.80 samples/sec. 160.220 ms/step.
Infer [40/40]. 1597.83 samples/sec. 160.218 ms/step.
Inference benchmark of convformer_s18.sail_in22k done. 1597.48 samples/sec, 160.22 ms/step
Model convformer_s18.sail_in22k created, param count: 69477657
Running train benchmark on convformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 220.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 245.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s18.sail_in22k created, param count: 69477657
Running train benchmark on convformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 189.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s18.sail_in22k created, param count: 69477657
Running train benchmark on convformer_s18.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 348.10 samples/sec. 367.714 ms/step.
Train [16/40]. 348.09 samples/sec. 367.720 ms/step.
Train [24/40]. 348.09 samples/sec. 367.723 ms/step.
Train [32/40]. 348.08 samples/sec. 367.731 ms/step.
Train [40/40]. 348.09 samples/sec. 367.725 ms/step.
Train benchmark of convformer_s18.sail_in22k done. 347.01 samples/sec, 367.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s18.sail_in22k_ft_in1k created, param count: 26774448
Running inference benchmark on convformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1601.86 samples/sec. 159.814 ms/step.
Infer [16/40]. 1601.49 samples/sec. 159.852 ms/step.
Infer [24/40]. 1601.35 samples/sec. 159.865 ms/step.
Infer [32/40]. 1601.31 samples/sec. 159.869 ms/step.
Infer [40/40]. 1601.26 samples/sec. 159.874 ms/step.
Inference benchmark of convformer_s18.sail_in22k_ft_in1k done. 1600.93 samples/sec, 159.87 ms/step
Model convformer_s18.sail_in22k_ft_in1k created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 236.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s18.sail_in22k_ft_in1k created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 175.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s18.sail_in22k_ft_in1k created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 350.81 samples/sec. 364.872 ms/step.
Train [16/40]. 350.81 samples/sec. 364.868 ms/step.
Train [24/40]. 350.79 samples/sec. 364.892 ms/step.
Train [32/40]. 350.80 samples/sec. 364.882 ms/step.
Train [40/40]. 350.81 samples/sec. 364.874 ms/step.
Train benchmark of convformer_s18.sail_in22k_ft_in1k done. 349.71 samples/sec, 364.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s18.sail_in22k_ft_in1k_384 created, param count: 26774448
Running inference benchmark on convformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 545.65 samples/sec. 469.163 ms/step.
Infer [16/40]. 545.67 samples/sec. 469.152 ms/step.
Infer [24/40]. 545.67 samples/sec. 469.151 ms/step.
Infer [32/40]. 545.67 samples/sec. 469.152 ms/step.
Infer [40/40]. 545.66 samples/sec. 469.156 ms/step.
Inference benchmark of convformer_s18.sail_in22k_ft_in1k_384 done. 545.61 samples/sec, 469.16 ms/step
Model convformer_s18.sail_in22k_ft_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.62 GiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.44 GiB is allocated by PyTorch, and 89.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s18.sail_in22k_ft_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 145.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s18.sail_in22k_ft_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 868.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 261.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_s18.sail_in22k_ft_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 205.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_s18.sail_in22k_ft_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 141.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_s18.sail_in22k_ft_in1k_384 created, param count: 26774448
Running train benchmark on convformer_s18.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 117.61 samples/sec. 408.136 ms/step.
Train [16/40]. 117.58 samples/sec. 408.217 ms/step.
Train [24/40]. 117.59 samples/sec. 408.195 ms/step.
Train [32/40]. 117.59 samples/sec. 408.205 ms/step.
Train [40/40]. 117.59 samples/sec. 408.194 ms/step.
Train benchmark of convformer_s18.sail_in22k_ft_in1k_384 done. 117.28 samples/sec, 408.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s36.sail_in1k created, param count: 40012152
Running inference benchmark on convformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 846.28 samples/sec. 302.500 ms/step.
Infer [16/40]. 846.28 samples/sec. 302.499 ms/step.
Infer [24/40]. 846.29 samples/sec. 302.497 ms/step.
Infer [32/40]. 846.29 samples/sec. 302.499 ms/step.
Infer [40/40]. 846.28 samples/sec. 302.500 ms/step.
Inference benchmark of convformer_s36.sail_in1k done. 846.16 samples/sec, 302.50 ms/step
Model convformer_s36.sail_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 297.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s36.sail_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 464.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s36.sail_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 527.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_s36.sail_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 278.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_s36.sail_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 181.63 samples/sec. 352.366 ms/step.
Train [16/40]. 181.62 samples/sec. 352.386 ms/step.
Train [24/40]. 181.62 samples/sec. 352.379 ms/step.
Train [32/40]. 181.62 samples/sec. 352.393 ms/step.
Train [40/40]. 181.61 samples/sec. 352.394 ms/step.
Train benchmark of convformer_s36.sail_in1k done. 180.72 samples/sec, 352.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running inference benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 288.80 samples/sec. 886.426 ms/step.
Infer [16/40]. 288.80 samples/sec. 886.429 ms/step.
Infer [24/40]. 288.79 samples/sec. 886.443 ms/step.
Infer [32/40]. 288.79 samples/sec. 886.444 ms/step.
Infer [40/40]. 288.79 samples/sec. 886.448 ms/step.
Inference benchmark of convformer_s36.sail_in1k_384 done. 288.78 samples/sec, 886.45 ms/step
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 22.06 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 84.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 193.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 786.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 293.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 288.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 284.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 193.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 100.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 410.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 519.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convformer_s36.sail_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 60.53 samples/sec. 396.525 ms/step.
Train [16/40]. 60.53 samples/sec. 396.525 ms/step.
Train [24/40]. 60.53 samples/sec. 396.515 ms/step.
Train [32/40]. 60.53 samples/sec. 396.504 ms/step.
Train [40/40]. 60.53 samples/sec. 396.498 ms/step.
Train benchmark of convformer_s36.sail_in1k_384 done. 60.27 samples/sec, 396.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s36.sail_in22k created, param count: 82715361
Running inference benchmark on convformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 845.35 samples/sec. 302.831 ms/step.
Infer [16/40]. 845.35 samples/sec. 302.835 ms/step.
Infer [24/40]. 845.34 samples/sec. 302.835 ms/step.
Infer [32/40]. 845.34 samples/sec. 302.838 ms/step.
Infer [40/40]. 845.34 samples/sec. 302.837 ms/step.
Inference benchmark of convformer_s36.sail_in22k done. 845.21 samples/sec, 302.84 ms/step
Model convformer_s36.sail_in22k created, param count: 82715361
Running train benchmark on convformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 110.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s36.sail_in22k created, param count: 82715361
Running train benchmark on convformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 256.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 152.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s36.sail_in22k created, param count: 82715361
Running train benchmark on convformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 513.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_s36.sail_in22k created, param count: 82715361
Running train benchmark on convformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 362.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_s36.sail_in22k created, param count: 82715361
Running train benchmark on convformer_s36.sail_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 180.36 samples/sec. 354.847 ms/step.
Train [16/40]. 180.36 samples/sec. 354.841 ms/step.
Train [24/40]. 180.35 samples/sec. 354.858 ms/step.
Train [32/40]. 180.35 samples/sec. 354.860 ms/step.
Train [40/40]. 180.35 samples/sec. 354.870 ms/step.
Train benchmark of convformer_s36.sail_in22k done. 179.47 samples/sec, 354.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s36.sail_in22k_ft_in1k created, param count: 40012152
Running inference benchmark on convformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 846.25 samples/sec. 302.510 ms/step.
Infer [16/40]. 846.25 samples/sec. 302.510 ms/step.
Infer [24/40]. 846.26 samples/sec. 302.508 ms/step.
Infer [32/40]. 846.25 samples/sec. 302.510 ms/step.
Infer [40/40]. 846.25 samples/sec. 302.511 ms/step.
Inference benchmark of convformer_s36.sail_in22k_ft_in1k done. 846.13 samples/sec, 302.51 ms/step
Model convformer_s36.sail_in22k_ft_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 297.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s36.sail_in22k_ft_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 137.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s36.sail_in22k_ft_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 527.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_s36.sail_in22k_ft_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 300.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_s36.sail_in22k_ft_in1k created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 181.68 samples/sec. 352.269 ms/step.
Train [16/40]. 181.67 samples/sec. 352.289 ms/step.
Train [24/40]. 181.67 samples/sec. 352.289 ms/step.
Train [32/40]. 181.67 samples/sec. 352.295 ms/step.
Train [40/40]. 181.66 samples/sec. 352.303 ms/step.
Train benchmark of convformer_s36.sail_in22k_ft_in1k done. 180.77 samples/sec, 352.30 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running inference benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 288.79 samples/sec. 886.447 ms/step.
Infer [16/40]. 288.79 samples/sec. 886.448 ms/step.
Infer [24/40]. 288.79 samples/sec. 886.448 ms/step.
Infer [32/40]. 288.79 samples/sec. 886.454 ms/step.
Infer [40/40]. 288.79 samples/sec. 886.456 ms/step.
Inference benchmark of convformer_s36.sail_in22k_ft_in1k_384 done. 288.77 samples/sec, 886.46 ms/step
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 22.06 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 84.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 193.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 786.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 293.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 288.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 284.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 193.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 100.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 410.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 520.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convformer_s36.sail_in22k_ft_in1k_384 created, param count: 40012152
Running train benchmark on convformer_s36.sail_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 60.50 samples/sec. 396.695 ms/step.
Train [16/40]. 60.50 samples/sec. 396.669 ms/step.
Train [24/40]. 60.50 samples/sec. 396.673 ms/step.
Train [32/40]. 60.50 samples/sec. 396.662 ms/step.
Train [40/40]. 60.50 samples/sec. 396.665 ms/step.
Train benchmark of convformer_s36.sail_in22k_ft_in1k_384 done. 60.24 samples/sec, 396.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convit_base.fb_in1k created, param count: 86540040
Running inference benchmark on convit_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 736.53 samples/sec. 347.576 ms/step.
Infer [16/40]. 736.54 samples/sec. 347.570 ms/step.
Infer [24/40]. 736.55 samples/sec. 347.566 ms/step.
Infer [32/40]. 736.55 samples/sec. 347.566 ms/step.
Infer [40/40]. 736.51 samples/sec. 347.587 ms/step.
Inference benchmark of convit_base.fb_in1k done. 736.41 samples/sec, 347.59 ms/step
Model convit_base.fb_in1k created, param count: 86540040
Running train benchmark on convit_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 602.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 274.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convit_base.fb_in1k created, param count: 86540040
Running train benchmark on convit_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 360.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 433.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convit_base.fb_in1k created, param count: 86540040
Running train benchmark on convit_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 406.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convit_base.fb_in1k created, param count: 86540040
Running train benchmark on convit_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 233.40 samples/sec. 411.305 ms/step.
Train [16/40]. 233.40 samples/sec. 411.304 ms/step.
Train [24/40]. 233.40 samples/sec. 411.303 ms/step.
Train [32/40]. 233.40 samples/sec. 411.307 ms/step.
Train [40/40]. 233.40 samples/sec. 411.306 ms/step.
Train benchmark of convit_base.fb_in1k done. 232.60 samples/sec, 411.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convit_small.fb_in1k created, param count: 27777322
Running inference benchmark on convit_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1446.12 samples/sec. 177.025 ms/step.
Infer [16/40]. 1446.07 samples/sec. 177.031 ms/step.
Infer [24/40]. 1446.10 samples/sec. 177.028 ms/step.
Infer [32/40]. 1446.11 samples/sec. 177.027 ms/step.
Infer [40/40]. 1446.09 samples/sec. 177.029 ms/step.
Inference benchmark of convit_small.fb_in1k done. 1445.81 samples/sec, 177.03 ms/step
Model convit_small.fb_in1k created, param count: 27777322
Running train benchmark on convit_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 145.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convit_small.fb_in1k created, param count: 27777322
Running train benchmark on convit_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 254.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 315.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convit_small.fb_in1k created, param count: 27777322
Running train benchmark on convit_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 454.79 samples/sec. 281.447 ms/step.
Train [16/40]. 454.78 samples/sec. 281.453 ms/step.
Train [24/40]. 454.79 samples/sec. 281.447 ms/step.
Train [32/40]. 454.79 samples/sec. 281.448 ms/step.
Train [40/40]. 454.79 samples/sec. 281.449 ms/step.
Train benchmark of convit_small.fb_in1k done. 452.64 samples/sec, 281.45 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convit_tiny.fb_in1k created, param count: 5710512
Running inference benchmark on convit_tiny.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3487.20 samples/sec. 73.411 ms/step.
Infer [16/40]. 3486.98 samples/sec. 73.416 ms/step.
Infer [24/40]. 3486.93 samples/sec. 73.417 ms/step.
Infer [32/40]. 3486.89 samples/sec. 73.418 ms/step.
Infer [40/40]. 3486.89 samples/sec. 73.418 ms/step.
Inference benchmark of convit_tiny.fb_in1k done. 3485.69 samples/sec, 73.42 ms/step
Model convit_tiny.fb_in1k created, param count: 5710512
Running train benchmark on convit_tiny.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1120.67 samples/sec. 228.436 ms/step.
Train [16/40]. 1120.66 samples/sec. 228.437 ms/step.
Train [24/40]. 1120.67 samples/sec. 228.435 ms/step.
Train [32/40]. 1120.68 samples/sec. 228.434 ms/step.
Train [40/40]. 1120.70 samples/sec. 228.428 ms/step.
Train benchmark of convit_tiny.fb_in1k done. 1114.45 samples/sec, 228.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convmixer_768_32.in1k created, param count: 21110248
Running inference benchmark on convmixer_768_32.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 369.38 samples/sec. 693.045 ms/step.
Infer [16/40]. 369.28 samples/sec. 693.239 ms/step.
Infer [24/40]. 369.25 samples/sec. 693.294 ms/step.
Infer [32/40]. 369.24 samples/sec. 693.324 ms/step.
Infer [40/40]. 369.23 samples/sec. 693.342 ms/step.
Inference benchmark of convmixer_768_32.in1k done. 369.20 samples/sec, 693.34 ms/step
Model convmixer_768_32.in1k created, param count: 21110248
Running train benchmark on convmixer_768_32.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 360.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 58.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convmixer_768_32.in1k created, param count: 21110248
Running train benchmark on convmixer_768_32.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 318.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 138.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convmixer_768_32.in1k created, param count: 21110248
Running train benchmark on convmixer_768_32.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 154.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convmixer_768_32.in1k created, param count: 21110248
Running train benchmark on convmixer_768_32.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 174.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convmixer_768_32.in1k created, param count: 21110248
Running train benchmark on convmixer_768_32.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 193.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convmixer_768_32.in1k created, param count: 21110248
Running train benchmark on convmixer_768_32.in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 114.04 samples/sec. 420.894 ms/step.
Train [16/40]. 114.04 samples/sec. 420.904 ms/step.
Train [24/40]. 114.04 samples/sec. 420.913 ms/step.
Train [32/40]. 114.03 samples/sec. 420.930 ms/step.
Train [40/40]. 114.02 samples/sec. 420.983 ms/step.
Train benchmark of convmixer_768_32.in1k done. 113.67 samples/sec, 420.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convmixer_1024_20_ks9_p14.in1k created, param count: 24383464
Running inference benchmark on convmixer_1024_20_ks9_p14.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1499.52 samples/sec. 170.721 ms/step.
Infer [16/40]. 1499.52 samples/sec. 170.722 ms/step.
Infer [24/40]. 1499.53 samples/sec. 170.720 ms/step.
Infer [32/40]. 1499.56 samples/sec. 170.717 ms/step.
Infer [40/40]. 1499.56 samples/sec. 170.716 ms/step.
Inference benchmark of convmixer_1024_20_ks9_p14.in1k done. 1499.23 samples/sec, 170.72 ms/step
Model convmixer_1024_20_ks9_p14.in1k created, param count: 24383464
Running train benchmark on convmixer_1024_20_ks9_p14.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 46.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convmixer_1024_20_ks9_p14.in1k created, param count: 24383464
Running train benchmark on convmixer_1024_20_ks9_p14.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 147.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convmixer_1024_20_ks9_p14.in1k created, param count: 24383464
Running train benchmark on convmixer_1024_20_ks9_p14.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 428.33 samples/sec. 298.836 ms/step.
Train [16/40]. 428.07 samples/sec. 299.013 ms/step.
Train [24/40]. 427.92 samples/sec. 299.123 ms/step.
Train [32/40]. 427.83 samples/sec. 299.183 ms/step.
Train [40/40]. 427.80 samples/sec. 299.208 ms/step.
Train benchmark of convmixer_1024_20_ks9_p14.in1k done. 426.42 samples/sec, 299.21 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convmixer_1536_20.in1k created, param count: 51625960
Running inference benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 230.75 samples/sec. 1109.417 ms/step.
Infer [16/40]. 230.79 samples/sec. 1109.231 ms/step.
Infer [24/40]. 230.79 samples/sec. 1109.235 ms/step.
Infer [32/40]. 230.79 samples/sec. 1109.225 ms/step.
Infer [40/40]. 230.80 samples/sec. 1109.174 ms/step.
Inference benchmark of convmixer_1536_20.in1k done. 230.79 samples/sec, 1109.17 ms/step
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 26.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 280.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 59.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 300.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 76.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 316.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 78.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 318.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 94.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 90.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 137.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convmixer_1536_20.in1k created, param count: 51625960
Running train benchmark on convmixer_1536_20.in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 69.26 samples/sec. 346.531 ms/step.
Train [16/40]. 69.25 samples/sec. 346.576 ms/step.
Train [24/40]. 69.24 samples/sec. 346.616 ms/step.
Train [32/40]. 69.23 samples/sec. 346.673 ms/step.
Train [40/40]. 69.23 samples/sec. 346.687 ms/step.
Train benchmark of convmixer_1536_20.in1k done. 69.04 samples/sec, 346.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_atto.d2_in1k created, param count: 3695520
Running inference benchmark on convnext_atto.d2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 4708.82 samples/sec. 54.366 ms/step.
Infer [16/40]. 4708.67 samples/sec. 54.368 ms/step.
Infer [24/40]. 4708.63 samples/sec. 54.368 ms/step.
Infer [32/40]. 4708.65 samples/sec. 54.368 ms/step.
Infer [40/40]. 4708.63 samples/sec. 54.368 ms/step.
Inference benchmark of convnext_atto.d2_in1k done. 4706.44 samples/sec, 54.37 ms/step
Model convnext_atto.d2_in1k created, param count: 3695520
Running train benchmark on convnext_atto.d2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1268.77 samples/sec. 201.771 ms/step.
Train [16/40]. 1269.06 samples/sec. 201.724 ms/step.
Train [24/40]. 1268.90 samples/sec. 201.749 ms/step.
Train [32/40]. 1268.97 samples/sec. 201.738 ms/step.
Train [40/40]. 1268.79 samples/sec. 201.767 ms/step.
Train benchmark of convnext_atto.d2_in1k done. 1264.87 samples/sec, 201.77 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_atto_ols.a2_in1k created, param count: 3702912
Running inference benchmark on convnext_atto_ols.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 4479.99 samples/sec. 57.143 ms/step.
Infer [16/40]. 4479.97 samples/sec. 57.143 ms/step.
Infer [24/40]. 4480.01 samples/sec. 57.143 ms/step.
Infer [32/40]. 4479.99 samples/sec. 57.143 ms/step.
Infer [40/40]. 4480.05 samples/sec. 57.142 ms/step.
Inference benchmark of convnext_atto_ols.a2_in1k done. 4478.07 samples/sec, 57.14 ms/step
Model convnext_atto_ols.a2_in1k created, param count: 3702912
Running train benchmark on convnext_atto_ols.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1212.59 samples/sec. 211.118 ms/step.
Train [16/40]. 1212.97 samples/sec. 211.053 ms/step.
Train [24/40]. 1212.99 samples/sec. 211.048 ms/step.
Train [32/40]. 1213.09 samples/sec. 211.032 ms/step.
Train [40/40]. 1213.13 samples/sec. 211.025 ms/step.
Train benchmark of convnext_atto_ols.a2_in1k done. 1209.33 samples/sec, 211.03 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laion2b created, param count: 88222464
Running inference benchmark on convnext_base.clip_laion2b for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 739.69 samples/sec. 346.093 ms/step.
Infer [16/40]. 739.69 samples/sec. 346.093 ms/step.
Infer [24/40]. 739.69 samples/sec. 346.093 ms/step.
Infer [32/40]. 739.68 samples/sec. 346.097 ms/step.
Infer [40/40]. 739.67 samples/sec. 346.098 ms/step.
Inference benchmark of convnext_base.clip_laion2b done. 739.58 samples/sec, 346.10 ms/step
Model convnext_base.clip_laion2b created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 7.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laion2b created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 72.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laion2b created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 85.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laion2b created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 90.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laion2b created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 174.88 samples/sec. 365.966 ms/step.
Train [16/40]. 174.91 samples/sec. 365.908 ms/step.
Train [24/40]. 174.90 samples/sec. 365.931 ms/step.
Train [32/40]. 174.91 samples/sec. 365.904 ms/step.
Train [40/40]. 174.90 samples/sec. 365.926 ms/step.
Train benchmark of convnext_base.clip_laion2b done. 174.29 samples/sec, 365.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laion2b_augreg created, param count: 88222464
Running inference benchmark on convnext_base.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 739.34 samples/sec. 346.256 ms/step.
Infer [16/40]. 739.31 samples/sec. 346.267 ms/step.
Infer [24/40]. 739.31 samples/sec. 346.268 ms/step.
Infer [32/40]. 739.31 samples/sec. 346.270 ms/step.
Infer [40/40]. 739.31 samples/sec. 346.270 ms/step.
Inference benchmark of convnext_base.clip_laion2b_augreg done. 739.21 samples/sec, 346.27 ms/step
Model convnext_base.clip_laion2b_augreg created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 7.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laion2b_augreg created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 88.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laion2b_augreg created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 85.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laion2b_augreg created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 90.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laion2b_augreg created, param count: 88222464
Running train benchmark on convnext_base.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 174.67 samples/sec. 366.396 ms/step.
Train [16/40]. 174.68 samples/sec. 366.379 ms/step.
Train [24/40]. 174.66 samples/sec. 366.419 ms/step.
Train [32/40]. 174.67 samples/sec. 366.398 ms/step.
Train [40/40]. 174.67 samples/sec. 366.411 ms/step.
Train benchmark of convnext_base.clip_laion2b_augreg done. 174.06 samples/sec, 366.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laion2b_augreg_ft_in1k created, param count: 88591464
Running inference benchmark on convnext_base.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 739.57 samples/sec. 346.145 ms/step.
Infer [16/40]. 739.58 samples/sec. 346.143 ms/step.
Infer [24/40]. 739.59 samples/sec. 346.139 ms/step.
Infer [32/40]. 739.58 samples/sec. 346.143 ms/step.
Infer [40/40]. 739.58 samples/sec. 346.143 ms/step.
Inference benchmark of convnext_base.clip_laion2b_augreg_ft_in1k done. 739.49 samples/sec, 346.14 ms/step
Model convnext_base.clip_laion2b_augreg_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 25.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 86.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 84.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 174.70 samples/sec. 366.336 ms/step.
Train [16/40]. 174.70 samples/sec. 366.340 ms/step.
Train [24/40]. 174.71 samples/sec. 366.331 ms/step.
Train [32/40]. 174.71 samples/sec. 366.326 ms/step.
Train [40/40]. 174.70 samples/sec. 366.334 ms/step.
Train benchmark of convnext_base.clip_laion2b_augreg_ft_in1k done. 174.10 samples/sec, 366.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laion2b_augreg_ft_in12k created, param count: 99682989
Running inference benchmark on convnext_base.clip_laion2b_augreg_ft_in12k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 739.01 samples/sec. 346.408 ms/step.
Infer [16/40]. 739.01 samples/sec. 346.409 ms/step.
Infer [24/40]. 739.01 samples/sec. 346.407 ms/step.
Infer [32/40]. 739.01 samples/sec. 346.411 ms/step.
Infer [40/40]. 739.00 samples/sec. 346.412 ms/step.
Inference benchmark of convnext_base.clip_laion2b_augreg_ft_in12k done. 738.90 samples/sec, 346.41 ms/step
Model convnext_base.clip_laion2b_augreg_ft_in12k created, param count: 99682989
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.12 GiB is allocated by PyTorch, and 11.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k created, param count: 99682989
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 92.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k created, param count: 99682989
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 86.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k created, param count: 99682989
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 76.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k created, param count: 99682989
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 174.45 samples/sec. 366.875 ms/step.
Train [16/40]. 174.45 samples/sec. 366.867 ms/step.
Train [24/40]. 174.46 samples/sec. 366.855 ms/step.
Train [32/40]. 174.44 samples/sec. 366.888 ms/step.
Train [40/40]. 174.44 samples/sec. 366.896 ms/step.
Train benchmark of convnext_base.clip_laion2b_augreg_ft_in12k done. 173.82 samples/sec, 366.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k created, param count: 88591464
Running inference benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 739.24 samples/sec. 346.302 ms/step.
Infer [16/40]. 739.27 samples/sec. 346.289 ms/step.
Infer [24/40]. 739.27 samples/sec. 346.287 ms/step.
Infer [32/40]. 739.27 samples/sec. 346.289 ms/step.
Infer [40/40]. 739.26 samples/sec. 346.291 ms/step.
Inference benchmark of convnext_base.clip_laion2b_augreg_ft_in12k_in1k done. 739.17 samples/sec, 346.29 ms/step
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 25.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 86.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 84.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 174.69 samples/sec. 366.358 ms/step.
Train [16/40]. 174.67 samples/sec. 366.412 ms/step.
Train [24/40]. 174.67 samples/sec. 366.410 ms/step.
Train [32/40]. 174.66 samples/sec. 366.426 ms/step.
Train [40/40]. 174.67 samples/sec. 366.407 ms/step.
Train benchmark of convnext_base.clip_laion2b_augreg_ft_in12k_in1k done. 174.06 samples/sec, 366.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running inference benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 327.57 samples/sec. 781.512 ms/step.
Infer [16/40]. 327.54 samples/sec. 781.586 ms/step.
Infer [24/40]. 327.53 samples/sec. 781.609 ms/step.
Infer [32/40]. 327.53 samples/sec. 781.619 ms/step.
Infer [40/40]. 327.52 samples/sec. 781.628 ms/step.
Inference benchmark of convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 done. 327.50 samples/sec, 781.63 ms/step
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.30 GiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 29.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 274.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 247.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 170.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 299.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 83.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 54.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 77.63 samples/sec. 412.229 ms/step.
Train [16/40]. 77.62 samples/sec. 412.254 ms/step.
Train [24/40]. 77.62 samples/sec. 412.239 ms/step.
Train [32/40]. 77.62 samples/sec. 412.245 ms/step.
Train [40/40]. 77.62 samples/sec. 412.249 ms/step.
Train benchmark of convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384 done. 77.38 samples/sec, 412.25 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laiona created, param count: 88222464
Running inference benchmark on convnext_base.clip_laiona for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 739.59 samples/sec. 346.140 ms/step.
Infer [16/40]. 739.59 samples/sec. 346.139 ms/step.
Infer [24/40]. 739.60 samples/sec. 346.134 ms/step.
Infer [32/40]. 739.59 samples/sec. 346.138 ms/step.
Infer [40/40]. 739.59 samples/sec. 346.137 ms/step.
Inference benchmark of convnext_base.clip_laiona done. 739.50 samples/sec, 346.14 ms/step
Model convnext_base.clip_laiona created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 7.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laiona created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 88.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laiona created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 85.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laiona created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 90.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laiona created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 174.77 samples/sec. 366.194 ms/step.
Train [16/40]. 174.77 samples/sec. 366.189 ms/step.
Train [24/40]. 174.76 samples/sec. 366.223 ms/step.
Train [32/40]. 174.73 samples/sec. 366.269 ms/step.
Train [40/40]. 174.73 samples/sec. 366.282 ms/step.
Train benchmark of convnext_base.clip_laiona done. 174.12 samples/sec, 366.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laiona_320 created, param count: 88222464
Running inference benchmark on convnext_base.clip_laiona_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 469.29 samples/sec. 545.509 ms/step.
Infer [16/40]. 469.27 samples/sec. 545.529 ms/step.
Infer [24/40]. 469.27 samples/sec. 545.528 ms/step.
Infer [32/40]. 469.27 samples/sec. 545.531 ms/step.
Infer [40/40]. 469.27 samples/sec. 545.531 ms/step.
Inference benchmark of convnext_base.clip_laiona_320 done. 469.23 samples/sec, 545.53 ms/step
Model convnext_base.clip_laiona_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 586.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 15.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laiona_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_320 for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 186.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laiona_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_320 for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 83.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laiona_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_320 for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 30.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laiona_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_320 for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 96.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_base.clip_laiona_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_320 for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 111.68 samples/sec. 429.815 ms/step.
Train [16/40]. 111.67 samples/sec. 429.845 ms/step.
Train [24/40]. 111.67 samples/sec. 429.846 ms/step.
Train [32/40]. 111.67 samples/sec. 429.836 ms/step.
Train [40/40]. 111.67 samples/sec. 429.824 ms/step.
Train benchmark of convnext_base.clip_laiona_320 done. 111.34 samples/sec, 429.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laiona_augreg_320 created, param count: 88222464
Running inference benchmark on convnext_base.clip_laiona_augreg_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 469.09 samples/sec. 545.735 ms/step.
Infer [16/40]. 469.09 samples/sec. 545.733 ms/step.
Infer [24/40]. 469.09 samples/sec. 545.740 ms/step.
Infer [32/40]. 469.08 samples/sec. 545.744 ms/step.
Infer [40/40]. 469.08 samples/sec. 545.744 ms/step.
Inference benchmark of convnext_base.clip_laiona_augreg_320 done. 469.04 samples/sec, 545.74 ms/step
Model convnext_base.clip_laiona_augreg_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_augreg_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 586.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 15.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laiona_augreg_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_augreg_320 for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 218.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laiona_augreg_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_augreg_320 for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 98.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laiona_augreg_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_augreg_320 for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 30.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laiona_augreg_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_augreg_320 for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 96.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_base.clip_laiona_augreg_320 created, param count: 88222464
Running train benchmark on convnext_base.clip_laiona_augreg_320 for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 111.86 samples/sec. 429.107 ms/step.
Train [16/40]. 111.84 samples/sec. 429.180 ms/step.
Train [24/40]. 111.84 samples/sec. 429.196 ms/step.
Train [32/40]. 111.83 samples/sec. 429.213 ms/step.
Train [40/40]. 111.83 samples/sec. 429.217 ms/step.
Train benchmark of convnext_base.clip_laiona_augreg_320 done. 111.48 samples/sec, 429.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running inference benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 327.55 samples/sec. 781.557 ms/step.
Infer [16/40]. 327.55 samples/sec. 781.565 ms/step.
Infer [24/40]. 327.55 samples/sec. 781.567 ms/step.
Infer [32/40]. 327.55 samples/sec. 781.569 ms/step.
Infer [40/40]. 327.54 samples/sec. 781.575 ms/step.
Inference benchmark of convnext_base.clip_laiona_augreg_ft_in1k_384 done. 327.52 samples/sec, 781.58 ms/step
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.30 GiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 29.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 274.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 247.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 170.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 299.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 83.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 54.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_base.clip_laiona_augreg_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.clip_laiona_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 77.49 samples/sec. 412.973 ms/step.
Train [16/40]. 77.49 samples/sec. 412.953 ms/step.
Train [24/40]. 77.49 samples/sec. 412.952 ms/step.
Train [32/40]. 77.49 samples/sec. 412.944 ms/step.
Train [40/40]. 77.49 samples/sec. 412.952 ms/step.
Train benchmark of convnext_base.clip_laiona_augreg_ft_in1k_384 done. 77.25 samples/sec, 412.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.fb_in1k created, param count: 88591464
Running inference benchmark on convnext_base.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 575.46 samples/sec. 444.864 ms/step.
Infer [16/40]. 575.44 samples/sec. 444.878 ms/step.
Infer [24/40]. 575.44 samples/sec. 444.874 ms/step.
Infer [32/40]. 575.44 samples/sec. 444.877 ms/step.
Infer [40/40]. 575.44 samples/sec. 444.879 ms/step.
Inference benchmark of convnext_base.fb_in1k done. 575.38 samples/sec, 444.88 ms/step
Model convnext_base.fb_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.25 GiB is free. Including non-PyTorch memory, this process has 21.39 GiB memory in use. Of the allocated memory 20.87 GiB is allocated by PyTorch, and 22.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.fb_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 352.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 168.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.fb_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 86.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.fb_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 116.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.fb_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 241.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_base.fb_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 137.36 samples/sec. 349.456 ms/step.
Train [16/40]. 137.36 samples/sec. 349.453 ms/step.
Train [24/40]. 137.35 samples/sec. 349.464 ms/step.
Train [32/40]. 137.35 samples/sec. 349.478 ms/step.
Train [40/40]. 137.34 samples/sec. 349.506 ms/step.
Train benchmark of convnext_base.fb_in1k done. 136.84 samples/sec, 349.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.fb_in22k created, param count: 109953489
Running inference benchmark on convnext_base.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 944.43 samples/sec. 271.063 ms/step.
Infer [16/40]. 944.41 samples/sec. 271.070 ms/step.
Infer [24/40]. 944.42 samples/sec. 271.067 ms/step.
Infer [32/40]. 944.43 samples/sec. 271.062 ms/step.
Infer [40/40]. 944.44 samples/sec. 271.061 ms/step.
Inference benchmark of convnext_base.fb_in22k done. 944.28 samples/sec, 271.06 ms/step
Model convnext_base.fb_in22k created, param count: 109953489
Running train benchmark on convnext_base.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.10 GiB is allocated by PyTorch, and 21.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.fb_in22k created, param count: 109953489
Running train benchmark on convnext_base.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.fb_in22k created, param count: 109953489
Running train benchmark on convnext_base.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 50.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.fb_in22k created, param count: 109953489
Running train benchmark on convnext_base.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 231.63 samples/sec. 414.456 ms/step.
Train [16/40]. 231.62 samples/sec. 414.469 ms/step.
Train [24/40]. 231.62 samples/sec. 414.468 ms/step.
Train [32/40]. 231.62 samples/sec. 414.464 ms/step.
Train [40/40]. 231.62 samples/sec. 414.464 ms/step.
Train benchmark of convnext_base.fb_in22k done. 230.90 samples/sec, 414.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.fb_in22k_ft_in1k created, param count: 88591464
Running inference benchmark on convnext_base.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 575.33 samples/sec. 444.965 ms/step.
Infer [16/40]. 575.32 samples/sec. 444.966 ms/step.
Infer [24/40]. 575.33 samples/sec. 444.961 ms/step.
Infer [32/40]. 575.33 samples/sec. 444.959 ms/step.
Infer [40/40]. 575.33 samples/sec. 444.959 ms/step.
Inference benchmark of convnext_base.fb_in22k_ft_in1k done. 575.27 samples/sec, 444.96 ms/step
Model convnext_base.fb_in22k_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.25 GiB is free. Including non-PyTorch memory, this process has 21.39 GiB memory in use. Of the allocated memory 20.87 GiB is allocated by PyTorch, and 22.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.fb_in22k_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 336.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 183.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.fb_in22k_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 102.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.fb_in22k_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 116.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.fb_in22k_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 241.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_base.fb_in22k_ft_in1k created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 137.56 samples/sec. 348.942 ms/step.
Train [16/40]. 137.56 samples/sec. 348.933 ms/step.
Train [24/40]. 137.55 samples/sec. 348.976 ms/step.
Train [32/40]. 137.53 samples/sec. 349.016 ms/step.
Train [40/40]. 137.53 samples/sec. 349.019 ms/step.
Train benchmark of convnext_base.fb_in22k_ft_in1k done. 137.03 samples/sec, 349.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running inference benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 327.56 samples/sec. 781.526 ms/step.
Infer [16/40]. 327.55 samples/sec. 781.553 ms/step.
Infer [24/40]. 327.55 samples/sec. 781.551 ms/step.
Infer [32/40]. 327.55 samples/sec. 781.550 ms/step.
Infer [40/40]. 327.55 samples/sec. 781.554 ms/step.
Inference benchmark of convnext_base.fb_in22k_ft_in1k_384 done. 327.53 samples/sec, 781.55 ms/step
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.30 GiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 29.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 274.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 247.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 170.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 299.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 83.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 54.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_base.fb_in22k_ft_in1k_384 created, param count: 88591464
Running train benchmark on convnext_base.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 77.54 samples/sec. 412.714 ms/step.
Train [16/40]. 77.53 samples/sec. 412.762 ms/step.
Train [24/40]. 77.53 samples/sec. 412.768 ms/step.
Train [32/40]. 77.52 samples/sec. 412.794 ms/step.
Train [40/40]. 77.52 samples/sec. 412.794 ms/step.
Train benchmark of convnext_base.fb_in22k_ft_in1k_384 done. 77.28 samples/sec, 412.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_femto.d1_in1k created, param count: 5217784
Running inference benchmark on convnext_femto.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 4015.56 samples/sec. 63.752 ms/step.
Infer [16/40]. 4015.52 samples/sec. 63.753 ms/step.
Infer [24/40]. 4015.64 samples/sec. 63.751 ms/step.
Infer [32/40]. 4015.60 samples/sec. 63.751 ms/step.
Infer [40/40]. 4015.64 samples/sec. 63.751 ms/step.
Inference benchmark of convnext_femto.d1_in1k done. 4014.02 samples/sec, 63.75 ms/step
Model convnext_femto.d1_in1k created, param count: 5217784
Running train benchmark on convnext_femto.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1081.21 samples/sec. 236.773 ms/step.
Train [16/40]. 1081.11 samples/sec. 236.794 ms/step.
Train [24/40]. 1080.63 samples/sec. 236.899 ms/step.
Train [32/40]. 1080.52 samples/sec. 236.923 ms/step.
Train [40/40]. 1080.54 samples/sec. 236.920 ms/step.
Train benchmark of convnext_femto.d1_in1k done. 1077.64 samples/sec, 236.92 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_femto_ols.d1_in1k created, param count: 5226520
Running inference benchmark on convnext_femto_ols.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 3876.26 samples/sec. 66.043 ms/step.
Infer [16/40]. 3875.96 samples/sec. 66.048 ms/step.
Infer [24/40]. 3875.88 samples/sec. 66.050 ms/step.
Infer [32/40]. 3875.87 samples/sec. 66.050 ms/step.
Infer [40/40]. 3875.82 samples/sec. 66.050 ms/step.
Inference benchmark of convnext_femto_ols.d1_in1k done. 3874.31 samples/sec, 66.05 ms/step
Model convnext_femto_ols.d1_in1k created, param count: 5226520
Running train benchmark on convnext_femto_ols.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1042.15 samples/sec. 245.645 ms/step.
Train [16/40]. 1042.52 samples/sec. 245.558 ms/step.
Train [24/40]. 1042.48 samples/sec. 245.569 ms/step.
Train [32/40]. 1042.48 samples/sec. 245.567 ms/step.
Train [40/40]. 1042.43 samples/sec. 245.580 ms/step.
Train benchmark of convnext_femto_ols.d1_in1k done. 1039.56 samples/sec, 245.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large.fb_in1k created, param count: 197767336
Running inference benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 332.25 samples/sec. 770.494 ms/step.
Infer [16/40]. 332.25 samples/sec. 770.499 ms/step.
Infer [24/40]. 332.25 samples/sec. 770.500 ms/step.
Infer [32/40]. 332.25 samples/sec. 770.498 ms/step.
Infer [40/40]. 332.25 samples/sec. 770.497 ms/step.
Inference benchmark of convnext_large.fb_in1k done. 332.23 samples/sec, 770.50 ms/step
Model convnext_large.fb_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.07 GiB is free. Including non-PyTorch memory, this process has 20.57 GiB memory in use. Of the allocated memory 20.00 GiB is allocated by PyTorch, and 70.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large.fb_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.01 GiB is free. Including non-PyTorch memory, this process has 21.63 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 240.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large.fb_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 145.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large.fb_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 258.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large.fb_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 192.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large.fb_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 298.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large.fb_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
Train [8/40]. 79.35 samples/sec. 403.274 ms/step.
Train [16/40]. 79.34 samples/sec. 403.307 ms/step.
Train [24/40]. 79.34 samples/sec. 403.317 ms/step.
Train [32/40]. 79.34 samples/sec. 403.323 ms/step.
Train [40/40]. 79.34 samples/sec. 403.322 ms/step.
Train benchmark of convnext_large.fb_in1k done. 79.10 samples/sec, 403.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large.fb_in22k created, param count: 229799953
Running inference benchmark on convnext_large.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 546.05 samples/sec. 468.822 ms/step.
Infer [16/40]. 546.00 samples/sec. 468.866 ms/step.
Infer [24/40]. 545.97 samples/sec. 468.887 ms/step.
Infer [32/40]. 545.97 samples/sec. 468.893 ms/step.
Infer [40/40]. 545.96 samples/sec. 468.897 ms/step.
Inference benchmark of convnext_large.fb_in22k done. 545.91 samples/sec, 468.90 ms/step
Model convnext_large.fb_in22k created, param count: 229799953
Running train benchmark on convnext_large.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 62.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large.fb_in22k created, param count: 229799953
Running train benchmark on convnext_large.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 91.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large.fb_in22k created, param count: 229799953
Running train benchmark on convnext_large.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 125.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large.fb_in22k created, param count: 229799953
Running train benchmark on convnext_large.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 193.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large.fb_in22k created, param count: 229799953
Running train benchmark on convnext_large.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 513.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large.fb_in22k created, param count: 229799953
Running train benchmark on convnext_large.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 126.40 samples/sec. 379.744 ms/step.
Train [16/40]. 126.39 samples/sec. 379.767 ms/step.
Train [24/40]. 126.39 samples/sec. 379.763 ms/step.
Train [32/40]. 126.39 samples/sec. 379.771 ms/step.
Train [40/40]. 126.39 samples/sec. 379.792 ms/step.
Train benchmark of convnext_large.fb_in22k done. 125.95 samples/sec, 379.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running inference benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 332.21 samples/sec. 770.602 ms/step.
Infer [16/40]. 332.21 samples/sec. 770.604 ms/step.
Infer [24/40]. 332.21 samples/sec. 770.596 ms/step.
Infer [32/40]. 332.21 samples/sec. 770.595 ms/step.
Infer [40/40]. 332.21 samples/sec. 770.592 ms/step.
Inference benchmark of convnext_large.fb_in22k_ft_in1k done. 332.19 samples/sec, 770.59 ms/step
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.07 GiB is free. Including non-PyTorch memory, this process has 20.57 GiB memory in use. Of the allocated memory 20.00 GiB is allocated by PyTorch, and 70.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.99 GiB is free. Including non-PyTorch memory, this process has 21.65 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 258.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 145.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 258.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 192.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 298.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large.fb_in22k_ft_in1k created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
Train [8/40]. 79.29 samples/sec. 403.598 ms/step.
Train [16/40]. 79.27 samples/sec. 403.667 ms/step.
Train [24/40]. 79.27 samples/sec. 403.691 ms/step.
Train [32/40]. 79.26 samples/sec. 403.709 ms/step.
Train [40/40]. 79.26 samples/sec. 403.737 ms/step.
Train benchmark of convnext_large.fb_in22k_ft_in1k done. 79.01 samples/sec, 403.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running inference benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.04 GiB is free. Including non-PyTorch memory, this process has 18.60 GiB memory in use. Of the allocated memory 12.99 GiB is allocated by PyTorch, and 5.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running inference benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 187.26 samples/sec. 1025.333 ms/step.
Infer [16/40]. 187.33 samples/sec. 1024.921 ms/step.
Infer [24/40]. 187.10 samples/sec. 1026.199 ms/step.
Infer [32/40]. 186.98 samples/sec. 1026.840 ms/step.
Infer [40/40]. 186.86 samples/sec. 1027.518 ms/step.
Inference benchmark of convnext_large.fb_in22k_ft_in1k_384 done. 186.85 samples/sec, 1027.52 ms/step
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 65.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.48 GiB is free. Including non-PyTorch memory, this process has 22.16 GiB memory in use. Of the allocated memory 21.36 GiB is allocated by PyTorch, and 314.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 177.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.60 GiB is free. Including non-PyTorch memory, this process has 22.04 GiB memory in use. Of the allocated memory 21.19 GiB is allocated by PyTorch, and 371.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 249.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 160.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 129.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 352.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_large.fb_in22k_ft_in1k_384 created, param count: 197767336
Running train benchmark on convnext_large.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 42.14 samples/sec. 379.691 ms/step.
Train [16/40]. 42.13 samples/sec. 379.741 ms/step.
Train [24/40]. 42.14 samples/sec. 379.730 ms/step.
Train [32/40]. 42.14 samples/sec. 379.730 ms/step.
Train [40/40]. 42.14 samples/sec. 379.730 ms/step.
Train benchmark of convnext_large.fb_in22k_ft_in1k_384 done. 41.99 samples/sec, 379.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_augreg created, param count: 199771584
Running inference benchmark on convnext_large_mlp.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 424.97 samples/sec. 602.401 ms/step.
Infer [16/40]. 424.96 samples/sec. 602.404 ms/step.
Infer [24/40]. 424.97 samples/sec. 602.397 ms/step.
Infer [32/40]. 424.97 samples/sec. 602.397 ms/step.
Infer [40/40]. 424.97 samples/sec. 602.395 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_augreg done. 424.94 samples/sec, 602.39 ms/step
Model convnext_large_mlp.clip_laion2b_augreg created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.11 GiB is free. Including non-PyTorch memory, this process has 22.53 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 61.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_augreg created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 240.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_augreg created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 142.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_augreg created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 202.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 232.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_augreg created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 158.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_augreg created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg for 40 steps w/ input size (3, 256, 256) and batch size 48.
Train [8/40]. 100.24 samples/sec. 478.849 ms/step.
Train [16/40]. 100.24 samples/sec. 478.843 ms/step.
Train [24/40]. 100.24 samples/sec. 478.851 ms/step.
Train [32/40]. 100.24 samples/sec. 478.852 ms/step.
Train [40/40]. 100.24 samples/sec. 478.863 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_augreg done. 99.97 samples/sec, 478.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k created, param count: 200128168
Running inference benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 425.20 samples/sec. 602.063 ms/step.
Infer [16/40]. 425.08 samples/sec. 602.245 ms/step.
Infer [24/40]. 425.03 samples/sec. 602.304 ms/step.
Infer [32/40]. 425.01 samples/sec. 602.332 ms/step.
Infer [40/40]. 425.00 samples/sec. 602.353 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_augreg_ft_in1k done. 424.97 samples/sec, 602.35 ms/step
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.11 GiB is free. Including non-PyTorch memory, this process has 22.53 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 60.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 238.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 140.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 202.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 230.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 156.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
Train [8/40]. 100.28 samples/sec. 478.678 ms/step.
Train [16/40]. 100.27 samples/sec. 478.704 ms/step.
Train [24/40]. 100.27 samples/sec. 478.718 ms/step.
Train [32/40]. 100.26 samples/sec. 478.751 ms/step.
Train [40/40]. 100.26 samples/sec. 478.777 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_augreg_ft_in1k done. 99.99 samples/sec, 478.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running inference benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.04 GiB is free. Including non-PyTorch memory, this process has 18.60 GiB memory in use. Of the allocated memory 13.00 GiB is allocated by PyTorch, and 5.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running inference benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 187.46 samples/sec. 1024.237 ms/step.
Infer [16/40]. 187.30 samples/sec. 1025.096 ms/step.
Infer [24/40]. 186.73 samples/sec. 1028.211 ms/step.
Infer [32/40]. 186.72 samples/sec. 1028.264 ms/step.
Infer [40/40]. 186.81 samples/sec. 1027.793 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 done. 186.80 samples/sec, 1027.79 ms/step
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 56.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.48 GiB is free. Including non-PyTorch memory, this process has 22.16 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 305.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 189.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 22.06 GiB memory in use. Of the allocated memory 21.20 GiB is allocated by PyTorch, and 382.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 260.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 191.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 140.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 363.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 42.17 samples/sec. 379.398 ms/step.
Train [16/40]. 42.17 samples/sec. 379.444 ms/step.
Train [24/40]. 42.17 samples/sec. 379.448 ms/step.
Train [32/40]. 42.17 samples/sec. 379.441 ms/step.
Train [40/40]. 42.17 samples/sec. 379.451 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 done. 42.02 samples/sec, 379.45 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running inference benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.97 GiB is free. Including non-PyTorch memory, this process has 18.67 GiB memory in use. Of the allocated memory 13.06 GiB is allocated by PyTorch, and 5.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running inference benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 187.37 samples/sec. 1024.688 ms/step.
Infer [16/40]. 186.74 samples/sec. 1028.164 ms/step.
Infer [24/40]. 186.74 samples/sec. 1028.183 ms/step.
Infer [32/40]. 186.89 samples/sec. 1027.365 ms/step.
Infer [40/40]. 186.93 samples/sec. 1027.120 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 done. 186.92 samples/sec, 1027.12 ms/step
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.56 GiB is free. Including non-PyTorch memory, this process has 22.08 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 62.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.41 GiB is free. Including non-PyTorch memory, this process has 22.23 GiB memory in use. Of the allocated memory 21.43 GiB is allocated by PyTorch, and 312.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 840.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 175.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 22.09 GiB memory in use. Of the allocated memory 21.26 GiB is allocated by PyTorch, and 348.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 227.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 137.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 122.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 368.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 42.10 samples/sec. 380.021 ms/step.
Train [16/40]. 42.10 samples/sec. 380.008 ms/step.
Train [24/40]. 42.10 samples/sec. 380.006 ms/step.
Train [32/40]. 42.11 samples/sec. 379.977 ms/step.
Train [40/40]. 42.11 samples/sec. 379.985 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384 done. 41.97 samples/sec, 379.99 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running inference benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 271.06 samples/sec. 944.444 ms/step.
Infer [16/40]. 270.99 samples/sec. 944.686 ms/step.
Infer [24/40]. 270.96 samples/sec. 944.785 ms/step.
Infer [32/40]. 270.95 samples/sec. 944.829 ms/step.
Infer [40/40]. 270.94 samples/sec. 944.861 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_ft_320 done. 270.93 samples/sec, 944.86 ms/step
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.25 GiB is free. Including non-PyTorch memory, this process has 20.39 GiB memory in use. Of the allocated memory 19.84 GiB is allocated by PyTorch, and 55.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 802.06 MiB is free. Including non-PyTorch memory, this process has 22.86 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 268.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 382.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 167.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 610.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 344.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 224.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 156.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 289.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 446.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_ft_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_320 for 40 steps w/ input size (3, 320, 320) and batch size 24.
Train [8/40]. 61.10 samples/sec. 392.824 ms/step.
Train [16/40]. 61.10 samples/sec. 392.797 ms/step.
Train [24/40]. 61.09 samples/sec. 392.847 ms/step.
Train [32/40]. 61.09 samples/sec. 392.852 ms/step.
Train [40/40]. 61.09 samples/sec. 392.864 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_ft_320 done. 60.88 samples/sec, 392.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running inference benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 270.97 samples/sec. 944.759 ms/step.
Infer [16/40]. 270.95 samples/sec. 944.818 ms/step.
Infer [24/40]. 270.95 samples/sec. 944.830 ms/step.
Infer [32/40]. 270.95 samples/sec. 944.833 ms/step.
Infer [40/40]. 270.95 samples/sec. 944.839 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_ft_soup_320 done. 270.93 samples/sec, 944.84 ms/step
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.25 GiB is free. Including non-PyTorch memory, this process has 20.39 GiB memory in use. Of the allocated memory 19.84 GiB is allocated by PyTorch, and 55.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 802.06 MiB is free. Including non-PyTorch memory, this process has 22.86 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 268.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 382.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 167.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 610.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 344.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 224.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 156.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 289.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 333.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_ft_soup_320 created, param count: 199771584
Running train benchmark on convnext_large_mlp.clip_laion2b_ft_soup_320 for 40 steps w/ input size (3, 320, 320) and batch size 24.
Train [8/40]. 60.90 samples/sec. 394.067 ms/step.
Train [16/40]. 60.91 samples/sec. 394.040 ms/step.
Train [24/40]. 60.91 samples/sec. 394.027 ms/step.
Train [32/40]. 60.91 samples/sec. 394.024 ms/step.
Train [40/40]. 60.91 samples/sec. 394.015 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_ft_soup_320 done. 60.70 samples/sec, 394.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running inference benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 270.90 samples/sec. 944.986 ms/step.
Infer [16/40]. 270.90 samples/sec. 944.985 ms/step.
Infer [24/40]. 270.90 samples/sec. 944.991 ms/step.
Infer [32/40]. 270.90 samples/sec. 944.981 ms/step.
Infer [40/40]. 270.87 samples/sec. 945.085 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 done. 270.86 samples/sec, 945.09 ms/step
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.19 GiB is free. Including non-PyTorch memory, this process has 20.46 GiB memory in use. Of the allocated memory 19.90 GiB is allocated by PyTorch, and 60.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 734.06 MiB is free. Including non-PyTorch memory, this process has 22.92 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 271.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 332.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 152.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 580.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 308.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 120.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 284.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 280.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 for 40 steps w/ input size (3, 320, 320) and batch size 24.
Train [8/40]. 60.83 samples/sec. 394.571 ms/step.
Train [16/40]. 60.83 samples/sec. 394.559 ms/step.
Train [24/40]. 60.83 samples/sec. 394.557 ms/step.
Train [32/40]. 60.82 samples/sec. 394.578 ms/step.
Train [40/40]. 60.82 samples/sec. 394.588 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_320 done. 60.62 samples/sec, 394.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running inference benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.97 GiB is free. Including non-PyTorch memory, this process has 18.67 GiB memory in use. Of the allocated memory 13.06 GiB is allocated by PyTorch, and 5.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running inference benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 186.79 samples/sec. 1027.872 ms/step.
Infer [16/40]. 186.88 samples/sec. 1027.373 ms/step.
Infer [24/40]. 186.29 samples/sec. 1030.664 ms/step.
Infer [32/40]. 186.52 samples/sec. 1029.391 ms/step.
Infer [40/40]. 186.52 samples/sec. 1029.407 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 done. 186.51 samples/sec, 1029.41 ms/step
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.56 GiB is free. Including non-PyTorch memory, this process has 22.08 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 62.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.41 GiB is free. Including non-PyTorch memory, this process has 22.23 GiB memory in use. Of the allocated memory 21.43 GiB is allocated by PyTorch, and 312.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 840.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 175.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 22.09 GiB memory in use. Of the allocated memory 21.26 GiB is allocated by PyTorch, and 348.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 227.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 137.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 122.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 368.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 created, param count: 216760045
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 42.10 samples/sec. 380.020 ms/step.
Train [16/40]. 42.11 samples/sec. 379.983 ms/step.
Train [24/40]. 42.11 samples/sec. 379.956 ms/step.
Train [32/40]. 42.11 samples/sec. 379.938 ms/step.
Train [40/40]. 42.11 samples/sec. 379.944 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_384 done. 41.97 samples/sec, 379.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running inference benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 271.06 samples/sec. 944.431 ms/step.
Infer [16/40]. 271.00 samples/sec. 944.655 ms/step.
Infer [24/40]. 270.98 samples/sec. 944.713 ms/step.
Infer [32/40]. 270.97 samples/sec. 944.749 ms/step.
Infer [40/40]. 270.97 samples/sec. 944.769 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 done. 270.95 samples/sec, 944.77 ms/step
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.25 GiB is free. Including non-PyTorch memory, this process has 20.39 GiB memory in use. Of the allocated memory 19.84 GiB is allocated by PyTorch, and 54.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 802.06 MiB is free. Including non-PyTorch memory, this process has 22.86 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 266.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 382.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 165.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 610.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 342.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 224.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 154.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 306.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 327.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 for 40 steps w/ input size (3, 320, 320) and batch size 24.
Train [8/40]. 60.95 samples/sec. 393.762 ms/step.
Train [16/40]. 60.95 samples/sec. 393.776 ms/step.
Train [24/40]. 60.94 samples/sec. 393.805 ms/step.
Train [32/40]. 60.94 samples/sec. 393.803 ms/step.
Train [40/40]. 60.94 samples/sec. 393.810 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320 done. 60.74 samples/sec, 393.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running inference benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.04 GiB is free. Including non-PyTorch memory, this process has 18.60 GiB memory in use. Of the allocated memory 13.00 GiB is allocated by PyTorch, and 5.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running inference benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 186.82 samples/sec. 1027.702 ms/step.
Infer [16/40]. 186.42 samples/sec. 1029.959 ms/step.
Infer [24/40]. 186.20 samples/sec. 1031.170 ms/step.
Infer [32/40]. 186.35 samples/sec. 1030.314 ms/step.
Infer [40/40]. 186.38 samples/sec. 1030.149 ms/step.
Inference benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 done. 186.37 samples/sec, 1030.15 ms/step
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 56.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.48 GiB is free. Including non-PyTorch memory, this process has 22.16 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 305.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 189.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 22.06 GiB memory in use. Of the allocated memory 21.20 GiB is allocated by PyTorch, and 382.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 260.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 191.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 140.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 363.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 created, param count: 200128168
Running train benchmark on convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 42.16 samples/sec. 379.497 ms/step.
Train [16/40]. 42.16 samples/sec. 379.496 ms/step.
Train [24/40]. 42.16 samples/sec. 379.506 ms/step.
Train [32/40]. 42.16 samples/sec. 379.491 ms/step.
Train [40/40]. 42.16 samples/sec. 379.487 ms/step.
Train benchmark of convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384 done. 42.02 samples/sec, 379.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_nano.d1h_in1k created, param count: 15593560
Running inference benchmark on convnext_nano.d1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2146.38 samples/sec. 119.271 ms/step.
Infer [16/40]. 2146.52 samples/sec. 119.263 ms/step.
Infer [24/40]. 2146.56 samples/sec. 119.261 ms/step.
Infer [32/40]. 2146.56 samples/sec. 119.260 ms/step.
Infer [40/40]. 2146.54 samples/sec. 119.262 ms/step.
Inference benchmark of convnext_nano.d1h_in1k done. 2146.00 samples/sec, 119.26 ms/step
Model convnext_nano.d1h_in1k created, param count: 15593560
Running train benchmark on convnext_nano.d1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 200.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_nano.d1h_in1k created, param count: 15593560
Running train benchmark on convnext_nano.d1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 533.85 samples/sec. 359.649 ms/step.
Train [16/40]. 533.96 samples/sec. 359.579 ms/step.
Train [24/40]. 533.96 samples/sec. 359.578 ms/step.
Train [32/40]. 533.94 samples/sec. 359.590 ms/step.
Train [40/40]. 533.98 samples/sec. 359.562 ms/step.
Train benchmark of convnext_nano.d1h_in1k done. 532.93 samples/sec, 359.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_nano.in12k created, param count: 22529821
Running inference benchmark on convnext_nano.in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3565.20 samples/sec. 71.805 ms/step.
Infer [16/40]. 3565.14 samples/sec. 71.806 ms/step.
Infer [24/40]. 3565.20 samples/sec. 71.805 ms/step.
Infer [32/40]. 3565.28 samples/sec. 71.804 ms/step.
Infer [40/40]. 3565.34 samples/sec. 71.802 ms/step.
Inference benchmark of convnext_nano.in12k done. 3564.09 samples/sec, 71.80 ms/step
Model convnext_nano.in12k created, param count: 22529821
Running train benchmark on convnext_nano.in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 903.34 samples/sec. 283.394 ms/step.
Train [16/40]. 903.32 samples/sec. 283.399 ms/step.
Train [24/40]. 903.22 samples/sec. 283.430 ms/step.
Train [32/40]. 903.09 samples/sec. 283.472 ms/step.
Train [40/40]. 903.02 samples/sec. 283.493 ms/step.
Train benchmark of convnext_nano.in12k done. 900.93 samples/sec, 283.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_nano.in12k_ft_in1k created, param count: 15593560
Running inference benchmark on convnext_nano.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2146.39 samples/sec. 119.270 ms/step.
Infer [16/40]. 2146.36 samples/sec. 119.271 ms/step.
Infer [24/40]. 2146.32 samples/sec. 119.274 ms/step.
Infer [32/40]. 2146.37 samples/sec. 119.271 ms/step.
Infer [40/40]. 2146.39 samples/sec. 119.270 ms/step.
Inference benchmark of convnext_nano.in12k_ft_in1k done. 2145.85 samples/sec, 119.27 ms/step
Model convnext_nano.in12k_ft_in1k created, param count: 15593560
Running train benchmark on convnext_nano.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 242.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 66.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_nano.in12k_ft_in1k created, param count: 15593560
Running train benchmark on convnext_nano.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 534.10 samples/sec. 359.483 ms/step.
Train [16/40]. 533.98 samples/sec. 359.565 ms/step.
Train [24/40]. 533.93 samples/sec. 359.601 ms/step.
Train [32/40]. 533.96 samples/sec. 359.580 ms/step.
Train [40/40]. 533.97 samples/sec. 359.569 ms/step.
Train benchmark of convnext_nano.in12k_ft_in1k done. 532.91 samples/sec, 359.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_nano_ols.d1h_in1k created, param count: 15649560
Running inference benchmark on convnext_nano_ols.d1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1980.48 samples/sec. 129.262 ms/step.
Infer [16/40]. 1980.40 samples/sec. 129.267 ms/step.
Infer [24/40]. 1980.26 samples/sec. 129.276 ms/step.
Infer [32/40]. 1980.21 samples/sec. 129.279 ms/step.
Infer [40/40]. 1980.23 samples/sec. 129.278 ms/step.
Inference benchmark of convnext_nano_ols.d1h_in1k done. 1979.75 samples/sec, 129.28 ms/step
Model convnext_nano_ols.d1h_in1k created, param count: 15649560
Running train benchmark on convnext_nano_ols.d1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 66.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_nano_ols.d1h_in1k created, param count: 15649560
Running train benchmark on convnext_nano_ols.d1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 498.66 samples/sec. 385.035 ms/step.
Train [16/40]. 498.69 samples/sec. 385.012 ms/step.
Train [24/40]. 498.69 samples/sec. 385.012 ms/step.
Train [32/40]. 498.67 samples/sec. 385.027 ms/step.
Train [40/40]. 498.64 samples/sec. 385.045 ms/step.
Train benchmark of convnext_nano_ols.d1h_in1k done. 497.68 samples/sec, 385.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_pico.d1_in1k created, param count: 9045672
Running inference benchmark on convnext_pico.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 3032.23 samples/sec. 84.426 ms/step.
Infer [16/40]. 3032.21 samples/sec. 84.427 ms/step.
Infer [24/40]. 3032.15 samples/sec. 84.429 ms/step.
Infer [32/40]. 3032.17 samples/sec. 84.428 ms/step.
Infer [40/40]. 3032.20 samples/sec. 84.427 ms/step.
Inference benchmark of convnext_pico.d1_in1k done. 3031.25 samples/sec, 84.43 ms/step
Model convnext_pico.d1_in1k created, param count: 9045672
Running train benchmark on convnext_pico.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 763.82 samples/sec. 335.158 ms/step.
Train [16/40]. 763.91 samples/sec. 335.117 ms/step.
Train [24/40]. 763.82 samples/sec. 335.156 ms/step.
Train [32/40]. 763.88 samples/sec. 335.130 ms/step.
Train [40/40]. 763.84 samples/sec. 335.151 ms/step.
Train benchmark of convnext_pico.d1_in1k done. 762.26 samples/sec, 335.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_pico_ols.d1_in1k created, param count: 9061928
Running inference benchmark on convnext_pico_ols.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2924.19 samples/sec. 87.546 ms/step.
Infer [16/40]. 2923.92 samples/sec. 87.554 ms/step.
Infer [24/40]. 2923.86 samples/sec. 87.555 ms/step.
Infer [32/40]. 2923.74 samples/sec. 87.559 ms/step.
Infer [40/40]. 2923.74 samples/sec. 87.559 ms/step.
Inference benchmark of convnext_pico_ols.d1_in1k done. 2922.82 samples/sec, 87.56 ms/step
Model convnext_pico_ols.d1_in1k created, param count: 9061928
Running train benchmark on convnext_pico_ols.d1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 738.73 samples/sec. 346.541 ms/step.
Train [16/40]. 738.74 samples/sec. 346.534 ms/step.
Train [24/40]. 738.77 samples/sec. 346.524 ms/step.
Train [32/40]. 738.76 samples/sec. 346.527 ms/step.
Train [40/40]. 738.79 samples/sec. 346.512 ms/step.
Train benchmark of convnext_pico_ols.d1_in1k done. 737.28 samples/sec, 346.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_small.fb_in1k created, param count: 50223688
Running inference benchmark on convnext_small.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 829.88 samples/sec. 308.477 ms/step.
Infer [16/40]. 829.88 samples/sec. 308.478 ms/step.
Infer [24/40]. 829.87 samples/sec. 308.482 ms/step.
Infer [32/40]. 829.87 samples/sec. 308.482 ms/step.
Infer [40/40]. 829.88 samples/sec. 308.480 ms/step.
Inference benchmark of convnext_small.fb_in1k done. 829.75 samples/sec, 308.48 ms/step
Model convnext_small.fb_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 31.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_small.fb_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 152.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_small.fb_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 182.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 84.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_small.fb_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 204.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_small.fb_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 192.51 samples/sec. 332.457 ms/step.
Train [16/40]. 192.51 samples/sec. 332.443 ms/step.
Train [24/40]. 192.52 samples/sec. 332.438 ms/step.
Train [32/40]. 192.52 samples/sec. 332.431 ms/step.
Train [40/40]. 192.52 samples/sec. 332.434 ms/step.
Train benchmark of convnext_small.fb_in1k done. 191.80 samples/sec, 332.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_small.fb_in22k created, param count: 66250417
Running inference benchmark on convnext_small.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1370.92 samples/sec. 186.735 ms/step.
Infer [16/40]. 1370.96 samples/sec. 186.730 ms/step.
Infer [24/40]. 1370.98 samples/sec. 186.728 ms/step.
Infer [32/40]. 1371.01 samples/sec. 186.724 ms/step.
Infer [40/40]. 1371.00 samples/sec. 186.725 ms/step.
Inference benchmark of convnext_small.fb_in22k done. 1370.73 samples/sec, 186.72 ms/step
Model convnext_small.fb_in22k created, param count: 66250417
Running train benchmark on convnext_small.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 26.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_small.fb_in22k created, param count: 66250417
Running train benchmark on convnext_small.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 129.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_small.fb_in22k created, param count: 66250417
Running train benchmark on convnext_small.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 328.43 samples/sec. 389.736 ms/step.
Train [16/40]. 328.47 samples/sec. 389.687 ms/step.
Train [24/40]. 328.48 samples/sec. 389.674 ms/step.
Train [32/40]. 328.48 samples/sec. 389.668 ms/step.
Train [40/40]. 328.49 samples/sec. 389.659 ms/step.
Train benchmark of convnext_small.fb_in22k done. 327.43 samples/sec, 389.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_small.fb_in22k_ft_in1k created, param count: 50223688
Running inference benchmark on convnext_small.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 830.04 samples/sec. 308.418 ms/step.
Infer [16/40]. 830.05 samples/sec. 308.416 ms/step.
Infer [24/40]. 830.04 samples/sec. 308.417 ms/step.
Infer [32/40]. 830.03 samples/sec. 308.421 ms/step.
Infer [40/40]. 830.04 samples/sec. 308.419 ms/step.
Inference benchmark of convnext_small.fb_in22k_ft_in1k done. 829.92 samples/sec, 308.42 ms/step
Model convnext_small.fb_in22k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 31.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_small.fb_in22k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 212.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 172.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_small.fb_in22k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 104.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_small.fb_in22k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 204.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_small.fb_in22k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 192.34 samples/sec. 332.737 ms/step.
Train [16/40]. 192.35 samples/sec. 332.718 ms/step.
Train [24/40]. 192.36 samples/sec. 332.708 ms/step.
Train [32/40]. 192.36 samples/sec. 332.706 ms/step.
Train [40/40]. 192.36 samples/sec. 332.703 ms/step.
Train benchmark of convnext_small.fb_in22k_ft_in1k done. 191.63 samples/sec, 332.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running inference benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 468.15 samples/sec. 546.828 ms/step.
Infer [16/40]. 468.14 samples/sec. 546.843 ms/step.
Infer [24/40]. 468.14 samples/sec. 546.847 ms/step.
Infer [32/40]. 468.14 samples/sec. 546.849 ms/step.
Infer [40/40]. 468.13 samples/sec. 546.853 ms/step.
Inference benchmark of convnext_small.fb_in22k_ft_in1k_384 done. 468.09 samples/sec, 546.85 ms/step
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 512.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 34.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 21.54 GiB memory in use. Of the allocated memory 20.82 GiB is allocated by PyTorch, and 228.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 388.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 157.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 204.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 147.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 127.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 216.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_small.fb_in22k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 102.04 samples/sec. 313.599 ms/step.
Train [16/40]. 102.04 samples/sec. 313.595 ms/step.
Train [24/40]. 102.04 samples/sec. 313.601 ms/step.
Train [32/40]. 102.04 samples/sec. 313.602 ms/step.
Train [40/40]. 102.04 samples/sec. 313.601 ms/step.
Train benchmark of convnext_small.fb_in22k_ft_in1k_384 done. 101.54 samples/sec, 313.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_small.in12k created, param count: 58545037
Running inference benchmark on convnext_small.in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1371.88 samples/sec. 186.605 ms/step.
Infer [16/40]. 1371.89 samples/sec. 186.604 ms/step.
Infer [24/40]. 1371.85 samples/sec. 186.609 ms/step.
Infer [32/40]. 1371.86 samples/sec. 186.608 ms/step.
Infer [40/40]. 1371.85 samples/sec. 186.609 ms/step.
Inference benchmark of convnext_small.in12k done. 1371.59 samples/sec, 186.61 ms/step
Model convnext_small.in12k created, param count: 58545037
Running train benchmark on convnext_small.in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 27.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_small.in12k created, param count: 58545037
Running train benchmark on convnext_small.in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 182.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 202.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_small.in12k created, param count: 58545037
Running train benchmark on convnext_small.in12k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 329.87 samples/sec. 388.026 ms/step.
Train [16/40]. 329.81 samples/sec. 388.100 ms/step.
Train [24/40]. 329.80 samples/sec. 388.115 ms/step.
Train [32/40]. 329.79 samples/sec. 388.125 ms/step.
Train [40/40]. 329.77 samples/sec. 388.154 ms/step.
Train benchmark of convnext_small.in12k done. 328.68 samples/sec, 388.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_small.in12k_ft_in1k created, param count: 50223688
Running inference benchmark on convnext_small.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 829.93 samples/sec. 308.459 ms/step.
Infer [16/40]. 829.93 samples/sec. 308.461 ms/step.
Infer [24/40]. 829.89 samples/sec. 308.474 ms/step.
Infer [32/40]. 829.85 samples/sec. 308.490 ms/step.
Infer [40/40]. 829.83 samples/sec. 308.495 ms/step.
Inference benchmark of convnext_small.in12k_ft_in1k done. 829.72 samples/sec, 308.50 ms/step
Model convnext_small.in12k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 31.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_small.in12k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 212.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 172.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_small.in12k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 104.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_small.in12k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 204.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_small.in12k_ft_in1k created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 192.21 samples/sec. 332.969 ms/step.
Train [16/40]. 192.22 samples/sec. 332.957 ms/step.
Train [24/40]. 192.21 samples/sec. 332.966 ms/step.
Train [32/40]. 192.21 samples/sec. 332.968 ms/step.
Train [40/40]. 192.21 samples/sec. 332.971 ms/step.
Train benchmark of convnext_small.in12k_ft_in1k done. 191.46 samples/sec, 332.97 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running inference benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 468.25 samples/sec. 546.718 ms/step.
Infer [16/40]. 468.24 samples/sec. 546.727 ms/step.
Infer [24/40]. 468.24 samples/sec. 546.727 ms/step.
Infer [32/40]. 468.24 samples/sec. 546.730 ms/step.
Infer [40/40]. 468.24 samples/sec. 546.733 ms/step.
Inference benchmark of convnext_small.in12k_ft_in1k_384 done. 468.19 samples/sec, 546.73 ms/step
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 512.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 34.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 21.60 GiB memory in use. Of the allocated memory 20.82 GiB is allocated by PyTorch, and 288.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 197.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 204.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 147.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 129.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 218.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_small.in12k_ft_in1k_384 created, param count: 50223688
Running train benchmark on convnext_small.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 102.01 samples/sec. 313.696 ms/step.
Train [16/40]. 102.01 samples/sec. 313.683 ms/step.
Train [24/40]. 102.02 samples/sec. 313.672 ms/step.
Train [32/40]. 102.02 samples/sec. 313.669 ms/step.
Train [40/40]. 102.01 samples/sec. 313.681 ms/step.
Train benchmark of convnext_small.in12k_ft_in1k_384 done. 101.48 samples/sec, 313.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny.fb_in1k created, param count: 28589128
Running inference benchmark on convnext_tiny.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1356.29 samples/sec. 188.751 ms/step.
Infer [16/40]. 1356.28 samples/sec. 188.751 ms/step.
Infer [24/40]. 1356.30 samples/sec. 188.748 ms/step.
Infer [32/40]. 1356.30 samples/sec. 188.749 ms/step.
Infer [40/40]. 1356.23 samples/sec. 188.758 ms/step.
Inference benchmark of convnext_tiny.fb_in1k done. 1355.97 samples/sec, 188.76 ms/step
Model convnext_tiny.fb_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 15.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny.fb_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 354.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 113.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_tiny.fb_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 337.92 samples/sec. 378.782 ms/step.
Train [16/40]. 337.91 samples/sec. 378.799 ms/step.
Train [24/40]. 337.85 samples/sec. 378.870 ms/step.
Train [32/40]. 337.83 samples/sec. 378.883 ms/step.
Train [40/40]. 337.85 samples/sec. 378.868 ms/step.
Train benchmark of convnext_tiny.fb_in1k done. 337.08 samples/sec, 378.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny.fb_in22k created, param count: 44615857
Running inference benchmark on convnext_tiny.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2243.99 samples/sec. 114.082 ms/step.
Infer [16/40]. 2243.84 samples/sec. 114.090 ms/step.
Infer [24/40]. 2243.78 samples/sec. 114.093 ms/step.
Infer [32/40]. 2243.81 samples/sec. 114.092 ms/step.
Infer [40/40]. 2243.74 samples/sec. 114.095 ms/step.
Inference benchmark of convnext_tiny.fb_in22k done. 2243.18 samples/sec, 114.09 ms/step
Model convnext_tiny.fb_in22k created, param count: 44615857
Running train benchmark on convnext_tiny.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 27.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny.fb_in22k created, param count: 44615857
Running train benchmark on convnext_tiny.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 551.01 samples/sec. 348.453 ms/step.
Train [16/40]. 551.02 samples/sec. 348.446 ms/step.
Train [24/40]. 551.03 samples/sec. 348.440 ms/step.
Train [32/40]. 551.03 samples/sec. 348.441 ms/step.
Train [40/40]. 551.04 samples/sec. 348.432 ms/step.
Train benchmark of convnext_tiny.fb_in22k done. 549.68 samples/sec, 348.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny.fb_in22k_ft_in1k created, param count: 28589128
Running inference benchmark on convnext_tiny.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1356.15 samples/sec. 188.769 ms/step.
Infer [16/40]. 1356.15 samples/sec. 188.770 ms/step.
Infer [24/40]. 1356.13 samples/sec. 188.772 ms/step.
Infer [32/40]. 1356.11 samples/sec. 188.775 ms/step.
Infer [40/40]. 1356.13 samples/sec. 188.773 ms/step.
Inference benchmark of convnext_tiny.fb_in22k_ft_in1k done. 1355.87 samples/sec, 188.77 ms/step
Model convnext_tiny.fb_in22k_ft_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 15.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny.fb_in22k_ft_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 354.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 113.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_tiny.fb_in22k_ft_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 338.01 samples/sec. 378.687 ms/step.
Train [16/40]. 338.03 samples/sec. 378.662 ms/step.
Train [24/40]. 338.05 samples/sec. 378.639 ms/step.
Train [32/40]. 338.06 samples/sec. 378.629 ms/step.
Train [40/40]. 338.06 samples/sec. 378.633 ms/step.
Train benchmark of convnext_tiny.fb_in22k_ft_in1k done. 337.32 samples/sec, 378.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny.fb_in22k_ft_in1k_384 created, param count: 28589128
Running inference benchmark on convnext_tiny.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 764.69 samples/sec. 334.777 ms/step.
Infer [16/40]. 764.69 samples/sec. 334.775 ms/step.
Infer [24/40]. 764.69 samples/sec. 334.776 ms/step.
Infer [32/40]. 764.69 samples/sec. 334.777 ms/step.
Infer [40/40]. 764.68 samples/sec. 334.780 ms/step.
Inference benchmark of convnext_tiny.fb_in22k_ft_in1k_384 done. 764.58 samples/sec, 334.78 ms/step
Model convnext_tiny.fb_in22k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 612.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 16.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny.fb_in22k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.22 GiB is free. Including non-PyTorch memory, this process has 21.42 GiB memory in use. Of the allocated memory 20.74 GiB is allocated by PyTorch, and 190.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_tiny.fb_in22k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 62.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_tiny.fb_in22k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 165.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_tiny.fb_in22k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 167.70 samples/sec. 381.637 ms/step.
Train [16/40]. 167.72 samples/sec. 381.590 ms/step.
Train [24/40]. 167.71 samples/sec. 381.609 ms/step.
Train [32/40]. 167.71 samples/sec. 381.617 ms/step.
Train [40/40]. 167.71 samples/sec. 381.612 ms/step.
Train benchmark of convnext_tiny.fb_in22k_ft_in1k_384 done. 167.32 samples/sec, 381.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny.in12k created, param count: 36910477
Running inference benchmark on convnext_tiny.in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2244.46 samples/sec. 114.059 ms/step.
Infer [16/40]. 2244.41 samples/sec. 114.061 ms/step.
Infer [24/40]. 2244.34 samples/sec. 114.065 ms/step.
Infer [32/40]. 2244.35 samples/sec. 114.064 ms/step.
Infer [40/40]. 2244.36 samples/sec. 114.063 ms/step.
Inference benchmark of convnext_tiny.in12k done. 2243.81 samples/sec, 114.06 ms/step
Model convnext_tiny.in12k created, param count: 36910477
Running train benchmark on convnext_tiny.in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.11 GiB is allocated by PyTorch, and 28.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny.in12k created, param count: 36910477
Running train benchmark on convnext_tiny.in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 551.49 samples/sec. 348.147 ms/step.
Train [16/40]. 551.48 samples/sec. 348.157 ms/step.
Train [24/40]. 551.44 samples/sec. 348.180 ms/step.
Train [32/40]. 551.43 samples/sec. 348.188 ms/step.
Train [40/40]. 551.44 samples/sec. 348.180 ms/step.
Train benchmark of convnext_tiny.in12k done. 550.05 samples/sec, 348.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny.in12k_ft_in1k created, param count: 28589128
Running inference benchmark on convnext_tiny.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1356.04 samples/sec. 188.784 ms/step.
Infer [16/40]. 1356.08 samples/sec. 188.779 ms/step.
Infer [24/40]. 1356.09 samples/sec. 188.778 ms/step.
Infer [32/40]. 1356.10 samples/sec. 188.777 ms/step.
Infer [40/40]. 1356.10 samples/sec. 188.777 ms/step.
Inference benchmark of convnext_tiny.in12k_ft_in1k done. 1355.80 samples/sec, 188.78 ms/step
Model convnext_tiny.in12k_ft_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 15.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny.in12k_ft_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 354.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 113.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_tiny.in12k_ft_in1k created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 337.93 samples/sec. 378.776 ms/step.
Train [16/40]. 337.93 samples/sec. 378.772 ms/step.
Train [24/40]. 337.92 samples/sec. 378.789 ms/step.
Train [32/40]. 337.94 samples/sec. 378.771 ms/step.
Train [40/40]. 337.93 samples/sec. 378.772 ms/step.
Train benchmark of convnext_tiny.in12k_ft_in1k done. 337.17 samples/sec, 378.77 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny.in12k_ft_in1k_384 created, param count: 28589128
Running inference benchmark on convnext_tiny.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 764.74 samples/sec. 334.755 ms/step.
Infer [16/40]. 764.72 samples/sec. 334.761 ms/step.
Infer [24/40]. 764.73 samples/sec. 334.759 ms/step.
Infer [32/40]. 764.72 samples/sec. 334.761 ms/step.
Infer [40/40]. 764.71 samples/sec. 334.766 ms/step.
Inference benchmark of convnext_tiny.in12k_ft_in1k_384 done. 764.61 samples/sec, 334.77 ms/step
Model convnext_tiny.in12k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 612.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 16.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny.in12k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.22 GiB is free. Including non-PyTorch memory, this process has 21.42 GiB memory in use. Of the allocated memory 20.74 GiB is allocated by PyTorch, and 190.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_tiny.in12k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 62.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_tiny.in12k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 165.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_tiny.in12k_ft_in1k_384 created, param count: 28589128
Running train benchmark on convnext_tiny.in12k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 167.74 samples/sec. 381.551 ms/step.
Train [16/40]. 167.75 samples/sec. 381.509 ms/step.
Train [24/40]. 167.74 samples/sec. 381.543 ms/step.
Train [32/40]. 167.74 samples/sec. 381.551 ms/step.
Train [40/40]. 167.74 samples/sec. 381.546 ms/step.
Train benchmark of convnext_tiny.in12k_ft_in1k_384 done. 167.33 samples/sec, 381.55 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_tiny_hnf.a2h_in1k created, param count: 28589128
Running inference benchmark on convnext_tiny_hnf.a2h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1356.48 samples/sec. 188.724 ms/step.
Infer [16/40]. 1356.41 samples/sec. 188.733 ms/step.
Infer [24/40]. 1356.41 samples/sec. 188.734 ms/step.
Infer [32/40]. 1356.41 samples/sec. 188.733 ms/step.
Infer [40/40]. 1356.39 samples/sec. 188.737 ms/step.
Inference benchmark of convnext_tiny_hnf.a2h_in1k done. 1356.13 samples/sec, 188.74 ms/step
Model convnext_tiny_hnf.a2h_in1k created, param count: 28589128
Running train benchmark on convnext_tiny_hnf.a2h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 570.06 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 103.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_tiny_hnf.a2h_in1k created, param count: 28589128
Running train benchmark on convnext_tiny_hnf.a2h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 318.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 150.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_tiny_hnf.a2h_in1k created, param count: 28589128
Running train benchmark on convnext_tiny_hnf.a2h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 339.57 samples/sec. 376.948 ms/step.
Train [16/40]. 339.48 samples/sec. 377.050 ms/step.
Train [24/40]. 339.51 samples/sec. 377.019 ms/step.
Train [32/40]. 339.47 samples/sec. 377.053 ms/step.
Train [40/40]. 339.48 samples/sec. 377.053 ms/step.
Train benchmark of convnext_tiny_hnf.a2h_in1k done. 338.78 samples/sec, 377.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running inference benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 360.60 samples/sec. 709.921 ms/step.
Infer [16/40]. 360.60 samples/sec. 709.921 ms/step.
Infer [24/40]. 360.61 samples/sec. 709.917 ms/step.
Infer [32/40]. 360.61 samples/sec. 709.915 ms/step.
Infer [40/40]. 360.60 samples/sec. 709.921 ms/step.
Inference benchmark of convnext_xlarge.fb_in22k done. 360.58 samples/sec, 709.92 ms/step
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running train benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.09 GiB is allocated by PyTorch, and 15.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running train benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 143.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running train benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 664.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 69.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running train benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 90.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running train benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 112.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running train benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 600.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_xlarge.fb_in22k created, param count: 392900177
Running train benchmark on convnext_xlarge.fb_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 85.48 samples/sec. 374.357 ms/step.
Train [16/40]. 85.47 samples/sec. 374.386 ms/step.
Train [24/40]. 85.47 samples/sec. 374.393 ms/step.
Train [32/40]. 85.47 samples/sec. 374.400 ms/step.
Train [40/40]. 85.47 samples/sec. 374.404 ms/step.
Train benchmark of convnext_xlarge.fb_in22k done. 85.10 samples/sec, 374.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running inference benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 219.23 samples/sec. 1167.729 ms/step.
Infer [16/40]. 219.22 samples/sec. 1167.759 ms/step.
Infer [24/40]. 219.22 samples/sec. 1167.769 ms/step.
Infer [32/40]. 219.17 samples/sec. 1168.054 ms/step.
Infer [40/40]. 219.12 samples/sec. 1168.314 ms/step.
Inference benchmark of convnext_xlarge.fb_in22k_ft_in1k done. 219.11 samples/sec, 1168.31 ms/step
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.29 GiB is free. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 21.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.47 GiB is free. Including non-PyTorch memory, this process has 21.17 GiB memory in use. Of the allocated memory 20.51 GiB is allocated by PyTorch, and 171.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 22.29 GiB memory in use. Of the allocated memory 21.71 GiB is allocated by PyTorch, and 89.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 206.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 122.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 179.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 279.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 24.
Train [8/40]. 53.36 samples/sec. 449.780 ms/step.
Train [16/40]. 53.36 samples/sec. 449.812 ms/step.
Train [24/40]. 53.35 samples/sec. 449.821 ms/step.
Train [32/40]. 53.36 samples/sec. 449.812 ms/step.
Train [40/40]. 53.36 samples/sec. 449.814 ms/step.
Train benchmark of convnext_xlarge.fb_in22k_ft_in1k done. 53.16 samples/sec, 449.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running inference benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.89 GiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 11.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running inference benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.40 GiB is free. Including non-PyTorch memory, this process has 19.24 GiB memory in use. Of the allocated memory 13.45 GiB is allocated by PyTorch, and 5.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running inference benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 123.77 samples/sec. 1034.197 ms/step.
Infer [16/40]. 123.74 samples/sec. 1034.411 ms/step.
Infer [24/40]. 123.90 samples/sec. 1033.120 ms/step.
Infer [32/40]. 123.87 samples/sec. 1033.332 ms/step.
Infer [40/40]. 123.83 samples/sec. 1033.634 ms/step.
Inference benchmark of convnext_xlarge.fb_in22k_ft_in1k_384 done. 123.83 samples/sec, 1033.63 ms/step
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.36 GiB is free. Including non-PyTorch memory, this process has 20.29 GiB memory in use. Of the allocated memory 19.78 GiB is allocated by PyTorch, and 15.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1018.06 MiB is free. Including non-PyTorch memory, this process has 22.65 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 246.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.45 GiB is free. Including non-PyTorch memory, this process has 20.19 GiB memory in use. Of the allocated memory 19.56 GiB is allocated by PyTorch, and 144.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 298.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 271.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 204.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 101.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 116.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 96.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 292.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnext_xlarge.fb_in22k_ft_in1k_384 created, param count: 350196968
Running train benchmark on convnext_xlarge.fb_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 29.55 samples/sec. 406.081 ms/step.
Train [16/40]. 29.53 samples/sec. 406.383 ms/step.
Train [24/40]. 29.52 samples/sec. 406.486 ms/step.
Train [32/40]. 29.52 samples/sec. 406.536 ms/step.
Train [40/40]. 29.52 samples/sec. 406.564 ms/step.
Train benchmark of convnext_xlarge.fb_in22k_ft_in1k_384 done. 29.40 samples/sec, 406.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running inference benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.78 GiB is free. Including non-PyTorch memory, this process has 18.86 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running inference benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 192.
Infer [8/40]. 134.71 samples/sec. 1425.260 ms/step.
Infer [16/40]. 134.72 samples/sec. 1425.198 ms/step.
Infer [24/40]. 134.72 samples/sec. 1425.145 ms/step.
Infer [32/40]. 134.69 samples/sec. 1425.537 ms/step.
Infer [40/40]. 134.66 samples/sec. 1425.807 ms/step.
Inference benchmark of convnext_xxlarge.clip_laion2b_rewind done. 134.66 samples/sec, 1425.81 ms/step
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 15.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.69 GiB is free. Including non-PyTorch memory, this process has 21.95 GiB memory in use. Of the allocated memory 21.33 GiB is allocated by PyTorch, and 136.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 302.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 78.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.67 GiB is free. Including non-PyTorch memory, this process has 21.97 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 226.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 68.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 131.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 96.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 152.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_xxlarge.clip_laion2b_rewind created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_rewind for 40 steps w/ input size (3, 256, 256) and batch size 16.
Train [8/40]. 31.28 samples/sec. 511.464 ms/step.
Train [16/40]. 31.28 samples/sec. 511.511 ms/step.
Train [24/40]. 31.27 samples/sec. 511.591 ms/step.
Train [32/40]. 31.27 samples/sec. 511.633 ms/step.
Train [40/40]. 31.27 samples/sec. 511.653 ms/step.
Train benchmark of convnext_xxlarge.clip_laion2b_rewind done. 31.16 samples/sec, 511.65 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running inference benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.78 GiB is free. Including non-PyTorch memory, this process has 18.86 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running inference benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 192.
Infer [8/40]. 134.70 samples/sec. 1425.386 ms/step.
Infer [16/40]. 134.70 samples/sec. 1425.361 ms/step.
Infer [24/40]. 134.70 samples/sec. 1425.366 ms/step.
Infer [32/40]. 134.67 samples/sec. 1425.728 ms/step.
Infer [40/40]. 134.65 samples/sec. 1425.947 ms/step.
Inference benchmark of convnext_xxlarge.clip_laion2b_soup done. 134.64 samples/sec, 1425.95 ms/step
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 15.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.69 GiB is free. Including non-PyTorch memory, this process has 21.95 GiB memory in use. Of the allocated memory 21.33 GiB is allocated by PyTorch, and 136.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 302.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 78.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.67 GiB is free. Including non-PyTorch memory, this process has 21.97 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 226.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 68.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 151.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 120.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 158.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_xxlarge.clip_laion2b_soup created, param count: 846544768
Running train benchmark on convnext_xxlarge.clip_laion2b_soup for 40 steps w/ input size (3, 256, 256) and batch size 16.
Train [8/40]. 31.28 samples/sec. 511.567 ms/step.
Train [16/40]. 31.27 samples/sec. 511.663 ms/step.
Train [24/40]. 31.27 samples/sec. 511.698 ms/step.
Train [32/40]. 31.27 samples/sec. 511.733 ms/step.
Train [40/40]. 31.27 samples/sec. 511.742 ms/step.
Train benchmark of convnext_xxlarge.clip_laion2b_soup done. 31.16 samples/sec, 511.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running inference benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.78 GiB is free. Including non-PyTorch memory, this process has 18.86 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running inference benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
Infer [8/40]. 134.71 samples/sec. 1425.296 ms/step.
Infer [16/40]. 134.71 samples/sec. 1425.270 ms/step.
Infer [24/40]. 134.67 samples/sec. 1425.692 ms/step.
Infer [32/40]. 134.64 samples/sec. 1425.993 ms/step.
Infer [40/40]. 134.63 samples/sec. 1426.177 ms/step.
Inference benchmark of convnext_xxlarge.clip_laion2b_soup_ft_in1k done. 134.62 samples/sec, 1426.18 ms/step
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 16.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.69 GiB is free. Including non-PyTorch memory, this process has 21.95 GiB memory in use. Of the allocated memory 21.33 GiB is allocated by PyTorch, and 136.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 282.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 100.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.67 GiB is free. Including non-PyTorch memory, this process has 21.97 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 227.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 88.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 151.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 176.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 106.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnext_xxlarge.clip_laion2b_soup_ft_in1k created, param count: 846471016
Running train benchmark on convnext_xxlarge.clip_laion2b_soup_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 16.
Train [8/40]. 31.28 samples/sec. 511.475 ms/step.
Train [16/40]. 31.28 samples/sec. 511.462 ms/step.
Train [24/40]. 31.28 samples/sec. 511.467 ms/step.
Train [32/40]. 31.28 samples/sec. 511.465 ms/step.
Train [40/40]. 31.28 samples/sec. 511.466 ms/step.
Train benchmark of convnext_xxlarge.clip_laion2b_soup_ft_in1k done. 31.17 samples/sec, 511.47 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_atto.fcmae created, param count: 3387400
Running inference benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4954.27 samples/sec. 51.673 ms/step.
Infer [16/40]. 4952.81 samples/sec. 51.688 ms/step.
Infer [24/40]. 4952.49 samples/sec. 51.691 ms/step.
Infer [32/40]. 4952.28 samples/sec. 51.693 ms/step.
Infer [40/40]. 4952.20 samples/sec. 51.694 ms/step.
Inference benchmark of convnextv2_atto.fcmae done. 4949.47 samples/sec, 51.69 ms/step
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_atto.fcmae created, param count: 3387400
Running train benchmark on convnextv2_atto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_atto.fcmae_ft_in1k created, param count: 3708400
Running inference benchmark on convnextv2_atto.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2940.90 samples/sec. 87.048 ms/step.
Infer [16/40]. 2940.96 samples/sec. 87.046 ms/step.
Infer [24/40]. 2940.95 samples/sec. 87.047 ms/step.
Infer [32/40]. 2940.98 samples/sec. 87.046 ms/step.
Infer [40/40]. 2940.97 samples/sec. 87.046 ms/step.
Inference benchmark of convnextv2_atto.fcmae_ft_in1k done. 2940.05 samples/sec, 87.05 ms/step
Model convnextv2_atto.fcmae_ft_in1k created, param count: 3708400
Running train benchmark on convnextv2_atto.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 738.29 samples/sec. 346.746 ms/step.
Train [16/40]. 738.14 samples/sec. 346.820 ms/step.
Train [24/40]. 738.14 samples/sec. 346.816 ms/step.
Train [32/40]. 738.01 samples/sec. 346.880 ms/step.
Train [40/40]. 737.91 samples/sec. 346.926 ms/step.
Train benchmark of convnextv2_atto.fcmae_ft_in1k done. 736.19 samples/sec, 346.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_base.fcmae created, param count: 87692800
Running inference benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 600.91 samples/sec. 426.022 ms/step.
Infer [16/40]. 600.90 samples/sec. 426.031 ms/step.
Infer [24/40]. 600.89 samples/sec. 426.032 ms/step.
Infer [32/40]. 600.90 samples/sec. 426.029 ms/step.
Infer [40/40]. 600.90 samples/sec. 426.029 ms/step.
Inference benchmark of convnextv2_base.fcmae done. 600.83 samples/sec, 426.03 ms/step
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 968.06 MiB is free. Including non-PyTorch memory, this process has 22.70 GiB memory in use. Of the allocated memory 21.19 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 514.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 59.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 126.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 184.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 140.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_base.fcmae created, param count: 87692800
Running train benchmark on convnextv2_base.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running inference benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 364.95 samples/sec. 701.475 ms/step.
Infer [16/40]. 364.78 samples/sec. 701.787 ms/step.
Infer [24/40]. 364.73 samples/sec. 701.897 ms/step.
Infer [32/40]. 364.70 samples/sec. 701.945 ms/step.
Infer [40/40]. 364.69 samples/sec. 701.969 ms/step.
Inference benchmark of convnextv2_base.fcmae_ft_in1k done. 364.66 samples/sec, 701.97 ms/step
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 21.37 GiB memory in use. Of the allocated memory 20.23 GiB is allocated by PyTorch, and 659.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.52 GiB is free. Including non-PyTorch memory, this process has 22.12 GiB memory in use. Of the allocated memory 20.49 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 230.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 450.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 171.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 206.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 110.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_base.fcmae_ft_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
Train [8/40]. 84.07 samples/sec. 380.621 ms/step.
Train [16/40]. 84.05 samples/sec. 380.733 ms/step.
Train [24/40]. 84.04 samples/sec. 380.771 ms/step.
Train [32/40]. 84.04 samples/sec. 380.785 ms/step.
Train [40/40]. 84.03 samples/sec. 380.802 ms/step.
Train benchmark of convnextv2_base.fcmae_ft_in1k done. 83.68 samples/sec, 380.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running inference benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 364.79 samples/sec. 701.773 ms/step.
Infer [16/40]. 364.77 samples/sec. 701.805 ms/step.
Infer [24/40]. 364.77 samples/sec. 701.811 ms/step.
Infer [32/40]. 364.77 samples/sec. 701.812 ms/step.
Infer [40/40]. 364.76 samples/sec. 701.836 ms/step.
Inference benchmark of convnextv2_base.fcmae_ft_in22k_in1k done. 364.73 samples/sec, 701.84 ms/step
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 21.37 GiB memory in use. Of the allocated memory 20.23 GiB is allocated by PyTorch, and 659.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.52 GiB is free. Including non-PyTorch memory, this process has 22.12 GiB memory in use. Of the allocated memory 20.49 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 230.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 450.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 171.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 206.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 110.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
Train [8/40]. 84.10 samples/sec. 380.483 ms/step.
Train [16/40]. 84.10 samples/sec. 380.512 ms/step.
Train [24/40]. 84.10 samples/sec. 380.485 ms/step.
Train [32/40]. 84.10 samples/sec. 380.492 ms/step.
Train [40/40]. 84.10 samples/sec. 380.487 ms/step.
Train benchmark of convnextv2_base.fcmae_ft_in22k_in1k done. 83.75 samples/sec, 380.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running inference benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 207.03 samples/sec. 1236.555 ms/step.
Infer [16/40]. 206.98 samples/sec. 1236.847 ms/step.
Infer [24/40]. 206.96 samples/sec. 1236.936 ms/step.
Infer [32/40]. 206.96 samples/sec. 1236.981 ms/step.
Infer [40/40]. 206.95 samples/sec. 1237.011 ms/step.
Inference benchmark of convnextv2_base.fcmae_ft_in22k_in1k_384 done. 206.94 samples/sec, 1237.01 ms/step
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.32 GiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 26.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.96 GiB is free. Including non-PyTorch memory, this process has 21.68 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.15 GiB is free. Including non-PyTorch memory, this process has 21.49 GiB memory in use. Of the allocated memory 20.27 GiB is allocated by PyTorch, and 745.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 390.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 21.63 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 530.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 508.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 86.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 208.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 132.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_base.fcmae_ft_in22k_in1k_384 created, param count: 88717800
Running train benchmark on convnextv2_base.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 46.90 samples/sec. 341.115 ms/step.
Train [16/40]. 46.91 samples/sec. 341.101 ms/step.
Train [24/40]. 46.91 samples/sec. 341.112 ms/step.
Train [32/40]. 46.90 samples/sec. 341.115 ms/step.
Train [40/40]. 46.90 samples/sec. 341.117 ms/step.
Train benchmark of convnextv2_base.fcmae_ft_in22k_in1k_384 done. 46.68 samples/sec, 341.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_femto.fcmae created, param count: 4848240
Running inference benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4159.51 samples/sec. 61.546 ms/step.
Infer [16/40]. 4159.18 samples/sec. 61.551 ms/step.
Infer [24/40]. 4159.06 samples/sec. 61.552 ms/step.
Infer [32/40]. 4159.07 samples/sec. 61.552 ms/step.
Infer [40/40]. 4158.72 samples/sec. 61.557 ms/step.
Inference benchmark of convnextv2_femto.fcmae done. 4156.85 samples/sec, 61.56 ms/step
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_femto.fcmae created, param count: 4848240
Running train benchmark on convnextv2_femto.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_femto.fcmae_ft_in1k created, param count: 5233240
Running inference benchmark on convnextv2_femto.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2485.16 samples/sec. 103.011 ms/step.
Infer [16/40]. 2484.94 samples/sec. 103.020 ms/step.
Infer [24/40]. 2484.94 samples/sec. 103.021 ms/step.
Infer [32/40]. 2484.96 samples/sec. 103.020 ms/step.
Infer [40/40]. 2484.95 samples/sec. 103.020 ms/step.
Inference benchmark of convnextv2_femto.fcmae_ft_in1k done. 2484.28 samples/sec, 103.02 ms/step
Model convnextv2_femto.fcmae_ft_in1k created, param count: 5233240
Running train benchmark on convnextv2_femto.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 94.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_femto.fcmae_ft_in1k created, param count: 5233240
Running train benchmark on convnextv2_femto.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 592.69 samples/sec. 323.947 ms/step.
Train [16/40]. 592.68 samples/sec. 323.955 ms/step.
Train [24/40]. 592.69 samples/sec. 323.944 ms/step.
Train [32/40]. 592.70 samples/sec. 323.943 ms/step.
Train [40/40]. 592.56 samples/sec. 324.017 ms/step.
Train benchmark of convnextv2_femto.fcmae_ft_in1k done. 590.92 samples/sec, 324.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_huge.fcmae created, param count: 657472640
Running inference benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 159.11 samples/sec. 1608.981 ms/step.
Infer [16/40]. 159.11 samples/sec. 1608.977 ms/step.
Infer [24/40]. 159.10 samples/sec. 1609.045 ms/step.
Infer [32/40]. 159.09 samples/sec. 1609.199 ms/step.
Infer [40/40]. 159.08 samples/sec. 1609.288 ms/step.
Inference benchmark of convnextv2_huge.fcmae done. 159.07 samples/sec, 1609.29 ms/step
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.57 GiB is free. Including non-PyTorch memory, this process has 20.07 GiB memory in use. Of the allocated memory 19.47 GiB is allocated by PyTorch, and 105.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.37 GiB is free. Including non-PyTorch memory, this process has 22.27 GiB memory in use. Of the allocated memory 20.76 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 20.98 GiB is allocated by PyTorch, and 767.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.34 GiB is free. Including non-PyTorch memory, this process has 22.30 GiB memory in use. Of the allocated memory 20.71 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 540.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 456.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 446.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 408.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 352.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 354.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_huge.fcmae created, param count: 657472640
Running train benchmark on convnextv2_huge.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.92 GiB is free. Including non-PyTorch memory, this process has 20.72 GiB memory in use. Of the allocated memory 20.13 GiB is allocated by PyTorch, and 107.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.22 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.92 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.02 GiB is allocated by PyTorch, and 4.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Infer [8/40]. 95.70 samples/sec. 1337.581 ms/step.
Infer [16/40]. 95.69 samples/sec. 1337.611 ms/step.
Infer [24/40]. 95.69 samples/sec. 1337.614 ms/step.
Infer [32/40]. 95.69 samples/sec. 1337.626 ms/step.
Infer [40/40]. 95.69 samples/sec. 1337.621 ms/step.
Inference benchmark of convnextv2_huge.fcmae_ft_in1k done. 95.69 samples/sec, 1337.62 ms/step
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.38 GiB is free. Including non-PyTorch memory, this process has 17.26 GiB memory in use. Of the allocated memory 16.66 GiB is allocated by PyTorch, and 110.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.22 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.53 GiB is free. Including non-PyTorch memory, this process has 19.12 GiB memory in use. Of the allocated memory 18.34 GiB is allocated by PyTorch, and 290.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.79 GiB is free. Including non-PyTorch memory, this process has 20.85 GiB memory in use. Of the allocated memory 20.02 GiB is allocated by PyTorch, and 343.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 21.54 GiB memory in use. Of the allocated memory 20.21 GiB is allocated by PyTorch, and 862.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 20.83 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 1.31 GiB. GPU 0 has a total capacty of 23.65 GiB of which 892.06 MiB is free. Including non-PyTorch memory, this process has 22.77 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 835.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 259.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 384.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 323.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 544.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_huge.fcmae_ft_in1k created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 8.
Train [8/40]. 21.92 samples/sec. 364.998 ms/step.
Train [16/40]. 21.92 samples/sec. 365.012 ms/step.
Train [24/40]. 21.92 samples/sec. 365.018 ms/step.
Train [32/40]. 21.92 samples/sec. 365.018 ms/step.
Train [40/40]. 21.92 samples/sec. 365.016 ms/step.
Train benchmark of convnextv2_huge.fcmae_ft_in1k done. 21.80 samples/sec, 365.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.57 GiB is free. Including non-PyTorch memory, this process has 22.07 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 110.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 9.28 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.09 GiB is free. Including non-PyTorch memory, this process has 17.55 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 348.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.71 GiB is free. Including non-PyTorch memory, this process has 18.93 GiB memory in use. Of the allocated memory 18.16 GiB is allocated by PyTorch, and 281.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.64 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.89 GiB is free. Including non-PyTorch memory, this process has 19.75 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
Infer [8/40]. 54.01 samples/sec. 1185.022 ms/step.
Infer [16/40]. 54.00 samples/sec. 1185.177 ms/step.
Infer [24/40]. 54.00 samples/sec. 1185.240 ms/step.
Infer [32/40]. 54.00 samples/sec. 1185.262 ms/step.
Infer [40/40]. 54.00 samples/sec. 1185.273 ms/step.
Inference benchmark of convnextv2_huge.fcmae_ft_in22k_in1k_384 done. 53.99 samples/sec, 1185.27 ms/step
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.72 GiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 114.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 9.28 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 21.39 GiB is allocated by PyTorch, and 353.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.61 GiB is free. Including non-PyTorch memory, this process has 22.04 GiB memory in use. Of the allocated memory 21.27 GiB is allocated by PyTorch, and 275.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.64 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.57 GiB is free. Including non-PyTorch memory, this process has 22.07 GiB memory in use. Of the allocated memory 21.22 GiB is allocated by PyTorch, and 365.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.65 GiB is free. Including non-PyTorch memory, this process has 21.99 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.65 GiB is free. Including non-PyTorch memory, this process has 21.99 GiB memory in use. Of the allocated memory 20.56 GiB is allocated by PyTorch, and 967.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.55 GiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 21.88 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 196.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 269.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 158.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 424.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 455.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 265.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 21.48 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_384 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 4.
Train [8/40]. 12.14 samples/sec. 329.442 ms/step.
Train [16/40]. 12.14 samples/sec. 329.437 ms/step.
Train [24/40]. 12.14 samples/sec. 329.430 ms/step.
Train [32/40]. 12.14 samples/sec. 329.433 ms/step.
Train [40/40]. 12.14 samples/sec. 329.473 ms/step.
Train benchmark of convnextv2_huge.fcmae_ft_in22k_in1k_384 done. 12.07 samples/sec, 329.47 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 22.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.83 GiB memory in use. Of the allocated memory 14.23 GiB is allocated by PyTorch, and 110.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 16.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 11.43 GiB is free. Including non-PyTorch memory, this process has 12.21 GiB memory in use. Of the allocated memory 11.29 GiB is allocated by PyTorch, and 432.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 11.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.44 GiB is free. Including non-PyTorch memory, this process has 20.20 GiB memory in use. Of the allocated memory 19.36 GiB is allocated by PyTorch, and 354.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 8.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.51 GiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Of the allocated memory 15.14 GiB is allocated by PyTorch, and 514.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 806.06 MiB is free. Including non-PyTorch memory, this process has 22.85 GiB memory in use. Of the allocated memory 17.79 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running inference benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 48.
Infer [8/40]. 30.56 samples/sec. 1570.573 ms/step.
Infer [16/40]. 30.56 samples/sec. 1570.801 ms/step.
Infer [24/40]. 30.56 samples/sec. 1570.852 ms/step.
Infer [32/40]. 30.56 samples/sec. 1570.892 ms/step.
Infer [40/40]. 30.56 samples/sec. 1570.907 ms/step.
Inference benchmark of convnextv2_huge.fcmae_ft_in22k_in1k_512 done. 30.55 samples/sec, 1570.91 ms/step
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.28 GiB is free. Including non-PyTorch memory, this process has 20.37 GiB memory in use. Of the allocated memory 19.76 GiB is allocated by PyTorch, and 110.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 16.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.12 GiB is free. Including non-PyTorch memory, this process has 20.52 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 448.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 11.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.93 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 13.89 GiB is allocated by PyTorch, and 334.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 8.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.35 GiB is free. Including non-PyTorch memory, this process has 20.29 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 522.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.54 GiB is free. Including non-PyTorch memory, this process has 20.10 GiB memory in use. Of the allocated memory 19.19 GiB is allocated by PyTorch, and 434.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 4.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.47 GiB is free. Including non-PyTorch memory, this process has 20.17 GiB memory in use. Of the allocated memory 19.14 GiB is allocated by PyTorch, and 548.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 838.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 21.15 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 22.17 GiB memory in use. Of the allocated memory 20.61 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 22.54 GiB memory in use. Of the allocated memory 21.10 GiB is allocated by PyTorch, and 969.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 528.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 352.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 434.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 336.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 183.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 826.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_huge.fcmae_ft_in22k_in1k_512 created, param count: 660289640
Running train benchmark on convnextv2_huge.fcmae_ft_in22k_in1k_512 for 40 steps w/ input size (3, 512, 512) and batch size 3.
Train [8/40]. 6.80 samples/sec. 441.180 ms/step.
Train [16/40]. 6.80 samples/sec. 441.188 ms/step.
Train [24/40]. 6.80 samples/sec. 441.193 ms/step.
Train [32/40]. 6.80 samples/sec. 441.192 ms/step.
Train [40/40]. 6.80 samples/sec. 441.190 ms/step.
Train benchmark of convnextv2_huge.fcmae_ft_in22k_in1k_512 done. 6.77 samples/sec, 441.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_large.fcmae created, param count: 196419840
Running inference benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 364.70 samples/sec. 701.951 ms/step.
Infer [16/40]. 364.69 samples/sec. 701.957 ms/step.
Infer [24/40]. 364.69 samples/sec. 701.962 ms/step.
Infer [32/40]. 364.68 samples/sec. 701.980 ms/step.
Infer [40/40]. 364.66 samples/sec. 702.020 ms/step.
Inference benchmark of convnextv2_large.fcmae done. 364.64 samples/sec, 702.02 ms/step
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.01 GiB is allocated by PyTorch, and 637.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 20.69 GiB is allocated by PyTorch, and 963.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 182.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 603.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 288.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 251.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 369.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_large.fcmae created, param count: 196419840
Running train benchmark on convnextv2_large.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running inference benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 221.80 samples/sec. 1154.177 ms/step.
Infer [16/40]. 221.80 samples/sec. 1154.178 ms/step.
Infer [24/40]. 221.80 samples/sec. 1154.176 ms/step.
Infer [32/40]. 221.79 samples/sec. 1154.222 ms/step.
Infer [40/40]. 221.79 samples/sec. 1154.266 ms/step.
Inference benchmark of convnextv2_large.fcmae_ft_in1k done. 221.78 samples/sec, 1154.27 ms/step
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process has 20.55 GiB memory in use. Of the allocated memory 20.00 GiB is allocated by PyTorch, and 60.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.99 GiB is free. Including non-PyTorch memory, this process has 21.65 GiB memory in use. Of the allocated memory 20.18 GiB is allocated by PyTorch, and 993.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 22.42 GiB memory in use. Of the allocated memory 20.83 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 638.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.51 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 269.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 354.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 247.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_large.fcmae_ft_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 24.
Train [8/40]. 51.29 samples/sec. 467.922 ms/step.
Train [16/40]. 51.29 samples/sec. 467.941 ms/step.
Train [24/40]. 51.29 samples/sec. 467.962 ms/step.
Train [32/40]. 51.29 samples/sec. 467.969 ms/step.
Train [40/40]. 51.28 samples/sec. 467.980 ms/step.
Train benchmark of convnextv2_large.fcmae_ft_in1k done. 51.10 samples/sec, 467.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running inference benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 221.79 samples/sec. 1154.225 ms/step.
Infer [16/40]. 221.79 samples/sec. 1154.219 ms/step.
Infer [24/40]. 221.80 samples/sec. 1154.212 ms/step.
Infer [32/40]. 221.80 samples/sec. 1154.216 ms/step.
Infer [40/40]. 221.80 samples/sec. 1154.213 ms/step.
Inference benchmark of convnextv2_large.fcmae_ft_in22k_in1k done. 221.79 samples/sec, 1154.21 ms/step
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process has 20.55 GiB memory in use. Of the allocated memory 20.00 GiB is allocated by PyTorch, and 60.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.99 GiB is free. Including non-PyTorch memory, this process has 21.65 GiB memory in use. Of the allocated memory 20.18 GiB is allocated by PyTorch, and 993.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 22.42 GiB memory in use. Of the allocated memory 20.83 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 638.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.51 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 269.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 354.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 247.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 24.
Train [8/40]. 51.26 samples/sec. 468.157 ms/step.
Train [16/40]. 51.27 samples/sec. 468.153 ms/step.
Train [24/40]. 51.26 samples/sec. 468.215 ms/step.
Train [32/40]. 51.26 samples/sec. 468.226 ms/step.
Train [40/40]. 51.26 samples/sec. 468.217 ms/step.
Train benchmark of convnextv2_large.fcmae_ft_in22k_in1k done. 51.07 samples/sec, 468.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running inference benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.04 GiB is free. Including non-PyTorch memory, this process has 18.61 GiB memory in use. Of the allocated memory 18.05 GiB is allocated by PyTorch, and 61.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running inference benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.05 GiB is free. Including non-PyTorch memory, this process has 19.59 GiB memory in use. Of the allocated memory 14.99 GiB is allocated by PyTorch, and 4.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running inference benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 124.96 samples/sec. 1024.322 ms/step.
Infer [16/40]. 124.96 samples/sec. 1024.333 ms/step.
Infer [24/40]. 124.96 samples/sec. 1024.341 ms/step.
Infer [32/40]. 124.96 samples/sec. 1024.345 ms/step.
Infer [40/40]. 124.95 samples/sec. 1024.369 ms/step.
Inference benchmark of convnextv2_large.fcmae_ft_in22k_in1k_384 done. 124.95 samples/sec, 1024.37 ms/step
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.62 GiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 65.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.50 GiB is free. Including non-PyTorch memory, this process has 22.14 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 306.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.73 GiB is free. Including non-PyTorch memory, this process has 21.91 GiB memory in use. Of the allocated memory 20.40 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 22.05 GiB memory in use. Of the allocated memory 20.55 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 394.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 560.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 270.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 136.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 255.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 301.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_large.fcmae_ft_in22k_in1k_384 created, param count: 197956840
Running train benchmark on convnextv2_large.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 28.51 samples/sec. 420.950 ms/step.
Train [16/40]. 28.51 samples/sec. 420.876 ms/step.
Train [24/40]. 28.51 samples/sec. 420.880 ms/step.
Train [32/40]. 28.50 samples/sec. 421.025 ms/step.
Train [40/40]. 28.50 samples/sec. 421.125 ms/step.
Train benchmark of convnextv2_large.fcmae_ft_in22k_in1k_384 done. 28.38 samples/sec, 421.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_nano.fcmae created, param count: 14982800
Running inference benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2217.38 samples/sec. 115.452 ms/step.
Infer [16/40]. 2217.39 samples/sec. 115.451 ms/step.
Infer [24/40]. 2217.39 samples/sec. 115.451 ms/step.
Infer [32/40]. 2217.35 samples/sec. 115.453 ms/step.
Infer [40/40]. 2217.32 samples/sec. 115.455 ms/step.
Inference benchmark of convnextv2_nano.fcmae done. 2216.71 samples/sec, 115.45 ms/step
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 136.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_nano.fcmae created, param count: 14982800
Running train benchmark on convnextv2_nano.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_nano.fcmae_ft_in1k created, param count: 15623800
Running inference benchmark on convnextv2_nano.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1337.54 samples/sec. 191.396 ms/step.
Infer [16/40]. 1337.57 samples/sec. 191.392 ms/step.
Infer [24/40]. 1337.52 samples/sec. 191.399 ms/step.
Infer [32/40]. 1337.52 samples/sec. 191.399 ms/step.
Infer [40/40]. 1337.41 samples/sec. 191.415 ms/step.
Inference benchmark of convnextv2_nano.fcmae_ft_in1k done. 1337.14 samples/sec, 191.41 ms/step
Model convnextv2_nano.fcmae_ft_in1k created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 810.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 378.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 269.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_nano.fcmae_ft_in1k created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 341.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_nano.fcmae_ft_in1k created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 321.54 samples/sec. 398.078 ms/step.
Train [16/40]. 321.52 samples/sec. 398.110 ms/step.
Train [24/40]. 321.51 samples/sec. 398.119 ms/step.
Train [32/40]. 321.50 samples/sec. 398.128 ms/step.
Train [40/40]. 321.51 samples/sec. 398.125 ms/step.
Train benchmark of convnextv2_nano.fcmae_ft_in1k done. 320.84 samples/sec, 398.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_nano.fcmae_ft_in22k_in1k created, param count: 15623800
Running inference benchmark on convnextv2_nano.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1337.11 samples/sec. 191.458 ms/step.
Infer [16/40]. 1337.10 samples/sec. 191.459 ms/step.
Infer [24/40]. 1337.09 samples/sec. 191.460 ms/step.
Infer [32/40]. 1337.11 samples/sec. 191.458 ms/step.
Infer [40/40]. 1337.08 samples/sec. 191.462 ms/step.
Inference benchmark of convnextv2_nano.fcmae_ft_in22k_in1k done. 1336.83 samples/sec, 191.46 ms/step
Model convnextv2_nano.fcmae_ft_in22k_in1k created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 810.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 378.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 269.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_nano.fcmae_ft_in22k_in1k created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 341.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_nano.fcmae_ft_in22k_in1k created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 321.37 samples/sec. 398.294 ms/step.
Train [16/40]. 321.38 samples/sec. 398.278 ms/step.
Train [24/40]. 321.34 samples/sec. 398.332 ms/step.
Train [32/40]. 321.27 samples/sec. 398.425 ms/step.
Train [40/40]. 321.22 samples/sec. 398.479 ms/step.
Train benchmark of convnextv2_nano.fcmae_ft_in22k_in1k done. 320.56 samples/sec, 398.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_nano.fcmae_ft_in22k_in1k_384 created, param count: 15623800
Running inference benchmark on convnextv2_nano.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 752.77 samples/sec. 340.078 ms/step.
Infer [16/40]. 752.75 samples/sec. 340.084 ms/step.
Infer [24/40]. 752.75 samples/sec. 340.086 ms/step.
Infer [32/40]. 752.75 samples/sec. 340.087 ms/step.
Infer [40/40]. 752.74 samples/sec. 340.090 ms/step.
Inference benchmark of convnextv2_nano.fcmae_ft_in22k_in1k_384 done. 752.65 samples/sec, 340.09 ms/step
Model convnextv2_nano.fcmae_ft_in22k_in1k_384 created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.81 GiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 741.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_nano.fcmae_ft_in22k_in1k_384 created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.48 GiB is free. Including non-PyTorch memory, this process has 22.16 GiB memory in use. Of the allocated memory 21.00 GiB is allocated by PyTorch, and 686.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_nano.fcmae_ft_in22k_in1k_384 created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 340.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_nano.fcmae_ft_in22k_in1k_384 created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 239.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_nano.fcmae_ft_in22k_in1k_384 created, param count: 15623800
Running train benchmark on convnextv2_nano.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 182.86 samples/sec. 349.991 ms/step.
Train [16/40]. 182.86 samples/sec. 349.990 ms/step.
Train [24/40]. 182.87 samples/sec. 349.969 ms/step.
Train [32/40]. 182.88 samples/sec. 349.950 ms/step.
Train [40/40]. 182.88 samples/sec. 349.948 ms/step.
Train benchmark of convnextv2_nano.fcmae_ft_in22k_in1k_384 done. 182.47 samples/sec, 349.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_pico.fcmae created, param count: 8553280
Running inference benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3123.60 samples/sec. 81.957 ms/step.
Infer [16/40]. 3122.91 samples/sec. 81.975 ms/step.
Infer [24/40]. 3122.61 samples/sec. 81.983 ms/step.
Infer [32/40]. 3122.48 samples/sec. 81.986 ms/step.
Infer [40/40]. 3122.37 samples/sec. 81.989 ms/step.
Inference benchmark of convnextv2_pico.fcmae done. 3121.29 samples/sec, 81.99 ms/step
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_pico.fcmae created, param count: 8553280
Running train benchmark on convnextv2_pico.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_pico.fcmae_ft_in1k created, param count: 9066280
Running inference benchmark on convnextv2_pico.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1869.96 samples/sec. 136.901 ms/step.
Infer [16/40]. 1869.79 samples/sec. 136.914 ms/step.
Infer [24/40]. 1869.32 samples/sec. 136.948 ms/step.
Infer [32/40]. 1869.13 samples/sec. 136.962 ms/step.
Infer [40/40]. 1869.01 samples/sec. 136.971 ms/step.
Inference benchmark of convnextv2_pico.fcmae_ft_in1k done. 1868.61 samples/sec, 136.97 ms/step
Model convnextv2_pico.fcmae_ft_in1k created, param count: 9066280
Running train benchmark on convnextv2_pico.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 158.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 350.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_pico.fcmae_ft_in1k created, param count: 9066280
Running train benchmark on convnextv2_pico.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 47.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_pico.fcmae_ft_in1k created, param count: 9066280
Running train benchmark on convnextv2_pico.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 451.94 samples/sec. 283.221 ms/step.
Train [16/40]. 451.94 samples/sec. 283.224 ms/step.
Train [24/40]. 451.97 samples/sec. 283.205 ms/step.
Train [32/40]. 451.96 samples/sec. 283.209 ms/step.
Train [40/40]. 451.97 samples/sec. 283.204 ms/step.
Train benchmark of convnextv2_pico.fcmae_ft_in1k done. 450.81 samples/sec, 283.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_tiny.fcmae created, param count: 27866496
Running inference benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1379.67 samples/sec. 185.552 ms/step.
Infer [16/40]. 1379.64 samples/sec. 185.556 ms/step.
Infer [24/40]. 1379.65 samples/sec. 185.554 ms/step.
Infer [32/40]. 1379.64 samples/sec. 185.555 ms/step.
Infer [40/40]. 1379.66 samples/sec. 185.554 ms/step.
Inference benchmark of convnextv2_tiny.fcmae done. 1379.36 samples/sec, 185.55 ms/step
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 264.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 490.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 176.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model convnextv2_tiny.fcmae created, param count: 27866496
Running train benchmark on convnextv2_tiny.fcmae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_tiny.fcmae_ft_in1k created, param count: 28635496
Running inference benchmark on convnextv2_tiny.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 835.58 samples/sec. 306.374 ms/step.
Infer [16/40]. 835.58 samples/sec. 306.375 ms/step.
Infer [24/40]. 835.57 samples/sec. 306.378 ms/step.
Infer [32/40]. 835.57 samples/sec. 306.379 ms/step.
Infer [40/40]. 835.51 samples/sec. 306.401 ms/step.
Inference benchmark of convnextv2_tiny.fcmae_ft_in1k done. 835.39 samples/sec, 306.40 ms/step
Model convnextv2_tiny.fcmae_ft_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 22.05 GiB memory in use. Of the allocated memory 20.34 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_tiny.fcmae_ft_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.29 GiB is free. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 20.98 GiB is allocated by PyTorch, and 900.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_tiny.fcmae_ft_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 268.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_tiny.fcmae_ft_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 329.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_tiny.fcmae_ft_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 193.57 samples/sec. 330.636 ms/step.
Train [16/40]. 193.55 samples/sec. 330.660 ms/step.
Train [24/40]. 193.55 samples/sec. 330.662 ms/step.
Train [32/40]. 193.55 samples/sec. 330.665 ms/step.
Train [40/40]. 193.55 samples/sec. 330.670 ms/step.
Train benchmark of convnextv2_tiny.fcmae_ft_in1k done. 193.00 samples/sec, 330.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_tiny.fcmae_ft_in22k_in1k created, param count: 28635496
Running inference benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 835.23 samples/sec. 306.502 ms/step.
Infer [16/40]. 835.24 samples/sec. 306.499 ms/step.
Infer [24/40]. 835.23 samples/sec. 306.501 ms/step.
Infer [32/40]. 835.23 samples/sec. 306.502 ms/step.
Infer [40/40]. 835.20 samples/sec. 306.513 ms/step.
Inference benchmark of convnextv2_tiny.fcmae_ft_in22k_in1k done. 835.08 samples/sec, 306.51 ms/step
Model convnextv2_tiny.fcmae_ft_in22k_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 22.05 GiB memory in use. Of the allocated memory 20.34 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.29 GiB is free. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 20.98 GiB is allocated by PyTorch, and 900.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 268.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 329.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 193.36 samples/sec. 330.993 ms/step.
Train [16/40]. 193.35 samples/sec. 331.011 ms/step.
Train [24/40]. 193.33 samples/sec. 331.036 ms/step.
Train [32/40]. 193.34 samples/sec. 331.032 ms/step.
Train [40/40]. 193.34 samples/sec. 331.030 ms/step.
Train benchmark of convnextv2_tiny.fcmae_ft_in22k_in1k done. 192.77 samples/sec, 331.03 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model convnextv2_tiny.fcmae_ft_in22k_in1k_384 created, param count: 28635496
Running inference benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 471.07 samples/sec. 543.446 ms/step.
Infer [16/40]. 471.06 samples/sec. 543.450 ms/step.
Infer [24/40]. 471.06 samples/sec. 543.453 ms/step.
Infer [32/40]. 471.06 samples/sec. 543.454 ms/step.
Infer [40/40]. 471.06 samples/sec. 543.455 ms/step.
Inference benchmark of convnextv2_tiny.fcmae_ft_in22k_in1k_384 done. 471.02 samples/sec, 543.46 ms/step
Model convnextv2_tiny.fcmae_ft_in22k_in1k_384 created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.09 GiB is free. Including non-PyTorch memory, this process has 21.55 GiB memory in use. Of the allocated memory 20.00 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k_384 created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.22 GiB is free. Including non-PyTorch memory, this process has 21.42 GiB memory in use. Of the allocated memory 20.10 GiB is allocated by PyTorch, and 850.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k_384 created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 586.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k_384 created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 368.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 489.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k_384 created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 270.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model convnextv2_tiny.fcmae_ft_in22k_in1k_384 created, param count: 28635496
Running train benchmark on convnextv2_tiny.fcmae_ft_in22k_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 105.45 samples/sec. 455.196 ms/step.
Train [16/40]. 105.45 samples/sec. 455.186 ms/step.
Train [24/40]. 105.45 samples/sec. 455.177 ms/step.
Train [32/40]. 105.45 samples/sec. 455.195 ms/step.
Train [40/40]. 105.44 samples/sec. 455.215 ms/step.
Train benchmark of convnextv2_tiny.fcmae_ft_in22k_in1k_384 done. 105.19 samples/sec, 455.21 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_9_240.in1k created, param count: 8553296
Running inference benchmark on crossvit_9_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 5843.70 samples/sec. 43.808 ms/step.
Infer [16/40]. 5843.64 samples/sec. 43.808 ms/step.
Infer [24/40]. 5843.84 samples/sec. 43.807 ms/step.
Infer [32/40]. 5843.58 samples/sec. 43.809 ms/step.
Infer [40/40]. 5843.51 samples/sec. 43.809 ms/step.
Inference benchmark of crossvit_9_240.in1k done. 5840.25 samples/sec, 43.81 ms/step
Model crossvit_9_240.in1k created, param count: 8553296
Running train benchmark on crossvit_9_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1522.71 samples/sec. 168.121 ms/step.
Train [16/40]. 1522.63 samples/sec. 168.130 ms/step.
Train [24/40]. 1522.63 samples/sec. 168.130 ms/step.
Train [32/40]. 1522.64 samples/sec. 168.130 ms/step.
Train [40/40]. 1522.60 samples/sec. 168.133 ms/step.
Train benchmark of crossvit_9_240.in1k done. 1511.80 samples/sec, 168.13 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_9_dagger_240.in1k created, param count: 8776592
Running inference benchmark on crossvit_9_dagger_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 5407.61 samples/sec. 47.341 ms/step.
Infer [16/40]. 5407.40 samples/sec. 47.343 ms/step.
Infer [24/40]. 5407.20 samples/sec. 47.344 ms/step.
Infer [32/40]. 5407.01 samples/sec. 47.346 ms/step.
Infer [40/40]. 5407.08 samples/sec. 47.345 ms/step.
Inference benchmark of crossvit_9_dagger_240.in1k done. 5404.27 samples/sec, 47.34 ms/step
Model crossvit_9_dagger_240.in1k created, param count: 8776592
Running train benchmark on crossvit_9_dagger_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1429.63 samples/sec. 179.067 ms/step.
Train [16/40]. 1429.63 samples/sec. 179.068 ms/step.
Train [24/40]. 1429.60 samples/sec. 179.071 ms/step.
Train [32/40]. 1429.57 samples/sec. 179.074 ms/step.
Train [40/40]. 1429.57 samples/sec. 179.074 ms/step.
Train benchmark of crossvit_9_dagger_240.in1k done. 1419.74 samples/sec, 179.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_15_240.in1k created, param count: 27528464
Running inference benchmark on crossvit_15_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2573.90 samples/sec. 99.460 ms/step.
Infer [16/40]. 2573.81 samples/sec. 99.463 ms/step.
Infer [24/40]. 2573.77 samples/sec. 99.465 ms/step.
Infer [32/40]. 2573.83 samples/sec. 99.463 ms/step.
Infer [40/40]. 2573.87 samples/sec. 99.461 ms/step.
Inference benchmark of crossvit_15_240.in1k done. 2573.19 samples/sec, 99.46 ms/step
Model crossvit_15_240.in1k created, param count: 27528464
Running train benchmark on crossvit_15_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 693.16 samples/sec. 369.325 ms/step.
Train [16/40]. 693.17 samples/sec. 369.318 ms/step.
Train [24/40]. 693.16 samples/sec. 369.325 ms/step.
Train [32/40]. 693.15 samples/sec. 369.326 ms/step.
Train [40/40]. 693.13 samples/sec. 369.338 ms/step.
Train benchmark of crossvit_15_240.in1k done. 689.84 samples/sec, 369.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_15_dagger_240.in1k created, param count: 28209008
Running inference benchmark on crossvit_15_dagger_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2427.03 samples/sec. 105.479 ms/step.
Infer [16/40]. 2426.98 samples/sec. 105.481 ms/step.
Infer [24/40]. 2427.03 samples/sec. 105.479 ms/step.
Infer [32/40]. 2426.99 samples/sec. 105.481 ms/step.
Infer [40/40]. 2426.97 samples/sec. 105.482 ms/step.
Inference benchmark of crossvit_15_dagger_240.in1k done. 2426.36 samples/sec, 105.48 ms/step
Model crossvit_15_dagger_240.in1k created, param count: 28209008
Running train benchmark on crossvit_15_dagger_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 659.56 samples/sec. 388.135 ms/step.
Train [16/40]. 659.57 samples/sec. 388.131 ms/step.
Train [24/40]. 659.57 samples/sec. 388.133 ms/step.
Train [32/40]. 659.56 samples/sec. 388.139 ms/step.
Train [40/40]. 659.56 samples/sec. 388.140 ms/step.
Train benchmark of crossvit_15_dagger_240.in1k done. 656.60 samples/sec, 388.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_15_dagger_408.in1k created, param count: 28500080
Running inference benchmark on crossvit_15_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 256.
Infer [8/40]. 626.39 samples/sec. 408.690 ms/step.
Infer [16/40]. 626.39 samples/sec. 408.690 ms/step.
Infer [24/40]. 626.40 samples/sec. 408.684 ms/step.
Infer [32/40]. 626.40 samples/sec. 408.683 ms/step.
Infer [40/40]. 626.39 samples/sec. 408.690 ms/step.
Inference benchmark of crossvit_15_dagger_408.in1k done. 626.32 samples/sec, 408.69 ms/step
Model crossvit_15_dagger_408.in1k created, param count: 28500080
Running train benchmark on crossvit_15_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 349.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model crossvit_15_dagger_408.in1k created, param count: 28500080
Running train benchmark on crossvit_15_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 418.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model crossvit_15_dagger_408.in1k created, param count: 28500080
Running train benchmark on crossvit_15_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 275.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model crossvit_15_dagger_408.in1k created, param count: 28500080
Running train benchmark on crossvit_15_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 208.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 216.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model crossvit_15_dagger_408.in1k created, param count: 28500080
Running train benchmark on crossvit_15_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 64.
Train [8/40]. 157.52 samples/sec. 406.294 ms/step.
Train [16/40]. 157.52 samples/sec. 406.298 ms/step.
Train [24/40]. 157.52 samples/sec. 406.308 ms/step.
Train [32/40]. 157.52 samples/sec. 406.303 ms/step.
Train [40/40]. 157.52 samples/sec. 406.304 ms/step.
Train benchmark of crossvit_15_dagger_408.in1k done. 156.83 samples/sec, 406.30 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_18_240.in1k created, param count: 43271408
Running inference benchmark on crossvit_18_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 1827.43 samples/sec. 140.088 ms/step.
Infer [16/40]. 1826.99 samples/sec. 140.121 ms/step.
Infer [24/40]. 1826.86 samples/sec. 140.131 ms/step.
Infer [32/40]. 1826.84 samples/sec. 140.133 ms/step.
Infer [40/40]. 1826.82 samples/sec. 140.134 ms/step.
Inference benchmark of crossvit_18_240.in1k done. 1826.41 samples/sec, 140.13 ms/step
Model crossvit_18_240.in1k created, param count: 43271408
Running train benchmark on crossvit_18_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 198.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model crossvit_18_240.in1k created, param count: 43271408
Running train benchmark on crossvit_18_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
Train [8/40]. 470.04 samples/sec. 408.477 ms/step.
Train [16/40]. 469.95 samples/sec. 408.555 ms/step.
Train [24/40]. 469.92 samples/sec. 408.578 ms/step.
Train [32/40]. 469.91 samples/sec. 408.587 ms/step.
Train [40/40]. 469.90 samples/sec. 408.599 ms/step.
Train benchmark of crossvit_18_240.in1k done. 467.73 samples/sec, 408.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_18_dagger_240.in1k created, param count: 44266976
Running inference benchmark on crossvit_18_dagger_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 1735.01 samples/sec. 147.550 ms/step.
Infer [16/40]. 1735.02 samples/sec. 147.548 ms/step.
Infer [24/40]. 1734.73 samples/sec. 147.574 ms/step.
Infer [32/40]. 1734.53 samples/sec. 147.590 ms/step.
Infer [40/40]. 1734.43 samples/sec. 147.599 ms/step.
Inference benchmark of crossvit_18_dagger_240.in1k done. 1734.07 samples/sec, 147.60 ms/step
Model crossvit_18_dagger_240.in1k created, param count: 44266976
Running train benchmark on crossvit_18_dagger_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 295.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model crossvit_18_dagger_240.in1k created, param count: 44266976
Running train benchmark on crossvit_18_dagger_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
Train [8/40]. 450.82 samples/sec. 425.890 ms/step.
Train [16/40]. 450.75 samples/sec. 425.958 ms/step.
Train [24/40]. 450.71 samples/sec. 425.996 ms/step.
Train [32/40]. 450.69 samples/sec. 426.014 ms/step.
Train [40/40]. 450.68 samples/sec. 426.022 ms/step.
Train benchmark of crossvit_18_dagger_240.in1k done. 448.63 samples/sec, 426.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_18_dagger_408.in1k created, param count: 44606560
Running inference benchmark on crossvit_18_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 256.
Infer [8/40]. 457.05 samples/sec. 560.112 ms/step.
Infer [16/40]. 456.95 samples/sec. 560.233 ms/step.
Infer [24/40]. 456.92 samples/sec. 560.274 ms/step.
Infer [32/40]. 456.75 samples/sec. 560.482 ms/step.
Infer [40/40]. 456.61 samples/sec. 560.655 ms/step.
Inference benchmark of crossvit_18_dagger_408.in1k done. 456.57 samples/sec, 560.65 ms/step
Model crossvit_18_dagger_408.in1k created, param count: 44606560
Running train benchmark on crossvit_18_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 228.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 401.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model crossvit_18_dagger_408.in1k created, param count: 44606560
Running train benchmark on crossvit_18_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 442.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model crossvit_18_dagger_408.in1k created, param count: 44606560
Running train benchmark on crossvit_18_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 322.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model crossvit_18_dagger_408.in1k created, param count: 44606560
Running train benchmark on crossvit_18_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 195.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model crossvit_18_dagger_408.in1k created, param count: 44606560
Running train benchmark on crossvit_18_dagger_408.in1k for 40 steps w/ input size (3, 408, 408) and batch size 64.
Train [8/40]. 116.43 samples/sec. 549.703 ms/step.
Train [16/40]. 116.30 samples/sec. 550.310 ms/step.
Train [24/40]. 116.26 samples/sec. 550.511 ms/step.
Train [32/40]. 116.24 samples/sec. 550.607 ms/step.
Train [40/40]. 116.22 samples/sec. 550.666 ms/step.
Train benchmark of crossvit_18_dagger_408.in1k done. 115.81 samples/sec, 550.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_base_240.in1k created, param count: 105025232
Running inference benchmark on crossvit_base_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 1071.11 samples/sec. 239.005 ms/step.
Infer [16/40]. 1071.06 samples/sec. 239.015 ms/step.
Infer [24/40]. 1071.03 samples/sec. 239.022 ms/step.
Infer [32/40]. 1071.01 samples/sec. 239.028 ms/step.
Infer [40/40]. 1071.00 samples/sec. 239.030 ms/step.
Inference benchmark of crossvit_base_240.in1k done. 1070.81 samples/sec, 239.03 ms/step
Model crossvit_base_240.in1k created, param count: 105025232
Running train benchmark on crossvit_base_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 424.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 42.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model crossvit_base_240.in1k created, param count: 105025232
Running train benchmark on crossvit_base_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 227.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model crossvit_base_240.in1k created, param count: 105025232
Running train benchmark on crossvit_base_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 299.22 samples/sec. 427.785 ms/step.
Train [16/40]. 299.14 samples/sec. 427.888 ms/step.
Train [24/40]. 299.12 samples/sec. 427.918 ms/step.
Train [32/40]. 299.11 samples/sec. 427.935 ms/step.
Train [40/40]. 299.11 samples/sec. 427.934 ms/step.
Train benchmark of crossvit_base_240.in1k done. 297.96 samples/sec, 427.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_small_240.in1k created, param count: 26856272
Running inference benchmark on crossvit_small_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2763.62 samples/sec. 92.632 ms/step.
Infer [16/40]. 2763.30 samples/sec. 92.643 ms/step.
Infer [24/40]. 2763.10 samples/sec. 92.649 ms/step.
Infer [32/40]. 2763.12 samples/sec. 92.649 ms/step.
Infer [40/40]. 2763.09 samples/sec. 92.650 ms/step.
Inference benchmark of crossvit_small_240.in1k done. 2762.30 samples/sec, 92.65 ms/step
Model crossvit_small_240.in1k created, param count: 26856272
Running train benchmark on crossvit_small_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 754.48 samples/sec. 339.304 ms/step.
Train [16/40]. 754.51 samples/sec. 339.294 ms/step.
Train [24/40]. 754.51 samples/sec. 339.295 ms/step.
Train [32/40]. 754.52 samples/sec. 339.289 ms/step.
Train [40/40]. 754.51 samples/sec. 339.291 ms/step.
Train benchmark of crossvit_small_240.in1k done. 750.99 samples/sec, 339.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model crossvit_tiny_240.in1k created, param count: 7014800
Running inference benchmark on crossvit_tiny_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 6167.62 samples/sec. 41.507 ms/step.
Infer [16/40]. 6168.89 samples/sec. 41.499 ms/step.
Infer [24/40]. 6169.73 samples/sec. 41.493 ms/step.
Infer [32/40]. 6169.80 samples/sec. 41.492 ms/step.
Infer [40/40]. 6170.00 samples/sec. 41.491 ms/step.
Inference benchmark of crossvit_tiny_240.in1k done. 6166.32 samples/sec, 41.49 ms/step
Model crossvit_tiny_240.in1k created, param count: 7014800
Running train benchmark on crossvit_tiny_240.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1633.80 samples/sec. 156.690 ms/step.
Train [16/40]. 1633.89 samples/sec. 156.681 ms/step.
Train [24/40]. 1633.92 samples/sec. 156.678 ms/step.
Train [32/40]. 1633.89 samples/sec. 156.682 ms/step.
Train [40/40]. 1633.95 samples/sec. 156.676 ms/step.
Train benchmark of crossvit_tiny_240.in1k done. 1620.82 samples/sec, 156.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3darknet_focus_l.c2ns_in1k created, param count: 21151720
Running inference benchmark on cs3darknet_focus_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2237.46 samples/sec. 114.415 ms/step.
Infer [16/40]. 2237.64 samples/sec. 114.406 ms/step.
Infer [24/40]. 2237.65 samples/sec. 114.406 ms/step.
Infer [32/40]. 2237.65 samples/sec. 114.406 ms/step.
Infer [40/40]. 2237.62 samples/sec. 114.407 ms/step.
Inference benchmark of cs3darknet_focus_l.c2ns_in1k done. 2237.07 samples/sec, 114.41 ms/step
Model cs3darknet_focus_l.c2ns_in1k created, param count: 21151720
Running train benchmark on cs3darknet_focus_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 82.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cs3darknet_focus_l.c2ns_in1k created, param count: 21151720
Running train benchmark on cs3darknet_focus_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 634.32 samples/sec. 302.688 ms/step.
Train [16/40]. 634.07 samples/sec. 302.808 ms/step.
Train [24/40]. 634.02 samples/sec. 302.831 ms/step.
Train [32/40]. 634.09 samples/sec. 302.795 ms/step.
Train [40/40]. 634.14 samples/sec. 302.774 ms/step.
Train benchmark of cs3darknet_focus_l.c2ns_in1k done. 632.16 samples/sec, 302.77 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3darknet_focus_m.c2ns_in1k created, param count: 9304360
Running inference benchmark on cs3darknet_focus_m.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 3939.14 samples/sec. 64.989 ms/step.
Infer [16/40]. 3939.09 samples/sec. 64.990 ms/step.
Infer [24/40]. 3939.03 samples/sec. 64.991 ms/step.
Infer [32/40]. 3938.95 samples/sec. 64.992 ms/step.
Infer [40/40]. 3938.89 samples/sec. 64.993 ms/step.
Inference benchmark of cs3darknet_focus_m.c2ns_in1k done. 3937.30 samples/sec, 64.99 ms/step
Model cs3darknet_focus_m.c2ns_in1k created, param count: 9304360
Running train benchmark on cs3darknet_focus_m.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1107.43 samples/sec. 231.166 ms/step.
Train [16/40]. 1107.43 samples/sec. 231.166 ms/step.
Train [24/40]. 1107.45 samples/sec. 231.162 ms/step.
Train [32/40]. 1107.43 samples/sec. 231.165 ms/step.
Train [40/40]. 1107.45 samples/sec. 231.162 ms/step.
Train benchmark of cs3darknet_focus_m.c2ns_in1k done. 1103.89 samples/sec, 231.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3darknet_l.c2ns_in1k created, param count: 21164168
Running inference benchmark on cs3darknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2126.69 samples/sec. 120.375 ms/step.
Infer [16/40]. 2126.78 samples/sec. 120.370 ms/step.
Infer [24/40]. 2126.68 samples/sec. 120.375 ms/step.
Infer [32/40]. 2126.63 samples/sec. 120.378 ms/step.
Infer [40/40]. 2126.61 samples/sec. 120.379 ms/step.
Inference benchmark of cs3darknet_l.c2ns_in1k done. 2126.08 samples/sec, 120.38 ms/step
Model cs3darknet_l.c2ns_in1k created, param count: 21164168
Running train benchmark on cs3darknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 84.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cs3darknet_l.c2ns_in1k created, param count: 21164168
Running train benchmark on cs3darknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 194.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cs3darknet_l.c2ns_in1k created, param count: 21164168
Running train benchmark on cs3darknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 601.31 samples/sec. 212.868 ms/step.
Train [16/40]. 601.34 samples/sec. 212.857 ms/step.
Train [24/40]. 601.32 samples/sec. 212.866 ms/step.
Train [32/40]. 601.31 samples/sec. 212.867 ms/step.
Train [40/40]. 601.31 samples/sec. 212.868 ms/step.
Train benchmark of cs3darknet_l.c2ns_in1k done. 598.87 samples/sec, 212.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3darknet_m.c2ns_in1k created, param count: 9310240
Running inference benchmark on cs3darknet_m.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 3682.18 samples/sec. 69.524 ms/step.
Infer [16/40]. 3681.78 samples/sec. 69.532 ms/step.
Infer [24/40]. 3681.64 samples/sec. 69.534 ms/step.
Infer [32/40]. 3681.28 samples/sec. 69.541 ms/step.
Infer [40/40]. 3681.00 samples/sec. 69.546 ms/step.
Inference benchmark of cs3darknet_m.c2ns_in1k done. 3679.59 samples/sec, 69.55 ms/step
Model cs3darknet_m.c2ns_in1k created, param count: 9310240
Running train benchmark on cs3darknet_m.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1004.57 samples/sec. 254.835 ms/step.
Train [16/40]. 1004.69 samples/sec. 254.804 ms/step.
Train [24/40]. 1004.61 samples/sec. 254.824 ms/step.
Train [32/40]. 1004.66 samples/sec. 254.812 ms/step.
Train [40/40]. 1004.66 samples/sec. 254.812 ms/step.
Train benchmark of cs3darknet_m.c2ns_in1k done. 1001.55 samples/sec, 254.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3darknet_x.c2ns_in1k created, param count: 35046320
Running inference benchmark on cs3darknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1388.04 samples/sec. 184.432 ms/step.
Infer [16/40]. 1386.78 samples/sec. 184.600 ms/step.
Infer [24/40]. 1386.96 samples/sec. 184.577 ms/step.
Infer [32/40]. 1387.06 samples/sec. 184.563 ms/step.
Infer [40/40]. 1387.10 samples/sec. 184.557 ms/step.
Inference benchmark of cs3darknet_x.c2ns_in1k done. 1386.83 samples/sec, 184.56 ms/step
Model cs3darknet_x.c2ns_in1k created, param count: 35046320
Running train benchmark on cs3darknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 17.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cs3darknet_x.c2ns_in1k created, param count: 35046320
Running train benchmark on cs3darknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 215.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cs3darknet_x.c2ns_in1k created, param count: 35046320
Running train benchmark on cs3darknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 401.21 samples/sec. 319.031 ms/step.
Train [16/40]. 401.20 samples/sec. 319.046 ms/step.
Train [24/40]. 401.19 samples/sec. 319.048 ms/step.
Train [32/40]. 401.18 samples/sec. 319.060 ms/step.
Train [40/40]. 401.17 samples/sec. 319.063 ms/step.
Train benchmark of cs3darknet_x.c2ns_in1k done. 399.89 samples/sec, 319.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3edgenet_x.c2_in1k created, param count: 47821120
Running inference benchmark on cs3edgenet_x.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1176.13 samples/sec. 217.663 ms/step.
Infer [16/40]. 1176.13 samples/sec. 217.663 ms/step.
Infer [24/40]. 1176.11 samples/sec. 217.667 ms/step.
Infer [32/40]. 1176.09 samples/sec. 217.670 ms/step.
Infer [40/40]. 1176.03 samples/sec. 217.682 ms/step.
Inference benchmark of cs3edgenet_x.c2_in1k done. 1175.82 samples/sec, 217.68 ms/step
Model cs3edgenet_x.c2_in1k created, param count: 47821120
Running train benchmark on cs3edgenet_x.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 810.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 758.06 MiB is free. Including non-PyTorch memory, this process has 22.90 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 7.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cs3edgenet_x.c2_in1k created, param count: 47821120
Running train benchmark on cs3edgenet_x.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 223.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cs3edgenet_x.c2_in1k created, param count: 47821120
Running train benchmark on cs3edgenet_x.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 404.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cs3edgenet_x.c2_in1k created, param count: 47821120
Running train benchmark on cs3edgenet_x.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 340.13 samples/sec. 282.242 ms/step.
Train [16/40]. 340.12 samples/sec. 282.255 ms/step.
Train [24/40]. 340.11 samples/sec. 282.263 ms/step.
Train [32/40]. 340.10 samples/sec. 282.270 ms/step.
Train [40/40]. 340.10 samples/sec. 282.273 ms/step.
Train benchmark of cs3edgenet_x.c2_in1k done. 338.89 samples/sec, 282.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3se_edgenet_x.c2ns_in1k created, param count: 50721584
Running inference benchmark on cs3se_edgenet_x.c2ns_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 905.63 samples/sec. 282.675 ms/step.
Infer [16/40]. 905.59 samples/sec. 282.689 ms/step.
Infer [24/40]. 905.56 samples/sec. 282.699 ms/step.
Infer [32/40]. 905.55 samples/sec. 282.701 ms/step.
Infer [40/40]. 905.36 samples/sec. 282.760 ms/step.
Inference benchmark of cs3se_edgenet_x.c2ns_in1k done. 905.23 samples/sec, 282.76 ms/step
Model cs3se_edgenet_x.c2ns_in1k created, param count: 50721584
Running train benchmark on cs3se_edgenet_x.c2ns_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 750.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 680.06 MiB is free. Including non-PyTorch memory, this process has 22.98 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 9.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cs3se_edgenet_x.c2ns_in1k created, param count: 50721584
Running train benchmark on cs3se_edgenet_x.c2ns_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 750.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 498.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 254.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cs3se_edgenet_x.c2ns_in1k created, param count: 50721584
Running train benchmark on cs3se_edgenet_x.c2ns_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 231.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cs3se_edgenet_x.c2ns_in1k created, param count: 50721584
Running train benchmark on cs3se_edgenet_x.c2ns_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 567.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model cs3se_edgenet_x.c2ns_in1k created, param count: 50721584
Running train benchmark on cs3se_edgenet_x.c2ns_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
Train [8/40]. 260.83 samples/sec. 245.369 ms/step.
Train [16/40]. 260.80 samples/sec. 245.401 ms/step.
Train [24/40]. 260.81 samples/sec. 245.389 ms/step.
Train [32/40]. 260.80 samples/sec. 245.396 ms/step.
Train [40/40]. 260.79 samples/sec. 245.406 ms/step.
Train benchmark of cs3se_edgenet_x.c2ns_in1k done. 259.43 samples/sec, 245.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3sedarknet_l.c2ns_in1k created, param count: 21913592
Running inference benchmark on cs3sedarknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1973.04 samples/sec. 129.749 ms/step.
Infer [16/40]. 1972.69 samples/sec. 129.772 ms/step.
Infer [24/40]. 1972.62 samples/sec. 129.776 ms/step.
Infer [32/40]. 1972.58 samples/sec. 129.779 ms/step.
Infer [40/40]. 1972.57 samples/sec. 129.780 ms/step.
Inference benchmark of cs3sedarknet_l.c2ns_in1k done. 1972.10 samples/sec, 129.78 ms/step
Model cs3sedarknet_l.c2ns_in1k created, param count: 21913592
Running train benchmark on cs3sedarknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 79.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cs3sedarknet_l.c2ns_in1k created, param count: 21913592
Running train benchmark on cs3sedarknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 167.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cs3sedarknet_l.c2ns_in1k created, param count: 21913592
Running train benchmark on cs3sedarknet_l.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 550.84 samples/sec. 232.371 ms/step.
Train [16/40]. 550.87 samples/sec. 232.361 ms/step.
Train [24/40]. 550.88 samples/sec. 232.354 ms/step.
Train [32/40]. 550.89 samples/sec. 232.351 ms/step.
Train [40/40]. 550.89 samples/sec. 232.353 ms/step.
Train benchmark of cs3sedarknet_l.c2ns_in1k done. 548.12 samples/sec, 232.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cs3sedarknet_x.c2ns_in1k created, param count: 35397904
Running inference benchmark on cs3sedarknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1295.13 samples/sec. 197.663 ms/step.
Infer [16/40]. 1295.11 samples/sec. 197.667 ms/step.
Infer [24/40]. 1295.09 samples/sec. 197.670 ms/step.
Infer [32/40]. 1295.08 samples/sec. 197.671 ms/step.
Infer [40/40]. 1294.78 samples/sec. 197.716 ms/step.
Inference benchmark of cs3sedarknet_x.c2ns_in1k done. 1294.54 samples/sec, 197.72 ms/step
Model cs3sedarknet_x.c2ns_in1k created, param count: 35397904
Running train benchmark on cs3sedarknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 384.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 17.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cs3sedarknet_x.c2ns_in1k created, param count: 35397904
Running train benchmark on cs3sedarknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 208.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cs3sedarknet_x.c2ns_in1k created, param count: 35397904
Running train benchmark on cs3sedarknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 329.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model cs3sedarknet_x.c2ns_in1k created, param count: 35397904
Running train benchmark on cs3sedarknet_x.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 369.41 samples/sec. 259.871 ms/step.
Train [16/40]. 369.42 samples/sec. 259.869 ms/step.
Train [24/40]. 369.42 samples/sec. 259.868 ms/step.
Train [32/40]. 369.42 samples/sec. 259.869 ms/step.
Train [40/40]. 369.41 samples/sec. 259.871 ms/step.
Train benchmark of cs3sedarknet_x.c2ns_in1k done. 367.54 samples/sec, 259.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cspdarknet53.ra_in1k created, param count: 27642184
Running inference benchmark on cspdarknet53.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1551.50 samples/sec. 165.001 ms/step.
Infer [16/40]. 1551.48 samples/sec. 165.004 ms/step.
Infer [24/40]. 1551.36 samples/sec. 165.016 ms/step.
Infer [32/40]. 1551.33 samples/sec. 165.019 ms/step.
Infer [40/40]. 1551.29 samples/sec. 165.024 ms/step.
Inference benchmark of cspdarknet53.ra_in1k done. 1550.95 samples/sec, 165.02 ms/step
Model cspdarknet53.ra_in1k created, param count: 27642184
Running train benchmark on cspdarknet53.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 48.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cspdarknet53.ra_in1k created, param count: 27642184
Running train benchmark on cspdarknet53.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 164.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cspdarknet53.ra_in1k created, param count: 27642184
Running train benchmark on cspdarknet53.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 475.13 samples/sec. 269.400 ms/step.
Train [16/40]. 475.20 samples/sec. 269.362 ms/step.
Train [24/40]. 475.22 samples/sec. 269.347 ms/step.
Train [32/40]. 475.24 samples/sec. 269.338 ms/step.
Train [40/40]. 475.25 samples/sec. 269.331 ms/step.
Train benchmark of cspdarknet53.ra_in1k done. 473.42 samples/sec, 269.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cspresnet50.ra_in1k created, param count: 21616168
Running inference benchmark on cspresnet50.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2336.47 samples/sec. 109.567 ms/step.
Infer [16/40]. 2336.41 samples/sec. 109.570 ms/step.
Infer [24/40]. 2336.31 samples/sec. 109.574 ms/step.
Infer [32/40]. 2336.33 samples/sec. 109.574 ms/step.
Infer [40/40]. 2336.28 samples/sec. 109.576 ms/step.
Inference benchmark of cspresnet50.ra_in1k done. 2335.66 samples/sec, 109.58 ms/step
Model cspresnet50.ra_in1k created, param count: 21616168
Running train benchmark on cspresnet50.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 138.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cspresnet50.ra_in1k created, param count: 21616168
Running train benchmark on cspresnet50.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
Train [8/40]. 734.50 samples/sec. 261.404 ms/step.
Train [16/40]. 734.48 samples/sec. 261.409 ms/step.
Train [24/40]. 734.47 samples/sec. 261.412 ms/step.
Train [32/40]. 734.47 samples/sec. 261.411 ms/step.
Train [40/40]. 734.47 samples/sec. 261.414 ms/step.
Train benchmark of cspresnet50.ra_in1k done. 731.86 samples/sec, 261.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model cspresnext50.ra_in1k created, param count: 20569896
Running inference benchmark on cspresnext50.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1871.24 samples/sec. 136.807 ms/step.
Infer [16/40]. 1870.83 samples/sec. 136.837 ms/step.
Infer [24/40]. 1871.02 samples/sec. 136.824 ms/step.
Infer [32/40]. 1871.00 samples/sec. 136.825 ms/step.
Infer [40/40]. 1870.95 samples/sec. 136.829 ms/step.
Inference benchmark of cspresnext50.ra_in1k done. 1870.53 samples/sec, 136.83 ms/step
Model cspresnext50.ra_in1k created, param count: 20569896
Running train benchmark on cspresnext50.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 70.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model cspresnext50.ra_in1k created, param count: 20569896
Running train benchmark on cspresnext50.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 250.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model cspresnext50.ra_in1k created, param count: 20569896
Running train benchmark on cspresnext50.ra_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 564.37 samples/sec. 226.800 ms/step.
Train [16/40]. 564.34 samples/sec. 226.813 ms/step.
Train [24/40]. 564.32 samples/sec. 226.823 ms/step.
Train [32/40]. 564.34 samples/sec. 226.813 ms/step.
Train [40/40]. 564.37 samples/sec. 226.801 ms/step.
Train benchmark of cspresnext50.ra_in1k done. 562.28 samples/sec, 226.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model darknet53.c2ns_in1k created, param count: 41609928
Running inference benchmark on darknet53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1338.87 samples/sec. 191.207 ms/step.
Infer [16/40]. 1338.79 samples/sec. 191.218 ms/step.
Infer [24/40]. 1338.83 samples/sec. 191.212 ms/step.
Infer [32/40]. 1338.82 samples/sec. 191.213 ms/step.
Infer [40/40]. 1338.82 samples/sec. 191.214 ms/step.
Inference benchmark of darknet53.c2ns_in1k done. 1338.55 samples/sec, 191.21 ms/step
Model darknet53.c2ns_in1k created, param count: 41609928
Running train benchmark on darknet53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 34.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model darknet53.c2ns_in1k created, param count: 41609928
Running train benchmark on darknet53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 241.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model darknet53.c2ns_in1k created, param count: 41609928
Running train benchmark on darknet53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 390.12 samples/sec. 328.104 ms/step.
Train [16/40]. 390.12 samples/sec. 328.101 ms/step.
Train [24/40]. 390.11 samples/sec. 328.111 ms/step.
Train [32/40]. 390.10 samples/sec. 328.118 ms/step.
Train [40/40]. 390.11 samples/sec. 328.116 ms/step.
Train benchmark of darknet53.c2ns_in1k done. 389.01 samples/sec, 328.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model darknetaa53.c2ns_in1k created, param count: 36022984
Running inference benchmark on darknetaa53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1397.65 samples/sec. 183.164 ms/step.
Infer [16/40]. 1397.61 samples/sec. 183.170 ms/step.
Infer [24/40]. 1397.60 samples/sec. 183.171 ms/step.
Infer [32/40]. 1397.60 samples/sec. 183.172 ms/step.
Infer [40/40]. 1397.60 samples/sec. 183.172 ms/step.
Inference benchmark of darknetaa53.c2ns_in1k done. 1397.32 samples/sec, 183.17 ms/step
Model darknetaa53.c2ns_in1k created, param count: 36022984
Running train benchmark on darknetaa53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 29.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model darknetaa53.c2ns_in1k created, param count: 36022984
Running train benchmark on darknetaa53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 243.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model darknetaa53.c2ns_in1k created, param count: 36022984
Running train benchmark on darknetaa53.c2ns_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 420.25 samples/sec. 304.579 ms/step.
Train [16/40]. 420.26 samples/sec. 304.576 ms/step.
Train [24/40]. 420.25 samples/sec. 304.583 ms/step.
Train [32/40]. 420.24 samples/sec. 304.587 ms/step.
Train [40/40]. 420.24 samples/sec. 304.589 ms/step.
Train benchmark of darknetaa53.c2ns_in1k done. 418.96 samples/sec, 304.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model davit_base.msft_in1k created, param count: 87954408
Running inference benchmark on davit_base.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 903.39 samples/sec. 283.377 ms/step.
Infer [16/40]. 903.38 samples/sec. 283.379 ms/step.
Infer [24/40]. 903.37 samples/sec. 283.382 ms/step.
Infer [32/40]. 903.37 samples/sec. 283.382 ms/step.
Infer [40/40]. 903.36 samples/sec. 283.385 ms/step.
Inference benchmark of davit_base.msft_in1k done. 903.23 samples/sec, 283.38 ms/step
Model davit_base.msft_in1k created, param count: 87954408
Running train benchmark on davit_base.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 720.06 MiB is free. Including non-PyTorch memory, this process has 22.94 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 495.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model davit_base.msft_in1k created, param count: 87954408
Running train benchmark on davit_base.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 42.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model davit_base.msft_in1k created, param count: 87954408
Running train benchmark on davit_base.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.10 GiB is allocated by PyTorch, and 25.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model davit_base.msft_in1k created, param count: 87954408
Running train benchmark on davit_base.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 269.68 samples/sec. 355.980 ms/step.
Train [16/40]. 269.71 samples/sec. 355.940 ms/step.
Train [24/40]. 269.73 samples/sec. 355.913 ms/step.
Train [32/40]. 269.71 samples/sec. 355.931 ms/step.
Train [40/40]. 269.72 samples/sec. 355.928 ms/step.
Train benchmark of davit_base.msft_in1k done. 268.11 samples/sec, 355.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model davit_small.msft_in1k created, param count: 49745896
Running inference benchmark on davit_small.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1284.56 samples/sec. 199.290 ms/step.
Infer [16/40]. 1284.49 samples/sec. 199.301 ms/step.
Infer [24/40]. 1284.50 samples/sec. 199.300 ms/step.
Infer [32/40]. 1284.50 samples/sec. 199.299 ms/step.
Infer [40/40]. 1284.48 samples/sec. 199.302 ms/step.
Inference benchmark of davit_small.msft_in1k done. 1284.25 samples/sec, 199.30 ms/step
Model davit_small.msft_in1k created, param count: 49745896
Running train benchmark on davit_small.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.09 GiB is allocated by PyTorch, and 32.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model davit_small.msft_in1k created, param count: 49745896
Running train benchmark on davit_small.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 134.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model davit_small.msft_in1k created, param count: 49745896
Running train benchmark on davit_small.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 385.59 samples/sec. 331.955 ms/step.
Train [16/40]. 385.56 samples/sec. 331.984 ms/step.
Train [24/40]. 385.62 samples/sec. 331.935 ms/step.
Train [32/40]. 385.58 samples/sec. 331.963 ms/step.
Train [40/40]. 385.61 samples/sec. 331.941 ms/step.
Train benchmark of davit_small.msft_in1k done. 383.21 samples/sec, 331.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model davit_tiny.msft_in1k created, param count: 28360168
Running inference benchmark on davit_tiny.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2082.40 samples/sec. 122.935 ms/step.
Infer [16/40]. 2082.01 samples/sec. 122.958 ms/step.
Infer [24/40]. 2081.95 samples/sec. 122.962 ms/step.
Infer [32/40]. 2081.93 samples/sec. 122.963 ms/step.
Infer [40/40]. 2081.90 samples/sec. 122.965 ms/step.
Inference benchmark of davit_tiny.msft_in1k done. 2081.38 samples/sec, 122.97 ms/step
Model davit_tiny.msft_in1k created, param count: 28360168
Running train benchmark on davit_tiny.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 36.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model davit_tiny.msft_in1k created, param count: 28360168
Running train benchmark on davit_tiny.msft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 591.97 samples/sec. 324.342 ms/step.
Train [16/40]. 592.03 samples/sec. 324.305 ms/step.
Train [24/40]. 592.08 samples/sec. 324.280 ms/step.
Train [32/40]. 592.05 samples/sec. 324.295 ms/step.
Train [40/40]. 592.00 samples/sec. 324.325 ms/step.
Train benchmark of davit_tiny.msft_in1k done. 589.60 samples/sec, 324.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_base_patch16_224.fb_in1k created, param count: 86585320
Running inference benchmark on deit3_base_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1415.45 samples/sec. 180.862 ms/step.
Infer [16/40]. 1415.51 samples/sec. 180.854 ms/step.
Infer [24/40]. 1415.59 samples/sec. 180.843 ms/step.
Infer [32/40]. 1415.63 samples/sec. 180.838 ms/step.
Infer [40/40]. 1415.63 samples/sec. 180.838 ms/step.
Inference benchmark of deit3_base_patch16_224.fb_in1k done. 1415.36 samples/sec, 180.84 ms/step
Model deit3_base_patch16_224.fb_in1k created, param count: 86585320
Running train benchmark on deit3_base_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 492.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 39.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_base_patch16_224.fb_in1k created, param count: 86585320
Running train benchmark on deit3_base_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 203.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_base_patch16_224.fb_in1k created, param count: 86585320
Running train benchmark on deit3_base_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 403.44 samples/sec. 317.275 ms/step.
Train [16/40]. 403.44 samples/sec. 317.268 ms/step.
Train [24/40]. 403.44 samples/sec. 317.273 ms/step.
Train [32/40]. 403.44 samples/sec. 317.273 ms/step.
Train [40/40]. 403.44 samples/sec. 317.268 ms/step.
Train benchmark of deit3_base_patch16_224.fb_in1k done. 402.08 samples/sec, 317.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_base_patch16_224.fb_in22k_ft_in1k created, param count: 86585320
Running inference benchmark on deit3_base_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1416.39 samples/sec. 180.742 ms/step.
Infer [16/40]. 1416.04 samples/sec. 180.786 ms/step.
Infer [24/40]. 1415.92 samples/sec. 180.801 ms/step.
Infer [32/40]. 1415.90 samples/sec. 180.804 ms/step.
Infer [40/40]. 1415.79 samples/sec. 180.818 ms/step.
Inference benchmark of deit3_base_patch16_224.fb_in22k_ft_in1k done. 1415.52 samples/sec, 180.82 ms/step
Model deit3_base_patch16_224.fb_in22k_ft_in1k created, param count: 86585320
Running train benchmark on deit3_base_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 492.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 39.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_base_patch16_224.fb_in22k_ft_in1k created, param count: 86585320
Running train benchmark on deit3_base_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 203.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_base_patch16_224.fb_in22k_ft_in1k created, param count: 86585320
Running train benchmark on deit3_base_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 403.57 samples/sec. 317.166 ms/step.
Train [16/40]. 403.52 samples/sec. 317.211 ms/step.
Train [24/40]. 403.50 samples/sec. 317.220 ms/step.
Train [32/40]. 403.49 samples/sec. 317.229 ms/step.
Train [40/40]. 403.49 samples/sec. 317.235 ms/step.
Train benchmark of deit3_base_patch16_224.fb_in22k_ft_in1k done. 402.14 samples/sec, 317.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_base_patch16_384.fb_in1k created, param count: 86877160
Running inference benchmark on deit3_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 410.91 samples/sec. 623.007 ms/step.
Infer [16/40]. 410.92 samples/sec. 622.986 ms/step.
Infer [24/40]. 410.70 samples/sec. 623.330 ms/step.
Infer [32/40]. 410.54 samples/sec. 623.562 ms/step.
Infer [40/40]. 410.46 samples/sec. 623.683 ms/step.
Inference benchmark of deit3_base_patch16_384.fb_in1k done. 410.44 samples/sec, 623.68 ms/step
Model deit3_base_patch16_384.fb_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 22.45 GiB memory in use. Of the allocated memory 21.50 GiB is allocated by PyTorch, and 462.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_base_patch16_384.fb_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 934.06 MiB is free. Including non-PyTorch memory, this process has 22.73 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 320.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_base_patch16_384.fb_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 590.06 MiB is free. Including non-PyTorch memory, this process has 23.06 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 220.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_base_patch16_384.fb_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 450.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_base_patch16_384.fb_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 328.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_base_patch16_384.fb_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 112.55 samples/sec. 426.490 ms/step.
Train [16/40]. 112.46 samples/sec. 426.812 ms/step.
Train [24/40]. 112.43 samples/sec. 426.927 ms/step.
Train [32/40]. 112.42 samples/sec. 426.977 ms/step.
Train [40/40]. 112.41 samples/sec. 427.011 ms/step.
Train benchmark of deit3_base_patch16_384.fb_in1k done. 112.12 samples/sec, 427.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_base_patch16_384.fb_in22k_ft_in1k created, param count: 86877160
Running inference benchmark on deit3_base_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 410.65 samples/sec. 623.407 ms/step.
Infer [16/40]. 410.75 samples/sec. 623.257 ms/step.
Infer [24/40]. 410.62 samples/sec. 623.448 ms/step.
Infer [32/40]. 410.57 samples/sec. 623.530 ms/step.
Infer [40/40]. 410.58 samples/sec. 623.511 ms/step.
Inference benchmark of deit3_base_patch16_384.fb_in22k_ft_in1k done. 410.55 samples/sec, 623.51 ms/step
Model deit3_base_patch16_384.fb_in22k_ft_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 22.45 GiB memory in use. Of the allocated memory 21.50 GiB is allocated by PyTorch, and 462.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_base_patch16_384.fb_in22k_ft_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 934.06 MiB is free. Including non-PyTorch memory, this process has 22.73 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 320.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_base_patch16_384.fb_in22k_ft_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 590.06 MiB is free. Including non-PyTorch memory, this process has 23.06 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 220.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_base_patch16_384.fb_in22k_ft_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 450.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_base_patch16_384.fb_in22k_ft_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 328.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_base_patch16_384.fb_in22k_ft_in1k created, param count: 86877160
Running train benchmark on deit3_base_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 112.57 samples/sec. 426.384 ms/step.
Train [16/40]. 112.58 samples/sec. 426.377 ms/step.
Train [24/40]. 112.52 samples/sec. 426.608 ms/step.
Train [32/40]. 112.48 samples/sec. 426.749 ms/step.
Train [40/40]. 112.46 samples/sec. 426.835 ms/step.
Train benchmark of deit3_base_patch16_384.fb_in22k_ft_in1k done. 112.17 samples/sec, 426.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running inference benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 171.15 samples/sec. 1495.773 ms/step.
Infer [16/40]. 171.15 samples/sec. 1495.738 ms/step.
Infer [24/40]. 171.17 samples/sec. 1495.585 ms/step.
Infer [32/40]. 171.08 samples/sec. 1496.378 ms/step.
Infer [40/40]. 170.96 samples/sec. 1497.427 ms/step.
Inference benchmark of deit3_huge_patch14_224.fb_in1k done. 170.95 samples/sec, 1497.43 ms/step
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.26 GiB. GPU 0 has a total capacty of 23.65 GiB of which 406.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 371.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 964.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 458.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 139.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 205.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 288.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 237.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 334.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 472.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 608.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.57 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model deit3_huge_patch14_224.fb_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 16.
Train [8/40]. 42.56 samples/sec. 375.902 ms/step.
Train [16/40]. 42.56 samples/sec. 375.917 ms/step.
Train [24/40]. 42.56 samples/sec. 375.918 ms/step.
Train [32/40]. 42.56 samples/sec. 375.922 ms/step.
Train [40/40]. 42.56 samples/sec. 375.925 ms/step.
Train benchmark of deit3_huge_patch14_224.fb_in1k done. 42.31 samples/sec, 375.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running inference benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 171.19 samples/sec. 1495.449 ms/step.
Infer [16/40]. 171.18 samples/sec. 1495.489 ms/step.
Infer [24/40]. 171.17 samples/sec. 1495.582 ms/step.
Infer [32/40]. 171.18 samples/sec. 1495.463 ms/step.
Infer [40/40]. 171.10 samples/sec. 1496.213 ms/step.
Inference benchmark of deit3_huge_patch14_224.fb_in22k_ft_in1k done. 171.09 samples/sec, 1496.21 ms/step
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.26 GiB. GPU 0 has a total capacty of 23.65 GiB of which 406.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 371.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 964.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 458.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 139.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 205.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 288.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 237.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 334.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 472.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 608.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model deit3_huge_patch14_224.fb_in22k_ft_in1k created, param count: 632126440
Running train benchmark on deit3_huge_patch14_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 16.
Train [8/40]. 42.55 samples/sec. 376.003 ms/step.
Train [16/40]. 42.55 samples/sec. 376.010 ms/step.
Train [24/40]. 42.55 samples/sec. 376.019 ms/step.
Train [32/40]. 42.55 samples/sec. 376.018 ms/step.
Train [40/40]. 42.55 samples/sec. 376.020 ms/step.
Train benchmark of deit3_huge_patch14_224.fb_in22k_ft_in1k done. 42.30 samples/sec, 376.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_large_patch16_224.fb_in1k created, param count: 304374760
Running inference benchmark on deit3_large_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 456.06 samples/sec. 561.327 ms/step.
Infer [16/40]. 456.06 samples/sec. 561.325 ms/step.
Infer [24/40]. 456.06 samples/sec. 561.331 ms/step.
Infer [32/40]. 455.99 samples/sec. 561.413 ms/step.
Infer [40/40]. 455.77 samples/sec. 561.686 ms/step.
Inference benchmark of deit3_large_patch16_224.fb_in1k done. 455.73 samples/sec, 561.69 ms/step
Model deit3_large_patch16_224.fb_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 434.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 195.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_large_patch16_224.fb_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.11 GiB is allocated by PyTorch, and 26.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_large_patch16_224.fb_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 206.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_large_patch16_224.fb_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 45.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_large_patch16_224.fb_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 136.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_large_patch16_224.fb_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 128.60 samples/sec. 373.254 ms/step.
Train [16/40]. 128.60 samples/sec. 373.241 ms/step.
Train [24/40]. 128.61 samples/sec. 373.233 ms/step.
Train [32/40]. 128.61 samples/sec. 373.233 ms/step.
Train [40/40]. 128.61 samples/sec. 373.231 ms/step.
Train benchmark of deit3_large_patch16_224.fb_in1k done. 128.02 samples/sec, 373.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_large_patch16_224.fb_in22k_ft_in1k created, param count: 304374760
Running inference benchmark on deit3_large_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 456.09 samples/sec. 561.296 ms/step.
Infer [16/40]. 456.05 samples/sec. 561.337 ms/step.
Infer [24/40]. 456.00 samples/sec. 561.409 ms/step.
Infer [32/40]. 455.95 samples/sec. 561.471 ms/step.
Infer [40/40]. 455.93 samples/sec. 561.490 ms/step.
Inference benchmark of deit3_large_patch16_224.fb_in22k_ft_in1k done. 455.89 samples/sec, 561.49 ms/step
Model deit3_large_patch16_224.fb_in22k_ft_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 434.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 195.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_large_patch16_224.fb_in22k_ft_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.11 GiB is allocated by PyTorch, and 26.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_large_patch16_224.fb_in22k_ft_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 206.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_large_patch16_224.fb_in22k_ft_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 45.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_large_patch16_224.fb_in22k_ft_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 242.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_large_patch16_224.fb_in22k_ft_in1k created, param count: 304374760
Running train benchmark on deit3_large_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 128.57 samples/sec. 373.345 ms/step.
Train [16/40]. 128.57 samples/sec. 373.351 ms/step.
Train [24/40]. 128.57 samples/sec. 373.348 ms/step.
Train [32/40]. 128.57 samples/sec. 373.349 ms/step.
Train [40/40]. 128.57 samples/sec. 373.348 ms/step.
Train benchmark of deit3_large_patch16_224.fb_in22k_ft_in1k done. 127.98 samples/sec, 373.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running inference benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 134.95 samples/sec. 1897.032 ms/step.
Infer [16/40]. 134.85 samples/sec. 1898.459 ms/step.
Infer [24/40]. 134.81 samples/sec. 1898.976 ms/step.
Infer [32/40]. 134.77 samples/sec. 1899.534 ms/step.
Infer [40/40]. 134.69 samples/sec. 1900.719 ms/step.
Inference benchmark of deit3_large_patch16_384.fb_in1k done. 134.68 samples/sec, 1900.72 ms/step
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 576.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 670.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 292.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 726.06 MiB is free. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 205.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 528.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 373.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 179.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 322.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 370.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 595.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model deit3_large_patch16_384.fb_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 36.91 samples/sec. 433.545 ms/step.
Train [16/40]. 36.90 samples/sec. 433.566 ms/step.
Train [24/40]. 36.90 samples/sec. 433.570 ms/step.
Train [32/40]. 36.90 samples/sec. 433.574 ms/step.
Train [40/40]. 36.90 samples/sec. 433.581 ms/step.
Train benchmark of deit3_large_patch16_384.fb_in1k done. 36.75 samples/sec, 433.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running inference benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 134.96 samples/sec. 1896.846 ms/step.
Infer [16/40]. 134.88 samples/sec. 1897.997 ms/step.
Infer [24/40]. 134.82 samples/sec. 1898.829 ms/step.
Infer [32/40]. 134.77 samples/sec. 1899.512 ms/step.
Infer [40/40]. 134.73 samples/sec. 1900.100 ms/step.
Inference benchmark of deit3_large_patch16_384.fb_in22k_ft_in1k done. 134.73 samples/sec, 1900.10 ms/step
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 576.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 670.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 292.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 726.06 MiB is free. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 205.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 528.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 373.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 179.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 322.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 370.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 595.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model deit3_large_patch16_384.fb_in22k_ft_in1k created, param count: 304763880
Running train benchmark on deit3_large_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 36.91 samples/sec. 433.523 ms/step.
Train [16/40]. 36.91 samples/sec. 433.539 ms/step.
Train [24/40]. 36.91 samples/sec. 433.535 ms/step.
Train [32/40]. 36.91 samples/sec. 433.537 ms/step.
Train [40/40]. 36.91 samples/sec. 433.535 ms/step.
Train benchmark of deit3_large_patch16_384.fb_in22k_ft_in1k done. 36.76 samples/sec, 433.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_medium_patch16_224.fb_in1k created, param count: 38849512
Running inference benchmark on deit3_medium_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2565.22 samples/sec. 99.796 ms/step.
Infer [16/40]. 2565.00 samples/sec. 99.805 ms/step.
Infer [24/40]. 2564.89 samples/sec. 99.809 ms/step.
Infer [32/40]. 2564.92 samples/sec. 99.808 ms/step.
Infer [40/40]. 2564.84 samples/sec. 99.811 ms/step.
Inference benchmark of deit3_medium_patch16_224.fb_in1k done. 2564.14 samples/sec, 99.81 ms/step
Model deit3_medium_patch16_224.fb_in1k created, param count: 38849512
Running train benchmark on deit3_medium_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 735.18 samples/sec. 348.215 ms/step.
Train [16/40]. 735.20 samples/sec. 348.206 ms/step.
Train [24/40]. 735.10 samples/sec. 348.251 ms/step.
Train [32/40]. 735.03 samples/sec. 348.286 ms/step.
Train [40/40]. 734.99 samples/sec. 348.305 ms/step.
Train benchmark of deit3_medium_patch16_224.fb_in1k done. 732.74 samples/sec, 348.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_medium_patch16_224.fb_in22k_ft_in1k created, param count: 38849512
Running inference benchmark on deit3_medium_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2566.36 samples/sec. 99.752 ms/step.
Infer [16/40]. 2566.17 samples/sec. 99.760 ms/step.
Infer [24/40]. 2565.67 samples/sec. 99.779 ms/step.
Infer [32/40]. 2565.37 samples/sec. 99.790 ms/step.
Infer [40/40]. 2565.17 samples/sec. 99.799 ms/step.
Inference benchmark of deit3_medium_patch16_224.fb_in22k_ft_in1k done. 2564.38 samples/sec, 99.80 ms/step
Model deit3_medium_patch16_224.fb_in22k_ft_in1k created, param count: 38849512
Running train benchmark on deit3_medium_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 735.16 samples/sec. 348.223 ms/step.
Train [16/40]. 735.15 samples/sec. 348.227 ms/step.
Train [24/40]. 735.15 samples/sec. 348.227 ms/step.
Train [32/40]. 735.16 samples/sec. 348.225 ms/step.
Train [40/40]. 735.15 samples/sec. 348.227 ms/step.
Train benchmark of deit3_medium_patch16_224.fb_in22k_ft_in1k done. 732.89 samples/sec, 348.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_small_patch16_224.fb_in1k created, param count: 22059496
Running inference benchmark on deit3_small_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3833.98 samples/sec. 66.771 ms/step.
Infer [16/40]. 3834.34 samples/sec. 66.765 ms/step.
Infer [24/40]. 3833.91 samples/sec. 66.773 ms/step.
Infer [32/40]. 3833.43 samples/sec. 66.781 ms/step.
Infer [40/40]. 3833.00 samples/sec. 66.788 ms/step.
Inference benchmark of deit3_small_patch16_224.fb_in1k done. 3831.55 samples/sec, 66.79 ms/step
Model deit3_small_patch16_224.fb_in1k created, param count: 22059496
Running train benchmark on deit3_small_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1083.26 samples/sec. 236.324 ms/step.
Train [16/40]. 1083.05 samples/sec. 236.369 ms/step.
Train [24/40]. 1082.92 samples/sec. 236.397 ms/step.
Train [32/40]. 1082.88 samples/sec. 236.407 ms/step.
Train [40/40]. 1082.85 samples/sec. 236.412 ms/step.
Train benchmark of deit3_small_patch16_224.fb_in1k done. 1078.29 samples/sec, 236.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_small_patch16_224.fb_in22k_ft_in1k created, param count: 22059496
Running inference benchmark on deit3_small_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3834.20 samples/sec. 66.767 ms/step.
Infer [16/40]. 3833.46 samples/sec. 66.780 ms/step.
Infer [24/40]. 3832.76 samples/sec. 66.793 ms/step.
Infer [32/40]. 3832.43 samples/sec. 66.798 ms/step.
Infer [40/40]. 3832.29 samples/sec. 66.801 ms/step.
Inference benchmark of deit3_small_patch16_224.fb_in22k_ft_in1k done. 3830.90 samples/sec, 66.80 ms/step
Model deit3_small_patch16_224.fb_in22k_ft_in1k created, param count: 22059496
Running train benchmark on deit3_small_patch16_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1083.34 samples/sec. 236.306 ms/step.
Train [16/40]. 1083.31 samples/sec. 236.312 ms/step.
Train [24/40]. 1083.31 samples/sec. 236.313 ms/step.
Train [32/40]. 1083.30 samples/sec. 236.315 ms/step.
Train [40/40]. 1083.28 samples/sec. 236.319 ms/step.
Train benchmark of deit3_small_patch16_224.fb_in22k_ft_in1k done. 1078.90 samples/sec, 236.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_small_patch16_384.fb_in1k created, param count: 22205416
Running inference benchmark on deit3_small_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 1066.69 samples/sec. 239.995 ms/step.
Infer [16/40]. 1066.12 samples/sec. 240.124 ms/step.
Infer [24/40]. 1065.58 samples/sec. 240.244 ms/step.
Infer [32/40]. 1065.15 samples/sec. 240.341 ms/step.
Infer [40/40]. 1064.91 samples/sec. 240.397 ms/step.
Inference benchmark of deit3_small_patch16_384.fb_in1k done. 1064.73 samples/sec, 240.40 ms/step
Model deit3_small_patch16_384.fb_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 732.06 MiB is free. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 104.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_small_patch16_384.fb_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 382.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 288.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_small_patch16_384.fb_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 357.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_small_patch16_384.fb_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
Train [8/40]. 288.00 samples/sec. 333.328 ms/step.
Train [16/40]. 287.97 samples/sec. 333.370 ms/step.
Train [24/40]. 287.96 samples/sec. 333.375 ms/step.
Train [32/40]. 287.97 samples/sec. 333.373 ms/step.
Train [40/40]. 287.96 samples/sec. 333.374 ms/step.
Train benchmark of deit3_small_patch16_384.fb_in1k done. 287.04 samples/sec, 333.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit3_small_patch16_384.fb_in22k_ft_in1k created, param count: 22205416
Running inference benchmark on deit3_small_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 1065.15 samples/sec. 240.342 ms/step.
Infer [16/40]. 1065.03 samples/sec. 240.369 ms/step.
Infer [24/40]. 1064.95 samples/sec. 240.386 ms/step.
Infer [32/40]. 1064.89 samples/sec. 240.400 ms/step.
Infer [40/40]. 1064.78 samples/sec. 240.426 ms/step.
Inference benchmark of deit3_small_patch16_384.fb_in22k_ft_in1k done. 1064.59 samples/sec, 240.43 ms/step
Model deit3_small_patch16_384.fb_in22k_ft_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 732.06 MiB is free. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 104.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit3_small_patch16_384.fb_in22k_ft_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 382.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 288.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit3_small_patch16_384.fb_in22k_ft_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 357.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit3_small_patch16_384.fb_in22k_ft_in1k created, param count: 22205416
Running train benchmark on deit3_small_patch16_384.fb_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
Train [8/40]. 288.10 samples/sec. 333.221 ms/step.
Train [16/40]. 288.08 samples/sec. 333.239 ms/step.
Train [24/40]. 288.08 samples/sec. 333.244 ms/step.
Train [32/40]. 288.08 samples/sec. 333.245 ms/step.
Train [40/40]. 288.00 samples/sec. 333.338 ms/step.
Train benchmark of deit3_small_patch16_384.fb_in22k_ft_in1k done. 287.07 samples/sec, 333.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_base_distilled_patch16_224.fb_in1k created, param count: 87338192
Running inference benchmark on deit_base_distilled_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1475.78 samples/sec. 173.467 ms/step.
Infer [16/40]. 1476.01 samples/sec. 173.440 ms/step.
Infer [24/40]. 1475.97 samples/sec. 173.445 ms/step.
Infer [32/40]. 1475.99 samples/sec. 173.443 ms/step.
Infer [40/40]. 1475.97 samples/sec. 173.446 ms/step.
Inference benchmark of deit_base_distilled_patch16_224.fb_in1k done. 1475.66 samples/sec, 173.45 ms/step
Model deit_base_distilled_patch16_224.fb_in1k created, param count: 87338192
Running train benchmark on deit_base_distilled_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 356.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 236.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit_base_distilled_patch16_224.fb_in1k created, param count: 87338192
Running train benchmark on deit_base_distilled_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 438.69 samples/sec. 437.663 ms/step.
Train [16/40]. 438.63 samples/sec. 437.727 ms/step.
Train [24/40]. 438.43 samples/sec. 437.926 ms/step.
Train [32/40]. 438.33 samples/sec. 438.022 ms/step.
Train [40/40]. 438.27 samples/sec. 438.083 ms/step.
Train benchmark of deit_base_distilled_patch16_224.fb_in1k done. 437.24 samples/sec, 438.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_base_distilled_patch16_384.fb_in1k created, param count: 87630032
Running inference benchmark on deit_base_distilled_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 424.87 samples/sec. 602.543 ms/step.
Infer [16/40]. 424.67 samples/sec. 602.827 ms/step.
Infer [24/40]. 424.63 samples/sec. 602.874 ms/step.
Infer [32/40]. 424.60 samples/sec. 602.920 ms/step.
Infer [40/40]. 424.60 samples/sec. 602.923 ms/step.
Inference benchmark of deit_base_distilled_patch16_384.fb_in1k done. 424.57 samples/sec, 602.92 ms/step
Model deit_base_distilled_patch16_384.fb_in1k created, param count: 87630032
Running train benchmark on deit_base_distilled_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 752.06 MiB is free. Including non-PyTorch memory, this process has 22.91 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 453.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit_base_distilled_patch16_384.fb_in1k created, param count: 87630032
Running train benchmark on deit_base_distilled_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 264.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 277.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit_base_distilled_patch16_384.fb_in1k created, param count: 87630032
Running train benchmark on deit_base_distilled_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 868.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 342.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 204.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit_base_distilled_patch16_384.fb_in1k created, param count: 87630032
Running train benchmark on deit_base_distilled_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 652.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 628.06 MiB is free. Including non-PyTorch memory, this process has 23.03 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 415.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit_base_distilled_patch16_384.fb_in1k created, param count: 87630032
Running train benchmark on deit_base_distilled_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.56 samples/sec. 558.662 ms/step.
Train [16/40]. 114.53 samples/sec. 558.828 ms/step.
Train [24/40]. 114.51 samples/sec. 558.885 ms/step.
Train [32/40]. 114.51 samples/sec. 558.909 ms/step.
Train [40/40]. 114.50 samples/sec. 558.931 ms/step.
Train benchmark of deit_base_distilled_patch16_384.fb_in1k done. 114.29 samples/sec, 558.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_base_patch16_224.fb_in1k created, param count: 86567656
Running inference benchmark on deit_base_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1483.13 samples/sec. 172.608 ms/step.
Infer [16/40]. 1483.15 samples/sec. 172.606 ms/step.
Infer [24/40]. 1483.01 samples/sec. 172.622 ms/step.
Infer [32/40]. 1482.74 samples/sec. 172.654 ms/step.
Infer [40/40]. 1482.57 samples/sec. 172.674 ms/step.
Inference benchmark of deit_base_patch16_224.fb_in1k done. 1482.26 samples/sec, 172.67 ms/step
Model deit_base_patch16_224.fb_in1k created, param count: 86567656
Running train benchmark on deit_base_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit_base_patch16_224.fb_in1k created, param count: 86567656
Running train benchmark on deit_base_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.42 samples/sec. 468.954 ms/step.
Train [16/40]. 409.51 samples/sec. 468.856 ms/step.
Train [24/40]. 409.56 samples/sec. 468.801 ms/step.
Train [32/40]. 409.58 samples/sec. 468.777 ms/step.
Train [40/40]. 409.49 samples/sec. 468.878 ms/step.
Train benchmark of deit_base_patch16_224.fb_in1k done. 408.61 samples/sec, 468.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_base_patch16_384.fb_in1k created, param count: 86859496
Running inference benchmark on deit_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 426.20 samples/sec. 600.661 ms/step.
Infer [16/40]. 426.20 samples/sec. 600.653 ms/step.
Infer [24/40]. 426.30 samples/sec. 600.517 ms/step.
Infer [32/40]. 426.27 samples/sec. 600.562 ms/step.
Infer [40/40]. 426.25 samples/sec. 600.593 ms/step.
Inference benchmark of deit_base_patch16_384.fb_in1k done. 426.21 samples/sec, 600.59 ms/step
Model deit_base_patch16_384.fb_in1k created, param count: 86859496
Running train benchmark on deit_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 790.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 458.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model deit_base_patch16_384.fb_in1k created, param count: 86859496
Running train benchmark on deit_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 290.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 313.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model deit_base_patch16_384.fb_in1k created, param count: 86859496
Running train benchmark on deit_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 380.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 208.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model deit_base_patch16_384.fb_in1k created, param count: 86859496
Running train benchmark on deit_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 640.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 433.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model deit_base_patch16_384.fb_in1k created, param count: 86859496
Running train benchmark on deit_base_patch16_384.fb_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.76 samples/sec. 557.668 ms/step.
Train [16/40]. 114.76 samples/sec. 557.667 ms/step.
Train [24/40]. 114.76 samples/sec. 557.669 ms/step.
Train [32/40]. 114.76 samples/sec. 557.670 ms/step.
Train [40/40]. 114.76 samples/sec. 557.676 ms/step.
Train benchmark of deit_base_patch16_384.fb_in1k done. 114.55 samples/sec, 557.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_small_distilled_patch16_224.fb_in1k created, param count: 22436432
Running inference benchmark on deit_small_distilled_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4074.69 samples/sec. 62.827 ms/step.
Infer [16/40]. 4074.77 samples/sec. 62.826 ms/step.
Infer [24/40]. 4074.35 samples/sec. 62.832 ms/step.
Infer [32/40]. 4073.92 samples/sec. 62.839 ms/step.
Infer [40/40]. 4073.52 samples/sec. 62.845 ms/step.
Inference benchmark of deit_small_distilled_patch16_224.fb_in1k done. 4071.86 samples/sec, 62.84 ms/step
Model deit_small_distilled_patch16_224.fb_in1k created, param count: 22436432
Running train benchmark on deit_small_distilled_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1161.68 samples/sec. 220.371 ms/step.
Train [16/40]. 1161.66 samples/sec. 220.374 ms/step.
Train [24/40]. 1161.52 samples/sec. 220.401 ms/step.
Train [32/40]. 1161.39 samples/sec. 220.426 ms/step.
Train [40/40]. 1161.32 samples/sec. 220.438 ms/step.
Train benchmark of deit_small_distilled_patch16_224.fb_in1k done. 1156.38 samples/sec, 220.44 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_small_patch16_224.fb_in1k created, param count: 22050664
Running inference benchmark on deit_small_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4077.19 samples/sec. 62.788 ms/step.
Infer [16/40]. 4077.04 samples/sec. 62.791 ms/step.
Infer [24/40]. 4076.85 samples/sec. 62.794 ms/step.
Infer [32/40]. 4076.96 samples/sec. 62.792 ms/step.
Infer [40/40]. 4076.92 samples/sec. 62.793 ms/step.
Inference benchmark of deit_small_patch16_224.fb_in1k done. 4074.83 samples/sec, 62.79 ms/step
Model deit_small_patch16_224.fb_in1k created, param count: 22050664
Running train benchmark on deit_small_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1167.41 samples/sec. 219.290 ms/step.
Train [16/40]. 1167.47 samples/sec. 219.278 ms/step.
Train [24/40]. 1167.45 samples/sec. 219.280 ms/step.
Train [32/40]. 1167.44 samples/sec. 219.283 ms/step.
Train [40/40]. 1167.45 samples/sec. 219.281 ms/step.
Train benchmark of deit_small_patch16_224.fb_in1k done. 1162.79 samples/sec, 219.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_tiny_distilled_patch16_224.fb_in1k created, param count: 5910800
Running inference benchmark on deit_tiny_distilled_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 9519.93 samples/sec. 26.891 ms/step.
Infer [16/40]. 9519.45 samples/sec. 26.892 ms/step.
Infer [24/40]. 9519.76 samples/sec. 26.891 ms/step.
Infer [32/40]. 9519.62 samples/sec. 26.892 ms/step.
Infer [40/40]. 9519.11 samples/sec. 26.893 ms/step.
Inference benchmark of deit_tiny_distilled_patch16_224.fb_in1k done. 9510.49 samples/sec, 26.89 ms/step
Model deit_tiny_distilled_patch16_224.fb_in1k created, param count: 5910800
Running train benchmark on deit_tiny_distilled_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2560.79 samples/sec. 99.969 ms/step.
Train [16/40]. 2560.66 samples/sec. 99.974 ms/step.
Train [24/40]. 2560.60 samples/sec. 99.977 ms/step.
Train [32/40]. 2560.51 samples/sec. 99.980 ms/step.
Train [40/40]. 2560.48 samples/sec. 99.981 ms/step.
Train benchmark of deit_tiny_distilled_patch16_224.fb_in1k done. 2543.32 samples/sec, 99.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model deit_tiny_patch16_224.fb_in1k created, param count: 5717416
Running inference benchmark on deit_tiny_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 9559.66 samples/sec. 26.779 ms/step.
Infer [16/40]. 9561.55 samples/sec. 26.774 ms/step.
Infer [24/40]. 9561.91 samples/sec. 26.773 ms/step.
Infer [32/40]. 9561.85 samples/sec. 26.773 ms/step.
Infer [40/40]. 9561.93 samples/sec. 26.773 ms/step.
Inference benchmark of deit_tiny_patch16_224.fb_in1k done. 9553.23 samples/sec, 26.77 ms/step
Model deit_tiny_patch16_224.fb_in1k created, param count: 5717416
Running train benchmark on deit_tiny_patch16_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2574.80 samples/sec. 99.425 ms/step.
Train [16/40]. 2575.02 samples/sec. 99.417 ms/step.
Train [24/40]. 2574.77 samples/sec. 99.426 ms/step.
Train [32/40]. 2574.79 samples/sec. 99.425 ms/step.
Train [40/40]. 2574.78 samples/sec. 99.426 ms/step.
Train benchmark of deit_tiny_patch16_224.fb_in1k done. 2557.31 samples/sec, 99.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model densenet121.ra_in1k created, param count: 7978856
Running inference benchmark on densenet121.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1182.21 samples/sec. 216.543 ms/step.
Infer [16/40]. 1182.18 samples/sec. 216.548 ms/step.
Infer [24/40]. 1182.19 samples/sec. 216.548 ms/step.
Infer [32/40]. 1182.16 samples/sec. 216.553 ms/step.
Infer [40/40]. 1182.14 samples/sec. 216.557 ms/step.
Inference benchmark of densenet121.ra_in1k done. 1181.93 samples/sec, 216.56 ms/step
Model densenet121.ra_in1k created, param count: 7978856
Running train benchmark on densenet121.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 126.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model densenet121.ra_in1k created, param count: 7978856
Running train benchmark on densenet121.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 186.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 60.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model densenet121.ra_in1k created, param count: 7978856
Running train benchmark on densenet121.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 75.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model densenet121.ra_in1k created, param count: 7978856
Running train benchmark on densenet121.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 370.60 samples/sec. 259.042 ms/step.
Train [16/40]. 370.60 samples/sec. 259.037 ms/step.
Train [24/40]. 370.61 samples/sec. 259.030 ms/step.
Train [32/40]. 370.61 samples/sec. 259.033 ms/step.
Train [40/40]. 370.60 samples/sec. 259.038 ms/step.
Train benchmark of densenet121.ra_in1k done. 368.44 samples/sec, 259.04 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model densenet121.tv_in1k created, param count: 7978856
Running inference benchmark on densenet121.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1996.40 samples/sec. 128.231 ms/step.
Infer [16/40]. 1996.44 samples/sec. 128.228 ms/step.
Infer [24/40]. 1996.52 samples/sec. 128.223 ms/step.
Infer [32/40]. 1996.57 samples/sec. 128.220 ms/step.
Infer [40/40]. 1996.58 samples/sec. 128.219 ms/step.
Inference benchmark of densenet121.tv_in1k done. 1996.12 samples/sec, 128.22 ms/step
Model densenet121.tv_in1k created, param count: 7978856
Running train benchmark on densenet121.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 64.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model densenet121.tv_in1k created, param count: 7978856
Running train benchmark on densenet121.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 193.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model densenet121.tv_in1k created, param count: 7978856
Running train benchmark on densenet121.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 634.40 samples/sec. 201.764 ms/step.
Train [16/40]. 634.32 samples/sec. 201.790 ms/step.
Train [24/40]. 634.31 samples/sec. 201.793 ms/step.
Train [32/40]. 634.30 samples/sec. 201.799 ms/step.
Train [40/40]. 634.29 samples/sec. 201.801 ms/step.
Train benchmark of densenet121.tv_in1k done. 629.72 samples/sec, 201.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model densenet161.tv_in1k created, param count: 28681000
Running inference benchmark on densenet161.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 988.62 samples/sec. 258.948 ms/step.
Infer [16/40]. 988.60 samples/sec. 258.951 ms/step.
Infer [24/40]. 988.57 samples/sec. 258.961 ms/step.
Infer [32/40]. 988.55 samples/sec. 258.964 ms/step.
Infer [40/40]. 988.55 samples/sec. 258.966 ms/step.
Inference benchmark of densenet161.tv_in1k done. 988.39 samples/sec, 258.97 ms/step
Model densenet161.tv_in1k created, param count: 28681000
Running train benchmark on densenet161.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 218.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 77.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model densenet161.tv_in1k created, param count: 28681000
Running train benchmark on densenet161.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 342.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 164.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model densenet161.tv_in1k created, param count: 28681000
Running train benchmark on densenet161.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 158.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 168.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model densenet161.tv_in1k created, param count: 28681000
Running train benchmark on densenet161.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 318.52 samples/sec. 301.396 ms/step.
Train [16/40]. 318.46 samples/sec. 301.446 ms/step.
Train [24/40]. 318.51 samples/sec. 301.400 ms/step.
Train [32/40]. 318.49 samples/sec. 301.427 ms/step.
Train [40/40]. 318.49 samples/sec. 301.423 ms/step.
Train benchmark of densenet161.tv_in1k done. 316.26 samples/sec, 301.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model densenet169.tv_in1k created, param count: 14149480
Running inference benchmark on densenet169.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1642.73 samples/sec. 155.839 ms/step.
Infer [16/40]. 1642.61 samples/sec. 155.849 ms/step.
Infer [24/40]. 1642.62 samples/sec. 155.848 ms/step.
Infer [32/40]. 1642.57 samples/sec. 155.853 ms/step.
Infer [40/40]. 1642.57 samples/sec. 155.854 ms/step.
Inference benchmark of densenet169.tv_in1k done. 1642.24 samples/sec, 155.85 ms/step
Model densenet169.tv_in1k created, param count: 14149480
Running train benchmark on densenet169.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 62.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model densenet169.tv_in1k created, param count: 14149480
Running train benchmark on densenet169.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 308.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model densenet169.tv_in1k created, param count: 14149480
Running train benchmark on densenet169.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 528.25 samples/sec. 242.309 ms/step.
Train [16/40]. 528.23 samples/sec. 242.318 ms/step.
Train [24/40]. 528.23 samples/sec. 242.319 ms/step.
Train [32/40]. 528.22 samples/sec. 242.324 ms/step.
Train [40/40]. 528.21 samples/sec. 242.326 ms/step.
Train benchmark of densenet169.tv_in1k done. 523.81 samples/sec, 242.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model densenet201.tv_in1k created, param count: 20013928
Running inference benchmark on densenet201.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1275.48 samples/sec. 200.709 ms/step.
Infer [16/40]. 1275.33 samples/sec. 200.733 ms/step.
Infer [24/40]. 1275.27 samples/sec. 200.742 ms/step.
Infer [32/40]. 1275.22 samples/sec. 200.750 ms/step.
Infer [40/40]. 1275.17 samples/sec. 200.758 ms/step.
Inference benchmark of densenet201.tv_in1k done. 1274.94 samples/sec, 200.76 ms/step
Model densenet201.tv_in1k created, param count: 20013928
Running train benchmark on densenet201.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 58.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model densenet201.tv_in1k created, param count: 20013928
Running train benchmark on densenet201.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 244.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model densenet201.tv_in1k created, param count: 20013928
Running train benchmark on densenet201.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 312.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model densenet201.tv_in1k created, param count: 20013928
Running train benchmark on densenet201.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 418.81 samples/sec. 229.220 ms/step.
Train [16/40]. 418.68 samples/sec. 229.290 ms/step.
Train [24/40]. 418.65 samples/sec. 229.309 ms/step.
Train [32/40]. 418.63 samples/sec. 229.317 ms/step.
Train [40/40]. 418.63 samples/sec. 229.319 ms/step.
Train benchmark of densenet201.tv_in1k done. 414.54 samples/sec, 229.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model densenetblur121d.ra_in1k created, param count: 7998088
Running inference benchmark on densenetblur121d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1085.57 samples/sec. 235.821 ms/step.
Infer [16/40]. 1085.51 samples/sec. 235.833 ms/step.
Infer [24/40]. 1085.48 samples/sec. 235.840 ms/step.
Infer [32/40]. 1085.47 samples/sec. 235.844 ms/step.
Infer [40/40]. 1085.43 samples/sec. 235.851 ms/step.
Inference benchmark of densenetblur121d.ra_in1k done. 1085.25 samples/sec, 235.85 ms/step
Model densenetblur121d.ra_in1k created, param count: 7998088
Running train benchmark on densenetblur121d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 130.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model densenetblur121d.ra_in1k created, param count: 7998088
Running train benchmark on densenetblur121d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 172.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model densenetblur121d.ra_in1k created, param count: 7998088
Running train benchmark on densenetblur121d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 97.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model densenetblur121d.ra_in1k created, param count: 7998088
Running train benchmark on densenetblur121d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 335.17 samples/sec. 286.423 ms/step.
Train [16/40]. 335.16 samples/sec. 286.434 ms/step.
Train [24/40]. 335.16 samples/sec. 286.434 ms/step.
Train [32/40]. 335.15 samples/sec. 286.440 ms/step.
Train [40/40]. 335.15 samples/sec. 286.436 ms/step.
Train benchmark of densenetblur121d.ra_in1k done. 333.16 samples/sec, 286.44 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla34.in1k created, param count: 15742104
Running inference benchmark on dla34.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4165.90 samples/sec. 61.451 ms/step.
Infer [16/40]. 4165.89 samples/sec. 61.451 ms/step.
Infer [24/40]. 4165.77 samples/sec. 61.453 ms/step.
Infer [32/40]. 4165.70 samples/sec. 61.454 ms/step.
Infer [40/40]. 4165.66 samples/sec. 61.455 ms/step.
Inference benchmark of dla34.in1k done. 4163.68 samples/sec, 61.45 ms/step
Model dla34.in1k created, param count: 15742104
Running train benchmark on dla34.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1103.95 samples/sec. 231.895 ms/step.
Train [16/40]. 1103.96 samples/sec. 231.892 ms/step.
Train [24/40]. 1104.36 samples/sec. 231.809 ms/step.
Train [32/40]. 1104.53 samples/sec. 231.773 ms/step.
Train [40/40]. 1104.63 samples/sec. 231.752 ms/step.
Train benchmark of dla34.in1k done. 1100.92 samples/sec, 231.75 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla46_c.in1k created, param count: 1301400
Running inference benchmark on dla46_c.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6696.54 samples/sec. 38.229 ms/step.
Infer [16/40]. 6696.43 samples/sec. 38.229 ms/step.
Infer [24/40]. 6696.36 samples/sec. 38.230 ms/step.
Infer [32/40]. 6696.05 samples/sec. 38.231 ms/step.
Infer [40/40]. 6695.83 samples/sec. 38.233 ms/step.
Inference benchmark of dla46_c.in1k done. 6690.92 samples/sec, 38.23 ms/step
Model dla46_c.in1k created, param count: 1301400
Running train benchmark on dla46_c.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1657.67 samples/sec. 154.433 ms/step.
Train [16/40]. 1657.35 samples/sec. 154.464 ms/step.
Train [24/40]. 1656.97 samples/sec. 154.499 ms/step.
Train [32/40]. 1656.83 samples/sec. 154.512 ms/step.
Train [40/40]. 1656.70 samples/sec. 154.524 ms/step.
Train benchmark of dla46_c.in1k done. 1648.71 samples/sec, 154.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla46x_c.in1k created, param count: 1068440
Running inference benchmark on dla46x_c.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5571.54 samples/sec. 45.948 ms/step.
Infer [16/40]. 5571.31 samples/sec. 45.950 ms/step.
Infer [24/40]. 5571.37 samples/sec. 45.949 ms/step.
Infer [32/40]. 5571.41 samples/sec. 45.949 ms/step.
Infer [40/40]. 5571.29 samples/sec. 45.950 ms/step.
Inference benchmark of dla46x_c.in1k done. 5567.84 samples/sec, 45.95 ms/step
Model dla46x_c.in1k created, param count: 1068440
Running train benchmark on dla46x_c.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1395.90 samples/sec. 183.394 ms/step.
Train [16/40]. 1396.82 samples/sec. 183.273 ms/step.
Train [24/40]. 1396.95 samples/sec. 183.256 ms/step.
Train [32/40]. 1396.89 samples/sec. 183.265 ms/step.
Train [40/40]. 1396.84 samples/sec. 183.270 ms/step.
Train benchmark of dla46x_c.in1k done. 1390.88 samples/sec, 183.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla60.in1k created, param count: 22036632
Running inference benchmark on dla60.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2359.79 samples/sec. 108.484 ms/step.
Infer [16/40]. 2359.33 samples/sec. 108.505 ms/step.
Infer [24/40]. 2359.13 samples/sec. 108.515 ms/step.
Infer [32/40]. 2358.94 samples/sec. 108.523 ms/step.
Infer [40/40]. 2358.83 samples/sec. 108.528 ms/step.
Inference benchmark of dla60.in1k done. 2358.11 samples/sec, 108.53 ms/step
Model dla60.in1k created, param count: 22036632
Running train benchmark on dla60.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 317.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla60.in1k created, param count: 22036632
Running train benchmark on dla60.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 686.56 samples/sec. 279.655 ms/step.
Train [16/40]. 686.37 samples/sec. 279.731 ms/step.
Train [24/40]. 686.30 samples/sec. 279.762 ms/step.
Train [32/40]. 686.25 samples/sec. 279.781 ms/step.
Train [40/40]. 686.22 samples/sec. 279.792 ms/step.
Train benchmark of dla60.in1k done. 683.57 samples/sec, 279.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla60_res2net.in1k created, param count: 20848072
Running inference benchmark on dla60_res2net.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1901.80 samples/sec. 134.610 ms/step.
Infer [16/40]. 1901.67 samples/sec. 134.619 ms/step.
Infer [24/40]. 1901.31 samples/sec. 134.644 ms/step.
Infer [32/40]. 1901.17 samples/sec. 134.654 ms/step.
Infer [40/40]. 1901.09 samples/sec. 134.660 ms/step.
Inference benchmark of dla60_res2net.in1k done. 1900.60 samples/sec, 134.66 ms/step
Model dla60_res2net.in1k created, param count: 20848072
Running train benchmark on dla60_res2net.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 139.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla60_res2net.in1k created, param count: 20848072
Running train benchmark on dla60_res2net.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 476.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dla60_res2net.in1k created, param count: 20848072
Running train benchmark on dla60_res2net.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 577.60 samples/sec. 221.605 ms/step.
Train [16/40]. 577.60 samples/sec. 221.607 ms/step.
Train [24/40]. 577.59 samples/sec. 221.610 ms/step.
Train [32/40]. 577.59 samples/sec. 221.610 ms/step.
Train [40/40]. 577.59 samples/sec. 221.610 ms/step.
Train benchmark of dla60_res2net.in1k done. 574.40 samples/sec, 221.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla60_res2next.in1k created, param count: 17032984
Running inference benchmark on dla60_res2next.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1840.52 samples/sec. 139.091 ms/step.
Infer [16/40]. 1840.31 samples/sec. 139.107 ms/step.
Infer [24/40]. 1840.23 samples/sec. 139.113 ms/step.
Infer [32/40]. 1840.25 samples/sec. 139.111 ms/step.
Infer [40/40]. 1840.14 samples/sec. 139.120 ms/step.
Inference benchmark of dla60_res2next.in1k done. 1839.69 samples/sec, 139.12 ms/step
Model dla60_res2next.in1k created, param count: 17032984
Running train benchmark on dla60_res2next.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 131.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla60_res2next.in1k created, param count: 17032984
Running train benchmark on dla60_res2next.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 443.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dla60_res2next.in1k created, param count: 17032984
Running train benchmark on dla60_res2next.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 538.39 samples/sec. 237.744 ms/step.
Train [16/40]. 538.38 samples/sec. 237.752 ms/step.
Train [24/40]. 538.39 samples/sec. 237.748 ms/step.
Train [32/40]. 538.39 samples/sec. 237.748 ms/step.
Train [40/40]. 538.36 samples/sec. 237.758 ms/step.
Train benchmark of dla60_res2next.in1k done. 535.49 samples/sec, 237.76 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla60x.in1k created, param count: 17352344
Running inference benchmark on dla60x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1977.17 samples/sec. 129.478 ms/step.
Infer [16/40]. 1976.99 samples/sec. 129.490 ms/step.
Infer [24/40]. 1977.00 samples/sec. 129.489 ms/step.
Infer [32/40]. 1976.96 samples/sec. 129.492 ms/step.
Infer [40/40]. 1976.98 samples/sec. 129.490 ms/step.
Inference benchmark of dla60x.in1k done. 1976.46 samples/sec, 129.49 ms/step
Model dla60x.in1k created, param count: 17352344
Running train benchmark on dla60x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 178.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla60x.in1k created, param count: 17352344
Running train benchmark on dla60x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.20 GiB is allocated by PyTorch, and 879.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dla60x.in1k created, param count: 17352344
Running train benchmark on dla60x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 563.23 samples/sec. 227.261 ms/step.
Train [16/40]. 563.22 samples/sec. 227.264 ms/step.
Train [24/40]. 563.24 samples/sec. 227.259 ms/step.
Train [32/40]. 563.23 samples/sec. 227.261 ms/step.
Train [40/40]. 563.21 samples/sec. 227.268 ms/step.
Train benchmark of dla60x.in1k done. 560.94 samples/sec, 227.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla60x_c.in1k created, param count: 1319832
Running inference benchmark on dla60x_c.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5343.47 samples/sec. 47.909 ms/step.
Infer [16/40]. 5343.40 samples/sec. 47.910 ms/step.
Infer [24/40]. 5343.32 samples/sec. 47.910 ms/step.
Infer [32/40]. 5342.94 samples/sec. 47.914 ms/step.
Infer [40/40]. 5342.76 samples/sec. 47.915 ms/step.
Inference benchmark of dla60x_c.in1k done. 5339.57 samples/sec, 47.91 ms/step
Model dla60x_c.in1k created, param count: 1319832
Running train benchmark on dla60x_c.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1340.69 samples/sec. 190.946 ms/step.
Train [16/40]. 1340.62 samples/sec. 190.957 ms/step.
Train [24/40]. 1340.65 samples/sec. 190.952 ms/step.
Train [32/40]. 1340.70 samples/sec. 190.945 ms/step.
Train [40/40]. 1340.72 samples/sec. 190.942 ms/step.
Train benchmark of dla60x_c.in1k done. 1334.67 samples/sec, 190.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla102.in1k created, param count: 33268888
Running inference benchmark on dla102.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1523.13 samples/sec. 168.074 ms/step.
Infer [16/40]. 1523.08 samples/sec. 168.080 ms/step.
Infer [24/40]. 1522.81 samples/sec. 168.110 ms/step.
Infer [32/40]. 1522.68 samples/sec. 168.125 ms/step.
Infer [40/40]. 1522.63 samples/sec. 168.130 ms/step.
Inference benchmark of dla102.in1k done. 1522.29 samples/sec, 168.13 ms/step
Model dla102.in1k created, param count: 33268888
Running train benchmark on dla102.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 170.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla102.in1k created, param count: 33268888
Running train benchmark on dla102.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 292.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dla102.in1k created, param count: 33268888
Running train benchmark on dla102.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 481.07 samples/sec. 266.076 ms/step.
Train [16/40]. 481.06 samples/sec. 266.078 ms/step.
Train [24/40]. 481.07 samples/sec. 266.075 ms/step.
Train [32/40]. 481.06 samples/sec. 266.078 ms/step.
Train [40/40]. 481.06 samples/sec. 266.077 ms/step.
Train benchmark of dla102.in1k done. 478.55 samples/sec, 266.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla102x2.in1k created, param count: 41282200
Running inference benchmark on dla102x2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 885.32 samples/sec. 289.163 ms/step.
Infer [16/40]. 885.29 samples/sec. 289.172 ms/step.
Infer [24/40]. 885.32 samples/sec. 289.162 ms/step.
Infer [32/40]. 885.30 samples/sec. 289.168 ms/step.
Infer [40/40]. 885.29 samples/sec. 289.171 ms/step.
Inference benchmark of dla102x2.in1k done. 885.14 samples/sec, 289.17 ms/step
Model dla102x2.in1k created, param count: 41282200
Running train benchmark on dla102x2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 88.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla102x2.in1k created, param count: 41282200
Running train benchmark on dla102x2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 137.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dla102x2.in1k created, param count: 41282200
Running train benchmark on dla102x2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 77.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dla102x2.in1k created, param count: 41282200
Running train benchmark on dla102x2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 525.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dla102x2.in1k created, param count: 41282200
Running train benchmark on dla102x2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 262.26 samples/sec. 244.033 ms/step.
Train [16/40]. 262.26 samples/sec. 244.032 ms/step.
Train [24/40]. 262.26 samples/sec. 244.028 ms/step.
Train [32/40]. 262.27 samples/sec. 244.025 ms/step.
Train [40/40]. 262.28 samples/sec. 244.017 ms/step.
Train benchmark of dla102x2.in1k done. 260.94 samples/sec, 244.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla102x.in1k created, param count: 26309272
Running inference benchmark on dla102x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1294.44 samples/sec. 197.768 ms/step.
Infer [16/40]. 1294.45 samples/sec. 197.767 ms/step.
Infer [24/40]. 1294.39 samples/sec. 197.776 ms/step.
Infer [32/40]. 1294.25 samples/sec. 197.798 ms/step.
Infer [40/40]. 1294.18 samples/sec. 197.808 ms/step.
Inference benchmark of dla102x.in1k done. 1293.91 samples/sec, 197.81 ms/step
Model dla102x.in1k created, param count: 26309272
Running train benchmark on dla102x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 254.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla102x.in1k created, param count: 26309272
Running train benchmark on dla102x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 231.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dla102x.in1k created, param count: 26309272
Running train benchmark on dla102x.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 385.69 samples/sec. 331.872 ms/step.
Train [16/40]. 385.71 samples/sec. 331.856 ms/step.
Train [24/40]. 385.69 samples/sec. 331.875 ms/step.
Train [32/40]. 385.67 samples/sec. 331.892 ms/step.
Train [40/40]. 385.66 samples/sec. 331.897 ms/step.
Train benchmark of dla102x.in1k done. 384.03 samples/sec, 331.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dla169.in1k created, param count: 53389720
Running inference benchmark on dla169.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1018.19 samples/sec. 251.426 ms/step.
Infer [16/40]. 1018.14 samples/sec. 251.439 ms/step.
Infer [24/40]. 1018.12 samples/sec. 251.444 ms/step.
Infer [32/40]. 1018.10 samples/sec. 251.448 ms/step.
Infer [40/40]. 1018.10 samples/sec. 251.448 ms/step.
Inference benchmark of dla169.in1k done. 1017.91 samples/sec, 251.45 ms/step
Model dla169.in1k created, param count: 53389720
Running train benchmark on dla169.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 179.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dla169.in1k created, param count: 53389720
Running train benchmark on dla169.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 229.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dla169.in1k created, param count: 53389720
Running train benchmark on dla169.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 380.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dla169.in1k created, param count: 53389720
Running train benchmark on dla169.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 339.82 samples/sec. 282.506 ms/step.
Train [16/40]. 339.82 samples/sec. 282.507 ms/step.
Train [24/40]. 339.80 samples/sec. 282.519 ms/step.
Train [32/40]. 339.78 samples/sec. 282.532 ms/step.
Train [40/40]. 339.78 samples/sec. 282.538 ms/step.
Train benchmark of dla169.in1k done. 337.47 samples/sec, 282.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dm_nfnet_f0.dm_in1k created, param count: 71489284
Running inference benchmark on dm_nfnet_f0.dm_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 834.26 samples/sec. 306.858 ms/step.
Infer [16/40]. 834.19 samples/sec. 306.885 ms/step.
Infer [24/40]. 834.12 samples/sec. 306.910 ms/step.
Infer [32/40]. 834.14 samples/sec. 306.902 ms/step.
Infer [40/40]. 834.17 samples/sec. 306.893 ms/step.
Inference benchmark of dm_nfnet_f0.dm_in1k done. 834.05 samples/sec, 306.89 ms/step
Model dm_nfnet_f0.dm_in1k created, param count: 71489284
Running train benchmark on dm_nfnet_f0.dm_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 746.06 MiB is free. Including non-PyTorch memory, this process has 22.91 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 193.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f0.dm_in1k created, param count: 71489284
Running train benchmark on dm_nfnet_f0.dm_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 356.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f0.dm_in1k created, param count: 71489284
Running train benchmark on dm_nfnet_f0.dm_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 297.80 samples/sec. 429.815 ms/step.
Train [16/40]. 297.78 samples/sec. 429.847 ms/step.
Train [24/40]. 297.80 samples/sec. 429.822 ms/step.
Train [32/40]. 297.80 samples/sec. 429.815 ms/step.
Train [40/40]. 297.80 samples/sec. 429.816 ms/step.
Train benchmark of dm_nfnet_f0.dm_in1k done. 296.84 samples/sec, 429.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dm_nfnet_f1.dm_in1k created, param count: 132634256
Running inference benchmark on dm_nfnet_f1.dm_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 293.18 samples/sec. 873.169 ms/step.
Infer [16/40]. 293.17 samples/sec. 873.227 ms/step.
Infer [24/40]. 293.16 samples/sec. 873.235 ms/step.
Infer [32/40]. 293.15 samples/sec. 873.272 ms/step.
Infer [40/40]. 293.15 samples/sec. 873.271 ms/step.
Inference benchmark of dm_nfnet_f1.dm_in1k done. 293.14 samples/sec, 873.27 ms/step
Model dm_nfnet_f1.dm_in1k created, param count: 132634256
Running train benchmark on dm_nfnet_f1.dm_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 800.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 75.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f1.dm_in1k created, param count: 132634256
Running train benchmark on dm_nfnet_f1.dm_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 384.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f1.dm_in1k created, param count: 132634256
Running train benchmark on dm_nfnet_f1.dm_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 302.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dm_nfnet_f1.dm_in1k created, param count: 132634256
Running train benchmark on dm_nfnet_f1.dm_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 198.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 454.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dm_nfnet_f1.dm_in1k created, param count: 132634256
Running train benchmark on dm_nfnet_f1.dm_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 714.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model dm_nfnet_f1.dm_in1k created, param count: 132634256
Running train benchmark on dm_nfnet_f1.dm_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 106.05 samples/sec. 452.615 ms/step.
Train [16/40]. 106.06 samples/sec. 452.577 ms/step.
Train [24/40]. 106.06 samples/sec. 452.564 ms/step.
Train [32/40]. 106.06 samples/sec. 452.572 ms/step.
Train [40/40]. 106.06 samples/sec. 452.568 ms/step.
Train benchmark of dm_nfnet_f1.dm_in1k done. 105.56 samples/sec, 452.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running inference benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 256.
Infer [8/40]. 170.90 samples/sec. 1497.927 ms/step.
Infer [16/40]. 170.89 samples/sec. 1498.070 ms/step.
Infer [24/40]. 170.89 samples/sec. 1498.069 ms/step.
Infer [32/40]. 170.87 samples/sec. 1498.197 ms/step.
Infer [40/40]. 170.87 samples/sec. 1498.247 ms/step.
Inference benchmark of dm_nfnet_f2.dm_in1k done. 170.86 samples/sec, 1498.25 ms/step
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 21.93 GiB memory in use. Of the allocated memory 21.33 GiB is allocated by PyTorch, and 105.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 818.06 MiB is free. Including non-PyTorch memory, this process has 22.84 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 488.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 968.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 364.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 407.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 768.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 445.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 849.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 540.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model dm_nfnet_f2.dm_in1k created, param count: 193779228
Running train benchmark on dm_nfnet_f2.dm_in1k for 40 steps w/ input size (3, 352, 352) and batch size 24.
Train [8/40]. 62.70 samples/sec. 382.773 ms/step.
Train [16/40]. 62.70 samples/sec. 382.754 ms/step.
Train [24/40]. 62.70 samples/sec. 382.759 ms/step.
Train [32/40]. 62.70 samples/sec. 382.751 ms/step.
Train [40/40]. 62.70 samples/sec. 382.768 ms/step.
Train benchmark of dm_nfnet_f2.dm_in1k done. 62.25 samples/sec, 382.77 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running inference benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
Infer [8/40]. 93.83 samples/sec. 2728.416 ms/step.
Infer [16/40]. 93.82 samples/sec. 2728.649 ms/step.
Infer [24/40]. 93.82 samples/sec. 2728.769 ms/step.
Infer [32/40]. 93.81 samples/sec. 2728.902 ms/step.
Infer [40/40]. 93.81 samples/sec. 2728.969 ms/step.
Inference benchmark of dm_nfnet_f3.dm_in1k done. 93.81 samples/sec, 2728.97 ms/step
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.21 GiB is free. Including non-PyTorch memory, this process has 22.43 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 137.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.96 GiB is free. Including non-PyTorch memory, this process has 21.68 GiB memory in use. Of the allocated memory 20.57 GiB is allocated by PyTorch, and 626.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 710.06 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 502.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 234.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 748.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 534.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 599.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 739.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 898.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 857.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 213.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model dm_nfnet_f3.dm_in1k created, param count: 254924200
Running train benchmark on dm_nfnet_f3.dm_in1k for 40 steps w/ input size (3, 416, 416) and batch size 12.
Train [8/40]. 35.68 samples/sec. 336.343 ms/step.
Train [16/40]. 35.67 samples/sec. 336.438 ms/step.
Train [24/40]. 35.66 samples/sec. 336.501 ms/step.
Train [32/40]. 35.66 samples/sec. 336.514 ms/step.
Train [40/40]. 35.65 samples/sec. 336.595 ms/step.
Train benchmark of dm_nfnet_f3.dm_in1k done. 35.27 samples/sec, 336.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running inference benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.06 GiB is free. Including non-PyTorch memory, this process has 20.58 GiB memory in use. Of the allocated memory 17.96 GiB is allocated by PyTorch, and 2.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running inference benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
Infer [8/40]. 51.20 samples/sec. 3749.951 ms/step.
Infer [16/40]. 51.20 samples/sec. 3749.959 ms/step.
Infer [24/40]. 51.20 samples/sec. 3749.979 ms/step.
Infer [32/40]. 51.20 samples/sec. 3749.973 ms/step.
Infer [40/40]. 51.20 samples/sec. 3749.988 ms/step.
Inference benchmark of dm_nfnet_f4.dm_in1k done. 51.20 samples/sec, 3749.99 ms/step
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 20.74 GiB is allocated by PyTorch, and 2.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 542.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 760.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.50 GiB is free. Including non-PyTorch memory, this process has 22.14 GiB memory in use. Of the allocated memory 20.98 GiB is allocated by PyTorch, and 676.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 938.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 272.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 796.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 900.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 220.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 911.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.11 GiB is allocated by PyTorch, and 951.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 705.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 21.78 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 219.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model dm_nfnet_f4.dm_in1k created, param count: 316069172
Running train benchmark on dm_nfnet_f4.dm_in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
Train [8/40]. 17.23 samples/sec. 348.167 ms/step.
Train [16/40]. 17.24 samples/sec. 348.019 ms/step.
Train [24/40]. 17.24 samples/sec. 347.955 ms/step.
Train [32/40]. 17.24 samples/sec. 347.970 ms/step.
Train [40/40]. 17.24 samples/sec. 348.014 ms/step.
Train benchmark of dm_nfnet_f4.dm_in1k done. 17.04 samples/sec, 348.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running inference benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 402.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 20.35 GiB is allocated by PyTorch, and 2.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running inference benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 192.
Infer [8/40]. 37.58 samples/sec. 5109.538 ms/step.
Infer [16/40]. 37.58 samples/sec. 5109.712 ms/step.
Infer [24/40]. 37.57 samples/sec. 5109.812 ms/step.
Infer [32/40]. 37.57 samples/sec. 5110.132 ms/step.
Infer [40/40]. 37.57 samples/sec. 5110.405 ms/step.
Inference benchmark of dm_nfnet_f5.dm_in1k done. 37.57 samples/sec, 5110.40 ms/step
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.55 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 GiB is free. Including non-PyTorch memory, this process has 19.58 GiB memory in use. Of the allocated memory 18.94 GiB is allocated by PyTorch, and 151.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.39 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.59 GiB is free. Including non-PyTorch memory, this process has 21.05 GiB memory in use. Of the allocated memory 18.00 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 23.65 GiB of which 886.06 MiB is free. Including non-PyTorch memory, this process has 22.78 GiB memory in use. Of the allocated memory 21.51 GiB is allocated by PyTorch, and 792.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 442.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 21.59 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 584.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 21.64 GiB is allocated by PyTorch, and 958.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 868.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 354.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 21.70 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 841.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 398.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 21.64 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 21.75 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 21.61 GiB is allocated by PyTorch, and 1.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.73 GiB is allocated by PyTorch, and 1.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 21.77 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model dm_nfnet_f5.dm_in1k created, param count: 377214144
Running train benchmark on dm_nfnet_f5.dm_in1k for 40 steps w/ input size (3, 544, 544) and batch size 4.
Train [8/40]. 11.44 samples/sec. 349.790 ms/step.
Train [16/40]. 11.43 samples/sec. 349.826 ms/step.
Train [24/40]. 11.43 samples/sec. 349.875 ms/step.
Train [32/40]. 11.43 samples/sec. 349.867 ms/step.
Train [40/40]. 11.43 samples/sec. 349.847 ms/step.
Train benchmark of dm_nfnet_f5.dm_in1k done. 11.28 samples/sec, 349.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running inference benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 21.04 GiB memory in use. Of the allocated memory 20.34 GiB is allocated by PyTorch, and 208.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running inference benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 20.91 GiB memory in use. Of the allocated memory 17.59 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running inference benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 128.
Infer [8/40]. 28.74 samples/sec. 4453.663 ms/step.
Infer [16/40]. 28.74 samples/sec. 4454.252 ms/step.
Infer [24/40]. 28.74 samples/sec. 4454.476 ms/step.
Infer [32/40]. 28.73 samples/sec. 4454.565 ms/step.
Infer [40/40]. 28.73 samples/sec. 4454.637 ms/step.
Inference benchmark of dm_nfnet_f6.dm_in1k done. 28.73 samples/sec, 4454.64 ms/step
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.10 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.69 GiB is free. Including non-PyTorch memory, this process has 21.95 GiB memory in use. Of the allocated memory 21.29 GiB is allocated by PyTorch, and 170.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 20.23 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 674.06 MiB is free. Including non-PyTorch memory, this process has 22.98 GiB memory in use. Of the allocated memory 21.63 GiB is allocated by PyTorch, and 874.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.56 GiB is free. Including non-PyTorch memory, this process has 22.08 GiB memory in use. Of the allocated memory 20.45 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 272.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.01 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 21.99 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 1016.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 21.20 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model dm_nfnet_f6.dm_in1k created, param count: 438359116
Running train benchmark on dm_nfnet_f6.dm_in1k for 40 steps w/ input size (3, 576, 576) and batch size 3.
Train [8/40]. 7.66 samples/sec. 391.723 ms/step.
Train [16/40]. 7.66 samples/sec. 391.880 ms/step.
Train [24/40]. 7.66 samples/sec. 391.859 ms/step.
Train [32/40]. 7.66 samples/sec. 391.892 ms/step.
Train [40/40]. 7.65 samples/sec. 391.977 ms/step.
Train benchmark of dm_nfnet_f6.dm_in1k done. 7.55 samples/sec, 391.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dpn68.mx_in1k created, param count: 12611602
Running inference benchmark on dpn68.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2336.55 samples/sec. 109.563 ms/step.
Infer [16/40]. 2336.60 samples/sec. 109.561 ms/step.
Infer [24/40]. 2336.55 samples/sec. 109.563 ms/step.
Infer [32/40]. 2336.60 samples/sec. 109.561 ms/step.
Infer [40/40]. 2336.58 samples/sec. 109.562 ms/step.
Inference benchmark of dpn68.mx_in1k done. 2335.90 samples/sec, 109.56 ms/step
Model dpn68.mx_in1k created, param count: 12611602
Running train benchmark on dpn68.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 357.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dpn68.mx_in1k created, param count: 12611602
Running train benchmark on dpn68.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 613.39 samples/sec. 313.015 ms/step.
Train [16/40]. 613.31 samples/sec. 313.053 ms/step.
Train [24/40]. 613.32 samples/sec. 313.052 ms/step.
Train [32/40]. 613.32 samples/sec. 313.052 ms/step.
Train [40/40]. 613.31 samples/sec. 313.058 ms/step.
Train benchmark of dpn68.mx_in1k done. 610.72 samples/sec, 313.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dpn68b.mx_in1k created, param count: 12611602
Running inference benchmark on dpn68b.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2274.99 samples/sec. 112.528 ms/step.
Infer [16/40]. 2274.78 samples/sec. 112.538 ms/step.
Infer [24/40]. 2274.28 samples/sec. 112.563 ms/step.
Infer [32/40]. 2274.02 samples/sec. 112.576 ms/step.
Infer [40/40]. 2273.91 samples/sec. 112.581 ms/step.
Inference benchmark of dpn68b.mx_in1k done. 2273.25 samples/sec, 112.58 ms/step
Model dpn68b.mx_in1k created, param count: 12611602
Running train benchmark on dpn68b.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 323.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dpn68b.mx_in1k created, param count: 12611602
Running train benchmark on dpn68b.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 635.89 samples/sec. 301.941 ms/step.
Train [16/40]. 635.90 samples/sec. 301.936 ms/step.
Train [24/40]. 635.87 samples/sec. 301.948 ms/step.
Train [32/40]. 635.81 samples/sec. 301.979 ms/step.
Train [40/40]. 635.78 samples/sec. 301.991 ms/step.
Train benchmark of dpn68b.mx_in1k done. 633.04 samples/sec, 301.99 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dpn68b.ra_in1k created, param count: 12611602
Running inference benchmark on dpn68b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1357.17 samples/sec. 188.628 ms/step.
Infer [16/40]. 1357.25 samples/sec. 188.617 ms/step.
Infer [24/40]. 1357.30 samples/sec. 188.609 ms/step.
Infer [32/40]. 1357.26 samples/sec. 188.615 ms/step.
Infer [40/40]. 1357.29 samples/sec. 188.611 ms/step.
Inference benchmark of dpn68b.ra_in1k done. 1356.99 samples/sec, 188.61 ms/step
Model dpn68b.ra_in1k created, param count: 12611602
Running train benchmark on dpn68b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 334.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dpn68b.ra_in1k created, param count: 12611602
Running train benchmark on dpn68b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 446.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dpn68b.ra_in1k created, param count: 12611602
Running train benchmark on dpn68b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 381.86 samples/sec. 335.201 ms/step.
Train [16/40]. 381.86 samples/sec. 335.206 ms/step.
Train [24/40]. 381.84 samples/sec. 335.219 ms/step.
Train [32/40]. 381.84 samples/sec. 335.218 ms/step.
Train [40/40]. 381.86 samples/sec. 335.205 ms/step.
Train benchmark of dpn68b.ra_in1k done. 380.38 samples/sec, 335.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dpn92.mx_in1k created, param count: 37668392
Running inference benchmark on dpn92.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1123.42 samples/sec. 227.875 ms/step.
Infer [16/40]. 1123.54 samples/sec. 227.852 ms/step.
Infer [24/40]. 1123.51 samples/sec. 227.857 ms/step.
Infer [32/40]. 1123.45 samples/sec. 227.869 ms/step.
Infer [40/40]. 1123.42 samples/sec. 227.875 ms/step.
Inference benchmark of dpn92.mx_in1k done. 1123.20 samples/sec, 227.88 ms/step
Model dpn92.mx_in1k created, param count: 37668392
Running train benchmark on dpn92.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 944.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dpn92.mx_in1k created, param count: 37668392
Running train benchmark on dpn92.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 400.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dpn92.mx_in1k created, param count: 37668392
Running train benchmark on dpn92.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 284.99 samples/sec. 449.135 ms/step.
Train [16/40]. 284.99 samples/sec. 449.131 ms/step.
Train [24/40]. 284.98 samples/sec. 449.147 ms/step.
Train [32/40]. 284.97 samples/sec. 449.174 ms/step.
Train [40/40]. 284.98 samples/sec. 449.149 ms/step.
Train benchmark of dpn92.mx_in1k done. 283.97 samples/sec, 449.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dpn98.mx_in1k created, param count: 61570728
Running inference benchmark on dpn98.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 793.27 samples/sec. 322.713 ms/step.
Infer [16/40]. 793.29 samples/sec. 322.708 ms/step.
Infer [24/40]. 793.32 samples/sec. 322.696 ms/step.
Infer [32/40]. 793.29 samples/sec. 322.708 ms/step.
Infer [40/40]. 793.26 samples/sec. 322.720 ms/step.
Inference benchmark of dpn98.mx_in1k done. 793.14 samples/sec, 322.72 ms/step
Model dpn98.mx_in1k created, param count: 61570728
Running train benchmark on dpn98.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dpn98.mx_in1k created, param count: 61570728
Running train benchmark on dpn98.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 746.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dpn98.mx_in1k created, param count: 61570728
Running train benchmark on dpn98.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dpn98.mx_in1k created, param count: 61570728
Running train benchmark on dpn98.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 210.28 samples/sec. 456.530 ms/step.
Train [16/40]. 210.29 samples/sec. 456.510 ms/step.
Train [24/40]. 210.28 samples/sec. 456.530 ms/step.
Train [32/40]. 210.27 samples/sec. 456.551 ms/step.
Train [40/40]. 210.27 samples/sec. 456.549 ms/step.
Train benchmark of dpn98.mx_in1k done. 209.49 samples/sec, 456.55 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dpn107.mx_in1k created, param count: 86917800
Running inference benchmark on dpn107.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 546.51 samples/sec. 468.427 ms/step.
Infer [16/40]. 546.63 samples/sec. 468.324 ms/step.
Infer [24/40]. 546.60 samples/sec. 468.353 ms/step.
Infer [32/40]. 546.60 samples/sec. 468.347 ms/step.
Infer [40/40]. 546.59 samples/sec. 468.356 ms/step.
Inference benchmark of dpn107.mx_in1k done. 546.53 samples/sec, 468.36 ms/step
Model dpn107.mx_in1k created, param count: 86917800
Running train benchmark on dpn107.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 614.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 282.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dpn107.mx_in1k created, param count: 86917800
Running train benchmark on dpn107.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 206.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 768.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dpn107.mx_in1k created, param count: 86917800
Running train benchmark on dpn107.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 957.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dpn107.mx_in1k created, param count: 86917800
Running train benchmark on dpn107.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 524.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dpn107.mx_in1k created, param count: 86917800
Running train benchmark on dpn107.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 150.64 samples/sec. 424.858 ms/step.
Train [16/40]. 150.65 samples/sec. 424.836 ms/step.
Train [24/40]. 150.65 samples/sec. 424.819 ms/step.
Train [32/40]. 150.66 samples/sec. 424.806 ms/step.
Train [40/40]. 150.66 samples/sec. 424.799 ms/step.
Train benchmark of dpn107.mx_in1k done. 150.03 samples/sec, 424.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model dpn131.mx_in1k created, param count: 79254504
Running inference benchmark on dpn131.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 581.50 samples/sec. 440.242 ms/step.
Infer [16/40]. 581.49 samples/sec. 440.251 ms/step.
Infer [24/40]. 581.47 samples/sec. 440.267 ms/step.
Infer [32/40]. 581.45 samples/sec. 440.280 ms/step.
Infer [40/40]. 581.44 samples/sec. 440.283 ms/step.
Inference benchmark of dpn131.mx_in1k done. 581.38 samples/sec, 440.28 ms/step
Model dpn131.mx_in1k created, param count: 79254504
Running train benchmark on dpn131.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 768.06 MiB is free. Including non-PyTorch memory, this process has 22.89 GiB memory in use. Of the allocated memory 20.66 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model dpn131.mx_in1k created, param count: 79254504
Running train benchmark on dpn131.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 310.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 896.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model dpn131.mx_in1k created, param count: 79254504
Running train benchmark on dpn131.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 716.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model dpn131.mx_in1k created, param count: 79254504
Running train benchmark on dpn131.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 21.77 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model dpn131.mx_in1k created, param count: 79254504
Running train benchmark on dpn131.mx_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 162.17 samples/sec. 394.649 ms/step.
Train [16/40]. 162.18 samples/sec. 394.616 ms/step.
Train [24/40]. 162.18 samples/sec. 394.627 ms/step.
Train [32/40]. 162.18 samples/sec. 394.622 ms/step.
Train [40/40]. 162.18 samples/sec. 394.612 ms/step.
Train benchmark of dpn131.mx_in1k done. 161.40 samples/sec, 394.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eca_botnext26ts_256.c1_in1k created, param count: 10593301
Running inference benchmark on eca_botnext26ts_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2511.81 samples/sec. 101.918 ms/step.
Infer [16/40]. 2511.55 samples/sec. 101.929 ms/step.
Infer [24/40]. 2511.35 samples/sec. 101.937 ms/step.
Infer [32/40]. 2511.30 samples/sec. 101.939 ms/step.
Infer [40/40]. 2511.19 samples/sec. 101.944 ms/step.
Inference benchmark of eca_botnext26ts_256.c1_in1k done. 2510.52 samples/sec, 101.94 ms/step
Model eca_botnext26ts_256.c1_in1k created, param count: 10593301
Running train benchmark on eca_botnext26ts_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 99.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eca_botnext26ts_256.c1_in1k created, param count: 10593301
Running train benchmark on eca_botnext26ts_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
Train [8/40]. 707.82 samples/sec. 271.256 ms/step.
Train [16/40]. 707.76 samples/sec. 271.277 ms/step.
Train [24/40]. 707.76 samples/sec. 271.280 ms/step.
Train [32/40]. 707.76 samples/sec. 271.279 ms/step.
Train [40/40]. 707.77 samples/sec. 271.274 ms/step.
Train benchmark of eca_botnext26ts_256.c1_in1k done. 705.35 samples/sec, 271.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eca_halonext26ts.c1_in1k created, param count: 10756885
Running inference benchmark on eca_halonext26ts.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2445.56 samples/sec. 104.679 ms/step.
Infer [16/40]. 2445.52 samples/sec. 104.681 ms/step.
Infer [24/40]. 2445.39 samples/sec. 104.687 ms/step.
Infer [32/40]. 2445.29 samples/sec. 104.691 ms/step.
Infer [40/40]. 2445.21 samples/sec. 104.695 ms/step.
Inference benchmark of eca_halonext26ts.c1_in1k done. 2444.55 samples/sec, 104.69 ms/step
Model eca_halonext26ts.c1_in1k created, param count: 10756885
Running train benchmark on eca_halonext26ts.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 99.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eca_halonext26ts.c1_in1k created, param count: 10756885
Running train benchmark on eca_halonext26ts.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
Train [8/40]. 684.11 samples/sec. 280.657 ms/step.
Train [16/40]. 684.04 samples/sec. 280.685 ms/step.
Train [24/40]. 684.04 samples/sec. 280.685 ms/step.
Train [32/40]. 684.02 samples/sec. 280.694 ms/step.
Train [40/40]. 684.02 samples/sec. 280.693 ms/step.
Train benchmark of eca_halonext26ts.c1_in1k done. 681.64 samples/sec, 280.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eca_nfnet_l0.ra2_in1k created, param count: 24143924
Running inference benchmark on eca_nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1098.39 samples/sec. 233.069 ms/step.
Infer [16/40]. 1098.29 samples/sec. 233.091 ms/step.
Infer [24/40]. 1098.27 samples/sec. 233.093 ms/step.
Infer [32/40]. 1098.29 samples/sec. 233.090 ms/step.
Infer [40/40]. 1098.28 samples/sec. 233.092 ms/step.
Inference benchmark of eca_nfnet_l0.ra2_in1k done. 1098.08 samples/sec, 233.09 ms/step
Model eca_nfnet_l0.ra2_in1k created, param count: 24143924
Running train benchmark on eca_nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 554.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eca_nfnet_l0.ra2_in1k created, param count: 24143924
Running train benchmark on eca_nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 195.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eca_nfnet_l0.ra2_in1k created, param count: 24143924
Running train benchmark on eca_nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 383.16 samples/sec. 334.060 ms/step.
Train [16/40]. 383.13 samples/sec. 334.090 ms/step.
Train [24/40]. 383.15 samples/sec. 334.074 ms/step.
Train [32/40]. 383.14 samples/sec. 334.079 ms/step.
Train [40/40]. 383.14 samples/sec. 334.082 ms/step.
Train benchmark of eca_nfnet_l0.ra2_in1k done. 381.66 samples/sec, 334.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eca_nfnet_l1.ra2_in1k created, param count: 41407728
Running inference benchmark on eca_nfnet_l1.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 508.54 samples/sec. 503.406 ms/step.
Infer [16/40]. 508.51 samples/sec. 503.430 ms/step.
Infer [24/40]. 508.47 samples/sec. 503.473 ms/step.
Infer [32/40]. 508.44 samples/sec. 503.503 ms/step.
Infer [40/40]. 508.42 samples/sec. 503.519 ms/step.
Inference benchmark of eca_nfnet_l1.ra2_in1k done. 508.37 samples/sec, 503.52 ms/step
Model eca_nfnet_l1.ra2_in1k created, param count: 41407728
Running train benchmark on eca_nfnet_l1.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 802.06 MiB is free. Including non-PyTorch memory, this process has 22.86 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 823.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eca_nfnet_l1.ra2_in1k created, param count: 41407728
Running train benchmark on eca_nfnet_l1.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 414.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eca_nfnet_l1.ra2_in1k created, param count: 41407728
Running train benchmark on eca_nfnet_l1.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 116.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eca_nfnet_l1.ra2_in1k created, param count: 41407728
Running train benchmark on eca_nfnet_l1.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 112.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eca_nfnet_l1.ra2_in1k created, param count: 41407728
Running train benchmark on eca_nfnet_l1.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
Train [8/40]. 184.64 samples/sec. 346.627 ms/step.
Train [16/40]. 184.63 samples/sec. 346.632 ms/step.
Train [24/40]. 184.63 samples/sec. 346.634 ms/step.
Train [32/40]. 184.63 samples/sec. 346.634 ms/step.
Train [40/40]. 184.63 samples/sec. 346.634 ms/step.
Train benchmark of eca_nfnet_l1.ra2_in1k done. 183.63 samples/sec, 346.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running inference benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 245.72 samples/sec. 1041.836 ms/step.
Infer [16/40]. 245.72 samples/sec. 1041.853 ms/step.
Infer [24/40]. 245.72 samples/sec. 1041.841 ms/step.
Infer [32/40]. 245.71 samples/sec. 1041.871 ms/step.
Infer [40/40]. 245.71 samples/sec. 1041.893 ms/step.
Inference benchmark of eca_nfnet_l2.ra3_in1k done. 245.69 samples/sec, 1041.89 ms/step
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running train benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.22 GiB is free. Including non-PyTorch memory, this process has 21.42 GiB memory in use. Of the allocated memory 20.90 GiB is allocated by PyTorch, and 23.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running train benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.18 GiB is free. Including non-PyTorch memory, this process has 22.46 GiB memory in use. Of the allocated memory 21.64 GiB is allocated by PyTorch, and 336.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running train benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 510.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 563.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running train benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 158.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 244.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running train benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 101.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running train benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 83.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eca_nfnet_l2.ra3_in1k created, param count: 56722348
Running train benchmark on eca_nfnet_l2.ra3_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 89.65 samples/sec. 356.939 ms/step.
Train [16/40]. 89.66 samples/sec. 356.910 ms/step.
Train [24/40]. 89.66 samples/sec. 356.906 ms/step.
Train [32/40]. 89.66 samples/sec. 356.905 ms/step.
Train [40/40]. 89.66 samples/sec. 356.916 ms/step.
Train benchmark of eca_nfnet_l2.ra3_in1k done. 89.05 samples/sec, 356.92 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eca_resnet33ts.ra2_in1k created, param count: 19676302
Running inference benchmark on eca_resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1705.62 samples/sec. 150.092 ms/step.
Infer [16/40]. 1705.61 samples/sec. 150.093 ms/step.
Infer [24/40]. 1705.64 samples/sec. 150.090 ms/step.
Infer [32/40]. 1705.62 samples/sec. 150.092 ms/step.
Infer [40/40]. 1705.58 samples/sec. 150.096 ms/step.
Inference benchmark of eca_resnet33ts.ra2_in1k done. 1705.19 samples/sec, 150.10 ms/step
Model eca_resnet33ts.ra2_in1k created, param count: 19676302
Running train benchmark on eca_resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 618.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.32 GiB is allocated by PyTorch, and 229.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eca_resnet33ts.ra2_in1k created, param count: 19676302
Running train benchmark on eca_resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 215.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eca_resnet33ts.ra2_in1k created, param count: 19676302
Running train benchmark on eca_resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 481.42 samples/sec. 265.883 ms/step.
Train [16/40]. 481.37 samples/sec. 265.906 ms/step.
Train [24/40]. 481.35 samples/sec. 265.918 ms/step.
Train [32/40]. 481.36 samples/sec. 265.912 ms/step.
Train [40/40]. 481.36 samples/sec. 265.912 ms/step.
Train benchmark of eca_resnet33ts.ra2_in1k done. 479.81 samples/sec, 265.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eca_resnext26ts.ch_in1k created, param count: 10297988
Running inference benchmark on eca_resnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2169.71 samples/sec. 117.988 ms/step.
Infer [16/40]. 2169.67 samples/sec. 117.990 ms/step.
Infer [24/40]. 2169.64 samples/sec. 117.992 ms/step.
Infer [32/40]. 2169.56 samples/sec. 117.996 ms/step.
Infer [40/40]. 2169.55 samples/sec. 117.997 ms/step.
Inference benchmark of eca_resnext26ts.ch_in1k done. 2168.95 samples/sec, 118.00 ms/step
Model eca_resnext26ts.ch_in1k created, param count: 10297988
Running train benchmark on eca_resnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 101.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eca_resnext26ts.ch_in1k created, param count: 10297988
Running train benchmark on eca_resnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 186.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 178.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eca_resnext26ts.ch_in1k created, param count: 10297988
Running train benchmark on eca_resnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 589.19 samples/sec. 217.246 ms/step.
Train [16/40]. 589.12 samples/sec. 217.273 ms/step.
Train [24/40]. 589.10 samples/sec. 217.282 ms/step.
Train [32/40]. 589.09 samples/sec. 217.286 ms/step.
Train [40/40]. 589.05 samples/sec. 217.300 ms/step.
Train benchmark of eca_resnext26ts.ch_in1k done. 587.10 samples/sec, 217.30 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet26t.ra2_in1k created, param count: 16011916
Running inference benchmark on ecaresnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 1507.92 samples/sec. 169.770 ms/step.
Infer [16/40]. 1507.91 samples/sec. 169.772 ms/step.
Infer [24/40]. 1507.90 samples/sec. 169.772 ms/step.
Infer [32/40]. 1507.87 samples/sec. 169.776 ms/step.
Infer [40/40]. 1507.86 samples/sec. 169.777 ms/step.
Inference benchmark of ecaresnet26t.ra2_in1k done. 1507.51 samples/sec, 169.78 ms/step
Model ecaresnet26t.ra2_in1k created, param count: 16011916
Running train benchmark on ecaresnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 83.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet26t.ra2_in1k created, param count: 16011916
Running train benchmark on ecaresnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 136.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 161.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnet26t.ra2_in1k created, param count: 16011916
Running train benchmark on ecaresnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
Train [8/40]. 438.11 samples/sec. 292.162 ms/step.
Train [16/40]. 438.07 samples/sec. 292.190 ms/step.
Train [24/40]. 438.10 samples/sec. 292.173 ms/step.
Train [32/40]. 438.08 samples/sec. 292.184 ms/step.
Train [40/40]. 438.07 samples/sec. 292.189 ms/step.
Train benchmark of ecaresnet26t.ra2_in1k done. 436.92 samples/sec, 292.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet50d.miil_in1k created, param count: 25576350
Running inference benchmark on ecaresnet50d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1140.60 samples/sec. 224.443 ms/step.
Infer [16/40]. 1140.64 samples/sec. 224.436 ms/step.
Infer [24/40]. 1140.63 samples/sec. 224.438 ms/step.
Infer [32/40]. 1140.64 samples/sec. 224.436 ms/step.
Infer [40/40]. 1140.63 samples/sec. 224.437 ms/step.
Inference benchmark of ecaresnet50d.miil_in1k done. 1140.42 samples/sec, 224.44 ms/step
Model ecaresnet50d.miil_in1k created, param count: 25576350
Running train benchmark on ecaresnet50d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 278.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 59.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet50d.miil_in1k created, param count: 25576350
Running train benchmark on ecaresnet50d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 180.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnet50d.miil_in1k created, param count: 25576350
Running train benchmark on ecaresnet50d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 126.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model ecaresnet50d.miil_in1k created, param count: 25576350
Running train benchmark on ecaresnet50d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 339.60 samples/sec. 282.689 ms/step.
Train [16/40]. 339.72 samples/sec. 282.586 ms/step.
Train [24/40]. 339.71 samples/sec. 282.592 ms/step.
Train [32/40]. 339.71 samples/sec. 282.593 ms/step.
Train [40/40]. 339.70 samples/sec. 282.604 ms/step.
Train benchmark of ecaresnet50d.miil_in1k done. 338.43 samples/sec, 282.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet50d_pruned.miil_in1k created, param count: 19939713
Running inference benchmark on ecaresnet50d_pruned.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2059.14 samples/sec. 124.323 ms/step.
Infer [16/40]. 2059.26 samples/sec. 124.316 ms/step.
Infer [24/40]. 2059.07 samples/sec. 124.328 ms/step.
Infer [32/40]. 2058.85 samples/sec. 124.341 ms/step.
Infer [40/40]. 2058.69 samples/sec. 124.351 ms/step.
Inference benchmark of ecaresnet50d_pruned.miil_in1k done. 2058.20 samples/sec, 124.35 ms/step
Model ecaresnet50d_pruned.miil_in1k created, param count: 19939713
Running train benchmark on ecaresnet50d_pruned.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 604.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet50d_pruned.miil_in1k created, param count: 19939713
Running train benchmark on ecaresnet50d_pruned.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 583.94 samples/sec. 328.801 ms/step.
Train [16/40]. 583.92 samples/sec. 328.811 ms/step.
Train [24/40]. 583.92 samples/sec. 328.812 ms/step.
Train [32/40]. 583.91 samples/sec. 328.819 ms/step.
Train [40/40]. 583.90 samples/sec. 328.826 ms/step.
Train benchmark of ecaresnet50d_pruned.miil_in1k done. 581.96 samples/sec, 328.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet50t.a1_in1k created, param count: 25573814
Running inference benchmark on ecaresnet50t.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1148.79 samples/sec. 222.843 ms/step.
Infer [16/40]. 1148.78 samples/sec. 222.844 ms/step.
Infer [24/40]. 1148.78 samples/sec. 222.846 ms/step.
Infer [32/40]. 1148.76 samples/sec. 222.850 ms/step.
Infer [40/40]. 1148.74 samples/sec. 222.853 ms/step.
Inference benchmark of ecaresnet50t.a1_in1k done. 1148.54 samples/sec, 222.85 ms/step
Model ecaresnet50t.a1_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 602.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 59.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet50t.a1_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 370.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 183.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnet50t.a1_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 151.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model ecaresnet50t.a1_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 341.62 samples/sec. 281.014 ms/step.
Train [16/40]. 341.67 samples/sec. 280.972 ms/step.
Train [24/40]. 341.69 samples/sec. 280.953 ms/step.
Train [32/40]. 341.69 samples/sec. 280.956 ms/step.
Train [40/40]. 341.72 samples/sec. 280.930 ms/step.
Train benchmark of ecaresnet50t.a1_in1k done. 340.42 samples/sec, 280.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet50t.a2_in1k created, param count: 25573814
Running inference benchmark on ecaresnet50t.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1148.47 samples/sec. 222.906 ms/step.
Infer [16/40]. 1148.47 samples/sec. 222.904 ms/step.
Infer [24/40]. 1148.49 samples/sec. 222.902 ms/step.
Infer [32/40]. 1148.49 samples/sec. 222.901 ms/step.
Infer [40/40]. 1148.49 samples/sec. 222.902 ms/step.
Inference benchmark of ecaresnet50t.a2_in1k done. 1148.28 samples/sec, 222.90 ms/step
Model ecaresnet50t.a2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 602.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 59.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet50t.a2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 370.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 183.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnet50t.a2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 147.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model ecaresnet50t.a2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 341.64 samples/sec. 281.000 ms/step.
Train [16/40]. 341.69 samples/sec. 280.958 ms/step.
Train [24/40]. 341.69 samples/sec. 280.959 ms/step.
Train [32/40]. 341.69 samples/sec. 280.956 ms/step.
Train [40/40]. 341.68 samples/sec. 280.968 ms/step.
Train benchmark of ecaresnet50t.a2_in1k done. 340.35 samples/sec, 280.97 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet50t.a3_in1k created, param count: 25573814
Running inference benchmark on ecaresnet50t.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1928.55 samples/sec. 132.742 ms/step.
Infer [16/40]. 1928.47 samples/sec. 132.747 ms/step.
Infer [24/40]. 1928.48 samples/sec. 132.747 ms/step.
Infer [32/40]. 1928.48 samples/sec. 132.747 ms/step.
Infer [40/40]. 1928.46 samples/sec. 132.748 ms/step.
Inference benchmark of ecaresnet50t.a3_in1k done. 1928.01 samples/sec, 132.75 ms/step
Model ecaresnet50t.a3_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 172.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet50t.a3_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 562.15 samples/sec. 341.548 ms/step.
Train [16/40]. 562.11 samples/sec. 341.569 ms/step.
Train [24/40]. 562.12 samples/sec. 341.565 ms/step.
Train [32/40]. 562.13 samples/sec. 341.560 ms/step.
Train [40/40]. 562.13 samples/sec. 341.559 ms/step.
Train benchmark of ecaresnet50t.a3_in1k done. 560.29 samples/sec, 341.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet50t.ra2_in1k created, param count: 25573814
Running inference benchmark on ecaresnet50t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 949.48 samples/sec. 269.623 ms/step.
Infer [16/40]. 949.47 samples/sec. 269.625 ms/step.
Infer [24/40]. 949.47 samples/sec. 269.623 ms/step.
Infer [32/40]. 949.47 samples/sec. 269.623 ms/step.
Infer [40/40]. 949.47 samples/sec. 269.625 ms/step.
Inference benchmark of ecaresnet50t.ra2_in1k done. 949.32 samples/sec, 269.62 ms/step
Model ecaresnet50t.ra2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 60.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet50t.ra2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 629.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnet50t.ra2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 146.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model ecaresnet50t.ra2_in1k created, param count: 25573814
Running train benchmark on ecaresnet50t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
Train [8/40]. 280.84 samples/sec. 341.833 ms/step.
Train [16/40]. 280.88 samples/sec. 341.781 ms/step.
Train [24/40]. 280.89 samples/sec. 341.774 ms/step.
Train [32/40]. 280.88 samples/sec. 341.783 ms/step.
Train [40/40]. 280.88 samples/sec. 341.786 ms/step.
Train benchmark of ecaresnet50t.ra2_in1k done. 279.96 samples/sec, 341.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet101d.miil_in1k created, param count: 44568563
Running inference benchmark on ecaresnet101d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 716.27 samples/sec. 357.406 ms/step.
Infer [16/40]. 716.27 samples/sec. 357.407 ms/step.
Infer [24/40]. 716.27 samples/sec. 357.408 ms/step.
Infer [32/40]. 716.25 samples/sec. 357.416 ms/step.
Infer [40/40]. 716.25 samples/sec. 357.418 ms/step.
Inference benchmark of ecaresnet101d.miil_in1k done. 716.15 samples/sec, 357.42 ms/step
Model ecaresnet101d.miil_in1k created, param count: 44568563
Running train benchmark on ecaresnet101d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 20.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet101d.miil_in1k created, param count: 44568563
Running train benchmark on ecaresnet101d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 222.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnet101d.miil_in1k created, param count: 44568563
Running train benchmark on ecaresnet101d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 236.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model ecaresnet101d.miil_in1k created, param count: 44568563
Running train benchmark on ecaresnet101d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 213.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model ecaresnet101d.miil_in1k created, param count: 44568563
Running train benchmark on ecaresnet101d.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 227.67 samples/sec. 281.105 ms/step.
Train [16/40]. 227.66 samples/sec. 281.117 ms/step.
Train [24/40]. 227.67 samples/sec. 281.115 ms/step.
Train [32/40]. 227.67 samples/sec. 281.113 ms/step.
Train [40/40]. 227.66 samples/sec. 281.116 ms/step.
Train benchmark of ecaresnet101d.miil_in1k done. 226.40 samples/sec, 281.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet101d_pruned.miil_in1k created, param count: 24876040
Running inference benchmark on ecaresnet101d_pruned.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1658.82 samples/sec. 154.326 ms/step.
Infer [16/40]. 1658.71 samples/sec. 154.337 ms/step.
Infer [24/40]. 1658.73 samples/sec. 154.335 ms/step.
Infer [32/40]. 1658.70 samples/sec. 154.337 ms/step.
Infer [40/40]. 1658.70 samples/sec. 154.338 ms/step.
Inference benchmark of ecaresnet101d_pruned.miil_in1k done. 1658.36 samples/sec, 154.34 ms/step
Model ecaresnet101d_pruned.miil_in1k created, param count: 24876040
Running train benchmark on ecaresnet101d_pruned.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 328.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet101d_pruned.miil_in1k created, param count: 24876040
Running train benchmark on ecaresnet101d_pruned.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 487.93 samples/sec. 393.499 ms/step.
Train [16/40]. 487.90 samples/sec. 393.521 ms/step.
Train [24/40]. 487.90 samples/sec. 393.525 ms/step.
Train [32/40]. 487.89 samples/sec. 393.531 ms/step.
Train [40/40]. 487.88 samples/sec. 393.535 ms/step.
Train benchmark of ecaresnet101d_pruned.miil_in1k done. 485.61 samples/sec, 393.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running inference benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 256.
Infer [8/40]. 201.04 samples/sec. 1273.406 ms/step.
Infer [16/40]. 201.04 samples/sec. 1273.406 ms/step.
Infer [24/40]. 201.03 samples/sec. 1273.417 ms/step.
Infer [32/40]. 201.03 samples/sec. 1273.422 ms/step.
Infer [40/40]. 201.03 samples/sec. 1273.434 ms/step.
Inference benchmark of ecaresnet269d.ra2_in1k done. 201.02 samples/sec, 1273.43 ms/step
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 35.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.59 GiB is allocated by PyTorch, and 408.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 466.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 365.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 386.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 459.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 771.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model ecaresnet269d.ra2_in1k created, param count: 102093077
Running train benchmark on ecaresnet269d.ra2_in1k for 40 steps w/ input size (3, 352, 352) and batch size 16.
Train [8/40]. 59.17 samples/sec. 270.402 ms/step.
Train [16/40]. 59.24 samples/sec. 270.074 ms/step.
Train [24/40]. 59.29 samples/sec. 269.861 ms/step.
Train [32/40]. 59.30 samples/sec. 269.799 ms/step.
Train [40/40]. 59.28 samples/sec. 269.916 ms/step.
Train benchmark of ecaresnet269d.ra2_in1k done. 58.60 samples/sec, 269.92 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ecaresnetlight.miil_in1k created, param count: 30162046
Running inference benchmark on ecaresnetlight.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1511.25 samples/sec. 169.396 ms/step.
Infer [16/40]. 1511.26 samples/sec. 169.395 ms/step.
Infer [24/40]. 1511.25 samples/sec. 169.396 ms/step.
Infer [32/40]. 1511.26 samples/sec. 169.395 ms/step.
Infer [40/40]. 1511.21 samples/sec. 169.401 ms/step.
Inference benchmark of ecaresnetlight.miil_in1k done. 1510.88 samples/sec, 169.40 ms/step
Model ecaresnetlight.miil_in1k created, param count: 30162046
Running train benchmark on ecaresnetlight.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 280.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 353.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ecaresnetlight.miil_in1k created, param count: 30162046
Running train benchmark on ecaresnetlight.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 130.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ecaresnetlight.miil_in1k created, param count: 30162046
Running train benchmark on ecaresnetlight.miil_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 461.44 samples/sec. 277.395 ms/step.
Train [16/40]. 461.42 samples/sec. 277.405 ms/step.
Train [24/40]. 461.40 samples/sec. 277.416 ms/step.
Train [32/40]. 461.41 samples/sec. 277.411 ms/step.
Train [40/40]. 461.42 samples/sec. 277.407 ms/step.
Train benchmark of ecaresnetlight.miil_in1k done. 459.53 samples/sec, 277.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model edgenext_base.in21k_ft_in1k created, param count: 18511292
Running inference benchmark on edgenext_base.in21k_ft_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 1220.46 samples/sec. 209.757 ms/step.
Infer [16/40]. 1220.58 samples/sec. 209.736 ms/step.
Infer [24/40]. 1220.49 samples/sec. 209.752 ms/step.
Infer [32/40]. 1220.50 samples/sec. 209.750 ms/step.
Infer [40/40]. 1220.48 samples/sec. 209.754 ms/step.
Inference benchmark of edgenext_base.in21k_ft_in1k done. 1220.30 samples/sec, 209.75 ms/step
Model edgenext_base.in21k_ft_in1k created, param count: 18511292
Running train benchmark on edgenext_base.in21k_ft_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 4.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model edgenext_base.in21k_ft_in1k created, param count: 18511292
Running train benchmark on edgenext_base.in21k_ft_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 750.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 454.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 178.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model edgenext_base.in21k_ft_in1k created, param count: 18511292
Running train benchmark on edgenext_base.in21k_ft_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 153.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model edgenext_base.in21k_ft_in1k created, param count: 18511292
Running train benchmark on edgenext_base.in21k_ft_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
Train [8/40]. 353.21 samples/sec. 271.792 ms/step.
Train [16/40]. 353.20 samples/sec. 271.803 ms/step.
Train [24/40]. 353.18 samples/sec. 271.814 ms/step.
Train [32/40]. 353.17 samples/sec. 271.820 ms/step.
Train [40/40]. 353.18 samples/sec. 271.814 ms/step.
Train benchmark of edgenext_base.in21k_ft_in1k done. 351.63 samples/sec, 271.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model edgenext_base.usi_in1k created, param count: 18511292
Running inference benchmark on edgenext_base.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 1219.78 samples/sec. 209.874 ms/step.
Infer [16/40]. 1219.69 samples/sec. 209.890 ms/step.
Infer [24/40]. 1219.77 samples/sec. 209.876 ms/step.
Infer [32/40]. 1219.78 samples/sec. 209.875 ms/step.
Infer [40/40]. 1219.80 samples/sec. 209.871 ms/step.
Inference benchmark of edgenext_base.usi_in1k done. 1219.62 samples/sec, 209.87 ms/step
Model edgenext_base.usi_in1k created, param count: 18511292
Running train benchmark on edgenext_base.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 4.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model edgenext_base.usi_in1k created, param count: 18511292
Running train benchmark on edgenext_base.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 750.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 454.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 178.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model edgenext_base.usi_in1k created, param count: 18511292
Running train benchmark on edgenext_base.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 135.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model edgenext_base.usi_in1k created, param count: 18511292
Running train benchmark on edgenext_base.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
Train [8/40]. 352.97 samples/sec. 271.974 ms/step.
Train [16/40]. 352.97 samples/sec. 271.976 ms/step.
Train [24/40]. 353.01 samples/sec. 271.951 ms/step.
Train [32/40]. 352.99 samples/sec. 271.964 ms/step.
Train [40/40]. 352.99 samples/sec. 271.959 ms/step.
Train benchmark of edgenext_base.usi_in1k done. 351.45 samples/sec, 271.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model edgenext_small.usi_in1k created, param count: 5586832
Running inference benchmark on edgenext_small.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 2141.87 samples/sec. 119.521 ms/step.
Infer [16/40]. 2141.90 samples/sec. 119.520 ms/step.
Infer [24/40]. 2141.88 samples/sec. 119.521 ms/step.
Infer [32/40]. 2141.87 samples/sec. 119.521 ms/step.
Infer [40/40]. 2141.87 samples/sec. 119.522 ms/step.
Inference benchmark of edgenext_small.usi_in1k done. 2141.39 samples/sec, 119.52 ms/step
Model edgenext_small.usi_in1k created, param count: 5586832
Running train benchmark on edgenext_small.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 226.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model edgenext_small.usi_in1k created, param count: 5586832
Running train benchmark on edgenext_small.usi_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
Train [8/40]. 647.95 samples/sec. 296.318 ms/step.
Train [16/40]. 647.98 samples/sec. 296.306 ms/step.
Train [24/40]. 648.00 samples/sec. 296.295 ms/step.
Train [32/40]. 648.00 samples/sec. 296.295 ms/step.
Train [40/40]. 647.96 samples/sec. 296.314 ms/step.
Train benchmark of edgenext_small.usi_in1k done. 645.59 samples/sec, 296.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model edgenext_small_rw.sw_in1k created, param count: 7826512
Running inference benchmark on edgenext_small_rw.sw_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 1995.59 samples/sec. 128.283 ms/step.
Infer [16/40]. 1995.81 samples/sec. 128.269 ms/step.
Infer [24/40]. 1995.91 samples/sec. 128.263 ms/step.
Infer [32/40]. 1995.96 samples/sec. 128.259 ms/step.
Infer [40/40]. 1996.01 samples/sec. 128.256 ms/step.
Inference benchmark of edgenext_small_rw.sw_in1k done. 1995.57 samples/sec, 128.26 ms/step
Model edgenext_small_rw.sw_in1k created, param count: 7826512
Running train benchmark on edgenext_small_rw.sw_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 99.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model edgenext_small_rw.sw_in1k created, param count: 7826512
Running train benchmark on edgenext_small_rw.sw_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
Train [8/40]. 606.39 samples/sec. 316.629 ms/step.
Train [16/40]. 606.47 samples/sec. 316.585 ms/step.
Train [24/40]. 606.43 samples/sec. 316.607 ms/step.
Train [32/40]. 606.44 samples/sec. 316.603 ms/step.
Train [40/40]. 606.43 samples/sec. 316.609 ms/step.
Train benchmark of edgenext_small_rw.sw_in1k done. 604.44 samples/sec, 316.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model edgenext_x_small.in1k created, param count: 2336804
Running inference benchmark on edgenext_x_small.in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 3943.86 samples/sec. 64.911 ms/step.
Infer [16/40]. 3944.32 samples/sec. 64.903 ms/step.
Infer [24/40]. 3944.49 samples/sec. 64.901 ms/step.
Infer [32/40]. 3944.32 samples/sec. 64.903 ms/step.
Infer [40/40]. 3944.29 samples/sec. 64.904 ms/step.
Inference benchmark of edgenext_x_small.in1k done. 3942.76 samples/sec, 64.90 ms/step
Model edgenext_x_small.in1k created, param count: 2336804
Running train benchmark on edgenext_x_small.in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1089.18 samples/sec. 235.039 ms/step.
Train [16/40]. 1089.45 samples/sec. 234.981 ms/step.
Train [24/40]. 1089.44 samples/sec. 234.984 ms/step.
Train [32/40]. 1089.51 samples/sec. 234.969 ms/step.
Train [40/40]. 1089.58 samples/sec. 234.954 ms/step.
Train benchmark of edgenext_x_small.in1k done. 1084.79 samples/sec, 234.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model edgenext_xx_small.in1k created, param count: 1327216
Running inference benchmark on edgenext_xx_small.in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 6569.05 samples/sec. 38.971 ms/step.
Infer [16/40]. 6568.59 samples/sec. 38.973 ms/step.
Infer [24/40]. 6567.35 samples/sec. 38.981 ms/step.
Infer [32/40]. 6566.62 samples/sec. 38.985 ms/step.
Infer [40/40]. 6567.23 samples/sec. 38.981 ms/step.
Inference benchmark of edgenext_xx_small.in1k done. 6563.11 samples/sec, 38.98 ms/step
Model edgenext_xx_small.in1k created, param count: 1327216
Running train benchmark on edgenext_xx_small.in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1916.13 samples/sec. 133.603 ms/step.
Train [16/40]. 1916.99 samples/sec. 133.543 ms/step.
Train [24/40]. 1916.92 samples/sec. 133.548 ms/step.
Train [32/40]. 1916.89 samples/sec. 133.549 ms/step.
Train [40/40]. 1917.00 samples/sec. 133.542 ms/step.
Train benchmark of edgenext_xx_small.in1k done. 1906.40 samples/sec, 133.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientformer_l1.snap_dist_in1k created, param count: 12289928
Running inference benchmark on efficientformer_l1.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3879.92 samples/sec. 65.981 ms/step.
Infer [16/40]. 3879.64 samples/sec. 65.985 ms/step.
Infer [24/40]. 3879.38 samples/sec. 65.990 ms/step.
Infer [32/40]. 3879.28 samples/sec. 65.992 ms/step.
Infer [40/40]. 3878.76 samples/sec. 66.001 ms/step.
Inference benchmark of efficientformer_l1.snap_dist_in1k done. 3877.12 samples/sec, 66.00 ms/step
Model efficientformer_l1.snap_dist_in1k created, param count: 12289928
Running train benchmark on efficientformer_l1.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1288.54 samples/sec. 198.675 ms/step.
Train [16/40]. 1288.72 samples/sec. 198.647 ms/step.
Train [24/40]. 1288.76 samples/sec. 198.640 ms/step.
Train [32/40]. 1288.72 samples/sec. 198.646 ms/step.
Train [40/40]. 1288.75 samples/sec. 198.642 ms/step.
Train benchmark of efficientformer_l1.snap_dist_in1k done. 1283.00 samples/sec, 198.64 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientformer_l3.snap_dist_in1k created, param count: 31406000
Running inference benchmark on efficientformer_l3.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1744.44 samples/sec. 146.752 ms/step.
Infer [16/40]. 1744.46 samples/sec. 146.751 ms/step.
Infer [24/40]. 1744.35 samples/sec. 146.759 ms/step.
Infer [32/40]. 1744.29 samples/sec. 146.765 ms/step.
Infer [40/40]. 1744.26 samples/sec. 146.767 ms/step.
Inference benchmark of efficientformer_l3.snap_dist_in1k done. 1743.87 samples/sec, 146.77 ms/step
Model efficientformer_l3.snap_dist_in1k created, param count: 31406000
Running train benchmark on efficientformer_l3.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 95.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientformer_l3.snap_dist_in1k created, param count: 31406000
Running train benchmark on efficientformer_l3.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 176.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientformer_l3.snap_dist_in1k created, param count: 31406000
Running train benchmark on efficientformer_l3.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 611.34 samples/sec. 209.374 ms/step.
Train [16/40]. 611.27 samples/sec. 209.399 ms/step.
Train [24/40]. 611.27 samples/sec. 209.399 ms/step.
Train [32/40]. 611.27 samples/sec. 209.401 ms/step.
Train [40/40]. 611.27 samples/sec. 209.400 ms/step.
Train benchmark of efficientformer_l3.snap_dist_in1k done. 607.67 samples/sec, 209.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientformer_l7.snap_dist_in1k created, param count: 82229328
Running inference benchmark on efficientformer_l7.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 830.90 samples/sec. 308.098 ms/step.
Infer [16/40]. 830.90 samples/sec. 308.101 ms/step.
Infer [24/40]. 830.89 samples/sec. 308.104 ms/step.
Infer [32/40]. 830.87 samples/sec. 308.111 ms/step.
Infer [40/40]. 830.87 samples/sec. 308.112 ms/step.
Inference benchmark of efficientformer_l7.snap_dist_in1k done. 830.75 samples/sec, 308.11 ms/step
Model efficientformer_l7.snap_dist_in1k created, param count: 82229328
Running train benchmark on efficientformer_l7.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 848.06 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 29.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientformer_l7.snap_dist_in1k created, param count: 82229328
Running train benchmark on efficientformer_l7.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 876.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 108.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientformer_l7.snap_dist_in1k created, param count: 82229328
Running train benchmark on efficientformer_l7.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 98.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientformer_l7.snap_dist_in1k created, param count: 82229328
Running train benchmark on efficientformer_l7.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 683.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientformer_l7.snap_dist_in1k created, param count: 82229328
Running train benchmark on efficientformer_l7.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 299.11 samples/sec. 213.967 ms/step.
Train [16/40]. 299.12 samples/sec. 213.959 ms/step.
Train [24/40]. 299.12 samples/sec. 213.962 ms/step.
Train [32/40]. 299.11 samples/sec. 213.967 ms/step.
Train [40/40]. 299.11 samples/sec. 213.966 ms/step.
Train benchmark of efficientformer_l7.snap_dist_in1k done. 296.79 samples/sec, 213.97 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientformerv2_l.snap_dist_in1k created, param count: 26322288
Running inference benchmark on efficientformerv2_l.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 468.75 samples/sec. 546.130 ms/step.
Infer [16/40]. 468.75 samples/sec. 546.138 ms/step.
Infer [24/40]. 468.76 samples/sec. 546.117 ms/step.
Infer [32/40]. 468.77 samples/sec. 546.109 ms/step.
Infer [40/40]. 468.76 samples/sec. 546.122 ms/step.
Inference benchmark of efficientformerv2_l.snap_dist_in1k done. 468.72 samples/sec, 546.12 ms/step
Model efficientformerv2_l.snap_dist_in1k created, param count: 26322288
Running train benchmark on efficientformerv2_l.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 54.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientformerv2_l.snap_dist_in1k created, param count: 26322288
Running train benchmark on efficientformerv2_l.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientformerv2_l.snap_dist_in1k created, param count: 26322288
Running train benchmark on efficientformerv2_l.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 244.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientformerv2_l.snap_dist_in1k created, param count: 26322288
Running train benchmark on efficientformerv2_l.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 342.65 samples/sec. 280.169 ms/step.
Train [16/40]. 342.65 samples/sec. 280.166 ms/step.
Train [24/40]. 342.64 samples/sec. 280.174 ms/step.
Train [32/40]. 342.67 samples/sec. 280.156 ms/step.
Train [40/40]. 342.67 samples/sec. 280.150 ms/step.
Train benchmark of efficientformerv2_l.snap_dist_in1k done. 339.65 samples/sec, 280.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientformerv2_s0.snap_dist_in1k created, param count: 3600256
Running inference benchmark on efficientformerv2_s0.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1496.94 samples/sec. 171.016 ms/step.
Infer [16/40]. 1497.04 samples/sec. 171.004 ms/step.
Infer [24/40]. 1497.04 samples/sec. 171.004 ms/step.
Infer [32/40]. 1497.01 samples/sec. 171.007 ms/step.
Infer [40/40]. 1497.05 samples/sec. 171.003 ms/step.
Inference benchmark of efficientformerv2_s0.snap_dist_in1k done. 1496.75 samples/sec, 171.00 ms/step
Model efficientformerv2_s0.snap_dist_in1k created, param count: 3600256
Running train benchmark on efficientformerv2_s0.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 952.24 samples/sec. 268.841 ms/step.
Train [16/40]. 952.30 samples/sec. 268.824 ms/step.
Train [24/40]. 952.27 samples/sec. 268.831 ms/step.
Train [32/40]. 952.26 samples/sec. 268.834 ms/step.
Train [40/40]. 952.24 samples/sec. 268.840 ms/step.
Train benchmark of efficientformerv2_s0.snap_dist_in1k done. 947.79 samples/sec, 268.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientformerv2_s1.snap_dist_in1k created, param count: 6185560
Running inference benchmark on efficientformerv2_s1.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1341.52 samples/sec. 190.828 ms/step.
Infer [16/40]. 1341.55 samples/sec. 190.825 ms/step.
Infer [24/40]. 1341.52 samples/sec. 190.828 ms/step.
Infer [32/40]. 1341.52 samples/sec. 190.828 ms/step.
Infer [40/40]. 1341.52 samples/sec. 190.829 ms/step.
Inference benchmark of efficientformerv2_s1.snap_dist_in1k done. 1341.27 samples/sec, 190.83 ms/step
Model efficientformerv2_s1.snap_dist_in1k created, param count: 6185560
Running train benchmark on efficientformerv2_s1.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 769.79 samples/sec. 332.559 ms/step.
Train [16/40]. 769.75 samples/sec. 332.574 ms/step.
Train [24/40]. 769.81 samples/sec. 332.552 ms/step.
Train [32/40]. 769.71 samples/sec. 332.591 ms/step.
Train [40/40]. 769.62 samples/sec. 332.632 ms/step.
Train benchmark of efficientformerv2_s1.snap_dist_in1k done. 766.10 samples/sec, 332.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientformerv2_s2.snap_dist_in1k created, param count: 12710112
Running inference benchmark on efficientformerv2_s2.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 721.26 samples/sec. 354.934 ms/step.
Infer [16/40]. 721.27 samples/sec. 354.930 ms/step.
Infer [24/40]. 721.27 samples/sec. 354.929 ms/step.
Infer [32/40]. 721.27 samples/sec. 354.931 ms/step.
Infer [40/40]. 721.26 samples/sec. 354.934 ms/step.
Inference benchmark of efficientformerv2_s2.snap_dist_in1k done. 721.17 samples/sec, 354.93 ms/step
Model efficientformerv2_s2.snap_dist_in1k created, param count: 12710112
Running train benchmark on efficientformerv2_s2.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 172.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientformerv2_s2.snap_dist_in1k created, param count: 12710112
Running train benchmark on efficientformerv2_s2.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 442.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientformerv2_s2.snap_dist_in1k created, param count: 12710112
Running train benchmark on efficientformerv2_s2.snap_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 473.62 samples/sec. 270.260 ms/step.
Train [16/40]. 473.62 samples/sec. 270.260 ms/step.
Train [24/40]. 473.62 samples/sec. 270.261 ms/step.
Train [32/40]. 473.59 samples/sec. 270.274 ms/step.
Train [40/40]. 473.58 samples/sec. 270.280 ms/step.
Train benchmark of efficientformerv2_s2.snap_dist_in1k done. 470.16 samples/sec, 270.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b0.ra_in1k created, param count: 5288548
Running inference benchmark on efficientnet_b0.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4650.60 samples/sec. 55.047 ms/step.
Infer [16/40]. 4650.52 samples/sec. 55.048 ms/step.
Infer [24/40]. 4650.72 samples/sec. 55.045 ms/step.
Infer [32/40]. 4650.10 samples/sec. 55.053 ms/step.
Infer [40/40]. 4649.65 samples/sec. 55.058 ms/step.
Inference benchmark of efficientnet_b0.ra_in1k done. 4647.54 samples/sec, 55.06 ms/step
Model efficientnet_b0.ra_in1k created, param count: 5288548
Running train benchmark on efficientnet_b0.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1161.03 samples/sec. 220.494 ms/step.
Train [16/40]. 1161.00 samples/sec. 220.499 ms/step.
Train [24/40]. 1160.76 samples/sec. 220.545 ms/step.
Train [32/40]. 1160.70 samples/sec. 220.557 ms/step.
Train [40/40]. 1160.64 samples/sec. 220.569 ms/step.
Train benchmark of efficientnet_b0.ra_in1k done. 1155.08 samples/sec, 220.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b1.ft_in1k created, param count: 7794184
Running inference benchmark on efficientnet_b1.ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2499.16 samples/sec. 102.435 ms/step.
Infer [16/40]. 2498.57 samples/sec. 102.459 ms/step.
Infer [24/40]. 2498.50 samples/sec. 102.462 ms/step.
Infer [32/40]. 2498.38 samples/sec. 102.466 ms/step.
Infer [40/40]. 2498.39 samples/sec. 102.466 ms/step.
Inference benchmark of efficientnet_b1.ft_in1k done. 2497.69 samples/sec, 102.47 ms/step
Model efficientnet_b1.ft_in1k created, param count: 7794184
Running train benchmark on efficientnet_b1.ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 136.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b1.ft_in1k created, param count: 7794184
Running train benchmark on efficientnet_b1.ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 128.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b1.ft_in1k created, param count: 7794184
Running train benchmark on efficientnet_b1.ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 658.05 samples/sec. 194.513 ms/step.
Train [16/40]. 658.10 samples/sec. 194.501 ms/step.
Train [24/40]. 658.13 samples/sec. 194.491 ms/step.
Train [32/40]. 658.14 samples/sec. 194.487 ms/step.
Train [40/40]. 658.10 samples/sec. 194.499 ms/step.
Train benchmark of efficientnet_b1.ft_in1k done. 653.93 samples/sec, 194.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b1_pruned.in1k created, param count: 6331916
Running inference benchmark on efficientnet_b1_pruned.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 4768.54 samples/sec. 53.685 ms/step.
Infer [16/40]. 4768.58 samples/sec. 53.685 ms/step.
Infer [24/40]. 4768.45 samples/sec. 53.686 ms/step.
Infer [32/40]. 4768.45 samples/sec. 53.686 ms/step.
Infer [40/40]. 4768.43 samples/sec. 53.686 ms/step.
Inference benchmark of efficientnet_b1_pruned.in1k done. 4766.27 samples/sec, 53.69 ms/step
Model efficientnet_b1_pruned.in1k created, param count: 6331916
Running train benchmark on efficientnet_b1_pruned.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1170.19 samples/sec. 218.767 ms/step.
Train [16/40]. 1170.19 samples/sec. 218.767 ms/step.
Train [24/40]. 1169.86 samples/sec. 218.829 ms/step.
Train [32/40]. 1169.63 samples/sec. 218.874 ms/step.
Train [40/40]. 1169.53 samples/sec. 218.892 ms/step.
Train benchmark of efficientnet_b1_pruned.in1k done. 1162.62 samples/sec, 218.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b2.ra_in1k created, param count: 9109994
Running inference benchmark on efficientnet_b2.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1827.42 samples/sec. 140.088 ms/step.
Infer [16/40]. 1827.45 samples/sec. 140.086 ms/step.
Infer [24/40]. 1827.47 samples/sec. 140.084 ms/step.
Infer [32/40]. 1827.48 samples/sec. 140.084 ms/step.
Infer [40/40]. 1827.31 samples/sec. 140.097 ms/step.
Inference benchmark of efficientnet_b2.ra_in1k done. 1826.90 samples/sec, 140.10 ms/step
Model efficientnet_b2.ra_in1k created, param count: 9109994
Running train benchmark on efficientnet_b2.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 730.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 516.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 198.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b2.ra_in1k created, param count: 9109994
Running train benchmark on efficientnet_b2.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 112.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b2.ra_in1k created, param count: 9109994
Running train benchmark on efficientnet_b2.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 264.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnet_b2.ra_in1k created, param count: 9109994
Running train benchmark on efficientnet_b2.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 480.86 samples/sec. 199.641 ms/step.
Train [16/40]. 480.86 samples/sec. 199.644 ms/step.
Train [24/40]. 480.81 samples/sec. 199.661 ms/step.
Train [32/40]. 480.82 samples/sec. 199.660 ms/step.
Train [40/40]. 480.82 samples/sec. 199.660 ms/step.
Train benchmark of efficientnet_b2.ra_in1k done. 477.82 samples/sec, 199.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b2_pruned.in1k created, param count: 8309737
Running inference benchmark on efficientnet_b2_pruned.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
Infer [8/40]. 2964.21 samples/sec. 86.364 ms/step.
Infer [16/40]. 2964.25 samples/sec. 86.362 ms/step.
Infer [24/40]. 2964.17 samples/sec. 86.365 ms/step.
Infer [32/40]. 2964.11 samples/sec. 86.367 ms/step.
Infer [40/40]. 2963.71 samples/sec. 86.378 ms/step.
Inference benchmark of efficientnet_b2_pruned.in1k done. 2962.83 samples/sec, 86.38 ms/step
Model efficientnet_b2_pruned.in1k created, param count: 8309737
Running train benchmark on efficientnet_b2_pruned.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 212.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b2_pruned.in1k created, param count: 8309737
Running train benchmark on efficientnet_b2_pruned.in1k for 40 steps w/ input size (3, 260, 260) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 21.52 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b2_pruned.in1k created, param count: 8309737
Running train benchmark on efficientnet_b2_pruned.in1k for 40 steps w/ input size (3, 260, 260) and batch size 128.
Train [8/40]. 791.58 samples/sec. 161.702 ms/step.
Train [16/40]. 791.54 samples/sec. 161.711 ms/step.
Train [24/40]. 791.56 samples/sec. 161.707 ms/step.
Train [32/40]. 791.54 samples/sec. 161.709 ms/step.
Train [40/40]. 791.54 samples/sec. 161.711 ms/step.
Train benchmark of efficientnet_b2_pruned.in1k done. 785.90 samples/sec, 161.71 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b3.ra2_in1k created, param count: 12233232
Running inference benchmark on efficientnet_b3.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 1130.13 samples/sec. 226.523 ms/step.
Infer [16/40]. 1130.12 samples/sec. 226.525 ms/step.
Infer [24/40]. 1130.12 samples/sec. 226.524 ms/step.
Infer [32/40]. 1130.10 samples/sec. 226.529 ms/step.
Infer [40/40]. 1130.09 samples/sec. 226.531 ms/step.
Inference benchmark of efficientnet_b3.ra2_in1k done. 1129.90 samples/sec, 226.53 ms/step
Model efficientnet_b3.ra2_in1k created, param count: 12233232
Running train benchmark on efficientnet_b3.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 636.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 101.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b3.ra2_in1k created, param count: 12233232
Running train benchmark on efficientnet_b3.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 580.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 179.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b3.ra2_in1k created, param count: 12233232
Running train benchmark on efficientnet_b3.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 54.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnet_b3.ra2_in1k created, param count: 12233232
Running train benchmark on efficientnet_b3.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 148.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientnet_b3.ra2_in1k created, param count: 12233232
Running train benchmark on efficientnet_b3.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
Train [8/40]. 305.16 samples/sec. 209.726 ms/step.
Train [16/40]. 305.17 samples/sec. 209.717 ms/step.
Train [24/40]. 305.17 samples/sec. 209.717 ms/step.
Train [32/40]. 305.15 samples/sec. 209.731 ms/step.
Train [40/40]. 305.15 samples/sec. 209.732 ms/step.
Train benchmark of efficientnet_b3.ra2_in1k done. 303.22 samples/sec, 209.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b3_pruned.in1k created, param count: 9855020
Running inference benchmark on efficientnet_b3_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 2326.23 samples/sec. 110.049 ms/step.
Infer [16/40]. 2326.13 samples/sec. 110.054 ms/step.
Infer [24/40]. 2326.10 samples/sec. 110.056 ms/step.
Infer [32/40]. 2326.13 samples/sec. 110.054 ms/step.
Infer [40/40]. 2326.12 samples/sec. 110.055 ms/step.
Inference benchmark of efficientnet_b3_pruned.in1k done. 2325.54 samples/sec, 110.06 ms/step
Model efficientnet_b3_pruned.in1k created, param count: 9855020
Running train benchmark on efficientnet_b3_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 217.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b3_pruned.in1k created, param count: 9855020
Running train benchmark on efficientnet_b3_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 223.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b3_pruned.in1k created, param count: 9855020
Running train benchmark on efficientnet_b3_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
Train [8/40]. 609.14 samples/sec. 210.131 ms/step.
Train [16/40]. 609.16 samples/sec. 210.127 ms/step.
Train [24/40]. 609.14 samples/sec. 210.131 ms/step.
Train [32/40]. 609.12 samples/sec. 210.138 ms/step.
Train [40/40]. 609.13 samples/sec. 210.137 ms/step.
Train benchmark of efficientnet_b3_pruned.in1k done. 605.15 samples/sec, 210.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running inference benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 583.06 samples/sec. 439.067 ms/step.
Infer [16/40]. 582.89 samples/sec. 439.194 ms/step.
Infer [24/40]. 582.84 samples/sec. 439.229 ms/step.
Infer [32/40]. 582.81 samples/sec. 439.250 ms/step.
Infer [40/40]. 582.79 samples/sec. 439.266 ms/step.
Inference benchmark of efficientnet_b4.ra2_in1k done. 582.73 samples/sec, 439.27 ms/step
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running train benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.99 GiB is free. Including non-PyTorch memory, this process has 19.65 GiB memory in use. Of the allocated memory 19.07 GiB is allocated by PyTorch, and 82.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running train benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.04 GiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 193.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running train benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 484.06 MiB is free. Including non-PyTorch memory, this process has 23.17 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 157.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running train benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 162.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running train benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 131.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running train benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 388.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model efficientnet_b4.ra2_in1k created, param count: 19341616
Running train benchmark on efficientnet_b4.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 164.36 samples/sec. 194.699 ms/step.
Train [16/40]. 164.34 samples/sec. 194.715 ms/step.
Train [24/40]. 164.34 samples/sec. 194.721 ms/step.
Train [32/40]. 164.33 samples/sec. 194.727 ms/step.
Train [40/40]. 164.32 samples/sec. 194.739 ms/step.
Train benchmark of efficientnet_b4.ra2_in1k done. 163.04 samples/sec, 194.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running inference benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 256.
Infer [8/40]. 356.87 samples/sec. 717.343 ms/step.
Infer [16/40]. 356.87 samples/sec. 717.356 ms/step.
Infer [24/40]. 356.84 samples/sec. 717.404 ms/step.
Infer [32/40]. 356.83 samples/sec. 717.431 ms/step.
Infer [40/40]. 356.82 samples/sec. 717.449 ms/step.
Inference benchmark of efficientnet_b5.sw_in12k done. 356.80 samples/sec, 717.45 ms/step
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1014.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 608.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 60.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.44 GiB is free. Including non-PyTorch memory, this process has 22.20 GiB memory in use. Of the allocated memory 21.39 GiB is allocated by PyTorch, and 323.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.45 GiB is free. Including non-PyTorch memory, this process has 21.20 GiB memory in use. Of the allocated memory 20.28 GiB is allocated by PyTorch, and 431.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 952.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 225.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 634.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 414.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 232.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 476.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 258.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 225.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 182.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model efficientnet_b5.sw_in12k created, param count: 52562013
Running train benchmark on efficientnet_b5.sw_in12k for 40 steps w/ input size (3, 416, 416) and batch size 16.
Train [8/40]. 101.46 samples/sec. 157.695 ms/step.
Train [16/40]. 101.45 samples/sec. 157.709 ms/step.
Train [24/40]. 101.45 samples/sec. 157.715 ms/step.
Train [32/40]. 101.44 samples/sec. 157.724 ms/step.
Train [40/40]. 101.43 samples/sec. 157.738 ms/step.
Train benchmark of efficientnet_b5.sw_in12k done. 100.42 samples/sec, 157.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running inference benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 308.81 samples/sec. 828.982 ms/step.
Infer [16/40]. 308.78 samples/sec. 829.074 ms/step.
Infer [24/40]. 308.76 samples/sec. 829.116 ms/step.
Infer [32/40]. 308.75 samples/sec. 829.141 ms/step.
Infer [40/40]. 308.75 samples/sec. 829.157 ms/step.
Inference benchmark of efficientnet_b5.sw_in12k_ft_in1k done. 308.73 samples/sec, 829.16 ms/step
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 586.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 50.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 838.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 238.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.83 GiB is free. Including non-PyTorch memory, this process has 20.81 GiB memory in use. Of the allocated memory 19.94 GiB is allocated by PyTorch, and 387.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 598.06 MiB is free. Including non-PyTorch memory, this process has 23.06 GiB memory in use. Of the allocated memory 22.11 GiB is allocated by PyTorch, and 463.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 736.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 134.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 552.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 156.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 234.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 219.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 354.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model efficientnet_b5.sw_in12k_ft_in1k created, param count: 30389784
Running train benchmark on efficientnet_b5.sw_in12k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
Train [8/40]. 88.00 samples/sec. 181.817 ms/step.
Train [16/40]. 88.00 samples/sec. 181.810 ms/step.
Train [24/40]. 88.01 samples/sec. 181.807 ms/step.
Train [32/40]. 88.01 samples/sec. 181.806 ms/step.
Train [40/40]. 88.01 samples/sec. 181.807 ms/step.
Train benchmark of efficientnet_b5.sw_in12k_ft_in1k done. 87.21 samples/sec, 181.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_el.ra_in1k created, param count: 10589712
Running inference benchmark on efficientnet_el.ra_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1010.95 samples/sec. 253.228 ms/step.
Infer [16/40]. 1010.93 samples/sec. 253.232 ms/step.
Infer [24/40]. 1010.93 samples/sec. 253.231 ms/step.
Infer [32/40]. 1010.93 samples/sec. 253.232 ms/step.
Infer [40/40]. 1010.92 samples/sec. 253.234 ms/step.
Inference benchmark of efficientnet_el.ra_in1k done. 1010.76 samples/sec, 253.23 ms/step
Model efficientnet_el.ra_in1k created, param count: 10589712
Running train benchmark on efficientnet_el.ra_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 220.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 350.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_el.ra_in1k created, param count: 10589712
Running train benchmark on efficientnet_el.ra_in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 474.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 271.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_el.ra_in1k created, param count: 10589712
Running train benchmark on efficientnet_el.ra_in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 208.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnet_el.ra_in1k created, param count: 10589712
Running train benchmark on efficientnet_el.ra_in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 156.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientnet_el.ra_in1k created, param count: 10589712
Running train benchmark on efficientnet_el.ra_in1k for 40 steps w/ input size (3, 300, 300) and batch size 64.
Train [8/40]. 273.10 samples/sec. 234.350 ms/step.
Train [16/40]. 272.94 samples/sec. 234.481 ms/step.
Train [24/40]. 272.84 samples/sec. 234.571 ms/step.
Train [32/40]. 272.92 samples/sec. 234.504 ms/step.
Train [40/40]. 272.93 samples/sec. 234.494 ms/step.
Train benchmark of efficientnet_el.ra_in1k done. 271.75 samples/sec, 234.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_el_pruned.in1k created, param count: 10589712
Running inference benchmark on efficientnet_el_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1010.82 samples/sec. 253.260 ms/step.
Infer [16/40]. 1010.78 samples/sec. 253.271 ms/step.
Infer [24/40]. 1010.77 samples/sec. 253.271 ms/step.
Infer [32/40]. 1010.76 samples/sec. 253.274 ms/step.
Infer [40/40]. 1010.76 samples/sec. 253.274 ms/step.
Inference benchmark of efficientnet_el_pruned.in1k done. 1010.60 samples/sec, 253.27 ms/step
Model efficientnet_el_pruned.in1k created, param count: 10589712
Running train benchmark on efficientnet_el_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 220.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 350.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_el_pruned.in1k created, param count: 10589712
Running train benchmark on efficientnet_el_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 474.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 241.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnet_el_pruned.in1k created, param count: 10589712
Running train benchmark on efficientnet_el_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 184.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnet_el_pruned.in1k created, param count: 10589712
Running train benchmark on efficientnet_el_pruned.in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
Train [8/40]. 264.35 samples/sec. 363.149 ms/step.
Train [16/40]. 264.29 samples/sec. 363.233 ms/step.
Train [24/40]. 264.30 samples/sec. 363.218 ms/step.
Train [32/40]. 264.31 samples/sec. 363.209 ms/step.
Train [40/40]. 264.31 samples/sec. 363.211 ms/step.
Train benchmark of efficientnet_el_pruned.in1k done. 263.49 samples/sec, 363.21 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_em.ra2_in1k created, param count: 6899496
Running inference benchmark on efficientnet_em.ra2_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2276.93 samples/sec. 112.432 ms/step.
Infer [16/40]. 2276.73 samples/sec. 112.442 ms/step.
Infer [24/40]. 2276.74 samples/sec. 112.441 ms/step.
Infer [32/40]. 2276.69 samples/sec. 112.444 ms/step.
Infer [40/40]. 2276.72 samples/sec. 112.443 ms/step.
Inference benchmark of efficientnet_em.ra2_in1k done. 2276.15 samples/sec, 112.44 ms/step
Model efficientnet_em.ra2_in1k created, param count: 6899496
Running train benchmark on efficientnet_em.ra2_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 254.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 87.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnet_em.ra2_in1k created, param count: 6899496
Running train benchmark on efficientnet_em.ra2_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
Train [8/40]. 580.62 samples/sec. 330.679 ms/step.
Train [16/40]. 580.57 samples/sec. 330.709 ms/step.
Train [24/40]. 580.68 samples/sec. 330.646 ms/step.
Train [32/40]. 580.74 samples/sec. 330.611 ms/step.
Train [40/40]. 580.80 samples/sec. 330.577 ms/step.
Train benchmark of efficientnet_em.ra2_in1k done. 579.03 samples/sec, 330.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_es.ra_in1k created, param count: 5438392
Running inference benchmark on efficientnet_es.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3741.19 samples/sec. 68.427 ms/step.
Infer [16/40]. 3741.26 samples/sec. 68.426 ms/step.
Infer [24/40]. 3741.13 samples/sec. 68.429 ms/step.
Infer [32/40]. 3741.16 samples/sec. 68.428 ms/step.
Infer [40/40]. 3741.13 samples/sec. 68.428 ms/step.
Inference benchmark of efficientnet_es.ra_in1k done. 3739.76 samples/sec, 68.43 ms/step
Model efficientnet_es.ra_in1k created, param count: 5438392
Running train benchmark on efficientnet_es.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 972.08 samples/sec. 263.354 ms/step.
Train [16/40]. 972.10 samples/sec. 263.348 ms/step.
Train [24/40]. 972.08 samples/sec. 263.354 ms/step.
Train [32/40]. 972.05 samples/sec. 263.360 ms/step.
Train [40/40]. 972.03 samples/sec. 263.366 ms/step.
Train benchmark of efficientnet_es.ra_in1k done. 968.96 samples/sec, 263.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_es_pruned.in1k created, param count: 5438392
Running inference benchmark on efficientnet_es_pruned.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3741.41 samples/sec. 68.423 ms/step.
Infer [16/40]. 3741.33 samples/sec. 68.425 ms/step.
Infer [24/40]. 3741.36 samples/sec. 68.424 ms/step.
Infer [32/40]. 3741.34 samples/sec. 68.425 ms/step.
Infer [40/40]. 3741.33 samples/sec. 68.425 ms/step.
Inference benchmark of efficientnet_es_pruned.in1k done. 3739.97 samples/sec, 68.42 ms/step
Model efficientnet_es_pruned.in1k created, param count: 5438392
Running train benchmark on efficientnet_es_pruned.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 972.05 samples/sec. 263.362 ms/step.
Train [16/40]. 972.07 samples/sec. 263.354 ms/step.
Train [24/40]. 972.01 samples/sec. 263.371 ms/step.
Train [32/40]. 972.03 samples/sec. 263.366 ms/step.
Train [40/40]. 972.02 samples/sec. 263.370 ms/step.
Train benchmark of efficientnet_es_pruned.in1k done. 968.94 samples/sec, 263.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnet_lite0.ra_in1k created, param count: 4652008
Running inference benchmark on efficientnet_lite0.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5384.69 samples/sec. 47.542 ms/step.
Infer [16/40]. 5384.97 samples/sec. 47.540 ms/step.
Infer [24/40]. 5384.96 samples/sec. 47.540 ms/step.
Infer [32/40]. 5384.93 samples/sec. 47.540 ms/step.
Infer [40/40]. 5384.89 samples/sec. 47.540 ms/step.
Inference benchmark of efficientnet_lite0.ra_in1k done. 5382.08 samples/sec, 47.54 ms/step
Model efficientnet_lite0.ra_in1k created, param count: 4652008
Running train benchmark on efficientnet_lite0.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1370.92 samples/sec. 186.736 ms/step.
Train [16/40]. 1371.45 samples/sec. 186.664 ms/step.
Train [24/40]. 1371.54 samples/sec. 186.651 ms/step.
Train [32/40]. 1371.56 samples/sec. 186.649 ms/step.
Train [40/40]. 1371.52 samples/sec. 186.654 ms/step.
Train benchmark of efficientnet_lite0.ra_in1k done. 1366.29 samples/sec, 186.65 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running inference benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
Infer [8/40]. 356.14 samples/sec. 718.816 ms/step.
Infer [16/40]. 356.13 samples/sec. 718.842 ms/step.
Infer [24/40]. 356.12 samples/sec. 718.857 ms/step.
Infer [32/40]. 356.12 samples/sec. 718.867 ms/step.
Infer [40/40]. 356.10 samples/sec. 718.901 ms/step.
Inference benchmark of efficientnetv2_rw_m.agc_in1k done. 356.08 samples/sec, 718.90 ms/step
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 22.34 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 6.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacty of 23.65 GiB of which 640.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 277.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 309.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 888.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 704.06 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 373.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 219.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 330.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 257.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 731.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model efficientnetv2_rw_m.agc_in1k created, param count: 53236442
Running train benchmark on efficientnetv2_rw_m.agc_in1k for 40 steps w/ input size (3, 416, 416) and batch size 16.
Train [8/40]. 93.15 samples/sec. 171.771 ms/step.
Train [16/40]. 93.18 samples/sec. 171.717 ms/step.
Train [24/40]. 93.18 samples/sec. 171.704 ms/step.
Train [32/40]. 93.20 samples/sec. 171.677 ms/step.
Train [40/40]. 93.19 samples/sec. 171.694 ms/step.
Train benchmark of efficientnetv2_rw_m.agc_in1k done. 92.11 samples/sec, 171.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnetv2_rw_s.ra2_in1k created, param count: 23941296
Running inference benchmark on efficientnetv2_rw_s.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 771.46 samples/sec. 331.839 ms/step.
Infer [16/40]. 771.43 samples/sec. 331.851 ms/step.
Infer [24/40]. 771.42 samples/sec. 331.855 ms/step.
Infer [32/40]. 771.34 samples/sec. 331.888 ms/step.
Infer [40/40]. 771.30 samples/sec. 331.908 ms/step.
Inference benchmark of efficientnetv2_rw_s.ra2_in1k done. 771.19 samples/sec, 331.91 ms/step
Model efficientnetv2_rw_s.ra2_in1k created, param count: 23941296
Running train benchmark on efficientnetv2_rw_s.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 616.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 81.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnetv2_rw_s.ra2_in1k created, param count: 23941296
Running train benchmark on efficientnetv2_rw_s.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 396.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 193.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnetv2_rw_s.ra2_in1k created, param count: 23941296
Running train benchmark on efficientnetv2_rw_s.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 59.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnetv2_rw_s.ra2_in1k created, param count: 23941296
Running train benchmark on efficientnetv2_rw_s.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 227.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model efficientnetv2_rw_s.ra2_in1k created, param count: 23941296
Running train benchmark on efficientnetv2_rw_s.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 83.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model efficientnetv2_rw_s.ra2_in1k created, param count: 23941296
Running train benchmark on efficientnetv2_rw_s.ra2_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 214.05 samples/sec. 224.244 ms/step.
Train [16/40]. 214.07 samples/sec. 224.223 ms/step.
Train [24/40]. 214.08 samples/sec. 224.220 ms/step.
Train [32/40]. 214.06 samples/sec. 224.232 ms/step.
Train [40/40]. 214.06 samples/sec. 224.237 ms/step.
Train benchmark of efficientnetv2_rw_s.ra2_in1k done. 212.37 samples/sec, 224.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model efficientnetv2_rw_t.ra2_in1k created, param count: 13649388
Running inference benchmark on efficientnetv2_rw_t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1724.12 samples/sec. 148.481 ms/step.
Infer [16/40]. 1724.05 samples/sec. 148.488 ms/step.
Infer [24/40]. 1723.99 samples/sec. 148.492 ms/step.
Infer [32/40]. 1723.95 samples/sec. 148.496 ms/step.
Infer [40/40]. 1723.94 samples/sec. 148.497 ms/step.
Inference benchmark of efficientnetv2_rw_t.ra2_in1k done. 1723.58 samples/sec, 148.50 ms/step
Model efficientnetv2_rw_t.ra2_in1k created, param count: 13649388
Running train benchmark on efficientnetv2_rw_t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 237.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model efficientnetv2_rw_t.ra2_in1k created, param count: 13649388
Running train benchmark on efficientnetv2_rw_t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 199.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model efficientnetv2_rw_t.ra2_in1k created, param count: 13649388
Running train benchmark on efficientnetv2_rw_t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 274.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model efficientnetv2_rw_t.ra2_in1k created, param count: 13649388
Running train benchmark on efficientnetv2_rw_t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 482.95 samples/sec. 198.779 ms/step.
Train [16/40]. 482.94 samples/sec. 198.782 ms/step.
Train [24/40]. 482.93 samples/sec. 198.785 ms/step.
Train [32/40]. 482.92 samples/sec. 198.791 ms/step.
Train [40/40]. 482.92 samples/sec. 198.791 ms/step.
Train benchmark of efficientnetv2_rw_t.ra2_in1k done. 479.28 samples/sec, 198.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ese_vovnet19b_dw.ra_in1k created, param count: 6543080
Running inference benchmark on ese_vovnet19b_dw.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2582.42 samples/sec. 99.132 ms/step.
Infer [16/40]. 2582.50 samples/sec. 99.129 ms/step.
Infer [24/40]. 2582.45 samples/sec. 99.131 ms/step.
Infer [32/40]. 2582.42 samples/sec. 99.132 ms/step.
Infer [40/40]. 2582.45 samples/sec. 99.131 ms/step.
Inference benchmark of ese_vovnet19b_dw.ra_in1k done. 2581.74 samples/sec, 99.13 ms/step
Model ese_vovnet19b_dw.ra_in1k created, param count: 6543080
Running train benchmark on ese_vovnet19b_dw.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 121.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ese_vovnet19b_dw.ra_in1k created, param count: 6543080
Running train benchmark on ese_vovnet19b_dw.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 785.61 samples/sec. 244.396 ms/step.
Train [16/40]. 785.51 samples/sec. 244.427 ms/step.
Train [24/40]. 785.54 samples/sec. 244.419 ms/step.
Train [32/40]. 785.54 samples/sec. 244.419 ms/step.
Train [40/40]. 785.47 samples/sec. 244.439 ms/step.
Train benchmark of ese_vovnet19b_dw.ra_in1k done. 783.26 samples/sec, 244.44 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ese_vovnet39b.ra_in1k created, param count: 24568936
Running inference benchmark on ese_vovnet39b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1457.66 samples/sec. 175.624 ms/step.
Infer [16/40]. 1457.18 samples/sec. 175.682 ms/step.
Infer [24/40]. 1457.06 samples/sec. 175.696 ms/step.
Infer [32/40]. 1457.02 samples/sec. 175.702 ms/step.
Infer [40/40]. 1456.97 samples/sec. 175.708 ms/step.
Inference benchmark of ese_vovnet39b.ra_in1k done. 1456.67 samples/sec, 175.71 ms/step
Model ese_vovnet39b.ra_in1k created, param count: 24568936
Running train benchmark on ese_vovnet39b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 193.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model ese_vovnet39b.ra_in1k created, param count: 24568936
Running train benchmark on ese_vovnet39b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 158.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model ese_vovnet39b.ra_in1k created, param count: 24568936
Running train benchmark on ese_vovnet39b.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 427.52 samples/sec. 299.403 ms/step.
Train [16/40]. 427.52 samples/sec. 299.399 ms/step.
Train [24/40]. 427.51 samples/sec. 299.408 ms/step.
Train [32/40]. 427.50 samples/sec. 299.412 ms/step.
Train [40/40]. 427.50 samples/sec. 299.415 ms/step.
Train benchmark of ese_vovnet39b.ra_in1k done. 426.34 samples/sec, 299.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running inference benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 756.26 samples/sec. 338.509 ms/step.
Infer [16/40]. 756.36 samples/sec. 338.463 ms/step.
Infer [24/40]. 756.41 samples/sec. 338.441 ms/step.
Infer [32/40]. 756.45 samples/sec. 338.423 ms/step.
Infer [40/40]. 756.47 samples/sec. 338.412 ms/step.
Inference benchmark of eva02_base_patch14_224.mim_in22k done. 756.38 samples/sec, 338.41 ms/step
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 402.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 163.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 286.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 167.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 239.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model eva02_base_patch14_224.mim_in22k created, param count: 85758720
Running train benchmark on eva02_base_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running inference benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 152.30 samples/sec. 1680.855 ms/step.
Infer [16/40]. 152.27 samples/sec. 1681.181 ms/step.
Infer [24/40]. 152.24 samples/sec. 1681.532 ms/step.
Infer [32/40]. 152.22 samples/sec. 1681.788 ms/step.
Infer [40/40]. 152.17 samples/sec. 1682.289 ms/step.
Inference benchmark of eva02_base_patch14_448.mim_in22k_ft_in1k done. 152.17 samples/sec, 1682.29 ms/step
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 397.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1002.06 MiB is free. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 21.82 GiB is allocated by PyTorch, and 353.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 235.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 770.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 346.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 461.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 352.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 272.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 272.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 262.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 391.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
Train [8/40]. 40.98 samples/sec. 585.676 ms/step.
Train [16/40]. 40.98 samples/sec. 585.651 ms/step.
Train [24/40]. 40.98 samples/sec. 585.654 ms/step.
Train [32/40]. 40.98 samples/sec. 585.665 ms/step.
Train [40/40]. 40.98 samples/sec. 585.669 ms/step.
Train benchmark of eva02_base_patch14_448.mim_in22k_ft_in1k done. 40.87 samples/sec, 585.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running inference benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 152.05 samples/sec. 1683.704 ms/step.
Infer [16/40]. 151.99 samples/sec. 1684.308 ms/step.
Infer [24/40]. 151.99 samples/sec. 1684.300 ms/step.
Infer [32/40]. 152.00 samples/sec. 1684.175 ms/step.
Infer [40/40]. 151.98 samples/sec. 1684.487 ms/step.
Inference benchmark of eva02_base_patch14_448.mim_in22k_ft_in22k done. 151.97 samples/sec, 1684.49 ms/step
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 500.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 400.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 938.06 MiB is free. Including non-PyTorch memory, this process has 22.72 GiB memory in use. Of the allocated memory 21.88 GiB is allocated by PyTorch, and 356.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 218.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 770.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 280.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 468.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 308.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 258.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 228.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 245.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 373.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k created, param count: 103144273
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 24.
Train [8/40]. 40.89 samples/sec. 586.934 ms/step.
Train [16/40]. 40.89 samples/sec. 586.904 ms/step.
Train [24/40]. 40.89 samples/sec. 586.891 ms/step.
Train [32/40]. 40.89 samples/sec. 586.886 ms/step.
Train [40/40]. 40.89 samples/sec. 586.885 ms/step.
Train benchmark of eva02_base_patch14_448.mim_in22k_ft_in22k done. 40.79 samples/sec, 586.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running inference benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 152.14 samples/sec. 1682.618 ms/step.
Infer [16/40]. 152.15 samples/sec. 1682.507 ms/step.
Infer [24/40]. 152.04 samples/sec. 1683.716 ms/step.
Infer [32/40]. 152.00 samples/sec. 1684.175 ms/step.
Infer [40/40]. 151.94 samples/sec. 1684.903 ms/step.
Inference benchmark of eva02_base_patch14_448.mim_in22k_ft_in22k_in1k done. 151.93 samples/sec, 1684.90 ms/step
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 397.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1002.06 MiB is free. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 21.82 GiB is allocated by PyTorch, and 353.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 235.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 770.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 346.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 461.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 352.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 272.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 272.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 262.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 391.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_base_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 87117544
Running train benchmark on eva02_base_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
Train [8/40]. 40.96 samples/sec. 585.872 ms/step.
Train [16/40]. 40.96 samples/sec. 585.889 ms/step.
Train [24/40]. 40.96 samples/sec. 585.889 ms/step.
Train [32/40]. 40.96 samples/sec. 585.878 ms/step.
Train [40/40]. 40.96 samples/sec. 585.875 ms/step.
Train benchmark of eva02_base_patch14_448.mim_in22k_ft_in22k_in1k done. 40.86 samples/sec, 585.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_base_patch16_clip_224.merged2b created, param count: 86263040
Running inference benchmark on eva02_base_patch16_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 990.31 samples/sec. 258.505 ms/step.
Infer [16/40]. 990.34 samples/sec. 258.496 ms/step.
Infer [24/40]. 990.31 samples/sec. 258.505 ms/step.
Infer [32/40]. 990.27 samples/sec. 258.515 ms/step.
Infer [40/40]. 990.28 samples/sec. 258.514 ms/step.
Inference benchmark of eva02_base_patch16_clip_224.merged2b done. 990.12 samples/sec, 258.51 ms/step
Model eva02_base_patch16_clip_224.merged2b created, param count: 86263040
Running train benchmark on eva02_base_patch16_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 378.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 79.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_base_patch16_clip_224.merged2b created, param count: 86263040
Running train benchmark on eva02_base_patch16_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 196.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_base_patch16_clip_224.merged2b created, param count: 86263040
Running train benchmark on eva02_base_patch16_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 278.32 samples/sec. 459.903 ms/step.
Train [16/40]. 278.31 samples/sec. 459.918 ms/step.
Train [24/40]. 278.31 samples/sec. 459.923 ms/step.
Train [32/40]. 278.31 samples/sec. 459.921 ms/step.
Train [40/40]. 278.31 samples/sec. 459.917 ms/step.
Train benchmark of eva02_base_patch16_clip_224.merged2b done. 277.39 samples/sec, 459.92 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_enormous_patch14_clip_224.laion2b created, param count: 4350556928
Running inference benchmark on eva02_enormous_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.82 GiB is free. Including non-PyTorch memory, this process has 21.82 GiB memory in use. Of the allocated memory 21.14 GiB is allocated by PyTorch, and 192.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_enormous_patch14_clip_224.laion2b_plus created, param count: 4350556928
Running inference benchmark on eva02_enormous_patch14_clip_224.laion2b_plus for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.82 GiB is free. Including non-PyTorch memory, this process has 21.82 GiB memory in use. Of the allocated memory 21.14 GiB is allocated by PyTorch, and 192.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 264.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running inference benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 242.88 samples/sec. 1054.025 ms/step.
Infer [16/40]. 242.90 samples/sec. 1053.942 ms/step.
Infer [24/40]. 243.27 samples/sec. 1052.339 ms/step.
Infer [32/40]. 243.34 samples/sec. 1052.047 ms/step.
Infer [40/40]. 243.43 samples/sec. 1051.645 ms/step.
Inference benchmark of eva02_large_patch14_224.mim_in22k done. 243.42 samples/sec, 1051.64 ms/step
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 204.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 186.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 300.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 358.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 390.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 687.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model eva02_large_patch14_224.mim_in22k created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running inference benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 244.59 samples/sec. 1046.665 ms/step.
Infer [16/40]. 244.04 samples/sec. 1049.009 ms/step.
Infer [24/40]. 244.15 samples/sec. 1048.526 ms/step.
Infer [32/40]. 244.20 samples/sec. 1048.325 ms/step.
Infer [40/40]. 243.92 samples/sec. 1049.525 ms/step.
Inference benchmark of eva02_large_patch14_224.mim_m38m done. 243.91 samples/sec, 1049.53 ms/step
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 204.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 186.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 300.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 358.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 390.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 687.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model eva02_large_patch14_224.mim_m38m created, param count: 303268800
Running train benchmark on eva02_large_patch14_224.mim_m38m for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running inference benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 50.28 samples/sec. 5091.511 ms/step.
Infer [16/40]. 50.24 samples/sec. 5095.262 ms/step.
Infer [24/40]. 50.23 samples/sec. 5096.306 ms/step.
Infer [32/40]. 50.22 samples/sec. 5097.301 ms/step.
Infer [40/40]. 50.21 samples/sec. 5098.225 ms/step.
Inference benchmark of eva02_large_patch14_448.mim_in22k_ft_in1k done. 50.21 samples/sec, 5098.23 ms/step
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 21.52 GiB memory in use. Of the allocated memory 20.44 GiB is allocated by PyTorch, and 602.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 400.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 297.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 514.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 379.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 535.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 391.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 515.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 589.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 755.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 8.
Train [8/40]. 14.53 samples/sec. 550.750 ms/step.
Train [16/40]. 14.52 samples/sec. 550.779 ms/step.
Train [24/40]. 14.52 samples/sec. 550.807 ms/step.
Train [32/40]. 14.52 samples/sec. 550.826 ms/step.
Train [40/40]. 14.52 samples/sec. 550.837 ms/step.
Train benchmark of eva02_large_patch14_448.mim_in22k_ft_in1k done. 14.46 samples/sec, 550.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running inference benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 50.14 samples/sec. 5106.138 ms/step.
Infer [16/40]. 50.17 samples/sec. 5103.000 ms/step.
Infer [24/40]. 50.16 samples/sec. 5104.150 ms/step.
Infer [32/40]. 50.14 samples/sec. 5105.832 ms/step.
Infer [40/40]. 50.13 samples/sec. 5107.189 ms/step.
Inference benchmark of eva02_large_patch14_448.mim_in22k_ft_in22k done. 50.12 samples/sec, 5107.19 ms/step
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 21.61 GiB memory in use. Of the allocated memory 20.52 GiB is allocated by PyTorch, and 606.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 424.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.29 GiB is free. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 304.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 553.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 383.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 532.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 374.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 490.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 600.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 771.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 8.
Train [8/40]. 14.45 samples/sec. 553.469 ms/step.
Train [16/40]. 14.45 samples/sec. 553.465 ms/step.
Train [24/40]. 14.45 samples/sec. 553.471 ms/step.
Train [32/40]. 14.45 samples/sec. 553.478 ms/step.
Train [40/40]. 14.45 samples/sec. 553.484 ms/step.
Train benchmark of eva02_large_patch14_448.mim_in22k_ft_in22k done. 14.39 samples/sec, 553.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running inference benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 50.17 samples/sec. 5102.285 ms/step.
Infer [16/40]. 50.12 samples/sec. 5107.528 ms/step.
Infer [24/40]. 50.13 samples/sec. 5107.084 ms/step.
Infer [32/40]. 50.12 samples/sec. 5107.663 ms/step.
Infer [40/40]. 50.13 samples/sec. 5106.946 ms/step.
Inference benchmark of eva02_large_patch14_448.mim_in22k_ft_in22k_in1k done. 50.13 samples/sec, 5106.95 ms/step
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 21.52 GiB memory in use. Of the allocated memory 20.44 GiB is allocated by PyTorch, and 602.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 246.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 420.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 321.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 538.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 391.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 535.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 391.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 515.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 589.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 755.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_448.mim_in22k_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_in22k_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 8.
Train [8/40]. 14.49 samples/sec. 551.999 ms/step.
Train [16/40]. 14.49 samples/sec. 552.010 ms/step.
Train [24/40]. 14.49 samples/sec. 552.023 ms/step.
Train [32/40]. 14.49 samples/sec. 552.036 ms/step.
Train [40/40]. 14.49 samples/sec. 552.084 ms/step.
Train benchmark of eva02_large_patch14_448.mim_in22k_ft_in22k_in1k done. 14.42 samples/sec, 552.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running inference benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 50.21 samples/sec. 5098.646 ms/step.
Infer [16/40]. 50.16 samples/sec. 5104.034 ms/step.
Infer [24/40]. 50.16 samples/sec. 5103.304 ms/step.
Infer [32/40]. 50.14 samples/sec. 5105.256 ms/step.
Infer [40/40]. 50.15 samples/sec. 5104.927 ms/step.
Inference benchmark of eva02_large_patch14_448.mim_m38m_ft_in1k done. 50.15 samples/sec, 5104.93 ms/step
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 21.52 GiB memory in use. Of the allocated memory 20.44 GiB is allocated by PyTorch, and 602.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 246.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 420.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 321.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 538.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 391.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 535.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 391.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 515.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 589.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 755.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 8.
Train [8/40]. 14.49 samples/sec. 552.210 ms/step.
Train [16/40]. 14.49 samples/sec. 552.234 ms/step.
Train [24/40]. 14.49 samples/sec. 552.247 ms/step.
Train [32/40]. 14.49 samples/sec. 552.255 ms/step.
Train [40/40]. 14.49 samples/sec. 552.269 ms/step.
Train benchmark of eva02_large_patch14_448.mim_m38m_ft_in1k done. 14.42 samples/sec, 552.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running inference benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 50.06 samples/sec. 5113.631 ms/step.
Infer [16/40]. 50.13 samples/sec. 5106.563 ms/step.
Infer [24/40]. 50.13 samples/sec. 5106.890 ms/step.
Infer [32/40]. 50.14 samples/sec. 5105.529 ms/step.
Infer [40/40]. 50.14 samples/sec. 5105.324 ms/step.
Inference benchmark of eva02_large_patch14_448.mim_m38m_ft_in22k done. 50.14 samples/sec, 5105.32 ms/step
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 21.61 GiB memory in use. Of the allocated memory 20.52 GiB is allocated by PyTorch, and 606.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 424.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.29 GiB is free. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 304.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 553.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 383.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 532.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 374.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 490.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 600.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 771.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k created, param count: 326442257
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k for 40 steps w/ input size (3, 448, 448) and batch size 8.
Train [8/40]. 14.46 samples/sec. 553.415 ms/step.
Train [16/40]. 14.45 samples/sec. 553.462 ms/step.
Train [24/40]. 14.45 samples/sec. 553.463 ms/step.
Train [32/40]. 14.45 samples/sec. 553.478 ms/step.
Train [40/40]. 14.45 samples/sec. 553.485 ms/step.
Train benchmark of eva02_large_patch14_448.mim_m38m_ft_in22k done. 14.39 samples/sec, 553.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running inference benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 50.17 samples/sec. 5102.432 ms/step.
Infer [16/40]. 50.15 samples/sec. 5105.056 ms/step.
Infer [24/40]. 50.16 samples/sec. 5104.025 ms/step.
Infer [32/40]. 50.16 samples/sec. 5104.075 ms/step.
Infer [40/40]. 50.16 samples/sec. 5103.843 ms/step.
Inference benchmark of eva02_large_patch14_448.mim_m38m_ft_in22k_in1k done. 50.16 samples/sec, 5103.84 ms/step
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 21.52 GiB memory in use. Of the allocated memory 20.44 GiB is allocated by PyTorch, and 602.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 246.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 420.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 321.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 538.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 391.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 535.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 391.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 515.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 589.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 755.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_large_patch14_448.mim_m38m_ft_in22k_in1k created, param count: 305080232
Running train benchmark on eva02_large_patch14_448.mim_m38m_ft_in22k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 8.
Train [8/40]. 14.49 samples/sec. 551.988 ms/step.
Train [16/40]. 14.49 samples/sec. 551.970 ms/step.
Train [24/40]. 14.49 samples/sec. 551.979 ms/step.
Train [32/40]. 14.49 samples/sec. 551.999 ms/step.
Train [40/40]. 14.49 samples/sec. 552.048 ms/step.
Train benchmark of eva02_large_patch14_448.mim_m38m_ft_in22k_in1k done. 14.43 samples/sec, 552.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running inference benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 240.49 samples/sec. 1064.484 ms/step.
Infer [16/40]. 240.20 samples/sec. 1065.786 ms/step.
Infer [24/40]. 239.97 samples/sec. 1066.782 ms/step.
Infer [32/40]. 240.03 samples/sec. 1066.535 ms/step.
Infer [40/40]. 239.97 samples/sec. 1066.814 ms/step.
Inference benchmark of eva02_large_patch14_clip_224.merged2b done. 239.96 samples/sec, 1066.81 ms/step
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running train benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 686.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 514.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 200.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running train benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 180.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running train benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 182.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 315.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running train benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 363.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running train benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 405.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running train benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 673.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_clip_224.merged2b created, param count: 304105152
Running train benchmark on eva02_large_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 32.
Train [8/40]. 72.69 samples/sec. 440.205 ms/step.
Train [16/40]. 72.69 samples/sec. 440.222 ms/step.
Train [24/40]. 72.69 samples/sec. 440.236 ms/step.
Train [32/40]. 72.69 samples/sec. 440.250 ms/step.
Train [40/40]. 72.68 samples/sec. 440.262 ms/step.
Train benchmark of eva02_large_patch14_clip_224.merged2b done. 72.27 samples/sec, 440.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running inference benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 256.
Infer [8/40]. 99.10 samples/sec. 2583.127 ms/step.
Infer [16/40]. 99.09 samples/sec. 2583.595 ms/step.
Infer [24/40]. 99.06 samples/sec. 2584.385 ms/step.
Infer [32/40]. 99.04 samples/sec. 2584.764 ms/step.
Infer [40/40]. 99.02 samples/sec. 2585.211 ms/step.
Inference benchmark of eva02_large_patch14_clip_336.merged2b done. 99.02 samples/sec, 2585.21 ms/step
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 602.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 391.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 412.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 348.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 770.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 230.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 469.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 246.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 391.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 497.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 535.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 669.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_large_patch14_clip_336.merged2b created, param count: 304432832
Running train benchmark on eva02_large_patch14_clip_336.merged2b for 40 steps w/ input size (3, 336, 336) and batch size 16.
Train [8/40]. 29.29 samples/sec. 546.209 ms/step.
Train [16/40]. 29.29 samples/sec. 546.282 ms/step.
Train [24/40]. 29.29 samples/sec. 546.308 ms/step.
Train [32/40]. 29.29 samples/sec. 546.317 ms/step.
Train [40/40]. 29.29 samples/sec. 546.324 ms/step.
Train benchmark of eva02_large_patch14_clip_336.merged2b done. 29.14 samples/sec, 546.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running inference benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1957.45 samples/sec. 130.782 ms/step.
Infer [16/40]. 1957.37 samples/sec. 130.788 ms/step.
Infer [24/40]. 1957.27 samples/sec. 130.794 ms/step.
Infer [32/40]. 1957.24 samples/sec. 130.797 ms/step.
Infer [40/40]. 1957.22 samples/sec. 130.797 ms/step.
Inference benchmark of eva02_small_patch14_224.mim_in22k done. 1956.77 samples/sec, 130.80 ms/step
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 340.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 176.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model eva02_small_patch14_224.mim_in22k created, param count: 21621120
Running train benchmark on eva02_small_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_small_patch14_336.mim_in22k_ft_in1k created, param count: 22129000
Running inference benchmark on eva02_small_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
Infer [8/40]. 777.95 samples/sec. 329.070 ms/step.
Infer [16/40]. 777.87 samples/sec. 329.102 ms/step.
Infer [24/40]. 777.84 samples/sec. 329.117 ms/step.
Infer [32/40]. 777.79 samples/sec. 329.138 ms/step.
Infer [40/40]. 777.82 samples/sec. 329.126 ms/step.
Inference benchmark of eva02_small_patch14_336.mim_in22k_ft_in1k done. 777.71 samples/sec, 329.13 ms/step
Model eva02_small_patch14_336.mim_in22k_ft_in1k created, param count: 22129000
Running train benchmark on eva02_small_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 330.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 103.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_small_patch14_336.mim_in22k_ft_in1k created, param count: 22129000
Running train benchmark on eva02_small_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 434.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 272.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_small_patch14_336.mim_in22k_ft_in1k created, param count: 22129000
Running train benchmark on eva02_small_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 237.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_small_patch14_336.mim_in22k_ft_in1k created, param count: 22129000
Running train benchmark on eva02_small_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 96.
Train [8/40]. 207.24 samples/sec. 463.221 ms/step.
Train [16/40]. 207.25 samples/sec. 463.219 ms/step.
Train [24/40]. 207.24 samples/sec. 463.221 ms/step.
Train [32/40]. 207.24 samples/sec. 463.228 ms/step.
Train [40/40]. 207.24 samples/sec. 463.230 ms/step.
Train benchmark of eva02_small_patch14_336.mim_in22k_ft_in1k done. 206.67 samples/sec, 463.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running inference benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4436.44 samples/sec. 57.704 ms/step.
Infer [16/40]. 4433.31 samples/sec. 57.745 ms/step.
Infer [24/40]. 4432.37 samples/sec. 57.757 ms/step.
Infer [32/40]. 4432.07 samples/sec. 57.761 ms/step.
Infer [40/40]. 4431.72 samples/sec. 57.765 ms/step.
Inference benchmark of eva02_tiny_patch14_224.mim_in22k done. 4429.71 samples/sec, 57.77 ms/step
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model eva02_tiny_patch14_224.mim_in22k created, param count: 5502144
Running train benchmark on eva02_tiny_patch14_224.mim_in22k for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva02_tiny_patch14_336.mim_in22k_ft_in1k created, param count: 5756584
Running inference benchmark on eva02_tiny_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
Infer [8/40]. 1689.78 samples/sec. 151.499 ms/step.
Infer [16/40]. 1689.72 samples/sec. 151.505 ms/step.
Infer [24/40]. 1689.74 samples/sec. 151.502 ms/step.
Infer [32/40]. 1689.75 samples/sec. 151.502 ms/step.
Infer [40/40]. 1689.72 samples/sec. 151.505 ms/step.
Inference benchmark of eva02_tiny_patch14_336.mim_in22k_ft_in1k done. 1689.36 samples/sec, 151.50 ms/step
Model eva02_tiny_patch14_336.mim_in22k_ft_in1k created, param count: 5756584
Running train benchmark on eva02_tiny_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 187.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva02_tiny_patch14_336.mim_in22k_ft_in1k created, param count: 5756584
Running train benchmark on eva02_tiny_patch14_336.mim_in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 192.
Train [8/40]. 438.72 samples/sec. 437.633 ms/step.
Train [16/40]. 438.72 samples/sec. 437.637 ms/step.
Train [24/40]. 438.72 samples/sec. 437.639 ms/step.
Train [32/40]. 438.72 samples/sec. 437.638 ms/step.
Train [40/40]. 438.72 samples/sec. 437.633 ms/step.
Train benchmark of eva02_tiny_patch14_336.mim_in22k_ft_in1k done. 437.47 samples/sec, 437.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running inference benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 114.39 samples/sec. 2237.878 ms/step.
Infer [16/40]. 114.36 samples/sec. 2238.635 ms/step.
Infer [24/40]. 114.27 samples/sec. 2240.264 ms/step.
Infer [32/40]. 114.23 samples/sec. 2241.146 ms/step.
Infer [40/40]. 114.20 samples/sec. 2241.627 ms/step.
Inference benchmark of eva_giant_patch14_224.clip_ft_in1k done. 114.20 samples/sec, 2241.63 ms/step
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 978.06 MiB is free. Including non-PyTorch memory, this process has 22.69 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 149.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 197.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 772.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 208.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 282.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 312.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 349.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 425.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 550.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 315.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.20 GiB is allocated by PyTorch, and 898.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva_giant_patch14_224.clip_ft_in1k created, param count: 1012555112
Running train benchmark on eva_giant_patch14_224.clip_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 12.
Train [8/40]. 27.70 samples/sec. 433.272 ms/step.
Train [16/40]. 27.69 samples/sec. 433.327 ms/step.
Train [24/40]. 27.69 samples/sec. 433.346 ms/step.
Train [32/40]. 27.69 samples/sec. 433.360 ms/step.
Train [40/40]. 27.69 samples/sec. 433.373 ms/step.
Train benchmark of eva_giant_patch14_224.clip_ft_in1k done. 27.53 samples/sec, 433.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running inference benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
Infer [8/40]. 46.77 samples/sec. 5473.790 ms/step.
Infer [16/40]. 46.77 samples/sec. 5473.779 ms/step.
Infer [24/40]. 46.77 samples/sec. 5473.756 ms/step.
Infer [32/40]. 46.76 samples/sec. 5474.488 ms/step.
Infer [40/40]. 46.75 samples/sec. 5476.208 ms/step.
Inference benchmark of eva_giant_patch14_336.clip_ft_in1k done. 46.75 samples/sec, 5476.21 ms/step
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 794.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 418.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 21.83 GiB is allocated by PyTorch, and 934.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 21.93 GiB memory in use. Of the allocated memory 21.04 GiB is allocated by PyTorch, and 405.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.07 GiB is free. Including non-PyTorch memory, this process has 22.57 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 289.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 540.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 442.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 350.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 562.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 479.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 249.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 430.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 359.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 415.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.34 GiB is allocated by PyTorch, and 813.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva_giant_patch14_336.clip_ft_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.clip_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 6.
Train [8/40]. 11.32 samples/sec. 530.167 ms/step.
Train [16/40]. 11.32 samples/sec. 530.163 ms/step.
Train [24/40]. 11.32 samples/sec. 530.149 ms/step.
Train [32/40]. 11.32 samples/sec. 530.145 ms/step.
Train [40/40]. 11.32 samples/sec. 530.139 ms/step.
Train benchmark of eva_giant_patch14_336.clip_ft_in1k done. 11.26 samples/sec, 530.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running inference benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
Infer [8/40]. 46.77 samples/sec. 5473.453 ms/step.
Infer [16/40]. 46.77 samples/sec. 5473.530 ms/step.
Infer [24/40]. 46.77 samples/sec. 5473.626 ms/step.
Infer [32/40]. 46.77 samples/sec. 5473.588 ms/step.
Infer [40/40]. 46.77 samples/sec. 5473.642 ms/step.
Inference benchmark of eva_giant_patch14_336.m30m_ft_in22k_in1k done. 46.77 samples/sec, 5473.64 ms/step
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 794.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 418.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 21.83 GiB is allocated by PyTorch, and 934.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 21.93 GiB memory in use. Of the allocated memory 21.04 GiB is allocated by PyTorch, and 405.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.07 GiB is free. Including non-PyTorch memory, this process has 22.57 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 289.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 540.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 442.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 350.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 562.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 479.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 249.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 430.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 359.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 415.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 20.76 GiB is allocated by PyTorch, and 2.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva_giant_patch14_336.m30m_ft_in22k_in1k created, param count: 1013005672
Running train benchmark on eva_giant_patch14_336.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 6.
Train [8/40]. 11.32 samples/sec. 530.201 ms/step.
Train [16/40]. 11.32 samples/sec. 530.188 ms/step.
Train [24/40]. 11.32 samples/sec. 530.200 ms/step.
Train [32/40]. 11.32 samples/sec. 530.209 ms/step.
Train [40/40]. 11.32 samples/sec. 530.198 ms/step.
Train benchmark of eva_giant_patch14_336.m30m_ft_in22k_in1k done. 11.26 samples/sec, 530.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running inference benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.40 GiB is free. Including non-PyTorch memory, this process has 21.24 GiB memory in use. Of the allocated memory 20.60 GiB is allocated by PyTorch, and 151.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running inference benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 7.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.18 GiB is free. Including non-PyTorch memory, this process has 17.46 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 557.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running inference benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 128.
Infer [8/40]. 12.79 samples/sec. 10007.592 ms/step.
Infer [16/40]. 12.79 samples/sec. 10006.349 ms/step.
Infer [24/40]. 12.79 samples/sec. 10005.892 ms/step.
Infer [32/40]. 12.79 samples/sec. 10005.844 ms/step.
Infer [40/40]. 12.79 samples/sec. 10006.114 ms/step.
Inference benchmark of eva_giant_patch14_560.m30m_ft_in22k_in1k done. 12.79 samples/sec, 10006.11 ms/step
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 19.85 GiB is allocated by PyTorch, and 2.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 7.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.13 GiB is free. Including non-PyTorch memory, this process has 18.51 GiB memory in use. Of the allocated memory 17.48 GiB is allocated by PyTorch, and 550.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacty of 23.65 GiB of which 438.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 414.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 826.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 792.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 21.74 GiB is allocated by PyTorch, and 649.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 552.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 534.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 549.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.67 GiB is free. Including non-PyTorch memory, this process has 21.97 GiB memory in use. Of the allocated memory 20.77 GiB is allocated by PyTorch, and 731.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 826.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 308.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 324.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 902.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 612.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 394.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 395.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 562.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 360.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 623.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 609.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model eva_giant_patch14_560.m30m_ft_in22k_in1k created, param count: 1014447464
Running train benchmark on eva_giant_patch14_560.m30m_ft_in22k_in1k for 40 steps w/ input size (3, 560, 560) and batch size 2.
Train [8/40]. 2.95 samples/sec. 677.527 ms/step.
Train [16/40]. 2.95 samples/sec. 677.575 ms/step.
Train [24/40]. 2.95 samples/sec. 677.641 ms/step.
Train [32/40]. 2.95 samples/sec. 677.683 ms/step.
Train [40/40]. 2.95 samples/sec. 677.709 ms/step.
Train benchmark of eva_giant_patch14_560.m30m_ft_in22k_in1k done. 2.94 samples/sec, 677.71 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running inference benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 114.29 samples/sec. 2239.941 ms/step.
Infer [16/40]. 114.19 samples/sec. 2241.950 ms/step.
Infer [24/40]. 114.15 samples/sec. 2242.601 ms/step.
Infer [32/40]. 114.14 samples/sec. 2242.867 ms/step.
Infer [40/40]. 114.13 samples/sec. 2243.028 ms/step.
Inference benchmark of eva_giant_patch14_clip_224.laion400m done. 114.13 samples/sec, 2243.03 ms/step
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 978.06 MiB is free. Including non-PyTorch memory, this process has 22.69 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 149.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 197.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 772.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 208.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 282.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 311.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 348.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 425.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 560.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 301.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 21.29 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva_giant_patch14_clip_224.laion400m created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.laion400m for 40 steps w/ input size (3, 224, 224) and batch size 12.
Train [8/40]. 27.70 samples/sec. 433.208 ms/step.
Train [16/40]. 27.70 samples/sec. 433.252 ms/step.
Train [24/40]. 27.70 samples/sec. 433.285 ms/step.
Train [32/40]. 27.69 samples/sec. 433.294 ms/step.
Train [40/40]. 27.69 samples/sec. 433.305 ms/step.
Train benchmark of eva_giant_patch14_clip_224.laion400m done. 27.54 samples/sec, 433.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running inference benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 114.37 samples/sec. 2238.440 ms/step.
Infer [16/40]. 114.25 samples/sec. 2240.619 ms/step.
Infer [24/40]. 114.19 samples/sec. 2241.856 ms/step.
Infer [32/40]. 114.16 samples/sec. 2242.374 ms/step.
Infer [40/40]. 114.15 samples/sec. 2242.737 ms/step.
Inference benchmark of eva_giant_patch14_clip_224.merged2b done. 114.14 samples/sec, 2242.74 ms/step
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 978.06 MiB is free. Including non-PyTorch memory, this process has 22.69 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 149.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 197.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 772.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 208.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 282.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 311.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 348.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 425.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 560.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 301.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 21.29 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model eva_giant_patch14_clip_224.merged2b created, param count: 1012588928
Running train benchmark on eva_giant_patch14_clip_224.merged2b for 40 steps w/ input size (3, 224, 224) and batch size 12.
Train [8/40]. 27.69 samples/sec. 433.292 ms/step.
Train [16/40]. 27.69 samples/sec. 433.293 ms/step.
Train [24/40]. 27.69 samples/sec. 433.294 ms/step.
Train [32/40]. 27.70 samples/sec. 433.290 ms/step.
Train [40/40]. 27.70 samples/sec. 433.286 ms/step.
Train benchmark of eva_giant_patch14_clip_224.merged2b done. 27.54 samples/sec, 433.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_large_patch14_196.in22k_ft_in1k created, param count: 304142312
Running inference benchmark on eva_large_patch14_196.in22k_ft_in1k for 40 steps w/ input size (3, 196, 196) and batch size 256.
Infer [8/40]. 474.64 samples/sec. 539.352 ms/step.
Infer [16/40]. 474.64 samples/sec. 539.357 ms/step.
Infer [24/40]. 474.66 samples/sec. 539.337 ms/step.
Infer [32/40]. 474.63 samples/sec. 539.370 ms/step.
Infer [40/40]. 474.62 samples/sec. 539.377 ms/step.
Inference benchmark of eva_large_patch14_196.in22k_ft_in1k done. 474.58 samples/sec, 539.38 ms/step
Model eva_large_patch14_196.in22k_ft_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in1k for 40 steps w/ input size (3, 196, 196) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 194.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_large_patch14_196.in22k_ft_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in1k for 40 steps w/ input size (3, 196, 196) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 153.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_large_patch14_196.in22k_ft_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in1k for 40 steps w/ input size (3, 196, 196) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 157.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_large_patch14_196.in22k_ft_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in1k for 40 steps w/ input size (3, 196, 196) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 97.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_large_patch14_196.in22k_ft_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in1k for 40 steps w/ input size (3, 196, 196) and batch size 64.
Train [8/40]. 133.10 samples/sec. 480.845 ms/step.
Train [16/40]. 133.08 samples/sec. 480.910 ms/step.
Train [24/40]. 133.07 samples/sec. 480.940 ms/step.
Train [32/40]. 133.07 samples/sec. 480.941 ms/step.
Train [40/40]. 133.07 samples/sec. 480.947 ms/step.
Train benchmark of eva_large_patch14_196.in22k_ft_in1k done. 132.60 samples/sec, 480.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_large_patch14_196.in22k_ft_in22k_in1k created, param count: 304142312
Running inference benchmark on eva_large_patch14_196.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 196, 196) and batch size 256.
Infer [8/40]. 475.02 samples/sec. 538.923 ms/step.
Infer [16/40]. 475.00 samples/sec. 538.950 ms/step.
Infer [24/40]. 474.85 samples/sec. 539.112 ms/step.
Infer [32/40]. 474.71 samples/sec. 539.273 ms/step.
Infer [40/40]. 474.58 samples/sec. 539.422 ms/step.
Inference benchmark of eva_large_patch14_196.in22k_ft_in22k_in1k done. 474.54 samples/sec, 539.42 ms/step
Model eva_large_patch14_196.in22k_ft_in22k_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 196, 196) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 194.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_large_patch14_196.in22k_ft_in22k_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 196, 196) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 165.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_large_patch14_196.in22k_ft_in22k_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 196, 196) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 180.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_large_patch14_196.in22k_ft_in22k_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 196, 196) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 109.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_large_patch14_196.in22k_ft_in22k_in1k created, param count: 304142312
Running train benchmark on eva_large_patch14_196.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 196, 196) and batch size 64.
Train [8/40]. 133.12 samples/sec. 480.767 ms/step.
Train [16/40]. 133.13 samples/sec. 480.749 ms/step.
Train [24/40]. 133.12 samples/sec. 480.752 ms/step.
Train [32/40]. 133.12 samples/sec. 480.754 ms/step.
Train [40/40]. 133.12 samples/sec. 480.758 ms/step.
Train benchmark of eva_large_patch14_196.in22k_ft_in22k_in1k done. 132.66 samples/sec, 480.76 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running inference benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
Infer [8/40]. 139.72 samples/sec. 1832.197 ms/step.
Infer [16/40]. 139.66 samples/sec. 1832.974 ms/step.
Infer [24/40]. 139.61 samples/sec. 1833.691 ms/step.
Infer [32/40]. 139.49 samples/sec. 1835.217 ms/step.
Infer [40/40]. 139.41 samples/sec. 1836.318 ms/step.
Inference benchmark of eva_large_patch14_336.in22k_ft_in1k done. 139.41 samples/sec, 1836.32 ms/step
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 578.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 267.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 152.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 334.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 210.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 257.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 432.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 363.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 350.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 586.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_large_patch14_336.in22k_ft_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in1k for 40 steps w/ input size (3, 336, 336) and batch size 16.
Train [8/40]. 38.07 samples/sec. 420.311 ms/step.
Train [16/40]. 38.07 samples/sec. 420.310 ms/step.
Train [24/40]. 38.07 samples/sec. 420.301 ms/step.
Train [32/40]. 38.07 samples/sec. 420.306 ms/step.
Train [40/40]. 38.06 samples/sec. 420.346 ms/step.
Train benchmark of eva_large_patch14_336.in22k_ft_in1k done. 37.92 samples/sec, 420.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running inference benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
Infer [8/40]. 139.56 samples/sec. 1834.274 ms/step.
Infer [16/40]. 139.53 samples/sec. 1834.745 ms/step.
Infer [24/40]. 139.51 samples/sec. 1835.043 ms/step.
Infer [32/40]. 139.47 samples/sec. 1835.499 ms/step.
Infer [40/40]. 139.44 samples/sec. 1835.955 ms/step.
Inference benchmark of eva_large_patch14_336.in22k_ft_in22k_in1k done. 139.43 samples/sec, 1835.95 ms/step
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 578.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 267.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 152.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 334.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 210.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 257.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 432.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 363.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 350.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 624.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model eva_large_patch14_336.in22k_ft_in22k_in1k created, param count: 304531432
Running train benchmark on eva_large_patch14_336.in22k_ft_in22k_in1k for 40 steps w/ input size (3, 336, 336) and batch size 16.
Train [8/40]. 38.06 samples/sec. 420.371 ms/step.
Train [16/40]. 38.06 samples/sec. 420.368 ms/step.
Train [24/40]. 38.06 samples/sec. 420.362 ms/step.
Train [32/40]. 38.06 samples/sec. 420.359 ms/step.
Train [40/40]. 38.06 samples/sec. 420.378 ms/step.
Train benchmark of eva_large_patch14_336.in22k_ft_in22k_in1k done. 37.91 samples/sec, 420.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model fbnetc_100.rmsp_in1k created, param count: 5572200
Running inference benchmark on fbnetc_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5457.80 samples/sec. 46.905 ms/step.
Infer [16/40]. 5457.47 samples/sec. 46.908 ms/step.
Infer [24/40]. 5457.50 samples/sec. 46.908 ms/step.
Infer [32/40]. 5457.47 samples/sec. 46.908 ms/step.
Infer [40/40]. 5457.55 samples/sec. 46.907 ms/step.
Inference benchmark of fbnetc_100.rmsp_in1k done. 5454.39 samples/sec, 46.91 ms/step
Model fbnetc_100.rmsp_in1k created, param count: 5572200
Running train benchmark on fbnetc_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1430.86 samples/sec. 178.913 ms/step.
Train [16/40]. 1431.16 samples/sec. 178.876 ms/step.
Train [24/40]. 1431.35 samples/sec. 178.852 ms/step.
Train [32/40]. 1431.30 samples/sec. 178.859 ms/step.
Train [40/40]. 1431.25 samples/sec. 178.865 ms/step.
Train benchmark of fbnetc_100.rmsp_in1k done. 1423.99 samples/sec, 178.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model fbnetv3_b.ra2_in1k created, param count: 8598464
Running inference benchmark on fbnetv3_b.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 3635.56 samples/sec. 70.416 ms/step.
Infer [16/40]. 3633.52 samples/sec. 70.455 ms/step.
Infer [24/40]. 3632.78 samples/sec. 70.469 ms/step.
Infer [32/40]. 3632.40 samples/sec. 70.477 ms/step.
Infer [40/40]. 3632.21 samples/sec. 70.480 ms/step.
Inference benchmark of fbnetv3_b.ra2_in1k done. 3630.76 samples/sec, 70.48 ms/step
Model fbnetv3_b.ra2_in1k created, param count: 8598464
Running train benchmark on fbnetv3_b.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 71.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model fbnetv3_b.ra2_in1k created, param count: 8598464
Running train benchmark on fbnetv3_b.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
Train [8/40]. 905.14 samples/sec. 212.123 ms/step.
Train [16/40]. 905.19 samples/sec. 212.110 ms/step.
Train [24/40]. 905.11 samples/sec. 212.130 ms/step.
Train [32/40]. 905.02 samples/sec. 212.150 ms/step.
Train [40/40]. 905.02 samples/sec. 212.149 ms/step.
Train benchmark of fbnetv3_b.ra2_in1k done. 899.15 samples/sec, 212.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model fbnetv3_d.ra2_in1k created, param count: 10306272
Running inference benchmark on fbnetv3_d.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 3097.51 samples/sec. 82.647 ms/step.
Infer [16/40]. 3096.84 samples/sec. 82.665 ms/step.
Infer [24/40]. 3096.69 samples/sec. 82.669 ms/step.
Infer [32/40]. 3096.70 samples/sec. 82.669 ms/step.
Infer [40/40]. 3096.61 samples/sec. 82.671 ms/step.
Inference benchmark of fbnetv3_d.ra2_in1k done. 3095.53 samples/sec, 82.67 ms/step
Model fbnetv3_d.ra2_in1k created, param count: 10306272
Running train benchmark on fbnetv3_d.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 96.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model fbnetv3_d.ra2_in1k created, param count: 10306272
Running train benchmark on fbnetv3_d.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 176.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model fbnetv3_d.ra2_in1k created, param count: 10306272
Running train benchmark on fbnetv3_d.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 835.54 samples/sec. 153.195 ms/step.
Train [16/40]. 835.54 samples/sec. 153.194 ms/step.
Train [24/40]. 835.59 samples/sec. 153.185 ms/step.
Train [32/40]. 835.61 samples/sec. 153.182 ms/step.
Train [40/40]. 835.58 samples/sec. 153.187 ms/step.
Train benchmark of fbnetv3_d.ra2_in1k done. 828.74 samples/sec, 153.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model fbnetv3_g.ra2_in1k created, param count: 16623888
Running inference benchmark on fbnetv3_g.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1450.64 samples/sec. 176.473 ms/step.
Infer [16/40]. 1450.59 samples/sec. 176.480 ms/step.
Infer [24/40]. 1450.60 samples/sec. 176.479 ms/step.
Infer [32/40]. 1450.61 samples/sec. 176.477 ms/step.
Infer [40/40]. 1450.62 samples/sec. 176.477 ms/step.
Inference benchmark of fbnetv3_g.ra2_in1k done. 1450.33 samples/sec, 176.48 ms/step
Model fbnetv3_g.ra2_in1k created, param count: 16623888
Running train benchmark on fbnetv3_g.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 96.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model fbnetv3_g.ra2_in1k created, param count: 16623888
Running train benchmark on fbnetv3_g.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 608.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 476.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 173.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model fbnetv3_g.ra2_in1k created, param count: 16623888
Running train benchmark on fbnetv3_g.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 225.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model fbnetv3_g.ra2_in1k created, param count: 16623888
Running train benchmark on fbnetv3_g.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 280.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model fbnetv3_g.ra2_in1k created, param count: 16623888
Running train benchmark on fbnetv3_g.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 416.90 samples/sec. 153.514 ms/step.
Train [16/40]. 416.85 samples/sec. 153.534 ms/step.
Train [24/40]. 416.85 samples/sec. 153.532 ms/step.
Train [32/40]. 416.86 samples/sec. 153.528 ms/step.
Train [40/40]. 416.84 samples/sec. 153.534 ms/step.
Train benchmark of fbnetv3_g.ra2_in1k done. 412.96 samples/sec, 153.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_base.300ep_in1k created, param count: 86589160
Running inference benchmark on flexivit_base.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 1321.57 samples/sec. 193.709 ms/step.
Infer [16/40]. 1321.32 samples/sec. 193.745 ms/step.
Infer [24/40]. 1321.06 samples/sec. 193.783 ms/step.
Infer [32/40]. 1320.93 samples/sec. 193.803 ms/step.
Infer [40/40]. 1320.91 samples/sec. 193.806 ms/step.
Inference benchmark of flexivit_base.300ep_in1k done. 1320.66 samples/sec, 193.81 ms/step
Model flexivit_base.300ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 49.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model flexivit_base.300ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 234.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model flexivit_base.300ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 374.00 samples/sec. 342.243 ms/step.
Train [16/40]. 373.98 samples/sec. 342.267 ms/step.
Train [24/40]. 373.95 samples/sec. 342.294 ms/step.
Train [32/40]. 373.94 samples/sec. 342.299 ms/step.
Train [40/40]. 373.93 samples/sec. 342.308 ms/step.
Train benchmark of flexivit_base.300ep_in1k done. 372.77 samples/sec, 342.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_base.600ep_in1k created, param count: 86589160
Running inference benchmark on flexivit_base.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 1319.79 samples/sec. 193.970 ms/step.
Infer [16/40]. 1319.57 samples/sec. 194.003 ms/step.
Infer [24/40]. 1319.36 samples/sec. 194.033 ms/step.
Infer [32/40]. 1319.08 samples/sec. 194.075 ms/step.
Infer [40/40]. 1318.84 samples/sec. 194.110 ms/step.
Inference benchmark of flexivit_base.600ep_in1k done. 1318.60 samples/sec, 194.11 ms/step
Model flexivit_base.600ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 49.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model flexivit_base.600ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 234.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model flexivit_base.600ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 373.93 samples/sec. 342.306 ms/step.
Train [16/40]. 373.95 samples/sec. 342.288 ms/step.
Train [24/40]. 373.96 samples/sec. 342.282 ms/step.
Train [32/40]. 373.95 samples/sec. 342.296 ms/step.
Train [40/40]. 373.93 samples/sec. 342.309 ms/step.
Train benchmark of flexivit_base.600ep_in1k done. 372.75 samples/sec, 342.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_base.1200ep_in1k created, param count: 86589160
Running inference benchmark on flexivit_base.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 1318.50 samples/sec. 194.160 ms/step.
Infer [16/40]. 1318.70 samples/sec. 194.130 ms/step.
Infer [24/40]. 1318.55 samples/sec. 194.152 ms/step.
Infer [32/40]. 1318.45 samples/sec. 194.168 ms/step.
Infer [40/40]. 1318.25 samples/sec. 194.196 ms/step.
Inference benchmark of flexivit_base.1200ep_in1k done. 1318.02 samples/sec, 194.20 ms/step
Model flexivit_base.1200ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 49.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model flexivit_base.1200ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 234.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model flexivit_base.1200ep_in1k created, param count: 86589160
Running train benchmark on flexivit_base.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 373.84 samples/sec. 342.389 ms/step.
Train [16/40]. 373.85 samples/sec. 342.386 ms/step.
Train [24/40]. 373.87 samples/sec. 342.368 ms/step.
Train [32/40]. 373.86 samples/sec. 342.376 ms/step.
Train [40/40]. 373.88 samples/sec. 342.360 ms/step.
Train benchmark of flexivit_base.1200ep_in1k done. 372.65 samples/sec, 342.36 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_large.300ep_in1k created, param count: 304355304
Running inference benchmark on flexivit_large.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 417.13 samples/sec. 613.712 ms/step.
Infer [16/40]. 416.96 samples/sec. 613.971 ms/step.
Infer [24/40]. 416.66 samples/sec. 614.403 ms/step.
Infer [32/40]. 416.49 samples/sec. 614.654 ms/step.
Infer [40/40]. 416.40 samples/sec. 614.791 ms/step.
Inference benchmark of flexivit_large.300ep_in1k done. 416.37 samples/sec, 614.79 ms/step
Model flexivit_large.300ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 17.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model flexivit_large.300ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 180.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model flexivit_large.300ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 65.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model flexivit_large.300ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 237.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model flexivit_large.300ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 354.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model flexivit_large.300ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 48.
Train [8/40]. 118.45 samples/sec. 405.237 ms/step.
Train [16/40]. 118.45 samples/sec. 405.236 ms/step.
Train [24/40]. 118.45 samples/sec. 405.235 ms/step.
Train [32/40]. 118.45 samples/sec. 405.238 ms/step.
Train [40/40]. 118.45 samples/sec. 405.248 ms/step.
Train benchmark of flexivit_large.300ep_in1k done. 117.95 samples/sec, 405.25 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_large.600ep_in1k created, param count: 304355304
Running inference benchmark on flexivit_large.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 417.30 samples/sec. 613.475 ms/step.
Infer [16/40]. 417.11 samples/sec. 613.749 ms/step.
Infer [24/40]. 417.02 samples/sec. 613.880 ms/step.
Infer [32/40]. 416.91 samples/sec. 614.036 ms/step.
Infer [40/40]. 416.75 samples/sec. 614.279 ms/step.
Inference benchmark of flexivit_large.600ep_in1k done. 416.72 samples/sec, 614.28 ms/step
Model flexivit_large.600ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 17.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model flexivit_large.600ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 192.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model flexivit_large.600ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 324.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 89.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model flexivit_large.600ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 237.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model flexivit_large.600ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 419.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model flexivit_large.600ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 48.
Train [8/40]. 118.44 samples/sec. 405.255 ms/step.
Train [16/40]. 118.44 samples/sec. 405.261 ms/step.
Train [24/40]. 118.44 samples/sec. 405.258 ms/step.
Train [32/40]. 118.44 samples/sec. 405.259 ms/step.
Train [40/40]. 118.44 samples/sec. 405.262 ms/step.
Train benchmark of flexivit_large.600ep_in1k done. 117.94 samples/sec, 405.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_large.1200ep_in1k created, param count: 304355304
Running inference benchmark on flexivit_large.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 417.18 samples/sec. 613.642 ms/step.
Infer [16/40]. 417.14 samples/sec. 613.702 ms/step.
Infer [24/40]. 417.06 samples/sec. 613.815 ms/step.
Infer [32/40]. 417.01 samples/sec. 613.894 ms/step.
Infer [40/40]. 416.89 samples/sec. 614.068 ms/step.
Inference benchmark of flexivit_large.1200ep_in1k done. 416.86 samples/sec, 614.07 ms/step
Model flexivit_large.1200ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 17.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model flexivit_large.1200ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 192.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model flexivit_large.1200ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 324.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 89.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model flexivit_large.1200ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 237.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model flexivit_large.1200ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 419.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model flexivit_large.1200ep_in1k created, param count: 304355304
Running train benchmark on flexivit_large.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 48.
Train [8/40]. 118.44 samples/sec. 405.262 ms/step.
Train [16/40]. 118.45 samples/sec. 405.238 ms/step.
Train [24/40]. 118.45 samples/sec. 405.239 ms/step.
Train [32/40]. 118.45 samples/sec. 405.235 ms/step.
Train [40/40]. 118.45 samples/sec. 405.232 ms/step.
Train benchmark of flexivit_large.1200ep_in1k done. 117.95 samples/sec, 405.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_small.300ep_in1k created, param count: 22061416
Running inference benchmark on flexivit_small.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 3602.19 samples/sec. 71.068 ms/step.
Infer [16/40]. 3602.45 samples/sec. 71.063 ms/step.
Infer [24/40]. 3602.51 samples/sec. 71.062 ms/step.
Infer [32/40]. 3602.63 samples/sec. 71.059 ms/step.
Infer [40/40]. 3602.68 samples/sec. 71.058 ms/step.
Inference benchmark of flexivit_small.300ep_in1k done. 3601.41 samples/sec, 71.06 ms/step
Model flexivit_small.300ep_in1k created, param count: 22061416
Running train benchmark on flexivit_small.300ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1032.76 samples/sec. 247.879 ms/step.
Train [16/40]. 1032.73 samples/sec. 247.886 ms/step.
Train [24/40]. 1032.72 samples/sec. 247.889 ms/step.
Train [32/40]. 1032.75 samples/sec. 247.883 ms/step.
Train [40/40]. 1032.74 samples/sec. 247.884 ms/step.
Train benchmark of flexivit_small.300ep_in1k done. 1028.49 samples/sec, 247.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_small.600ep_in1k created, param count: 22061416
Running inference benchmark on flexivit_small.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 3603.83 samples/sec. 71.036 ms/step.
Infer [16/40]. 3603.72 samples/sec. 71.038 ms/step.
Infer [24/40]. 3603.66 samples/sec. 71.039 ms/step.
Infer [32/40]. 3603.68 samples/sec. 71.039 ms/step.
Infer [40/40]. 3603.65 samples/sec. 71.039 ms/step.
Inference benchmark of flexivit_small.600ep_in1k done. 3602.34 samples/sec, 71.04 ms/step
Model flexivit_small.600ep_in1k created, param count: 22061416
Running train benchmark on flexivit_small.600ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1032.83 samples/sec. 247.863 ms/step.
Train [16/40]. 1032.81 samples/sec. 247.868 ms/step.
Train [24/40]. 1032.80 samples/sec. 247.869 ms/step.
Train [32/40]. 1032.82 samples/sec. 247.865 ms/step.
Train [40/40]. 1032.81 samples/sec. 247.867 ms/step.
Train benchmark of flexivit_small.600ep_in1k done. 1028.57 samples/sec, 247.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model flexivit_small.1200ep_in1k created, param count: 22061416
Running inference benchmark on flexivit_small.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 3603.82 samples/sec. 71.036 ms/step.
Infer [16/40]. 3604.15 samples/sec. 71.029 ms/step.
Infer [24/40]. 3603.99 samples/sec. 71.032 ms/step.
Infer [32/40]. 3604.03 samples/sec. 71.031 ms/step.
Infer [40/40]. 3604.15 samples/sec. 71.029 ms/step.
Inference benchmark of flexivit_small.1200ep_in1k done. 3602.88 samples/sec, 71.03 ms/step
Model flexivit_small.1200ep_in1k created, param count: 22061416
Running train benchmark on flexivit_small.1200ep_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1032.78 samples/sec. 247.874 ms/step.
Train [16/40]. 1032.79 samples/sec. 247.872 ms/step.
Train [24/40]. 1032.81 samples/sec. 247.867 ms/step.
Train [32/40]. 1032.80 samples/sec. 247.870 ms/step.
Train [40/40]. 1032.81 samples/sec. 247.867 ms/step.
Train benchmark of flexivit_small.1200ep_in1k done. 1028.62 samples/sec, 247.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_base_lrf.ms_in1k created, param count: 88749768
Running inference benchmark on focalnet_base_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 680.93 samples/sec. 375.958 ms/step.
Infer [16/40]. 680.93 samples/sec. 375.956 ms/step.
Infer [24/40]. 680.93 samples/sec. 375.959 ms/step.
Infer [32/40]. 680.92 samples/sec. 375.961 ms/step.
Infer [40/40]. 680.92 samples/sec. 375.961 ms/step.
Inference benchmark of focalnet_base_lrf.ms_in1k done. 680.84 samples/sec, 375.96 ms/step
Model focalnet_base_lrf.ms_in1k created, param count: 88749768
Running train benchmark on focalnet_base_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 376.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 21.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_base_lrf.ms_in1k created, param count: 88749768
Running train benchmark on focalnet_base_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 117.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_base_lrf.ms_in1k created, param count: 88749768
Running train benchmark on focalnet_base_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 724.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_base_lrf.ms_in1k created, param count: 88749768
Running train benchmark on focalnet_base_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.15 GiB is allocated by PyTorch, and 902.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_base_lrf.ms_in1k created, param count: 88749768
Running train benchmark on focalnet_base_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 170.01 samples/sec. 376.458 ms/step.
Train [16/40]. 169.27 samples/sec. 378.099 ms/step.
Train [24/40]. 169.50 samples/sec. 377.576 ms/step.
Train [32/40]. 169.63 samples/sec. 377.287 ms/step.
Train [40/40]. 169.71 samples/sec. 377.124 ms/step.
Train benchmark of focalnet_base_lrf.ms_in1k done. 168.88 samples/sec, 377.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_base_srf.ms_in1k created, param count: 88148144
Running inference benchmark on focalnet_base_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 752.44 samples/sec. 340.228 ms/step.
Infer [16/40]. 752.46 samples/sec. 340.219 ms/step.
Infer [24/40]. 752.45 samples/sec. 340.220 ms/step.
Infer [32/40]. 752.46 samples/sec. 340.220 ms/step.
Infer [40/40]. 752.45 samples/sec. 340.221 ms/step.
Inference benchmark of focalnet_base_srf.ms_in1k done. 752.36 samples/sec, 340.22 ms/step
Model focalnet_base_srf.ms_in1k created, param count: 88148144
Running train benchmark on focalnet_base_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 22.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_base_srf.ms_in1k created, param count: 88148144
Running train benchmark on focalnet_base_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 332.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_base_srf.ms_in1k created, param count: 88148144
Running train benchmark on focalnet_base_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 815.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_base_srf.ms_in1k created, param count: 88148144
Running train benchmark on focalnet_base_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 915.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_base_srf.ms_in1k created, param count: 88148144
Running train benchmark on focalnet_base_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 219.93 samples/sec. 291.000 ms/step.
Train [16/40]. 219.91 samples/sec. 291.030 ms/step.
Train [24/40]. 219.89 samples/sec. 291.059 ms/step.
Train [32/40]. 219.89 samples/sec. 291.053 ms/step.
Train [40/40]. 219.89 samples/sec. 291.055 ms/step.
Train benchmark of focalnet_base_srf.ms_in1k done. 218.58 samples/sec, 291.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running inference benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 169.52 samples/sec. 1510.109 ms/step.
Infer [16/40]. 169.47 samples/sec. 1510.555 ms/step.
Infer [24/40]. 169.46 samples/sec. 1510.710 ms/step.
Infer [32/40]. 169.45 samples/sec. 1510.777 ms/step.
Infer [40/40]. 169.45 samples/sec. 1510.807 ms/step.
Inference benchmark of focalnet_huge_fl3.ms_in22k done. 169.44 samples/sec, 1510.81 ms/step
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 21.52 GiB memory in use. Of the allocated memory 20.88 GiB is allocated by PyTorch, and 148.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 810.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 306.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 540.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 442.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 312.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.23 GiB is free. Including non-PyTorch memory, this process has 22.41 GiB memory in use. Of the allocated memory 21.45 GiB is allocated by PyTorch, and 475.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 407.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 815.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 576.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 503.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model focalnet_huge_fl3.ms_in22k created, param count: 745276338
Running train benchmark on focalnet_huge_fl3.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 16.
Train [8/40]. 38.78 samples/sec. 412.565 ms/step.
Train [16/40]. 38.78 samples/sec. 412.567 ms/step.
Train [24/40]. 38.78 samples/sec. 412.564 ms/step.
Train [32/40]. 38.78 samples/sec. 412.568 ms/step.
Train [40/40]. 38.78 samples/sec. 412.578 ms/step.
Train benchmark of focalnet_huge_fl3.ms_in22k done. 38.54 samples/sec, 412.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running inference benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 127.17 samples/sec. 2012.994 ms/step.
Infer [16/40]. 127.16 samples/sec. 2013.139 ms/step.
Infer [24/40]. 127.12 samples/sec. 2013.901 ms/step.
Infer [32/40]. 127.07 samples/sec. 2014.712 ms/step.
Infer [40/40]. 127.03 samples/sec. 2015.195 ms/step.
Inference benchmark of focalnet_huge_fl4.ms_in22k done. 127.03 samples/sec, 2015.19 ms/step
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 145.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.96 GiB is free. Including non-PyTorch memory, this process has 21.68 GiB memory in use. Of the allocated memory 20.89 GiB is allocated by PyTorch, and 305.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 540.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 313.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.44 GiB is free. Including non-PyTorch memory, this process has 22.20 GiB memory in use. Of the allocated memory 21.23 GiB is allocated by PyTorch, and 486.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 399.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 771.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 613.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 549.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model focalnet_huge_fl4.ms_in22k created, param count: 686460664
Running train benchmark on focalnet_huge_fl4.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running inference benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.56 GiB is free. Including non-PyTorch memory, this process has 17.08 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 3.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running inference benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 95.26 samples/sec. 2015.550 ms/step.
Infer [16/40]. 95.26 samples/sec. 2015.567 ms/step.
Infer [24/40]. 95.26 samples/sec. 2015.558 ms/step.
Infer [32/40]. 95.26 samples/sec. 2015.546 ms/step.
Infer [40/40]. 95.26 samples/sec. 2015.552 ms/step.
Inference benchmark of focalnet_large_fl3.ms_in22k done. 95.26 samples/sec, 2015.55 ms/step
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.44 GiB is free. Including non-PyTorch memory, this process has 22.20 GiB memory in use. Of the allocated memory 21.63 GiB is allocated by PyTorch, and 73.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.25 GiB is free. Including non-PyTorch memory, this process has 22.39 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 373.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 702.06 MiB is free. Including non-PyTorch memory, this process has 22.96 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 216.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 455.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 258.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 330.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 367.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 467.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 597.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 344.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model focalnet_large_fl3.ms_in22k created, param count: 239134898
Running train benchmark on focalnet_large_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 23.62 samples/sec. 507.943 ms/step.
Train [16/40]. 23.59 samples/sec. 508.623 ms/step.
Train [24/40]. 23.58 samples/sec. 508.837 ms/step.
Train [32/40]. 23.58 samples/sec. 508.976 ms/step.
Train [40/40]. 23.57 samples/sec. 509.046 ms/step.
Train benchmark of focalnet_large_fl3.ms_in22k done. 23.48 samples/sec, 509.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running inference benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.56 GiB is free. Including non-PyTorch memory, this process has 17.08 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running inference benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 90.43 samples/sec. 2123.238 ms/step.
Infer [16/40]. 90.43 samples/sec. 2123.222 ms/step.
Infer [24/40]. 90.43 samples/sec. 2123.206 ms/step.
Infer [32/40]. 90.43 samples/sec. 2123.217 ms/step.
Infer [40/40]. 90.43 samples/sec. 2123.212 ms/step.
Inference benchmark of focalnet_large_fl4.ms_in22k done. 90.43 samples/sec, 2123.21 ms/step
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.43 GiB is free. Including non-PyTorch memory, this process has 22.21 GiB memory in use. Of the allocated memory 21.64 GiB is allocated by PyTorch, and 74.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 352.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.21 GiB is free. Including non-PyTorch memory, this process has 20.44 GiB memory in use. Of the allocated memory 19.72 GiB is allocated by PyTorch, and 223.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 462.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 22.56 GiB memory in use. Of the allocated memory 21.73 GiB is allocated by PyTorch, and 342.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 570.06 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 370.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 423.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 582.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 402.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model focalnet_large_fl4.ms_in22k created, param count: 239315402
Running train benchmark on focalnet_large_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 22.38 samples/sec. 536.093 ms/step.
Train [16/40]. 22.36 samples/sec. 536.641 ms/step.
Train [24/40]. 22.35 samples/sec. 536.874 ms/step.
Train [32/40]. 22.35 samples/sec. 536.997 ms/step.
Train [40/40]. 22.34 samples/sec. 537.061 ms/step.
Train benchmark of focalnet_large_fl4.ms_in22k done. 22.26 samples/sec, 537.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_small_lrf.ms_in1k created, param count: 50342440
Running inference benchmark on focalnet_small_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 964.11 samples/sec. 265.531 ms/step.
Infer [16/40]. 964.10 samples/sec. 265.531 ms/step.
Infer [24/40]. 964.10 samples/sec. 265.532 ms/step.
Infer [32/40]. 964.09 samples/sec. 265.535 ms/step.
Infer [40/40]. 964.09 samples/sec. 265.536 ms/step.
Inference benchmark of focalnet_small_lrf.ms_in1k done. 963.93 samples/sec, 265.54 ms/step
Model focalnet_small_lrf.ms_in1k created, param count: 50342440
Running train benchmark on focalnet_small_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 113.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_small_lrf.ms_in1k created, param count: 50342440
Running train benchmark on focalnet_small_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 351.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_small_lrf.ms_in1k created, param count: 50342440
Running train benchmark on focalnet_small_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 620.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_small_lrf.ms_in1k created, param count: 50342440
Running train benchmark on focalnet_small_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 236.71 samples/sec. 405.559 ms/step.
Train [16/40]. 236.05 samples/sec. 406.686 ms/step.
Train [24/40]. 236.27 samples/sec. 406.317 ms/step.
Train [32/40]. 236.36 samples/sec. 406.157 ms/step.
Train [40/40]. 236.43 samples/sec. 406.042 ms/step.
Train benchmark of focalnet_small_lrf.ms_in1k done. 235.34 samples/sec, 406.04 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_small_srf.ms_in1k created, param count: 49891216
Running inference benchmark on focalnet_small_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1067.43 samples/sec. 239.829 ms/step.
Infer [16/40]. 1067.42 samples/sec. 239.832 ms/step.
Infer [24/40]. 1067.39 samples/sec. 239.838 ms/step.
Infer [32/40]. 1067.39 samples/sec. 239.837 ms/step.
Infer [40/40]. 1067.40 samples/sec. 239.836 ms/step.
Inference benchmark of focalnet_small_srf.ms_in1k done. 1067.23 samples/sec, 239.84 ms/step
Model focalnet_small_srf.ms_in1k created, param count: 49891216
Running train benchmark on focalnet_small_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 115.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_small_srf.ms_in1k created, param count: 49891216
Running train benchmark on focalnet_small_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 449.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_small_srf.ms_in1k created, param count: 49891216
Running train benchmark on focalnet_small_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 424.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_small_srf.ms_in1k created, param count: 49891216
Running train benchmark on focalnet_small_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 310.39 samples/sec. 309.290 ms/step.
Train [16/40]. 310.38 samples/sec. 309.299 ms/step.
Train [24/40]. 310.37 samples/sec. 309.311 ms/step.
Train [32/40]. 310.36 samples/sec. 309.317 ms/step.
Train [40/40]. 310.36 samples/sec. 309.321 ms/step.
Train benchmark of focalnet_small_srf.ms_in1k done. 308.53 samples/sec, 309.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_tiny_lrf.ms_in1k created, param count: 28647928
Running inference benchmark on focalnet_tiny_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1575.78 samples/sec. 162.459 ms/step.
Infer [16/40]. 1575.79 samples/sec. 162.459 ms/step.
Infer [24/40]. 1575.76 samples/sec. 162.461 ms/step.
Infer [32/40]. 1575.75 samples/sec. 162.462 ms/step.
Infer [40/40]. 1575.74 samples/sec. 162.464 ms/step.
Inference benchmark of focalnet_tiny_lrf.ms_in1k done. 1575.41 samples/sec, 162.46 ms/step
Model focalnet_tiny_lrf.ms_in1k created, param count: 28647928
Running train benchmark on focalnet_tiny_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 68.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_tiny_lrf.ms_in1k created, param count: 28647928
Running train benchmark on focalnet_tiny_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 275.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_tiny_lrf.ms_in1k created, param count: 28647928
Running train benchmark on focalnet_tiny_lrf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 385.90 samples/sec. 331.691 ms/step.
Train [16/40]. 385.89 samples/sec. 331.701 ms/step.
Train [24/40]. 385.92 samples/sec. 331.677 ms/step.
Train [32/40]. 385.90 samples/sec. 331.693 ms/step.
Train [40/40]. 385.94 samples/sec. 331.659 ms/step.
Train benchmark of focalnet_tiny_lrf.ms_in1k done. 384.52 samples/sec, 331.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_tiny_srf.ms_in1k created, param count: 28427116
Running inference benchmark on focalnet_tiny_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1748.52 samples/sec. 146.410 ms/step.
Infer [16/40]. 1748.47 samples/sec. 146.414 ms/step.
Infer [24/40]. 1747.91 samples/sec. 146.461 ms/step.
Infer [32/40]. 1747.66 samples/sec. 146.482 ms/step.
Infer [40/40]. 1747.49 samples/sec. 146.496 ms/step.
Inference benchmark of focalnet_tiny_srf.ms_in1k done. 1747.11 samples/sec, 146.50 ms/step
Model focalnet_tiny_srf.ms_in1k created, param count: 28427116
Running train benchmark on focalnet_tiny_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 67.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_tiny_srf.ms_in1k created, param count: 28427116
Running train benchmark on focalnet_tiny_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 353.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_tiny_srf.ms_in1k created, param count: 28427116
Running train benchmark on focalnet_tiny_srf.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 487.63 samples/sec. 262.495 ms/step.
Train [16/40]. 487.65 samples/sec. 262.482 ms/step.
Train [24/40]. 487.59 samples/sec. 262.516 ms/step.
Train [32/40]. 487.61 samples/sec. 262.505 ms/step.
Train [40/40]. 487.59 samples/sec. 262.514 ms/step.
Train benchmark of focalnet_tiny_srf.ms_in1k done. 485.30 samples/sec, 262.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running inference benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.61 GiB is free. Including non-PyTorch memory, this process has 16.03 GiB memory in use. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 78.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running inference benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.76 GiB is free. Including non-PyTorch memory, this process has 17.88 GiB memory in use. Of the allocated memory 13.67 GiB is allocated by PyTorch, and 3.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running inference benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 67.57 samples/sec. 1894.221 ms/step.
Infer [16/40]. 67.57 samples/sec. 1894.210 ms/step.
Infer [24/40]. 67.57 samples/sec. 1894.210 ms/step.
Infer [32/40]. 67.57 samples/sec. 1894.199 ms/step.
Infer [40/40]. 67.58 samples/sec. 1894.189 ms/step.
Inference benchmark of focalnet_xlarge_fl3.ms_in22k done. 67.57 samples/sec, 1894.19 ms/step
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 824.06 MiB is free. Including non-PyTorch memory, this process has 22.84 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 80.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 688.06 MiB is free. Including non-PyTorch memory, this process has 22.97 GiB memory in use. Of the allocated memory 22.15 GiB is allocated by PyTorch, and 336.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.16 GiB is free. Including non-PyTorch memory, this process has 20.48 GiB memory in use. Of the allocated memory 19.79 GiB is allocated by PyTorch, and 210.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 628.06 MiB is free. Including non-PyTorch memory, this process has 23.03 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 570.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 386.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 286.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 242.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 174.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 320.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 264.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 345.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 329.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 403.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model focalnet_xlarge_fl3.ms_in22k created, param count: 408787378
Running train benchmark on focalnet_xlarge_fl3.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 16.23 samples/sec. 492.944 ms/step.
Train [16/40]. 16.20 samples/sec. 493.759 ms/step.
Train [24/40]. 16.19 samples/sec. 494.089 ms/step.
Train [32/40]. 16.19 samples/sec. 494.251 ms/step.
Train [40/40]. 16.18 samples/sec. 494.350 ms/step.
Train benchmark of focalnet_xlarge_fl3.ms_in22k done. 16.10 samples/sec, 494.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running inference benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.61 GiB is free. Including non-PyTorch memory, this process has 16.03 GiB memory in use. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 79.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running inference benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.76 GiB is free. Including non-PyTorch memory, this process has 17.88 GiB memory in use. Of the allocated memory 13.67 GiB is allocated by PyTorch, and 3.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running inference benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 64.42 samples/sec. 1987.008 ms/step.
Infer [16/40]. 64.42 samples/sec. 1987.017 ms/step.
Infer [24/40]. 64.41 samples/sec. 1987.150 ms/step.
Infer [32/40]. 64.41 samples/sec. 1987.346 ms/step.
Infer [40/40]. 64.40 samples/sec. 1987.464 ms/step.
Inference benchmark of focalnet_xlarge_fl4.ms_in22k done. 64.40 samples/sec, 1987.46 ms/step
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 812.06 MiB is free. Including non-PyTorch memory, this process has 22.85 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 81.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 680.06 MiB is free. Including non-PyTorch memory, this process has 22.98 GiB memory in use. Of the allocated memory 22.15 GiB is allocated by PyTorch, and 337.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 920.06 MiB is free. Including non-PyTorch memory, this process has 22.74 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 212.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.29 GiB is free. Including non-PyTorch memory, this process has 21.35 GiB memory in use. Of the allocated memory 20.29 GiB is allocated by PyTorch, and 572.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 380.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 287.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 668.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.32 GiB is allocated by PyTorch, and 175.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 262.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 307.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 387.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 735.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model focalnet_xlarge_fl4.ms_in22k created, param count: 409028042
Running train benchmark on focalnet_xlarge_fl4.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 15.33 samples/sec. 521.886 ms/step.
Train [16/40]. 15.33 samples/sec. 521.898 ms/step.
Train [24/40]. 15.33 samples/sec. 521.894 ms/step.
Train [32/40]. 15.33 samples/sec. 521.898 ms/step.
Train [40/40]. 15.33 samples/sec. 521.887 ms/step.
Train benchmark of focalnet_xlarge_fl4.ms_in22k done. 15.26 samples/sec, 521.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gc_efficientnetv2_rw_t.agc_in1k created, param count: 13677713
Running inference benchmark on gc_efficientnetv2_rw_t.agc_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1678.00 samples/sec. 152.562 ms/step.
Infer [16/40]. 1677.95 samples/sec. 152.567 ms/step.
Infer [24/40]. 1677.92 samples/sec. 152.570 ms/step.
Infer [32/40]. 1677.91 samples/sec. 152.571 ms/step.
Infer [40/40]. 1677.90 samples/sec. 152.572 ms/step.
Inference benchmark of gc_efficientnetv2_rw_t.agc_in1k done. 1677.56 samples/sec, 152.57 ms/step
Model gc_efficientnetv2_rw_t.agc_in1k created, param count: 13677713
Running train benchmark on gc_efficientnetv2_rw_t.agc_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 237.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gc_efficientnetv2_rw_t.agc_in1k created, param count: 13677713
Running train benchmark on gc_efficientnetv2_rw_t.agc_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 209.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gc_efficientnetv2_rw_t.agc_in1k created, param count: 13677713
Running train benchmark on gc_efficientnetv2_rw_t.agc_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 305.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model gc_efficientnetv2_rw_t.agc_in1k created, param count: 13677713
Running train benchmark on gc_efficientnetv2_rw_t.agc_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 453.22 samples/sec. 211.818 ms/step.
Train [16/40]. 453.23 samples/sec. 211.813 ms/step.
Train [24/40]. 453.22 samples/sec. 211.818 ms/step.
Train [32/40]. 453.22 samples/sec. 211.818 ms/step.
Train [40/40]. 453.22 samples/sec. 211.819 ms/step.
Train benchmark of gc_efficientnetv2_rw_t.agc_in1k done. 448.84 samples/sec, 211.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcresnet33ts.ra2_in1k created, param count: 19880698
Running inference benchmark on gcresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1700.18 samples/sec. 150.572 ms/step.
Infer [16/40]. 1700.03 samples/sec. 150.586 ms/step.
Infer [24/40]. 1700.02 samples/sec. 150.587 ms/step.
Infer [32/40]. 1699.93 samples/sec. 150.595 ms/step.
Infer [40/40]. 1699.95 samples/sec. 150.593 ms/step.
Inference benchmark of gcresnet33ts.ra2_in1k done. 1699.59 samples/sec, 150.59 ms/step
Model gcresnet33ts.ra2_in1k created, param count: 19880698
Running train benchmark on gcresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 616.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 219.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcresnet33ts.ra2_in1k created, param count: 19880698
Running train benchmark on gcresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 219.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcresnet33ts.ra2_in1k created, param count: 19880698
Running train benchmark on gcresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 477.55 samples/sec. 268.036 ms/step.
Train [16/40]. 477.52 samples/sec. 268.052 ms/step.
Train [24/40]. 477.51 samples/sec. 268.056 ms/step.
Train [32/40]. 477.52 samples/sec. 268.053 ms/step.
Train [40/40]. 477.53 samples/sec. 268.045 ms/step.
Train benchmark of gcresnet33ts.ra2_in1k done. 475.34 samples/sec, 268.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcresnet50t.ra2_in1k created, param count: 25897080
Running inference benchmark on gcresnet50t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1331.42 samples/sec. 192.275 ms/step.
Infer [16/40]. 1331.43 samples/sec. 192.274 ms/step.
Infer [24/40]. 1331.38 samples/sec. 192.282 ms/step.
Infer [32/40]. 1331.37 samples/sec. 192.283 ms/step.
Infer [40/40]. 1331.37 samples/sec. 192.283 ms/step.
Inference benchmark of gcresnet50t.ra2_in1k done. 1331.12 samples/sec, 192.28 ms/step
Model gcresnet50t.ra2_in1k created, param count: 25897080
Running train benchmark on gcresnet50t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 606.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 36.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcresnet50t.ra2_in1k created, param count: 25897080
Running train benchmark on gcresnet50t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 173.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcresnet50t.ra2_in1k created, param count: 25897080
Running train benchmark on gcresnet50t.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 407.31 samples/sec. 314.258 ms/step.
Train [16/40]. 407.32 samples/sec. 314.247 ms/step.
Train [24/40]. 407.33 samples/sec. 314.241 ms/step.
Train [32/40]. 407.32 samples/sec. 314.249 ms/step.
Train [40/40]. 407.32 samples/sec. 314.249 ms/step.
Train benchmark of gcresnet50t.ra2_in1k done. 405.21 samples/sec, 314.25 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcresnext26ts.ch_in1k created, param count: 10476600
Running inference benchmark on gcresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2145.09 samples/sec. 119.342 ms/step.
Infer [16/40]. 2145.15 samples/sec. 119.339 ms/step.
Infer [24/40]. 2145.13 samples/sec. 119.340 ms/step.
Infer [32/40]. 2145.13 samples/sec. 119.340 ms/step.
Infer [40/40]. 2145.09 samples/sec. 119.343 ms/step.
Inference benchmark of gcresnext26ts.ch_in1k done. 2144.55 samples/sec, 119.34 ms/step
Model gcresnext26ts.ch_in1k created, param count: 10476600
Running train benchmark on gcresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 93.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcresnext26ts.ch_in1k created, param count: 10476600
Running train benchmark on gcresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 185.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcresnext26ts.ch_in1k created, param count: 10476600
Running train benchmark on gcresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 584.78 samples/sec. 218.887 ms/step.
Train [16/40]. 584.68 samples/sec. 218.921 ms/step.
Train [24/40]. 584.63 samples/sec. 218.944 ms/step.
Train [32/40]. 584.61 samples/sec. 218.951 ms/step.
Train [40/40]. 584.61 samples/sec. 218.949 ms/step.
Train benchmark of gcresnext26ts.ch_in1k done. 581.90 samples/sec, 218.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcresnext50ts.ch_in1k created, param count: 15667320
Running inference benchmark on gcresnext50ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1372.25 samples/sec. 186.554 ms/step.
Infer [16/40]. 1372.29 samples/sec. 186.550 ms/step.
Infer [24/40]. 1372.30 samples/sec. 186.548 ms/step.
Infer [32/40]. 1372.26 samples/sec. 186.554 ms/step.
Infer [40/40]. 1372.23 samples/sec. 186.558 ms/step.
Inference benchmark of gcresnext50ts.ch_in1k done. 1371.96 samples/sec, 186.56 ms/step
Model gcresnext50ts.ch_in1k created, param count: 15667320
Running train benchmark on gcresnext50ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 85.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcresnext50ts.ch_in1k created, param count: 15667320
Running train benchmark on gcresnext50ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 284.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 165.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcresnext50ts.ch_in1k created, param count: 15667320
Running train benchmark on gcresnext50ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 91.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model gcresnext50ts.ch_in1k created, param count: 15667320
Running train benchmark on gcresnext50ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 390.49 samples/sec. 245.846 ms/step.
Train [16/40]. 390.46 samples/sec. 245.864 ms/step.
Train [24/40]. 390.49 samples/sec. 245.843 ms/step.
Train [32/40]. 390.49 samples/sec. 245.843 ms/step.
Train [40/40]. 390.50 samples/sec. 245.836 ms/step.
Train benchmark of gcresnext50ts.ch_in1k done. 388.19 samples/sec, 245.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcvit_base.in1k created, param count: 90320836
Running inference benchmark on gcvit_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 545.63 samples/sec. 469.179 ms/step.
Infer [16/40]. 545.61 samples/sec. 469.202 ms/step.
Infer [24/40]. 545.61 samples/sec. 469.200 ms/step.
Infer [32/40]. 545.61 samples/sec. 469.198 ms/step.
Infer [40/40]. 545.61 samples/sec. 469.203 ms/step.
Inference benchmark of gcvit_base.in1k done. 545.55 samples/sec, 469.20 ms/step
Model gcvit_base.in1k created, param count: 90320836
Running train benchmark on gcvit_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 523.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcvit_base.in1k created, param count: 90320836
Running train benchmark on gcvit_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 344.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 826.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcvit_base.in1k created, param count: 90320836
Running train benchmark on gcvit_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 265.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model gcvit_base.in1k created, param count: 90320836
Running train benchmark on gcvit_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 229.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model gcvit_base.in1k created, param count: 90320836
Running train benchmark on gcvit_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 582.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model gcvit_base.in1k created, param count: 90320836
Running train benchmark on gcvit_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 185.99 samples/sec. 258.081 ms/step.
Train [16/40]. 186.01 samples/sec. 258.048 ms/step.
Train [24/40]. 186.02 samples/sec. 258.035 ms/step.
Train [32/40]. 186.02 samples/sec. 258.038 ms/step.
Train [40/40]. 186.02 samples/sec. 258.031 ms/step.
Train benchmark of gcvit_base.in1k done. 184.13 samples/sec, 258.03 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcvit_small.in1k created, param count: 51092173
Running inference benchmark on gcvit_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 752.31 samples/sec. 340.287 ms/step.
Infer [16/40]. 752.28 samples/sec. 340.297 ms/step.
Infer [24/40]. 752.28 samples/sec. 340.298 ms/step.
Infer [32/40]. 752.28 samples/sec. 340.301 ms/step.
Infer [40/40]. 752.27 samples/sec. 340.302 ms/step.
Inference benchmark of gcvit_small.in1k done. 752.17 samples/sec, 340.30 ms/step
Model gcvit_small.in1k created, param count: 51092173
Running train benchmark on gcvit_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 440.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 828.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcvit_small.in1k created, param count: 51092173
Running train benchmark on gcvit_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 366.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcvit_small.in1k created, param count: 51092173
Running train benchmark on gcvit_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 208.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model gcvit_small.in1k created, param count: 51092173
Running train benchmark on gcvit_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 433.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model gcvit_small.in1k created, param count: 51092173
Running train benchmark on gcvit_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 254.94 samples/sec. 251.040 ms/step.
Train [16/40]. 254.93 samples/sec. 251.050 ms/step.
Train [24/40]. 254.94 samples/sec. 251.042 ms/step.
Train [32/40]. 254.92 samples/sec. 251.058 ms/step.
Train [40/40]. 254.84 samples/sec. 251.141 ms/step.
Train benchmark of gcvit_small.in1k done. 252.23 samples/sec, 251.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcvit_tiny.in1k created, param count: 28221974
Running inference benchmark on gcvit_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1125.95 samples/sec. 227.364 ms/step.
Infer [16/40]. 1125.50 samples/sec. 227.455 ms/step.
Infer [24/40]. 1125.33 samples/sec. 227.488 ms/step.
Infer [32/40]. 1125.24 samples/sec. 227.508 ms/step.
Infer [40/40]. 1125.18 samples/sec. 227.518 ms/step.
Inference benchmark of gcvit_tiny.in1k done. 1124.99 samples/sec, 227.52 ms/step
Model gcvit_tiny.in1k created, param count: 28221974
Running train benchmark on gcvit_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 495.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcvit_tiny.in1k created, param count: 28221974
Running train benchmark on gcvit_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 253.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcvit_tiny.in1k created, param count: 28221974
Running train benchmark on gcvit_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 376.21 samples/sec. 340.233 ms/step.
Train [16/40]. 376.22 samples/sec. 340.225 ms/step.
Train [24/40]. 376.21 samples/sec. 340.236 ms/step.
Train [32/40]. 376.21 samples/sec. 340.236 ms/step.
Train [40/40]. 376.20 samples/sec. 340.246 ms/step.
Train benchmark of gcvit_tiny.in1k done. 373.42 samples/sec, 340.25 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcvit_xtiny.in1k created, param count: 19981294
Running inference benchmark on gcvit_xtiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1588.27 samples/sec. 161.182 ms/step.
Infer [16/40]. 1588.19 samples/sec. 161.189 ms/step.
Infer [24/40]. 1588.13 samples/sec. 161.196 ms/step.
Infer [32/40]. 1587.82 samples/sec. 161.227 ms/step.
Infer [40/40]. 1587.61 samples/sec. 161.249 ms/step.
Inference benchmark of gcvit_xtiny.in1k done. 1587.28 samples/sec, 161.25 ms/step
Model gcvit_xtiny.in1k created, param count: 19981294
Running train benchmark on gcvit_xtiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 268.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 495.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcvit_xtiny.in1k created, param count: 19981294
Running train benchmark on gcvit_xtiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 256.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gcvit_xtiny.in1k created, param count: 19981294
Running train benchmark on gcvit_xtiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 512.59 samples/sec. 249.710 ms/step.
Train [16/40]. 512.62 samples/sec. 249.697 ms/step.
Train [24/40]. 512.61 samples/sec. 249.703 ms/step.
Train [32/40]. 512.64 samples/sec. 249.688 ms/step.
Train [40/40]. 512.62 samples/sec. 249.696 ms/step.
Train benchmark of gcvit_xtiny.in1k done. 509.08 samples/sec, 249.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gcvit_xxtiny.in1k created, param count: 11995428
Running inference benchmark on gcvit_xxtiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2081.17 samples/sec. 123.008 ms/step.
Infer [16/40]. 2081.08 samples/sec. 123.013 ms/step.
Infer [24/40]. 2081.09 samples/sec. 123.012 ms/step.
Infer [32/40]. 2081.12 samples/sec. 123.011 ms/step.
Infer [40/40]. 2081.12 samples/sec. 123.011 ms/step.
Inference benchmark of gcvit_xxtiny.in1k done. 2080.63 samples/sec, 123.01 ms/step
Model gcvit_xxtiny.in1k created, param count: 11995428
Running train benchmark on gcvit_xxtiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 140.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gcvit_xxtiny.in1k created, param count: 11995428
Running train benchmark on gcvit_xxtiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 648.50 samples/sec. 296.067 ms/step.
Train [16/40]. 648.56 samples/sec. 296.040 ms/step.
Train [24/40]. 648.53 samples/sec. 296.055 ms/step.
Train [32/40]. 648.46 samples/sec. 296.084 ms/step.
Train [40/40]. 648.46 samples/sec. 296.088 ms/step.
Train benchmark of gcvit_xxtiny.in1k done. 645.06 samples/sec, 296.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gernet_l.idstcv_in1k created, param count: 31078280
Running inference benchmark on gernet_l.idstcv_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 3084.38 samples/sec. 82.999 ms/step.
Infer [16/40]. 3084.18 samples/sec. 83.004 ms/step.
Infer [24/40]. 3084.13 samples/sec. 83.006 ms/step.
Infer [32/40]. 3084.11 samples/sec. 83.006 ms/step.
Infer [40/40]. 3084.01 samples/sec. 83.009 ms/step.
Inference benchmark of gernet_l.idstcv_in1k done. 3082.99 samples/sec, 83.01 ms/step
Model gernet_l.idstcv_in1k created, param count: 31078280
Running train benchmark on gernet_l.idstcv_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Train [8/40]. 885.05 samples/sec. 289.250 ms/step.
Train [16/40]. 885.03 samples/sec. 289.254 ms/step.
Train [24/40]. 885.03 samples/sec. 289.255 ms/step.
Train [32/40]. 885.01 samples/sec. 289.262 ms/step.
Train [40/40]. 885.01 samples/sec. 289.262 ms/step.
Train benchmark of gernet_l.idstcv_in1k done. 881.80 samples/sec, 289.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gernet_m.idstcv_in1k created, param count: 21142920
Running inference benchmark on gernet_m.idstcv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4563.17 samples/sec. 56.101 ms/step.
Infer [16/40]. 4563.01 samples/sec. 56.103 ms/step.
Infer [24/40]. 4562.92 samples/sec. 56.104 ms/step.
Infer [32/40]. 4563.14 samples/sec. 56.102 ms/step.
Infer [40/40]. 4563.05 samples/sec. 56.103 ms/step.
Inference benchmark of gernet_m.idstcv_in1k done. 4560.86 samples/sec, 56.10 ms/step
Model gernet_m.idstcv_in1k created, param count: 21142920
Running train benchmark on gernet_m.idstcv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1286.81 samples/sec. 198.941 ms/step.
Train [16/40]. 1286.82 samples/sec. 198.940 ms/step.
Train [24/40]. 1286.79 samples/sec. 198.945 ms/step.
Train [32/40]. 1286.69 samples/sec. 198.960 ms/step.
Train [40/40]. 1286.70 samples/sec. 198.959 ms/step.
Train benchmark of gernet_m.idstcv_in1k done. 1281.71 samples/sec, 198.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gernet_s.idstcv_in1k created, param count: 8173761
Running inference benchmark on gernet_s.idstcv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 11290.76 samples/sec. 22.673 ms/step.
Infer [16/40]. 11290.11 samples/sec. 22.675 ms/step.
Infer [24/40]. 11282.86 samples/sec. 22.689 ms/step.
Infer [32/40]. 11279.70 samples/sec. 22.696 ms/step.
Infer [40/40]. 11278.20 samples/sec. 22.699 ms/step.
Inference benchmark of gernet_s.idstcv_in1k done. 11266.05 samples/sec, 22.70 ms/step
Model gernet_s.idstcv_in1k created, param count: 8173761
Running train benchmark on gernet_s.idstcv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2972.27 samples/sec. 86.129 ms/step.
Train [16/40]. 2972.62 samples/sec. 86.119 ms/step.
Train [24/40]. 2972.49 samples/sec. 86.123 ms/step.
Train [32/40]. 2972.47 samples/sec. 86.124 ms/step.
Train [40/40]. 2972.52 samples/sec. 86.122 ms/step.
Train benchmark of gernet_s.idstcv_in1k done. 2953.80 samples/sec, 86.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model ghostnet_100.in1k created, param count: 5182508
Running inference benchmark on ghostnet_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 8284.40 samples/sec. 30.901 ms/step.
Infer [16/40]. 8285.04 samples/sec. 30.899 ms/step.
Infer [24/40]. 8285.41 samples/sec. 30.898 ms/step.
Infer [32/40]. 8285.51 samples/sec. 30.897 ms/step.
Infer [40/40]. 8285.71 samples/sec. 30.897 ms/step.
Inference benchmark of ghostnet_100.in1k done. 8278.99 samples/sec, 30.90 ms/step
Model ghostnet_100.in1k created, param count: 5182508
Running train benchmark on ghostnet_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1664.25 samples/sec. 153.823 ms/step.
Train [16/40]. 1664.22 samples/sec. 153.826 ms/step.
Train [24/40]. 1664.21 samples/sec. 153.827 ms/step.
Train [32/40]. 1664.11 samples/sec. 153.836 ms/step.
Train [40/40]. 1663.89 samples/sec. 153.856 ms/step.
Train benchmark of ghostnet_100.in1k done. 1652.98 samples/sec, 153.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gmixer_24_224.ra3_in1k created, param count: 24721096
Running inference benchmark on gmixer_24_224.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2232.50 samples/sec. 114.670 ms/step.
Infer [16/40]. 2232.54 samples/sec. 114.668 ms/step.
Infer [24/40]. 2232.58 samples/sec. 114.665 ms/step.
Infer [32/40]. 2232.61 samples/sec. 114.664 ms/step.
Infer [40/40]. 2232.65 samples/sec. 114.662 ms/step.
Inference benchmark of gmixer_24_224.ra3_in1k done. 2232.08 samples/sec, 114.66 ms/step
Model gmixer_24_224.ra3_in1k created, param count: 24721096
Running train benchmark on gmixer_24_224.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 49.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gmixer_24_224.ra3_in1k created, param count: 24721096
Running train benchmark on gmixer_24_224.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 726.71 samples/sec. 264.205 ms/step.
Train [16/40]. 726.66 samples/sec. 264.223 ms/step.
Train [24/40]. 726.67 samples/sec. 264.218 ms/step.
Train [32/40]. 726.68 samples/sec. 264.215 ms/step.
Train [40/40]. 726.71 samples/sec. 264.204 ms/step.
Train benchmark of gmixer_24_224.ra3_in1k done. 722.42 samples/sec, 264.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model gmlp_s16_224.ra3_in1k created, param count: 19422656
Running inference benchmark on gmlp_s16_224.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1986.49 samples/sec. 128.871 ms/step.
Infer [16/40]. 1986.50 samples/sec. 128.870 ms/step.
Infer [24/40]. 1986.61 samples/sec. 128.863 ms/step.
Infer [32/40]. 1986.60 samples/sec. 128.863 ms/step.
Infer [40/40]. 1986.58 samples/sec. 128.865 ms/step.
Inference benchmark of gmlp_s16_224.ra3_in1k done. 1986.12 samples/sec, 128.87 ms/step
Model gmlp_s16_224.ra3_in1k created, param count: 19422656
Running train benchmark on gmlp_s16_224.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 40.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model gmlp_s16_224.ra3_in1k created, param count: 19422656
Running train benchmark on gmlp_s16_224.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 208.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 381.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model gmlp_s16_224.ra3_in1k created, param count: 19422656
Running train benchmark on gmlp_s16_224.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 656.01 samples/sec. 195.120 ms/step.
Train [16/40]. 655.97 samples/sec. 195.129 ms/step.
Train [24/40]. 656.01 samples/sec. 195.120 ms/step.
Train [32/40]. 656.01 samples/sec. 195.120 ms/step.
Train [40/40]. 656.01 samples/sec. 195.119 ms/step.
Train benchmark of gmlp_s16_224.ra3_in1k done. 651.60 samples/sec, 195.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model halo2botnet50ts_256.a1h_in1k created, param count: 22635360
Running inference benchmark on halo2botnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1097.92 samples/sec. 233.168 ms/step.
Infer [16/40]. 1097.91 samples/sec. 233.171 ms/step.
Infer [24/40]. 1097.90 samples/sec. 233.172 ms/step.
Infer [32/40]. 1097.91 samples/sec. 233.170 ms/step.
Infer [40/40]. 1097.92 samples/sec. 233.169 ms/step.
Inference benchmark of halo2botnet50ts_256.a1h_in1k done. 1097.72 samples/sec, 233.17 ms/step
Model halo2botnet50ts_256.a1h_in1k created, param count: 22635360
Running train benchmark on halo2botnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 362.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 323.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model halo2botnet50ts_256.a1h_in1k created, param count: 22635360
Running train benchmark on halo2botnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 441.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model halo2botnet50ts_256.a1h_in1k created, param count: 22635360
Running train benchmark on halo2botnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 152.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model halo2botnet50ts_256.a1h_in1k created, param count: 22635360
Running train benchmark on halo2botnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
Train [8/40]. 369.41 samples/sec. 259.874 ms/step.
Train [16/40]. 369.46 samples/sec. 259.841 ms/step.
Train [24/40]. 369.46 samples/sec. 259.837 ms/step.
Train [32/40]. 369.46 samples/sec. 259.842 ms/step.
Train [40/40]. 369.44 samples/sec. 259.850 ms/step.
Train benchmark of halo2botnet50ts_256.a1h_in1k done. 367.80 samples/sec, 259.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model halonet26t.a1h_in1k created, param count: 12480288
Running inference benchmark on halonet26t.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2332.98 samples/sec. 109.731 ms/step.
Infer [16/40]. 2332.98 samples/sec. 109.731 ms/step.
Infer [24/40]. 2332.90 samples/sec. 109.735 ms/step.
Infer [32/40]. 2332.78 samples/sec. 109.740 ms/step.
Infer [40/40]. 2332.76 samples/sec. 109.741 ms/step.
Inference benchmark of halonet26t.a1h_in1k done. 2332.18 samples/sec, 109.74 ms/step
Model halonet26t.a1h_in1k created, param count: 12480288
Running train benchmark on halonet26t.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Train [8/40]. 708.09 samples/sec. 361.538 ms/step.
Train [16/40]. 708.04 samples/sec. 361.563 ms/step.
Train [24/40]. 708.00 samples/sec. 361.580 ms/step.
Train [32/40]. 708.03 samples/sec. 361.568 ms/step.
Train [40/40]. 708.02 samples/sec. 361.573 ms/step.
Train benchmark of halonet26t.a1h_in1k done. 706.31 samples/sec, 361.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model halonet50ts.a1h_in1k created, param count: 22733280
Running inference benchmark on halonet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1294.17 samples/sec. 197.811 ms/step.
Infer [16/40]. 1294.14 samples/sec. 197.815 ms/step.
Infer [24/40]. 1294.11 samples/sec. 197.820 ms/step.
Infer [32/40]. 1294.09 samples/sec. 197.822 ms/step.
Infer [40/40]. 1294.08 samples/sec. 197.824 ms/step.
Inference benchmark of halonet50ts.a1h_in1k done. 1293.83 samples/sec, 197.82 ms/step
Model halonet50ts.a1h_in1k created, param count: 22733280
Running train benchmark on halonet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 68.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model halonet50ts.a1h_in1k created, param count: 22733280
Running train benchmark on halonet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 240.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model halonet50ts.a1h_in1k created, param count: 22733280
Running train benchmark on halonet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 126.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model halonet50ts.a1h_in1k created, param count: 22733280
Running train benchmark on halonet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
Train [8/40]. 412.44 samples/sec. 232.763 ms/step.
Train [16/40]. 412.51 samples/sec. 232.724 ms/step.
Train [24/40]. 412.52 samples/sec. 232.715 ms/step.
Train [32/40]. 412.53 samples/sec. 232.708 ms/step.
Train [40/40]. 412.54 samples/sec. 232.704 ms/step.
Train benchmark of halonet50ts.a1h_in1k done. 410.60 samples/sec, 232.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model haloregnetz_b.ra3_in1k created, param count: 11680072
Running inference benchmark on haloregnetz_b.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2207.85 samples/sec. 115.950 ms/step.
Infer [16/40]. 2208.22 samples/sec. 115.931 ms/step.
Infer [24/40]. 2208.11 samples/sec. 115.936 ms/step.
Infer [32/40]. 2207.97 samples/sec. 115.944 ms/step.
Infer [40/40]. 2207.47 samples/sec. 115.970 ms/step.
Inference benchmark of haloregnetz_b.ra3_in1k done. 2206.92 samples/sec, 115.97 ms/step
Model haloregnetz_b.ra3_in1k created, param count: 11680072
Running train benchmark on haloregnetz_b.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 212.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 169.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model haloregnetz_b.ra3_in1k created, param count: 11680072
Running train benchmark on haloregnetz_b.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 372.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model haloregnetz_b.ra3_in1k created, param count: 11680072
Running train benchmark on haloregnetz_b.ra3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 616.07 samples/sec. 207.768 ms/step.
Train [16/40]. 616.07 samples/sec. 207.768 ms/step.
Train [24/40]. 616.09 samples/sec. 207.762 ms/step.
Train [32/40]. 616.05 samples/sec. 207.776 ms/step.
Train [40/40]. 616.00 samples/sec. 207.791 ms/step.
Train benchmark of haloregnetz_b.ra3_in1k done. 612.12 samples/sec, 207.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hardcorenas_a.miil_green_in1k created, param count: 5260232
Running inference benchmark on hardcorenas_a.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7421.18 samples/sec. 34.496 ms/step.
Infer [16/40]. 7421.19 samples/sec. 34.496 ms/step.
Infer [24/40]. 7419.42 samples/sec. 34.504 ms/step.
Infer [32/40]. 7417.70 samples/sec. 34.512 ms/step.
Infer [40/40]. 7416.77 samples/sec. 34.516 ms/step.
Inference benchmark of hardcorenas_a.miil_green_in1k done. 7411.39 samples/sec, 34.52 ms/step
Model hardcorenas_a.miil_green_in1k created, param count: 5260232
Running train benchmark on hardcorenas_a.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1834.23 samples/sec. 139.568 ms/step.
Train [16/40]. 1834.02 samples/sec. 139.584 ms/step.
Train [24/40]. 1834.00 samples/sec. 139.585 ms/step.
Train [32/40]. 1833.94 samples/sec. 139.590 ms/step.
Train [40/40]. 1833.86 samples/sec. 139.596 ms/step.
Train benchmark of hardcorenas_a.miil_green_in1k done. 1825.29 samples/sec, 139.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hardcorenas_b.miil_green_in1k created, param count: 5176544
Running inference benchmark on hardcorenas_b.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7180.16 samples/sec. 35.654 ms/step.
Infer [16/40]. 7180.35 samples/sec. 35.653 ms/step.
Infer [24/40]. 7179.35 samples/sec. 35.658 ms/step.
Infer [32/40]. 7178.80 samples/sec. 35.661 ms/step.
Infer [40/40]. 7178.25 samples/sec. 35.663 ms/step.
Inference benchmark of hardcorenas_b.miil_green_in1k done. 7173.17 samples/sec, 35.66 ms/step
Model hardcorenas_b.miil_green_in1k created, param count: 5176544
Running train benchmark on hardcorenas_b.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1793.19 samples/sec. 142.762 ms/step.
Train [16/40]. 1793.11 samples/sec. 142.769 ms/step.
Train [24/40]. 1793.08 samples/sec. 142.771 ms/step.
Train [32/40]. 1793.00 samples/sec. 142.778 ms/step.
Train [40/40]. 1792.98 samples/sec. 142.779 ms/step.
Train benchmark of hardcorenas_b.miil_green_in1k done. 1783.56 samples/sec, 142.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hardcorenas_c.miil_green_in1k created, param count: 5521224
Running inference benchmark on hardcorenas_c.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7002.62 samples/sec. 36.558 ms/step.
Infer [16/40]. 7001.69 samples/sec. 36.563 ms/step.
Infer [24/40]. 7000.90 samples/sec. 36.567 ms/step.
Infer [32/40]. 7000.52 samples/sec. 36.569 ms/step.
Infer [40/40]. 7000.10 samples/sec. 36.571 ms/step.
Inference benchmark of hardcorenas_c.miil_green_in1k done. 6995.37 samples/sec, 36.57 ms/step
Model hardcorenas_c.miil_green_in1k created, param count: 5521224
Running train benchmark on hardcorenas_c.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1750.35 samples/sec. 146.257 ms/step.
Train [16/40]. 1750.31 samples/sec. 146.260 ms/step.
Train [24/40]. 1750.22 samples/sec. 146.268 ms/step.
Train [32/40]. 1750.15 samples/sec. 146.273 ms/step.
Train [40/40]. 1750.08 samples/sec. 146.279 ms/step.
Train benchmark of hardcorenas_c.miil_green_in1k done. 1740.75 samples/sec, 146.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hardcorenas_d.miil_green_in1k created, param count: 7500208
Running inference benchmark on hardcorenas_d.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6809.89 samples/sec. 37.592 ms/step.
Infer [16/40]. 6809.97 samples/sec. 37.592 ms/step.
Infer [24/40]. 6809.03 samples/sec. 37.597 ms/step.
Infer [32/40]. 6808.50 samples/sec. 37.600 ms/step.
Infer [40/40]. 6807.95 samples/sec. 37.603 ms/step.
Inference benchmark of hardcorenas_d.miil_green_in1k done. 6803.27 samples/sec, 37.60 ms/step
Model hardcorenas_d.miil_green_in1k created, param count: 7500208
Running train benchmark on hardcorenas_d.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1656.59 samples/sec. 154.534 ms/step.
Train [16/40]. 1656.63 samples/sec. 154.531 ms/step.
Train [24/40]. 1656.41 samples/sec. 154.551 ms/step.
Train [32/40]. 1656.27 samples/sec. 154.564 ms/step.
Train [40/40]. 1656.23 samples/sec. 154.568 ms/step.
Train benchmark of hardcorenas_d.miil_green_in1k done. 1646.35 samples/sec, 154.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hardcorenas_e.miil_green_in1k created, param count: 8070992
Running inference benchmark on hardcorenas_e.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5565.47 samples/sec. 45.998 ms/step.
Infer [16/40]. 5565.22 samples/sec. 46.000 ms/step.
Infer [24/40]. 5565.25 samples/sec. 46.000 ms/step.
Infer [32/40]. 5565.23 samples/sec. 46.000 ms/step.
Infer [40/40]. 5565.10 samples/sec. 46.001 ms/step.
Inference benchmark of hardcorenas_e.miil_green_in1k done. 5562.09 samples/sec, 46.00 ms/step
Model hardcorenas_e.miil_green_in1k created, param count: 8070992
Running train benchmark on hardcorenas_e.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1396.90 samples/sec. 183.263 ms/step.
Train [16/40]. 1396.91 samples/sec. 183.262 ms/step.
Train [24/40]. 1396.88 samples/sec. 183.265 ms/step.
Train [32/40]. 1396.88 samples/sec. 183.265 ms/step.
Train [40/40]. 1396.91 samples/sec. 183.261 ms/step.
Train benchmark of hardcorenas_e.miil_green_in1k done. 1389.82 samples/sec, 183.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hardcorenas_f.miil_green_in1k created, param count: 8199688
Running inference benchmark on hardcorenas_f.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5789.20 samples/sec. 44.220 ms/step.
Infer [16/40]. 5788.60 samples/sec. 44.225 ms/step.
Infer [24/40]. 5788.52 samples/sec. 44.225 ms/step.
Infer [32/40]. 5788.36 samples/sec. 44.227 ms/step.
Infer [40/40]. 5788.19 samples/sec. 44.228 ms/step.
Inference benchmark of hardcorenas_f.miil_green_in1k done. 5784.89 samples/sec, 44.23 ms/step
Model hardcorenas_f.miil_green_in1k created, param count: 8199688
Running train benchmark on hardcorenas_f.miil_green_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1432.00 samples/sec. 178.772 ms/step.
Train [16/40]. 1432.12 samples/sec. 178.756 ms/step.
Train [24/40]. 1432.17 samples/sec. 178.750 ms/step.
Train [32/40]. 1432.17 samples/sec. 178.749 ms/step.
Train [40/40]. 1432.15 samples/sec. 178.752 ms/step.
Train benchmark of hardcorenas_f.miil_green_in1k done. 1424.55 samples/sec, 178.75 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w18.ms_aug_in1k created, param count: 21299004
Running inference benchmark on hrnet_w18.ms_aug_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1628.91 samples/sec. 157.160 ms/step.
Infer [16/40]. 1628.53 samples/sec. 157.197 ms/step.
Infer [24/40]. 1628.36 samples/sec. 157.214 ms/step.
Infer [32/40]. 1628.25 samples/sec. 157.224 ms/step.
Infer [40/40]. 1628.17 samples/sec. 157.232 ms/step.
Inference benchmark of hrnet_w18.ms_aug_in1k done. 1627.87 samples/sec, 157.23 ms/step
Model hrnet_w18.ms_aug_in1k created, param count: 21299004
Running train benchmark on hrnet_w18.ms_aug_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 69.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w18.ms_aug_in1k created, param count: 21299004
Running train benchmark on hrnet_w18.ms_aug_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 485.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w18.ms_aug_in1k created, param count: 21299004
Running train benchmark on hrnet_w18.ms_aug_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 452.27 samples/sec. 283.018 ms/step.
Train [16/40]. 452.16 samples/sec. 283.085 ms/step.
Train [24/40]. 452.18 samples/sec. 283.070 ms/step.
Train [32/40]. 452.18 samples/sec. 283.071 ms/step.
Train [40/40]. 452.26 samples/sec. 283.025 ms/step.
Train benchmark of hrnet_w18.ms_aug_in1k done. 447.67 samples/sec, 283.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w18.ms_in1k created, param count: 21299004
Running inference benchmark on hrnet_w18.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1629.20 samples/sec. 157.133 ms/step.
Infer [16/40]. 1629.07 samples/sec. 157.145 ms/step.
Infer [24/40]. 1629.08 samples/sec. 157.144 ms/step.
Infer [32/40]. 1628.98 samples/sec. 157.154 ms/step.
Infer [40/40]. 1628.84 samples/sec. 157.167 ms/step.
Inference benchmark of hrnet_w18.ms_in1k done. 1628.56 samples/sec, 157.17 ms/step
Model hrnet_w18.ms_in1k created, param count: 21299004
Running train benchmark on hrnet_w18.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 69.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w18.ms_in1k created, param count: 21299004
Running train benchmark on hrnet_w18.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 516.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w18.ms_in1k created, param count: 21299004
Running train benchmark on hrnet_w18.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 451.00 samples/sec. 283.814 ms/step.
Train [16/40]. 451.15 samples/sec. 283.716 ms/step.
Train [24/40]. 451.16 samples/sec. 283.715 ms/step.
Train [32/40]. 451.20 samples/sec. 283.686 ms/step.
Train [40/40]. 451.22 samples/sec. 283.678 ms/step.
Train benchmark of hrnet_w18.ms_in1k done. 446.61 samples/sec, 283.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w18_small.ms_in1k created, param count: 13187464
Running inference benchmark on hrnet_w18_small.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5083.42 samples/sec. 50.360 ms/step.
Infer [16/40]. 5083.27 samples/sec. 50.361 ms/step.
Infer [24/40]. 5082.94 samples/sec. 50.365 ms/step.
Infer [32/40]. 5082.80 samples/sec. 50.366 ms/step.
Infer [40/40]. 5082.73 samples/sec. 50.367 ms/step.
Inference benchmark of hrnet_w18_small.ms_in1k done. 5080.26 samples/sec, 50.37 ms/step
Model hrnet_w18_small.ms_in1k created, param count: 13187464
Running train benchmark on hrnet_w18_small.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1368.44 samples/sec. 187.074 ms/step.
Train [16/40]. 1368.59 samples/sec. 187.053 ms/step.
Train [24/40]. 1368.53 samples/sec. 187.062 ms/step.
Train [32/40]. 1368.59 samples/sec. 187.054 ms/step.
Train [40/40]. 1368.61 samples/sec. 187.051 ms/step.
Train benchmark of hrnet_w18_small.ms_in1k done. 1360.38 samples/sec, 187.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w18_small_v2.ms_in1k created, param count: 15597464
Running inference benchmark on hrnet_w18_small_v2.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2730.00 samples/sec. 93.773 ms/step.
Infer [16/40]. 2729.88 samples/sec. 93.777 ms/step.
Infer [24/40]. 2729.81 samples/sec. 93.779 ms/step.
Infer [32/40]. 2729.70 samples/sec. 93.783 ms/step.
Infer [40/40]. 2729.67 samples/sec. 93.784 ms/step.
Inference benchmark of hrnet_w18_small_v2.ms_in1k done. 2728.92 samples/sec, 93.78 ms/step
Model hrnet_w18_small_v2.ms_in1k created, param count: 15597464
Running train benchmark on hrnet_w18_small_v2.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 746.44 samples/sec. 342.960 ms/step.
Train [16/40]. 746.84 samples/sec. 342.778 ms/step.
Train [24/40]. 747.07 samples/sec. 342.671 ms/step.
Train [32/40]. 747.25 samples/sec. 342.591 ms/step.
Train [40/40]. 747.36 samples/sec. 342.537 ms/step.
Train benchmark of hrnet_w18_small_v2.ms_in1k done. 743.32 samples/sec, 342.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w18_ssld.paddle_in1k created, param count: 21295164
Running inference benchmark on hrnet_w18_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 912.70 samples/sec. 280.487 ms/step.
Infer [16/40]. 912.73 samples/sec. 280.477 ms/step.
Infer [24/40]. 912.72 samples/sec. 280.479 ms/step.
Infer [32/40]. 912.70 samples/sec. 280.485 ms/step.
Infer [40/40]. 912.67 samples/sec. 280.496 ms/step.
Inference benchmark of hrnet_w18_ssld.paddle_in1k done. 912.57 samples/sec, 280.50 ms/step
Model hrnet_w18_ssld.paddle_in1k created, param count: 21295164
Running train benchmark on hrnet_w18_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 53.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w18_ssld.paddle_in1k created, param count: 21295164
Running train benchmark on hrnet_w18_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 279.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w18_ssld.paddle_in1k created, param count: 21295164
Running train benchmark on hrnet_w18_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 366.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model hrnet_w18_ssld.paddle_in1k created, param count: 21295164
Running train benchmark on hrnet_w18_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 274.01 samples/sec. 350.347 ms/step.
Train [16/40]. 273.93 samples/sec. 350.449 ms/step.
Train [24/40]. 274.01 samples/sec. 350.351 ms/step.
Train [32/40]. 273.99 samples/sec. 350.380 ms/step.
Train [40/40]. 274.00 samples/sec. 350.371 ms/step.
Train benchmark of hrnet_w18_ssld.paddle_in1k done. 271.56 samples/sec, 350.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w30.ms_in1k created, param count: 37712220
Running inference benchmark on hrnet_w30.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1134.99 samples/sec. 225.552 ms/step.
Infer [16/40]. 1134.83 samples/sec. 225.584 ms/step.
Infer [24/40]. 1134.66 samples/sec. 225.618 ms/step.
Infer [32/40]. 1134.58 samples/sec. 225.634 ms/step.
Infer [40/40]. 1134.52 samples/sec. 225.647 ms/step.
Inference benchmark of hrnet_w30.ms_in1k done. 1134.37 samples/sec, 225.65 ms/step
Model hrnet_w30.ms_in1k created, param count: 37712220
Running train benchmark on hrnet_w30.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 172.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w30.ms_in1k created, param count: 37712220
Running train benchmark on hrnet_w30.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 348.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w30.ms_in1k created, param count: 37712220
Running train benchmark on hrnet_w30.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 339.52 samples/sec. 377.004 ms/step.
Train [16/40]. 339.45 samples/sec. 377.082 ms/step.
Train [24/40]. 339.42 samples/sec. 377.110 ms/step.
Train [32/40]. 339.43 samples/sec. 377.105 ms/step.
Train [40/40]. 339.42 samples/sec. 377.113 ms/step.
Train benchmark of hrnet_w30.ms_in1k done. 336.60 samples/sec, 377.11 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w32.ms_in1k created, param count: 41232680
Running inference benchmark on hrnet_w32.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1103.79 samples/sec. 231.927 ms/step.
Infer [16/40]. 1103.82 samples/sec. 231.922 ms/step.
Infer [24/40]. 1103.84 samples/sec. 231.918 ms/step.
Infer [32/40]. 1103.83 samples/sec. 231.919 ms/step.
Infer [40/40]. 1103.82 samples/sec. 231.921 ms/step.
Inference benchmark of hrnet_w32.ms_in1k done. 1103.68 samples/sec, 231.92 ms/step
Model hrnet_w32.ms_in1k created, param count: 41232680
Running train benchmark on hrnet_w32.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 117.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w32.ms_in1k created, param count: 41232680
Running train benchmark on hrnet_w32.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 315.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w32.ms_in1k created, param count: 41232680
Running train benchmark on hrnet_w32.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 325.96 samples/sec. 392.691 ms/step.
Train [16/40]. 325.94 samples/sec. 392.712 ms/step.
Train [24/40]. 325.94 samples/sec. 392.713 ms/step.
Train [32/40]. 325.94 samples/sec. 392.714 ms/step.
Train [40/40]. 325.93 samples/sec. 392.717 ms/step.
Train benchmark of hrnet_w32.ms_in1k done. 323.24 samples/sec, 392.72 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w40.ms_in1k created, param count: 57557160
Running inference benchmark on hrnet_w40.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 776.05 samples/sec. 329.874 ms/step.
Infer [16/40]. 776.03 samples/sec. 329.884 ms/step.
Infer [24/40]. 775.94 samples/sec. 329.924 ms/step.
Infer [32/40]. 775.89 samples/sec. 329.942 ms/step.
Infer [40/40]. 775.88 samples/sec. 329.949 ms/step.
Inference benchmark of hrnet_w40.ms_in1k done. 775.79 samples/sec, 329.95 ms/step
Model hrnet_w40.ms_in1k created, param count: 57557160
Running train benchmark on hrnet_w40.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 160.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w40.ms_in1k created, param count: 57557160
Running train benchmark on hrnet_w40.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 206.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w40.ms_in1k created, param count: 57557160
Running train benchmark on hrnet_w40.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 361.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model hrnet_w40.ms_in1k created, param count: 57557160
Running train benchmark on hrnet_w40.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 251.37 samples/sec. 381.914 ms/step.
Train [16/40]. 251.36 samples/sec. 381.928 ms/step.
Train [24/40]. 251.36 samples/sec. 381.927 ms/step.
Train [32/40]. 251.34 samples/sec. 381.947 ms/step.
Train [40/40]. 251.35 samples/sec. 381.945 ms/step.
Train benchmark of hrnet_w40.ms_in1k done. 249.23 samples/sec, 381.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w44.ms_in1k created, param count: 67064984
Running inference benchmark on hrnet_w44.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 710.79 samples/sec. 360.161 ms/step.
Infer [16/40]. 710.80 samples/sec. 360.155 ms/step.
Infer [24/40]. 710.80 samples/sec. 360.157 ms/step.
Infer [32/40]. 710.80 samples/sec. 360.156 ms/step.
Infer [40/40]. 710.80 samples/sec. 360.160 ms/step.
Inference benchmark of hrnet_w44.ms_in1k done. 710.72 samples/sec, 360.16 ms/step
Model hrnet_w44.ms_in1k created, param count: 67064984
Running train benchmark on hrnet_w44.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 158.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w44.ms_in1k created, param count: 67064984
Running train benchmark on hrnet_w44.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 197.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w44.ms_in1k created, param count: 67064984
Running train benchmark on hrnet_w44.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 239.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model hrnet_w44.ms_in1k created, param count: 67064984
Running train benchmark on hrnet_w44.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 229.34 samples/sec. 418.587 ms/step.
Train [16/40]. 229.33 samples/sec. 418.617 ms/step.
Train [24/40]. 229.32 samples/sec. 418.636 ms/step.
Train [32/40]. 229.31 samples/sec. 418.641 ms/step.
Train [40/40]. 229.31 samples/sec. 418.652 ms/step.
Train benchmark of hrnet_w44.ms_in1k done. 227.56 samples/sec, 418.65 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w48.ms_in1k created, param count: 77469864
Running inference benchmark on hrnet_w48.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 677.26 samples/sec. 377.995 ms/step.
Infer [16/40]. 677.28 samples/sec. 377.984 ms/step.
Infer [24/40]. 677.28 samples/sec. 377.985 ms/step.
Infer [32/40]. 677.27 samples/sec. 377.988 ms/step.
Infer [40/40]. 677.27 samples/sec. 377.989 ms/step.
Inference benchmark of hrnet_w48.ms_in1k done. 677.20 samples/sec, 377.99 ms/step
Model hrnet_w48.ms_in1k created, param count: 77469864
Running train benchmark on hrnet_w48.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 104.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w48.ms_in1k created, param count: 77469864
Running train benchmark on hrnet_w48.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 285.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w48.ms_in1k created, param count: 77469864
Running train benchmark on hrnet_w48.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 479.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model hrnet_w48.ms_in1k created, param count: 77469864
Running train benchmark on hrnet_w48.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 216.17 samples/sec. 444.098 ms/step.
Train [16/40]. 216.18 samples/sec. 444.074 ms/step.
Train [24/40]. 216.18 samples/sec. 444.077 ms/step.
Train [32/40]. 216.17 samples/sec. 444.085 ms/step.
Train [40/40]. 216.17 samples/sec. 444.088 ms/step.
Train benchmark of hrnet_w48.ms_in1k done. 214.60 samples/sec, 444.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w48_ssld.paddle_in1k created, param count: 77466024
Running inference benchmark on hrnet_w48_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 400.64 samples/sec. 638.970 ms/step.
Infer [16/40]. 400.64 samples/sec. 638.971 ms/step.
Infer [24/40]. 400.64 samples/sec. 638.978 ms/step.
Infer [32/40]. 400.64 samples/sec. 638.981 ms/step.
Infer [40/40]. 400.64 samples/sec. 638.980 ms/step.
Inference benchmark of hrnet_w48_ssld.paddle_in1k done. 400.61 samples/sec, 638.98 ms/step
Model hrnet_w48_ssld.paddle_in1k created, param count: 77466024
Running train benchmark on hrnet_w48_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 322.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w48_ssld.paddle_in1k created, param count: 77466024
Running train benchmark on hrnet_w48_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 330.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w48_ssld.paddle_in1k created, param count: 77466024
Running train benchmark on hrnet_w48_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 267.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model hrnet_w48_ssld.paddle_in1k created, param count: 77466024
Running train benchmark on hrnet_w48_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 206.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model hrnet_w48_ssld.paddle_in1k created, param count: 77466024
Running train benchmark on hrnet_w48_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 772.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model hrnet_w48_ssld.paddle_in1k created, param count: 77466024
Running train benchmark on hrnet_w48_ssld.paddle_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 134.99 samples/sec. 355.591 ms/step.
Train [16/40]. 134.99 samples/sec. 355.581 ms/step.
Train [24/40]. 134.98 samples/sec. 355.599 ms/step.
Train [32/40]. 134.98 samples/sec. 355.604 ms/step.
Train [40/40]. 134.98 samples/sec. 355.606 ms/step.
Train benchmark of hrnet_w48_ssld.paddle_in1k done. 133.82 samples/sec, 355.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model hrnet_w64.ms_in1k created, param count: 128059944
Running inference benchmark on hrnet_w64.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 524.85 samples/sec. 487.757 ms/step.
Infer [16/40]. 524.84 samples/sec. 487.772 ms/step.
Infer [24/40]. 524.82 samples/sec. 487.785 ms/step.
Infer [32/40]. 524.81 samples/sec. 487.792 ms/step.
Infer [40/40]. 524.81 samples/sec. 487.795 ms/step.
Inference benchmark of hrnet_w64.ms_in1k done. 524.77 samples/sec, 487.80 ms/step
Model hrnet_w64.ms_in1k created, param count: 128059944
Running train benchmark on hrnet_w64.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 97.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model hrnet_w64.ms_in1k created, param count: 128059944
Running train benchmark on hrnet_w64.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 292.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model hrnet_w64.ms_in1k created, param count: 128059944
Running train benchmark on hrnet_w64.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 471.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model hrnet_w64.ms_in1k created, param count: 128059944
Running train benchmark on hrnet_w64.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 566.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model hrnet_w64.ms_in1k created, param count: 128059944
Running train benchmark on hrnet_w64.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 165.37 samples/sec. 387.017 ms/step.
Train [16/40]. 165.37 samples/sec. 387.013 ms/step.
Train [24/40]. 165.36 samples/sec. 387.023 ms/step.
Train [32/40]. 165.36 samples/sec. 387.029 ms/step.
Train [40/40]. 165.36 samples/sec. 387.033 ms/step.
Train benchmark of hrnet_w64.ms_in1k done. 163.96 samples/sec, 387.03 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model inception_resnet_v2.tf_ens_adv_in1k created, param count: 55843464
Running inference benchmark on inception_resnet_v2.tf_ens_adv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 797.09 samples/sec. 321.169 ms/step.
Infer [16/40]. 797.08 samples/sec. 321.172 ms/step.
Infer [24/40]. 797.08 samples/sec. 321.174 ms/step.
Infer [32/40]. 797.07 samples/sec. 321.176 ms/step.
Infer [40/40]. 797.07 samples/sec. 321.178 ms/step.
Inference benchmark of inception_resnet_v2.tf_ens_adv_in1k done. 796.96 samples/sec, 321.18 ms/step
Model inception_resnet_v2.tf_ens_adv_in1k created, param count: 55843464
Running train benchmark on inception_resnet_v2.tf_ens_adv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 186.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 189.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model inception_resnet_v2.tf_ens_adv_in1k created, param count: 55843464
Running train benchmark on inception_resnet_v2.tf_ens_adv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 748.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model inception_resnet_v2.tf_ens_adv_in1k created, param count: 55843464
Running train benchmark on inception_resnet_v2.tf_ens_adv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 128.
Train [8/40]. 247.13 samples/sec. 517.951 ms/step.
Train [16/40]. 247.13 samples/sec. 517.949 ms/step.
Train [24/40]. 247.12 samples/sec. 517.963 ms/step.
Train [32/40]. 247.12 samples/sec. 517.960 ms/step.
Train [40/40]. 247.12 samples/sec. 517.976 ms/step.
Train benchmark of inception_resnet_v2.tf_ens_adv_in1k done. 245.81 samples/sec, 517.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model inception_resnet_v2.tf_in1k created, param count: 55843464
Running inference benchmark on inception_resnet_v2.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 797.01 samples/sec. 321.201 ms/step.
Infer [16/40]. 797.04 samples/sec. 321.190 ms/step.
Infer [24/40]. 797.04 samples/sec. 321.189 ms/step.
Infer [32/40]. 797.03 samples/sec. 321.191 ms/step.
Infer [40/40]. 797.02 samples/sec. 321.197 ms/step.
Inference benchmark of inception_resnet_v2.tf_in1k done. 796.91 samples/sec, 321.20 ms/step
Model inception_resnet_v2.tf_in1k created, param count: 55843464
Running train benchmark on inception_resnet_v2.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 186.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 189.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model inception_resnet_v2.tf_in1k created, param count: 55843464
Running train benchmark on inception_resnet_v2.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 579.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model inception_resnet_v2.tf_in1k created, param count: 55843464
Running train benchmark on inception_resnet_v2.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 128.
Train [8/40]. 247.09 samples/sec. 518.030 ms/step.
Train [16/40]. 247.08 samples/sec. 518.052 ms/step.
Train [24/40]. 247.08 samples/sec. 518.060 ms/step.
Train [32/40]. 247.07 samples/sec. 518.066 ms/step.
Train [40/40]. 247.07 samples/sec. 518.081 ms/step.
Train benchmark of inception_resnet_v2.tf_in1k done. 245.73 samples/sec, 518.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model inception_v3.gluon_in1k created, param count: 23834568
Running inference benchmark on inception_v3.gluon_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 2256.02 samples/sec. 113.474 ms/step.
Infer [16/40]. 2255.69 samples/sec. 113.491 ms/step.
Infer [24/40]. 2255.67 samples/sec. 113.492 ms/step.
Infer [32/40]. 2255.63 samples/sec. 113.494 ms/step.
Infer [40/40]. 2255.61 samples/sec. 113.495 ms/step.
Inference benchmark of inception_v3.gluon_in1k done. 2255.03 samples/sec, 113.50 ms/step
Model inception_v3.gluon_in1k created, param count: 23834568
Running train benchmark on inception_v3.gluon_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 314.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model inception_v3.gluon_in1k created, param count: 23834568
Running train benchmark on inception_v3.gluon_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
Train [8/40]. 585.26 samples/sec. 328.057 ms/step.
Train [16/40]. 585.27 samples/sec. 328.054 ms/step.
Train [24/40]. 585.25 samples/sec. 328.062 ms/step.
Train [32/40]. 585.23 samples/sec. 328.077 ms/step.
Train [40/40]. 585.21 samples/sec. 328.087 ms/step.
Train benchmark of inception_v3.gluon_in1k done. 582.74 samples/sec, 328.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model inception_v3.tf_adv_in1k created, param count: 23834568
Running inference benchmark on inception_v3.tf_adv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 2249.21 samples/sec. 113.818 ms/step.
Infer [16/40]. 2249.33 samples/sec. 113.812 ms/step.
Infer [24/40]. 2249.32 samples/sec. 113.812 ms/step.
Infer [32/40]. 2249.28 samples/sec. 113.814 ms/step.
Infer [40/40]. 2249.20 samples/sec. 113.818 ms/step.
Inference benchmark of inception_v3.tf_adv_in1k done. 2248.63 samples/sec, 113.82 ms/step
Model inception_v3.tf_adv_in1k created, param count: 23834568
Running train benchmark on inception_v3.tf_adv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 314.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model inception_v3.tf_adv_in1k created, param count: 23834568
Running train benchmark on inception_v3.tf_adv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
Train [8/40]. 585.28 samples/sec. 328.047 ms/step.
Train [16/40]. 585.29 samples/sec. 328.041 ms/step.
Train [24/40]. 585.28 samples/sec. 328.046 ms/step.
Train [32/40]. 585.28 samples/sec. 328.048 ms/step.
Train [40/40]. 585.27 samples/sec. 328.051 ms/step.
Train benchmark of inception_v3.tf_adv_in1k done. 582.75 samples/sec, 328.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model inception_v3.tf_in1k created, param count: 23834568
Running inference benchmark on inception_v3.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 2250.48 samples/sec. 113.754 ms/step.
Infer [16/40]. 2249.95 samples/sec. 113.780 ms/step.
Infer [24/40]. 2249.85 samples/sec. 113.785 ms/step.
Infer [32/40]. 2249.76 samples/sec. 113.790 ms/step.
Infer [40/40]. 2249.69 samples/sec. 113.793 ms/step.
Inference benchmark of inception_v3.tf_in1k done. 2249.12 samples/sec, 113.79 ms/step
Model inception_v3.tf_in1k created, param count: 23834568
Running train benchmark on inception_v3.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 314.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model inception_v3.tf_in1k created, param count: 23834568
Running train benchmark on inception_v3.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
Train [8/40]. 585.34 samples/sec. 328.017 ms/step.
Train [16/40]. 585.34 samples/sec. 328.013 ms/step.
Train [24/40]. 585.33 samples/sec. 328.019 ms/step.
Train [32/40]. 585.32 samples/sec. 328.025 ms/step.
Train [40/40]. 585.32 samples/sec. 328.026 ms/step.
Train benchmark of inception_v3.tf_in1k done. 582.79 samples/sec, 328.03 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model inception_v3.tv_in1k created, param count: 23834568
Running inference benchmark on inception_v3.tv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 2250.60 samples/sec. 113.747 ms/step.
Infer [16/40]. 2250.69 samples/sec. 113.743 ms/step.
Infer [24/40]. 2250.31 samples/sec. 113.762 ms/step.
Infer [32/40]. 2250.11 samples/sec. 113.772 ms/step.
Infer [40/40]. 2249.97 samples/sec. 113.779 ms/step.
Inference benchmark of inception_v3.tv_in1k done. 2249.37 samples/sec, 113.78 ms/step
Model inception_v3.tv_in1k created, param count: 23834568
Running train benchmark on inception_v3.tv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 314.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model inception_v3.tv_in1k created, param count: 23834568
Running train benchmark on inception_v3.tv_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
Train [8/40]. 585.16 samples/sec. 328.115 ms/step.
Train [16/40]. 585.20 samples/sec. 328.093 ms/step.
Train [24/40]. 585.22 samples/sec. 328.083 ms/step.
Train [32/40]. 585.24 samples/sec. 328.071 ms/step.
Train [40/40]. 585.25 samples/sec. 328.065 ms/step.
Train benchmark of inception_v3.tv_in1k done. 582.75 samples/sec, 328.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model inception_v4.tf_in1k created, param count: 42679816
Running inference benchmark on inception_v4.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 1125.29 samples/sec. 227.498 ms/step.
Infer [16/40]. 1125.27 samples/sec. 227.502 ms/step.
Infer [24/40]. 1125.26 samples/sec. 227.503 ms/step.
Infer [32/40]. 1125.26 samples/sec. 227.503 ms/step.
Infer [40/40]. 1125.24 samples/sec. 227.507 ms/step.
Inference benchmark of inception_v4.tf_in1k done. 1125.05 samples/sec, 227.51 ms/step
Model inception_v4.tf_in1k created, param count: 42679816
Running train benchmark on inception_v4.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 299.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model inception_v4.tf_in1k created, param count: 42679816
Running train benchmark on inception_v4.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 358.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model inception_v4.tf_in1k created, param count: 42679816
Running train benchmark on inception_v4.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 128.
Train [8/40]. 316.78 samples/sec. 404.072 ms/step.
Train [16/40]. 316.78 samples/sec. 404.065 ms/step.
Train [24/40]. 316.77 samples/sec. 404.072 ms/step.
Train [32/40]. 316.77 samples/sec. 404.081 ms/step.
Train [40/40]. 316.76 samples/sec. 404.089 ms/step.
Train benchmark of inception_v4.tf_in1k done. 315.24 samples/sec, 404.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model lambda_resnet26rpt_256.c1_in1k created, param count: 10988688
Running inference benchmark on lambda_resnet26rpt_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1794.73 samples/sec. 142.640 ms/step.
Infer [16/40]. 1794.22 samples/sec. 142.680 ms/step.
Infer [24/40]. 1794.07 samples/sec. 142.693 ms/step.
Infer [32/40]. 1793.94 samples/sec. 142.702 ms/step.
Infer [40/40]. 1793.86 samples/sec. 142.709 ms/step.
Inference benchmark of lambda_resnet26rpt_256.c1_in1k done. 1793.47 samples/sec, 142.71 ms/step
Model lambda_resnet26rpt_256.c1_in1k created, param count: 10988688
Running train benchmark on lambda_resnet26rpt_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 172.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model lambda_resnet26rpt_256.c1_in1k created, param count: 10988688
Running train benchmark on lambda_resnet26rpt_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.78 GiB is free. Including non-PyTorch memory, this process has 19.86 GiB memory in use. Of the allocated memory 19.33 GiB is allocated by PyTorch, and 44.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model lambda_resnet26rpt_256.c1_in1k created, param count: 10988688
Running train benchmark on lambda_resnet26rpt_256.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 581.73 samples/sec. 220.035 ms/step.
Train [16/40]. 581.93 samples/sec. 219.957 ms/step.
Train [24/40]. 581.94 samples/sec. 219.956 ms/step.
Train [32/40]. 581.91 samples/sec. 219.965 ms/step.
Train [40/40]. 581.91 samples/sec. 219.964 ms/step.
Train benchmark of lambda_resnet26rpt_256.c1_in1k done. 579.71 samples/sec, 219.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model lambda_resnet26t.c1_in1k created, param count: 10958272
Running inference benchmark on lambda_resnet26t.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2339.84 samples/sec. 109.409 ms/step.
Infer [16/40]. 2339.67 samples/sec. 109.417 ms/step.
Infer [24/40]. 2339.56 samples/sec. 109.422 ms/step.
Infer [32/40]. 2339.49 samples/sec. 109.425 ms/step.
Infer [40/40]. 2339.47 samples/sec. 109.427 ms/step.
Inference benchmark of lambda_resnet26t.c1_in1k done. 2338.84 samples/sec, 109.43 ms/step
Model lambda_resnet26t.c1_in1k created, param count: 10958272
Running train benchmark on lambda_resnet26t.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 116.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model lambda_resnet26t.c1_in1k created, param count: 10958272
Running train benchmark on lambda_resnet26t.c1_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
Train [8/40]. 703.91 samples/sec. 272.763 ms/step.
Train [16/40]. 703.89 samples/sec. 272.769 ms/step.
Train [24/40]. 703.87 samples/sec. 272.780 ms/step.
Train [32/40]. 703.87 samples/sec. 272.778 ms/step.
Train [40/40]. 703.87 samples/sec. 272.778 ms/step.
Train benchmark of lambda_resnet26t.c1_in1k done. 701.59 samples/sec, 272.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model lambda_resnet50ts.a1h_in1k created, param count: 21536832
Running inference benchmark on lambda_resnet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1508.62 samples/sec. 169.692 ms/step.
Infer [16/40]. 1508.59 samples/sec. 169.695 ms/step.
Infer [24/40]. 1508.48 samples/sec. 169.708 ms/step.
Infer [32/40]. 1508.50 samples/sec. 169.705 ms/step.
Infer [40/40]. 1508.48 samples/sec. 169.707 ms/step.
Inference benchmark of lambda_resnet50ts.a1h_in1k done. 1508.17 samples/sec, 169.71 ms/step
Model lambda_resnet50ts.a1h_in1k created, param count: 21536832
Running train benchmark on lambda_resnet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 69.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model lambda_resnet50ts.a1h_in1k created, param count: 21536832
Running train benchmark on lambda_resnet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 274.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 69.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model lambda_resnet50ts.a1h_in1k created, param count: 21536832
Running train benchmark on lambda_resnet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.12 GiB is allocated by PyTorch, and 18.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model lambda_resnet50ts.a1h_in1k created, param count: 21536832
Running train benchmark on lambda_resnet50ts.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
Train [8/40]. 451.14 samples/sec. 212.797 ms/step.
Train [16/40]. 451.10 samples/sec. 212.811 ms/step.
Train [24/40]. 451.08 samples/sec. 212.824 ms/step.
Train [32/40]. 451.07 samples/sec. 212.829 ms/step.
Train [40/40]. 451.07 samples/sec. 212.825 ms/step.
Train benchmark of lambda_resnet50ts.a1h_in1k done. 448.79 samples/sec, 212.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model lamhalobotnet50ts_256.a1h_in1k created, param count: 22569824
Running inference benchmark on lamhalobotnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1360.00 samples/sec. 188.236 ms/step.
Infer [16/40]. 1359.91 samples/sec. 188.247 ms/step.
Infer [24/40]. 1359.89 samples/sec. 188.251 ms/step.
Infer [32/40]. 1359.89 samples/sec. 188.251 ms/step.
Infer [40/40]. 1359.91 samples/sec. 188.248 ms/step.
Inference benchmark of lamhalobotnet50ts_256.a1h_in1k done. 1359.64 samples/sec, 188.25 ms/step
Model lamhalobotnet50ts_256.a1h_in1k created, param count: 22569824
Running train benchmark on lamhalobotnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 236.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 30.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model lamhalobotnet50ts_256.a1h_in1k created, param count: 22569824
Running train benchmark on lamhalobotnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 462.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model lamhalobotnet50ts_256.a1h_in1k created, param count: 22569824
Running train benchmark on lamhalobotnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 119.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model lamhalobotnet50ts_256.a1h_in1k created, param count: 22569824
Running train benchmark on lamhalobotnet50ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
Train [8/40]. 420.48 samples/sec. 228.308 ms/step.
Train [16/40]. 420.50 samples/sec. 228.298 ms/step.
Train [24/40]. 420.49 samples/sec. 228.307 ms/step.
Train [32/40]. 420.49 samples/sec. 228.307 ms/step.
Train [40/40]. 420.48 samples/sec. 228.309 ms/step.
Train benchmark of lamhalobotnet50ts_256.a1h_in1k done. 418.40 samples/sec, 228.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model lcnet_050.ra2_in1k created, param count: 1880856
Running inference benchmark on lcnet_050.ra2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 33007.27 samples/sec. 7.756 ms/step.
Infer [16/40]. 33007.76 samples/sec. 7.756 ms/step.
Infer [24/40]. 33004.84 samples/sec. 7.756 ms/step.
Infer [32/40]. 33006.74 samples/sec. 7.756 ms/step.
Infer [40/40]. 33006.65 samples/sec. 7.756 ms/step.
Inference benchmark of lcnet_050.ra2_in1k done. 32924.82 samples/sec, 7.76 ms/step
Model lcnet_050.ra2_in1k created, param count: 1880856
Running train benchmark on lcnet_050.ra2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 6134.67 samples/sec. 41.730 ms/step.
Train [16/40]. 6134.83 samples/sec. 41.729 ms/step.
Train [24/40]. 6134.81 samples/sec. 41.729 ms/step.
Train [32/40]. 6134.69 samples/sec. 41.730 ms/step.
Train [40/40]. 6134.68 samples/sec. 41.730 ms/step.
Train benchmark of lcnet_050.ra2_in1k done. 6073.96 samples/sec, 41.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model lcnet_075.ra2_in1k created, param count: 2358288
Running inference benchmark on lcnet_075.ra2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 19617.41 samples/sec. 13.050 ms/step.
Infer [16/40]. 19612.28 samples/sec. 13.053 ms/step.
Infer [24/40]. 19612.32 samples/sec. 13.053 ms/step.
Infer [32/40]. 19611.68 samples/sec. 13.053 ms/step.
Infer [40/40]. 19612.05 samples/sec. 13.053 ms/step.
Inference benchmark of lcnet_075.ra2_in1k done. 19579.32 samples/sec, 13.05 ms/step
Model lcnet_075.ra2_in1k created, param count: 2358288
Running train benchmark on lcnet_075.ra2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 4318.93 samples/sec. 59.274 ms/step.
Train [16/40]. 4318.83 samples/sec. 59.275 ms/step.
Train [24/40]. 4318.68 samples/sec. 59.277 ms/step.
Train [32/40]. 4318.87 samples/sec. 59.275 ms/step.
Train [40/40]. 4318.74 samples/sec. 59.277 ms/step.
Train benchmark of lcnet_075.ra2_in1k done. 4287.73 samples/sec, 59.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model lcnet_100.ra2_in1k created, param count: 2953800
Running inference benchmark on lcnet_100.ra2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 14645.74 samples/sec. 17.479 ms/step.
Infer [16/40]. 14645.23 samples/sec. 17.480 ms/step.
Infer [24/40]. 14645.24 samples/sec. 17.480 ms/step.
Infer [32/40]. 14645.34 samples/sec. 17.480 ms/step.
Infer [40/40]. 14644.90 samples/sec. 17.480 ms/step.
Inference benchmark of lcnet_100.ra2_in1k done. 14625.74 samples/sec, 17.48 ms/step
Model lcnet_100.ra2_in1k created, param count: 2953800
Running train benchmark on lcnet_100.ra2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 3441.03 samples/sec. 74.396 ms/step.
Train [16/40]. 3440.75 samples/sec. 74.402 ms/step.
Train [24/40]. 3440.75 samples/sec. 74.402 ms/step.
Train [32/40]. 3440.76 samples/sec. 74.402 ms/step.
Train [40/40]. 3440.83 samples/sec. 74.401 ms/step.
Train benchmark of lcnet_100.ra2_in1k done. 3420.57 samples/sec, 74.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_senet154.in1k created, param count: 115088984
Running inference benchmark on legacy_senet154.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 558.90 samples/sec. 458.040 ms/step.
Infer [16/40]. 558.88 samples/sec. 458.063 ms/step.
Infer [24/40]. 558.77 samples/sec. 458.149 ms/step.
Infer [32/40]. 558.70 samples/sec. 458.205 ms/step.
Infer [40/40]. 558.67 samples/sec. 458.231 ms/step.
Inference benchmark of legacy_senet154.in1k done. 558.62 samples/sec, 458.23 ms/step
Model legacy_senet154.in1k created, param count: 115088984
Running train benchmark on legacy_senet154.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 740.06 MiB is free. Including non-PyTorch memory, this process has 22.92 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 9.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model legacy_senet154.in1k created, param count: 115088984
Running train benchmark on legacy_senet154.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 76.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model legacy_senet154.in1k created, param count: 115088984
Running train benchmark on legacy_senet154.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 134.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model legacy_senet154.in1k created, param count: 115088984
Running train benchmark on legacy_senet154.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 571.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model legacy_senet154.in1k created, param count: 115088984
Running train benchmark on legacy_senet154.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.16 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model legacy_senet154.in1k created, param count: 115088984
Running train benchmark on legacy_senet154.in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 170.26 samples/sec. 281.918 ms/step.
Train [16/40]. 170.26 samples/sec. 281.927 ms/step.
Train [24/40]. 170.26 samples/sec. 281.928 ms/step.
Train [32/40]. 170.26 samples/sec. 281.925 ms/step.
Train [40/40]. 170.26 samples/sec. 281.925 ms/step.
Train benchmark of legacy_senet154.in1k done. 168.90 samples/sec, 281.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnet18.in1k created, param count: 11778592
Running inference benchmark on legacy_seresnet18.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6654.50 samples/sec. 38.470 ms/step.
Infer [16/40]. 6655.34 samples/sec. 38.465 ms/step.
Infer [24/40]. 6653.58 samples/sec. 38.476 ms/step.
Infer [32/40]. 6653.01 samples/sec. 38.479 ms/step.
Infer [40/40]. 6651.98 samples/sec. 38.485 ms/step.
Inference benchmark of legacy_seresnet18.in1k done. 6647.70 samples/sec, 38.48 ms/step
Model legacy_seresnet18.in1k created, param count: 11778592
Running train benchmark on legacy_seresnet18.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1996.68 samples/sec. 128.213 ms/step.
Train [16/40]. 1996.76 samples/sec. 128.208 ms/step.
Train [24/40]. 1996.51 samples/sec. 128.224 ms/step.
Train [32/40]. 1996.38 samples/sec. 128.232 ms/step.
Train [40/40]. 1996.31 samples/sec. 128.237 ms/step.
Train benchmark of legacy_seresnet18.in1k done. 1987.81 samples/sec, 128.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnet34.in1k created, param count: 21958868
Running inference benchmark on legacy_seresnet34.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3565.67 samples/sec. 71.796 ms/step.
Infer [16/40]. 3558.61 samples/sec. 71.938 ms/step.
Infer [24/40]. 3562.48 samples/sec. 71.860 ms/step.
Infer [32/40]. 3560.70 samples/sec. 71.896 ms/step.
Infer [40/40]. 3555.55 samples/sec. 72.000 ms/step.
Inference benchmark of legacy_seresnet34.in1k done. 3554.27 samples/sec, 72.00 ms/step
Model legacy_seresnet34.in1k created, param count: 21958868
Running train benchmark on legacy_seresnet34.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1141.88 samples/sec. 224.193 ms/step.
Train [16/40]. 1141.90 samples/sec. 224.189 ms/step.
Train [24/40]. 1142.14 samples/sec. 224.141 ms/step.
Train [32/40]. 1142.04 samples/sec. 224.161 ms/step.
Train [40/40]. 1142.04 samples/sec. 224.160 ms/step.
Train benchmark of legacy_seresnet34.in1k done. 1137.07 samples/sec, 224.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnet50.in1k created, param count: 28088024
Running inference benchmark on legacy_seresnet50.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1971.54 samples/sec. 129.848 ms/step.
Infer [16/40]. 1971.76 samples/sec. 129.833 ms/step.
Infer [24/40]. 1971.27 samples/sec. 129.866 ms/step.
Infer [32/40]. 1970.92 samples/sec. 129.889 ms/step.
Infer [40/40]. 1970.67 samples/sec. 129.905 ms/step.
Inference benchmark of legacy_seresnet50.in1k done. 1970.23 samples/sec, 129.91 ms/step
Model legacy_seresnet50.in1k created, param count: 28088024
Running train benchmark on legacy_seresnet50.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 113.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model legacy_seresnet50.in1k created, param count: 28088024
Running train benchmark on legacy_seresnet50.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 611.55 samples/sec. 313.956 ms/step.
Train [16/40]. 611.54 samples/sec. 313.962 ms/step.
Train [24/40]. 611.57 samples/sec. 313.946 ms/step.
Train [32/40]. 611.58 samples/sec. 313.941 ms/step.
Train [40/40]. 611.58 samples/sec. 313.942 ms/step.
Train benchmark of legacy_seresnet50.in1k done. 609.23 samples/sec, 313.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnet101.in1k created, param count: 49326872
Running inference benchmark on legacy_seresnet101.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1149.66 samples/sec. 222.674 ms/step.
Infer [16/40]. 1149.53 samples/sec. 222.699 ms/step.
Infer [24/40]. 1149.53 samples/sec. 222.700 ms/step.
Infer [32/40]. 1149.44 samples/sec. 222.717 ms/step.
Infer [40/40]. 1149.42 samples/sec. 222.721 ms/step.
Inference benchmark of legacy_seresnet101.in1k done. 1149.22 samples/sec, 222.72 ms/step
Model legacy_seresnet101.in1k created, param count: 49326872
Running train benchmark on legacy_seresnet101.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 126.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model legacy_seresnet101.in1k created, param count: 49326872
Running train benchmark on legacy_seresnet101.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 170.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model legacy_seresnet101.in1k created, param count: 49326872
Running train benchmark on legacy_seresnet101.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 392.52 samples/sec. 326.100 ms/step.
Train [16/40]. 392.57 samples/sec. 326.053 ms/step.
Train [24/40]. 392.44 samples/sec. 326.164 ms/step.
Train [32/40]. 392.39 samples/sec. 326.207 ms/step.
Train [40/40]. 392.35 samples/sec. 326.236 ms/step.
Train benchmark of legacy_seresnet101.in1k done. 390.20 samples/sec, 326.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnet152.in1k created, param count: 66821848
Running inference benchmark on legacy_seresnet152.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 791.44 samples/sec. 323.463 ms/step.
Infer [16/40]. 791.28 samples/sec. 323.524 ms/step.
Infer [24/40]. 791.18 samples/sec. 323.568 ms/step.
Infer [32/40]. 791.19 samples/sec. 323.564 ms/step.
Infer [40/40]. 791.15 samples/sec. 323.578 ms/step.
Inference benchmark of legacy_seresnet152.in1k done. 791.06 samples/sec, 323.58 ms/step
Model legacy_seresnet152.in1k created, param count: 66821848
Running train benchmark on legacy_seresnet152.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 225.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model legacy_seresnet152.in1k created, param count: 66821848
Running train benchmark on legacy_seresnet152.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 189.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model legacy_seresnet152.in1k created, param count: 66821848
Running train benchmark on legacy_seresnet152.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 238.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model legacy_seresnet152.in1k created, param count: 66821848
Running train benchmark on legacy_seresnet152.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 276.47 samples/sec. 347.231 ms/step.
Train [16/40]. 276.34 samples/sec. 347.397 ms/step.
Train [24/40]. 276.31 samples/sec. 347.438 ms/step.
Train [32/40]. 276.29 samples/sec. 347.463 ms/step.
Train [40/40]. 276.28 samples/sec. 347.479 ms/step.
Train benchmark of legacy_seresnet152.in1k done. 274.35 samples/sec, 347.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnext26_32x4d.in1k created, param count: 16790280
Running inference benchmark on legacy_seresnext26_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2753.77 samples/sec. 92.963 ms/step.
Infer [16/40]. 2753.27 samples/sec. 92.980 ms/step.
Infer [24/40]. 2753.01 samples/sec. 92.989 ms/step.
Infer [32/40]. 2752.40 samples/sec. 93.010 ms/step.
Infer [40/40]. 2752.13 samples/sec. 93.019 ms/step.
Inference benchmark of legacy_seresnext26_32x4d.in1k done. 2751.35 samples/sec, 93.02 ms/step
Model legacy_seresnext26_32x4d.in1k created, param count: 16790280
Running train benchmark on legacy_seresnext26_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 785.91 samples/sec. 325.736 ms/step.
Train [16/40]. 785.88 samples/sec. 325.748 ms/step.
Train [24/40]. 785.86 samples/sec. 325.758 ms/step.
Train [32/40]. 785.83 samples/sec. 325.771 ms/step.
Train [40/40]. 785.83 samples/sec. 325.770 ms/step.
Train benchmark of legacy_seresnext26_32x4d.in1k done. 783.75 samples/sec, 325.77 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnext50_32x4d.in1k created, param count: 27559896
Running inference benchmark on legacy_seresnext50_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1681.85 samples/sec. 152.213 ms/step.
Infer [16/40]. 1681.71 samples/sec. 152.226 ms/step.
Infer [24/40]. 1681.44 samples/sec. 152.250 ms/step.
Infer [32/40]. 1681.00 samples/sec. 152.290 ms/step.
Infer [40/40]. 1680.85 samples/sec. 152.303 ms/step.
Inference benchmark of legacy_seresnext50_32x4d.in1k done. 1680.51 samples/sec, 152.30 ms/step
Model legacy_seresnext50_32x4d.in1k created, param count: 27559896
Running train benchmark on legacy_seresnext50_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 44.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model legacy_seresnext50_32x4d.in1k created, param count: 27559896
Running train benchmark on legacy_seresnext50_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 143.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model legacy_seresnext50_32x4d.in1k created, param count: 27559896
Running train benchmark on legacy_seresnext50_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 493.24 samples/sec. 259.511 ms/step.
Train [16/40]. 493.22 samples/sec. 259.521 ms/step.
Train [24/40]. 493.25 samples/sec. 259.501 ms/step.
Train [32/40]. 493.23 samples/sec. 259.515 ms/step.
Train [40/40]. 493.24 samples/sec. 259.506 ms/step.
Train benchmark of legacy_seresnext50_32x4d.in1k done. 491.08 samples/sec, 259.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_seresnext101_32x4d.in1k created, param count: 48955416
Running inference benchmark on legacy_seresnext101_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1060.38 samples/sec. 241.423 ms/step.
Infer [16/40]. 1060.41 samples/sec. 241.416 ms/step.
Infer [24/40]. 1060.45 samples/sec. 241.407 ms/step.
Infer [32/40]. 1060.42 samples/sec. 241.415 ms/step.
Infer [40/40]. 1060.42 samples/sec. 241.413 ms/step.
Inference benchmark of legacy_seresnext101_32x4d.in1k done. 1060.25 samples/sec, 241.41 ms/step
Model legacy_seresnext101_32x4d.in1k created, param count: 48955416
Running train benchmark on legacy_seresnext101_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 392.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model legacy_seresnext101_32x4d.in1k created, param count: 48955416
Running train benchmark on legacy_seresnext101_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 138.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model legacy_seresnext101_32x4d.in1k created, param count: 48955416
Running train benchmark on legacy_seresnext101_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 159.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model legacy_seresnext101_32x4d.in1k created, param count: 48955416
Running train benchmark on legacy_seresnext101_32x4d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 319.80 samples/sec. 300.184 ms/step.
Train [16/40]. 319.79 samples/sec. 300.199 ms/step.
Train [24/40]. 319.77 samples/sec. 300.212 ms/step.
Train [32/40]. 319.77 samples/sec. 300.216 ms/step.
Train [40/40]. 319.77 samples/sec. 300.220 ms/step.
Train benchmark of legacy_seresnext101_32x4d.in1k done. 317.89 samples/sec, 300.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model legacy_xception.tf_in1k created, param count: 22855952
Running inference benchmark on legacy_xception.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
Infer [8/40]. 1111.36 samples/sec. 230.348 ms/step.
Infer [16/40]. 1111.37 samples/sec. 230.347 ms/step.
Infer [24/40]. 1111.36 samples/sec. 230.347 ms/step.
Infer [32/40]. 1111.35 samples/sec. 230.351 ms/step.
Infer [40/40]. 1111.35 samples/sec. 230.350 ms/step.
Inference benchmark of legacy_xception.tf_in1k done. 1111.15 samples/sec, 230.35 ms/step
Model legacy_xception.tf_in1k created, param count: 22855952
Running train benchmark on legacy_xception.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacty of 23.65 GiB of which 210.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 66.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model legacy_xception.tf_in1k created, param count: 22855952
Running train benchmark on legacy_xception.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 182.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model legacy_xception.tf_in1k created, param count: 22855952
Running train benchmark on legacy_xception.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 355.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model legacy_xception.tf_in1k created, param count: 22855952
Running train benchmark on legacy_xception.tf_in1k for 40 steps w/ input size (3, 299, 299) and batch size 96.
Train [8/40]. 300.43 samples/sec. 319.545 ms/step.
Train [16/40]. 300.64 samples/sec. 319.314 ms/step.
Train [24/40]. 300.63 samples/sec. 319.325 ms/step.
Train [32/40]. 300.60 samples/sec. 319.365 ms/step.
Train [40/40]. 300.62 samples/sec. 319.343 ms/step.
Train benchmark of legacy_xception.tf_in1k done. 299.74 samples/sec, 319.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_128.fb_dist_in1k created, param count: 9213936
Running inference benchmark on levit_128.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 13508.03 samples/sec. 18.952 ms/step.
Infer [16/40]. 13507.92 samples/sec. 18.952 ms/step.
Infer [24/40]. 13508.65 samples/sec. 18.951 ms/step.
Infer [32/40]. 13509.15 samples/sec. 18.950 ms/step.
Infer [40/40]. 13509.27 samples/sec. 18.950 ms/step.
Inference benchmark of levit_128.fb_dist_in1k done. 13493.61 samples/sec, 18.95 ms/step
Model levit_128.fb_dist_in1k created, param count: 9213936
Running train benchmark on levit_128.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 3557.86 samples/sec. 71.953 ms/step.
Train [16/40]. 3559.87 samples/sec. 71.913 ms/step.
Train [24/40]. 3559.89 samples/sec. 71.912 ms/step.
Train [32/40]. 3560.31 samples/sec. 71.904 ms/step.
Train [40/40]. 3560.48 samples/sec. 71.900 ms/step.
Train benchmark of levit_128.fb_dist_in1k done. 3515.39 samples/sec, 71.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_128s.fb_dist_in1k created, param count: 7777058
Running inference benchmark on levit_128s.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 17515.98 samples/sec. 14.615 ms/step.
Infer [16/40]. 17512.40 samples/sec. 14.618 ms/step.
Infer [24/40]. 17517.09 samples/sec. 14.614 ms/step.
Infer [32/40]. 17518.60 samples/sec. 14.613 ms/step.
Infer [40/40]. 17520.33 samples/sec. 14.612 ms/step.
Inference benchmark of levit_128s.fb_dist_in1k done. 17495.22 samples/sec, 14.61 ms/step
Model levit_128s.fb_dist_in1k created, param count: 7777058
Running train benchmark on levit_128s.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 4516.96 samples/sec. 56.675 ms/step.
Train [16/40]. 4516.53 samples/sec. 56.681 ms/step.
Train [24/40]. 4516.48 samples/sec. 56.681 ms/step.
Train [32/40]. 4517.38 samples/sec. 56.670 ms/step.
Train [40/40]. 4516.87 samples/sec. 56.676 ms/step.
Train benchmark of levit_128s.fb_dist_in1k done. 4455.76 samples/sec, 56.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_192.fb_dist_in1k created, param count: 10947069
Running inference benchmark on levit_192.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 10729.70 samples/sec. 23.859 ms/step.
Infer [16/40]. 10727.73 samples/sec. 23.863 ms/step.
Infer [24/40]. 10725.46 samples/sec. 23.868 ms/step.
Infer [32/40]. 10724.45 samples/sec. 23.871 ms/step.
Infer [40/40]. 10723.38 samples/sec. 23.873 ms/step.
Inference benchmark of levit_192.fb_dist_in1k done. 10712.40 samples/sec, 23.87 ms/step
Model levit_192.fb_dist_in1k created, param count: 10947069
Running train benchmark on levit_192.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 3076.29 samples/sec. 83.217 ms/step.
Train [16/40]. 3051.63 samples/sec. 83.890 ms/step.
Train [24/40]. 3080.03 samples/sec. 83.116 ms/step.
Train [32/40]. 3094.18 samples/sec. 82.736 ms/step.
Train [40/40]. 3103.22 samples/sec. 82.495 ms/step.
Train benchmark of levit_192.fb_dist_in1k done. 3066.07 samples/sec, 82.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_256.fb_dist_in1k created, param count: 18893876
Running inference benchmark on levit_256.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7748.36 samples/sec. 33.039 ms/step.
Infer [16/40]. 7747.52 samples/sec. 33.043 ms/step.
Infer [24/40]. 7746.11 samples/sec. 33.049 ms/step.
Infer [32/40]. 7745.29 samples/sec. 33.052 ms/step.
Infer [40/40]. 7744.92 samples/sec. 33.054 ms/step.
Inference benchmark of levit_256.fb_dist_in1k done. 7738.87 samples/sec, 33.05 ms/step
Model levit_256.fb_dist_in1k created, param count: 18893876
Running train benchmark on levit_256.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2440.68 samples/sec. 104.889 ms/step.
Train [16/40]. 2440.57 samples/sec. 104.894 ms/step.
Train [24/40]. 2440.67 samples/sec. 104.889 ms/step.
Train [32/40]. 2440.62 samples/sec. 104.891 ms/step.
Train [40/40]. 2440.61 samples/sec. 104.892 ms/step.
Train benchmark of levit_256.fb_dist_in1k done. 2418.48 samples/sec, 104.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_384.fb_dist_in1k created, param count: 39128836
Running inference benchmark on levit_384.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4653.42 samples/sec. 55.013 ms/step.
Infer [16/40]. 4652.72 samples/sec. 55.022 ms/step.
Infer [24/40]. 4652.63 samples/sec. 55.023 ms/step.
Infer [32/40]. 4652.61 samples/sec. 55.023 ms/step.
Infer [40/40]. 4652.56 samples/sec. 55.023 ms/step.
Inference benchmark of levit_384.fb_dist_in1k done. 4650.46 samples/sec, 55.02 ms/step
Model levit_384.fb_dist_in1k created, param count: 39128836
Running train benchmark on levit_384.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1503.84 samples/sec. 170.230 ms/step.
Train [16/40]. 1503.88 samples/sec. 170.226 ms/step.
Train [24/40]. 1503.87 samples/sec. 170.227 ms/step.
Train [32/40]. 1503.89 samples/sec. 170.225 ms/step.
Train [40/40]. 1503.90 samples/sec. 170.224 ms/step.
Train benchmark of levit_384.fb_dist_in1k done. 1493.67 samples/sec, 170.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_conv_128.fb_dist_in1k created, param count: 9213936
Running inference benchmark on levit_conv_128.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 13167.18 samples/sec. 19.442 ms/step.
Infer [16/40]. 13166.61 samples/sec. 19.443 ms/step.
Infer [24/40]. 13167.43 samples/sec. 19.442 ms/step.
Infer [32/40]. 13167.88 samples/sec. 19.441 ms/step.
Infer [40/40]. 13167.77 samples/sec. 19.441 ms/step.
Inference benchmark of levit_conv_128.fb_dist_in1k done. 13151.53 samples/sec, 19.44 ms/step
Model levit_conv_128.fb_dist_in1k created, param count: 9213936
Running train benchmark on levit_conv_128.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 3425.73 samples/sec. 74.729 ms/step.
Train [16/40]. 3425.80 samples/sec. 74.727 ms/step.
Train [24/40]. 3426.16 samples/sec. 74.719 ms/step.
Train [32/40]. 3425.86 samples/sec. 74.726 ms/step.
Train [40/40]. 3425.77 samples/sec. 74.728 ms/step.
Train benchmark of levit_conv_128.fb_dist_in1k done. 3388.64 samples/sec, 74.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_conv_128s.fb_dist_in1k created, param count: 7777058
Running inference benchmark on levit_conv_128s.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 18398.38 samples/sec. 13.914 ms/step.
Infer [16/40]. 18419.21 samples/sec. 13.899 ms/step.
Infer [24/40]. 18419.66 samples/sec. 13.898 ms/step.
Infer [32/40]. 18430.54 samples/sec. 13.890 ms/step.
Infer [40/40]. 18433.59 samples/sec. 13.888 ms/step.
Inference benchmark of levit_conv_128s.fb_dist_in1k done. 18404.27 samples/sec, 13.89 ms/step
Model levit_conv_128s.fb_dist_in1k created, param count: 7777058
Running train benchmark on levit_conv_128s.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 4451.94 samples/sec. 57.503 ms/step.
Train [16/40]. 4452.80 samples/sec. 57.492 ms/step.
Train [24/40]. 4453.23 samples/sec. 57.486 ms/step.
Train [32/40]. 4453.39 samples/sec. 57.484 ms/step.
Train [40/40]. 4453.11 samples/sec. 57.488 ms/step.
Train benchmark of levit_conv_128s.fb_dist_in1k done. 4400.09 samples/sec, 57.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_conv_192.fb_dist_in1k created, param count: 10947069
Running inference benchmark on levit_conv_192.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 10895.09 samples/sec. 23.497 ms/step.
Infer [16/40]. 10894.16 samples/sec. 23.499 ms/step.
Infer [24/40]. 10893.58 samples/sec. 23.500 ms/step.
Infer [32/40]. 10893.73 samples/sec. 23.500 ms/step.
Infer [40/40]. 10893.63 samples/sec. 23.500 ms/step.
Inference benchmark of levit_conv_192.fb_dist_in1k done. 10882.12 samples/sec, 23.50 ms/step
Model levit_conv_192.fb_dist_in1k created, param count: 10947069
Running train benchmark on levit_conv_192.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 3014.89 samples/sec. 84.912 ms/step.
Train [16/40]. 3015.12 samples/sec. 84.905 ms/step.
Train [24/40]. 3015.33 samples/sec. 84.900 ms/step.
Train [32/40]. 3014.91 samples/sec. 84.911 ms/step.
Train [40/40]. 3014.92 samples/sec. 84.911 ms/step.
Train benchmark of levit_conv_192.fb_dist_in1k done. 2985.29 samples/sec, 84.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_conv_256.fb_dist_in1k created, param count: 18893876
Running inference benchmark on levit_conv_256.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7779.16 samples/sec. 32.908 ms/step.
Infer [16/40]. 7778.87 samples/sec. 32.910 ms/step.
Infer [24/40]. 7778.72 samples/sec. 32.910 ms/step.
Infer [32/40]. 7778.52 samples/sec. 32.911 ms/step.
Infer [40/40]. 7778.36 samples/sec. 32.912 ms/step.
Inference benchmark of levit_conv_256.fb_dist_in1k done. 7772.46 samples/sec, 32.91 ms/step
Model levit_conv_256.fb_dist_in1k created, param count: 18893876
Running train benchmark on levit_conv_256.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2289.28 samples/sec. 111.825 ms/step.
Train [16/40]. 2289.42 samples/sec. 111.819 ms/step.
Train [24/40]. 2288.89 samples/sec. 111.844 ms/step.
Train [32/40]. 2288.20 samples/sec. 111.878 ms/step.
Train [40/40]. 2287.81 samples/sec. 111.897 ms/step.
Train benchmark of levit_conv_256.fb_dist_in1k done. 2270.88 samples/sec, 111.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model levit_conv_384.fb_dist_in1k created, param count: 39128836
Running inference benchmark on levit_conv_384.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4668.61 samples/sec. 54.834 ms/step.
Infer [16/40]. 4668.46 samples/sec. 54.836 ms/step.
Infer [24/40]. 4668.48 samples/sec. 54.836 ms/step.
Infer [32/40]. 4668.42 samples/sec. 54.837 ms/step.
Infer [40/40]. 4668.43 samples/sec. 54.836 ms/step.
Inference benchmark of levit_conv_384.fb_dist_in1k done. 4666.29 samples/sec, 54.84 ms/step
Model levit_conv_384.fb_dist_in1k created, param count: 39128836
Running train benchmark on levit_conv_384.fb_dist_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1371.11 samples/sec. 186.710 ms/step.
Train [16/40]. 1371.16 samples/sec. 186.703 ms/step.
Train [24/40]. 1371.14 samples/sec. 186.706 ms/step.
Train [32/40]. 1371.17 samples/sec. 186.702 ms/step.
Train [40/40]. 1371.19 samples/sec. 186.699 ms/step.
Train benchmark of levit_conv_384.fb_dist_in1k done. 1363.87 samples/sec, 186.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running inference benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 287.68 samples/sec. 889.864 ms/step.
Infer [16/40]. 287.62 samples/sec. 890.076 ms/step.
Infer [24/40]. 287.58 samples/sec. 890.192 ms/step.
Infer [32/40]. 287.56 samples/sec. 890.251 ms/step.
Infer [40/40]. 287.55 samples/sec. 890.290 ms/step.
Inference benchmark of maxvit_base_tf_224.in1k done. 287.53 samples/sec, 890.29 ms/step
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.68 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.51 GiB is free. Including non-PyTorch memory, this process has 20.13 GiB memory in use. Of the allocated memory 19.61 GiB is allocated by PyTorch, and 24.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 252.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 349.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 387.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 575.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 575.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 196.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 928.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 873.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_base_tf_224.in1k created, param count: 119467708
Running train benchmark on maxvit_base_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 84.96 samples/sec. 282.479 ms/step.
Train [16/40]. 84.97 samples/sec. 282.453 ms/step.
Train [24/40]. 84.96 samples/sec. 282.489 ms/step.
Train [32/40]. 84.95 samples/sec. 282.524 ms/step.
Train [40/40]. 84.94 samples/sec. 282.550 ms/step.
Train benchmark of maxvit_base_tf_224.in1k done. 83.73 samples/sec, 282.55 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.23 GiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 17.48 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 13.23 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.41 GiB is free. Including non-PyTorch memory, this process has 17.23 GiB memory in use. Of the allocated memory 15.73 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
Infer [8/40]. 89.04 samples/sec. 1078.162 ms/step.
Infer [16/40]. 89.02 samples/sec. 1078.445 ms/step.
Infer [24/40]. 89.01 samples/sec. 1078.544 ms/step.
Infer [32/40]. 89.01 samples/sec. 1078.591 ms/step.
Infer [40/40]. 89.00 samples/sec. 1078.625 ms/step.
Inference benchmark of maxvit_base_tf_384.in1k done. 89.00 samples/sec, 1078.62 ms/step
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.90 GiB is free. Including non-PyTorch memory, this process has 16.74 GiB memory in use. Of the allocated memory 16.22 GiB is allocated by PyTorch, and 22.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 332.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 417.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1018.06 MiB is free. Including non-PyTorch memory, this process has 22.65 GiB memory in use. Of the allocated memory 21.85 GiB is allocated by PyTorch, and 312.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 5.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.07 GiB is free. Including non-PyTorch memory, this process has 22.57 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 521.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 860.06 MiB is free. Including non-PyTorch memory, this process has 22.80 GiB memory in use. Of the allocated memory 21.23 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 458.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 573.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 342.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 642.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 396.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 803.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 634.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_base_tf_384.in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 28.03 samples/sec. 285.456 ms/step.
Train [16/40]. 28.04 samples/sec. 285.349 ms/step.
Train [24/40]. 28.03 samples/sec. 285.420 ms/step.
Train [32/40]. 28.03 samples/sec. 285.412 ms/step.
Train [40/40]. 28.03 samples/sec. 285.384 ms/step.
Train benchmark of maxvit_base_tf_384.in1k done. 27.63 samples/sec, 285.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.24 GiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 17.48 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 13.23 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.41 GiB is free. Including non-PyTorch memory, this process has 17.23 GiB memory in use. Of the allocated memory 15.73 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running inference benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
Infer [8/40]. 89.03 samples/sec. 1078.233 ms/step.
Infer [16/40]. 89.04 samples/sec. 1078.221 ms/step.
Infer [24/40]. 89.02 samples/sec. 1078.417 ms/step.
Infer [32/40]. 89.01 samples/sec. 1078.520 ms/step.
Infer [40/40]. 89.01 samples/sec. 1078.586 ms/step.
Inference benchmark of maxvit_base_tf_384.in21k_ft_in1k done. 89.00 samples/sec, 1078.59 ms/step
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.90 GiB is free. Including non-PyTorch memory, this process has 16.74 GiB memory in use. Of the allocated memory 16.22 GiB is allocated by PyTorch, and 22.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 332.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 417.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1018.06 MiB is free. Including non-PyTorch memory, this process has 22.65 GiB memory in use. Of the allocated memory 21.85 GiB is allocated by PyTorch, and 312.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 5.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.07 GiB is free. Including non-PyTorch memory, this process has 22.57 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 521.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 860.06 MiB is free. Including non-PyTorch memory, this process has 22.80 GiB memory in use. Of the allocated memory 21.23 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 458.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 573.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 342.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 642.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 396.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 803.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 628.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_base_tf_384.in21k_ft_in1k created, param count: 119653468
Running train benchmark on maxvit_base_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 28.11 samples/sec. 284.633 ms/step.
Train [16/40]. 28.11 samples/sec. 284.630 ms/step.
Train [24/40]. 28.10 samples/sec. 284.664 ms/step.
Train [32/40]. 28.11 samples/sec. 284.639 ms/step.
Train [40/40]. 28.11 samples/sec. 284.643 ms/step.
Train benchmark of maxvit_base_tf_384.in21k_ft_in1k done. 27.70 samples/sec, 284.64 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.90 GiB is free. Including non-PyTorch memory, this process has 13.74 GiB memory in use. Of the allocated memory 10.72 GiB is allocated by PyTorch, and 2.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 12.63 GiB is free. Including non-PyTorch memory, this process has 11.01 GiB memory in use. Of the allocated memory 8.16 GiB is allocated by PyTorch, and 2.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.86 GiB is free. Including non-PyTorch memory, this process has 17.78 GiB memory in use. Of the allocated memory 15.59 GiB is allocated by PyTorch, and 1.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 878.06 MiB is free. Including non-PyTorch memory, this process has 22.78 GiB memory in use. Of the allocated memory 20.82 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
Infer [8/40]. 44.78 samples/sec. 1429.145 ms/step.
Infer [16/40]. 44.78 samples/sec. 1429.260 ms/step.
Infer [24/40]. 44.77 samples/sec. 1429.449 ms/step.
Infer [32/40]. 44.77 samples/sec. 1429.548 ms/step.
Infer [40/40]. 44.77 samples/sec. 1429.602 ms/step.
Inference benchmark of maxvit_base_tf_512.in1k done. 44.77 samples/sec, 1429.60 ms/step
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 20.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 22.46 GiB memory in use. Of the allocated memory 21.48 GiB is allocated by PyTorch, and 493.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.23 GiB is free. Including non-PyTorch memory, this process has 15.41 GiB memory in use. Of the allocated memory 14.47 GiB is allocated by PyTorch, and 449.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.64 GiB is free. Including non-PyTorch memory, this process has 21.00 GiB memory in use. Of the allocated memory 19.97 GiB is allocated by PyTorch, and 547.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.23 GiB is free. Including non-PyTorch memory, this process has 20.41 GiB memory in use. Of the allocated memory 19.47 GiB is allocated by PyTorch, and 450.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.38 GiB is free. Including non-PyTorch memory, this process has 20.26 GiB memory in use. Of the allocated memory 19.22 GiB is allocated by PyTorch, and 550.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 656.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.20 GiB is allocated by PyTorch, and 315.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 466.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 302.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 782.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 304.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 284.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 315.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 356.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 207.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model maxvit_base_tf_512.in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 4.
Train [8/40]. 14.07 samples/sec. 284.324 ms/step.
Train [16/40]. 14.06 samples/sec. 284.427 ms/step.
Train [24/40]. 14.06 samples/sec. 284.453 ms/step.
Train [32/40]. 14.06 samples/sec. 284.426 ms/step.
Train [40/40]. 14.06 samples/sec. 284.411 ms/step.
Train benchmark of maxvit_base_tf_512.in1k done. 13.86 samples/sec, 284.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.91 GiB is free. Including non-PyTorch memory, this process has 13.73 GiB memory in use. Of the allocated memory 10.72 GiB is allocated by PyTorch, and 2.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 12.63 GiB is free. Including non-PyTorch memory, this process has 11.01 GiB memory in use. Of the allocated memory 8.16 GiB is allocated by PyTorch, and 2.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.86 GiB is free. Including non-PyTorch memory, this process has 17.78 GiB memory in use. Of the allocated memory 15.59 GiB is allocated by PyTorch, and 1.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 880.06 MiB is free. Including non-PyTorch memory, this process has 22.78 GiB memory in use. Of the allocated memory 20.82 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running inference benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
Infer [8/40]. 44.78 samples/sec. 1429.340 ms/step.
Infer [16/40]. 44.78 samples/sec. 1429.360 ms/step.
Infer [24/40]. 44.78 samples/sec. 1429.362 ms/step.
Infer [32/40]. 44.78 samples/sec. 1429.367 ms/step.
Infer [40/40]. 44.78 samples/sec. 1429.367 ms/step.
Inference benchmark of maxvit_base_tf_512.in21k_ft_in1k done. 44.77 samples/sec, 1429.37 ms/step
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 20.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 22.46 GiB memory in use. Of the allocated memory 21.48 GiB is allocated by PyTorch, and 493.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.23 GiB is free. Including non-PyTorch memory, this process has 15.41 GiB memory in use. Of the allocated memory 14.47 GiB is allocated by PyTorch, and 449.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.64 GiB is free. Including non-PyTorch memory, this process has 21.00 GiB memory in use. Of the allocated memory 19.97 GiB is allocated by PyTorch, and 547.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.23 GiB is free. Including non-PyTorch memory, this process has 20.41 GiB memory in use. Of the allocated memory 19.47 GiB is allocated by PyTorch, and 450.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.38 GiB is free. Including non-PyTorch memory, this process has 20.26 GiB memory in use. Of the allocated memory 19.22 GiB is allocated by PyTorch, and 550.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 656.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.20 GiB is allocated by PyTorch, and 315.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 466.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 302.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 782.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 304.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 284.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 335.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 356.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 207.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model maxvit_base_tf_512.in21k_ft_in1k created, param count: 119876380
Running train benchmark on maxvit_base_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 4.
Train [8/40]. 13.91 samples/sec. 287.600 ms/step.
Train [16/40]. 13.91 samples/sec. 287.565 ms/step.
Train [24/40]. 13.91 samples/sec. 287.542 ms/step.
Train [32/40]. 13.91 samples/sec. 287.544 ms/step.
Train [40/40]. 13.91 samples/sec. 287.573 ms/step.
Train benchmark of maxvit_base_tf_512.in21k_ft_in1k done. 13.71 samples/sec, 287.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running inference benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.91 GiB is free. Including non-PyTorch memory, this process has 20.73 GiB memory in use. Of the allocated memory 15.13 GiB is allocated by PyTorch, and 5.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running inference benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Infer [8/40]. 205.19 samples/sec. 935.713 ms/step.
Infer [16/40]. 205.19 samples/sec. 935.734 ms/step.
Infer [24/40]. 205.18 samples/sec. 935.745 ms/step.
Infer [32/40]. 205.18 samples/sec. 935.753 ms/step.
Infer [40/40]. 205.18 samples/sec. 935.758 ms/step.
Inference benchmark of maxvit_large_tf_224.in1k done. 205.17 samples/sec, 935.76 ms/step
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 28.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.68 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.04 GiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 110.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 166.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 226.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 584.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 185.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 260.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 439.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 339.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 701.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_large_tf_224.in1k created, param count: 211785560
Running train benchmark on maxvit_large_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 16.
Train [8/40]. 57.91 samples/sec. 276.302 ms/step.
Train [16/40]. 57.93 samples/sec. 276.186 ms/step.
Train [24/40]. 57.96 samples/sec. 276.044 ms/step.
Train [32/40]. 57.98 samples/sec. 275.972 ms/step.
Train [40/40]. 57.98 samples/sec. 275.972 ms/step.
Train benchmark of maxvit_large_tf_224.in1k done. 57.11 samples/sec, 275.97 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.38 GiB is free. Including non-PyTorch memory, this process has 15.26 GiB memory in use. Of the allocated memory 11.37 GiB is allocated by PyTorch, and 3.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 11.60 GiB is free. Including non-PyTorch memory, this process has 12.04 GiB memory in use. Of the allocated memory 8.73 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.43 GiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 12.84 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.93 GiB is free. Including non-PyTorch memory, this process has 18.71 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Infer [8/40]. 64.18 samples/sec. 997.193 ms/step.
Infer [16/40]. 64.18 samples/sec. 997.242 ms/step.
Infer [24/40]. 64.16 samples/sec. 997.440 ms/step.
Infer [32/40]. 64.16 samples/sec. 997.543 ms/step.
Infer [40/40]. 64.15 samples/sec. 997.602 ms/step.
Inference benchmark of maxvit_large_tf_384.in1k done. 64.15 samples/sec, 997.60 ms/step
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.45 GiB is free. Including non-PyTorch memory, this process has 20.19 GiB memory in use. Of the allocated memory 19.67 GiB is allocated by PyTorch, and 26.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 316.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 289.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.66 GiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Of the allocated memory 15.30 GiB is allocated by PyTorch, and 187.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.35 GiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.43 GiB is allocated by PyTorch, and 368.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 4.55 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 169.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 549.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 574.06 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 405.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 394.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 351.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 321.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 430.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 424.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_large_tf_384.in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 6.
Train [8/40]. 20.45 samples/sec. 293.447 ms/step.
Train [16/40]. 20.45 samples/sec. 293.376 ms/step.
Train [24/40]. 20.46 samples/sec. 293.309 ms/step.
Train [32/40]. 20.46 samples/sec. 293.297 ms/step.
Train [40/40]. 20.46 samples/sec. 293.316 ms/step.
Train benchmark of maxvit_large_tf_384.in1k done. 20.16 samples/sec, 293.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.38 GiB is free. Including non-PyTorch memory, this process has 15.26 GiB memory in use. Of the allocated memory 11.37 GiB is allocated by PyTorch, and 3.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 11.60 GiB is free. Including non-PyTorch memory, this process has 12.04 GiB memory in use. Of the allocated memory 8.73 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.44 GiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 12.84 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.94 GiB is free. Including non-PyTorch memory, this process has 18.71 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running inference benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Infer [8/40]. 64.14 samples/sec. 997.855 ms/step.
Infer [16/40]. 64.14 samples/sec. 997.855 ms/step.
Infer [24/40]. 64.14 samples/sec. 997.852 ms/step.
Infer [32/40]. 64.14 samples/sec. 997.859 ms/step.
Infer [40/40]. 64.14 samples/sec. 997.860 ms/step.
Inference benchmark of maxvit_large_tf_384.in21k_ft_in1k done. 64.13 samples/sec, 997.86 ms/step
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.45 GiB is free. Including non-PyTorch memory, this process has 20.19 GiB memory in use. Of the allocated memory 19.67 GiB is allocated by PyTorch, and 26.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 316.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 289.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.66 GiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Of the allocated memory 15.30 GiB is allocated by PyTorch, and 187.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.35 GiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.43 GiB is allocated by PyTorch, and 368.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 4.55 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 169.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 549.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 574.06 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 405.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 394.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 351.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 301.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 386.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 452.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_large_tf_384.in21k_ft_in1k created, param count: 212033240
Running train benchmark on maxvit_large_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 6.
Train [8/40]. 20.53 samples/sec. 292.268 ms/step.
Train [16/40]. 20.52 samples/sec. 292.372 ms/step.
Train [24/40]. 20.53 samples/sec. 292.300 ms/step.
Train [32/40]. 20.53 samples/sec. 292.268 ms/step.
Train [40/40]. 20.53 samples/sec. 292.263 ms/step.
Train benchmark of maxvit_large_tf_384.in21k_ft_in1k done. 20.24 samples/sec, 292.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.55 GiB is free. Including non-PyTorch memory, this process has 18.09 GiB memory in use. Of the allocated memory 17.57 GiB is allocated by PyTorch, and 24.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.89 GiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 14.89 GiB is allocated by PyTorch, and 375.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.69 GiB is free. Including non-PyTorch memory, this process has 13.95 GiB memory in use. Of the allocated memory 10.19 GiB is allocated by PyTorch, and 3.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.56 GiB is free. Including non-PyTorch memory, this process has 20.08 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.76 GiB is free. Including non-PyTorch memory, this process has 21.88 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 1.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
Infer [8/40]. 32.36 samples/sec. 1483.287 ms/step.
Infer [16/40]. 32.36 samples/sec. 1483.509 ms/step.
Infer [24/40]. 32.35 samples/sec. 1483.581 ms/step.
Infer [32/40]. 32.35 samples/sec. 1483.615 ms/step.
Infer [40/40]. 32.35 samples/sec. 1483.639 ms/step.
Inference benchmark of maxvit_large_tf_512.in1k done. 32.35 samples/sec, 1483.64 ms/step
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.79 GiB is free. Including non-PyTorch memory, this process has 18.85 GiB memory in use. Of the allocated memory 18.33 GiB is allocated by PyTorch, and 24.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 20.82 GiB memory in use. Of the allocated memory 19.95 GiB is allocated by PyTorch, and 376.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 318.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 273.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.53 GiB is free. Including non-PyTorch memory, this process has 21.12 GiB memory in use. Of the allocated memory 20.13 GiB is allocated by PyTorch, and 496.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 22.38 GiB memory in use. Of the allocated memory 21.69 GiB is allocated by PyTorch, and 201.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 272.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 418.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.53 GiB is free. Including non-PyTorch memory, this process has 20.11 GiB memory in use. Of the allocated memory 19.25 GiB is allocated by PyTorch, and 371.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 270.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 336.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 204.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 307.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 221.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 329.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 377.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model maxvit_large_tf_512.in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 3.
Train [8/40]. 10.14 samples/sec. 295.924 ms/step.
Train [16/40]. 10.14 samples/sec. 295.948 ms/step.
Train [24/40]. 10.14 samples/sec. 295.938 ms/step.
Train [32/40]. 10.13 samples/sec. 296.203 ms/step.
Train [40/40]. 10.13 samples/sec. 296.141 ms/step.
Train benchmark of maxvit_large_tf_512.in1k done. 9.98 samples/sec, 296.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.55 GiB is free. Including non-PyTorch memory, this process has 18.09 GiB memory in use. Of the allocated memory 17.57 GiB is allocated by PyTorch, and 24.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.39 GiB is free. Including non-PyTorch memory, this process has 20.25 GiB memory in use. Of the allocated memory 14.89 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.69 GiB is free. Including non-PyTorch memory, this process has 13.95 GiB memory in use. Of the allocated memory 10.19 GiB is allocated by PyTorch, and 3.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.56 GiB is free. Including non-PyTorch memory, this process has 20.08 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.76 GiB is free. Including non-PyTorch memory, this process has 21.88 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 1.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.09 GiB is free. Including non-PyTorch memory, this process has 21.55 GiB memory in use. Of the allocated memory 14.83 GiB is allocated by PyTorch, and 6.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running inference benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
Infer [8/40]. 32.38 samples/sec. 988.386 ms/step.
Infer [16/40]. 32.38 samples/sec. 988.406 ms/step.
Infer [24/40]. 32.38 samples/sec. 988.404 ms/step.
Infer [32/40]. 32.38 samples/sec. 988.405 ms/step.
Infer [40/40]. 32.37 samples/sec. 988.417 ms/step.
Inference benchmark of maxvit_large_tf_512.in21k_ft_in1k done. 32.37 samples/sec, 988.42 ms/step
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.79 GiB is free. Including non-PyTorch memory, this process has 18.85 GiB memory in use. Of the allocated memory 18.33 GiB is allocated by PyTorch, and 24.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 20.82 GiB memory in use. Of the allocated memory 19.95 GiB is allocated by PyTorch, and 376.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 318.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 273.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.53 GiB is free. Including non-PyTorch memory, this process has 21.12 GiB memory in use. Of the allocated memory 20.13 GiB is allocated by PyTorch, and 496.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 22.38 GiB memory in use. Of the allocated memory 21.69 GiB is allocated by PyTorch, and 201.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 272.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 418.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.53 GiB is free. Including non-PyTorch memory, this process has 20.11 GiB memory in use. Of the allocated memory 19.25 GiB is allocated by PyTorch, and 371.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 270.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 336.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 204.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 307.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 237.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 329.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 385.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model maxvit_large_tf_512.in21k_ft_in1k created, param count: 212330456
Running train benchmark on maxvit_large_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 3.
Train [8/40]. 10.17 samples/sec. 295.122 ms/step.
Train [16/40]. 10.17 samples/sec. 295.112 ms/step.
Train [24/40]. 10.16 samples/sec. 295.131 ms/step.
Train [32/40]. 10.16 samples/sec. 295.198 ms/step.
Train [40/40]. 10.11 samples/sec. 296.839 ms/step.
Train benchmark of maxvit_large_tf_512.in21k_ft_in1k done. 9.96 samples/sec, 296.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_nano_rw_256.sw_in1k created, param count: 15451148
Running inference benchmark on maxvit_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1037.93 samples/sec. 246.645 ms/step.
Infer [16/40]. 1037.85 samples/sec. 246.665 ms/step.
Infer [24/40]. 1037.87 samples/sec. 246.659 ms/step.
Infer [32/40]. 1037.87 samples/sec. 246.658 ms/step.
Infer [40/40]. 1037.87 samples/sec. 246.658 ms/step.
Inference benchmark of maxvit_nano_rw_256.sw_in1k done. 1037.69 samples/sec, 246.66 ms/step
Model maxvit_nano_rw_256.sw_in1k created, param count: 15451148
Running train benchmark on maxvit_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 860.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_nano_rw_256.sw_in1k created, param count: 15451148
Running train benchmark on maxvit_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 662.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 377.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_nano_rw_256.sw_in1k created, param count: 15451148
Running train benchmark on maxvit_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 212.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 89.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_nano_rw_256.sw_in1k created, param count: 15451148
Running train benchmark on maxvit_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 95.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_nano_rw_256.sw_in1k created, param count: 15451148
Running train benchmark on maxvit_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 359.27 samples/sec. 178.138 ms/step.
Train [16/40]. 359.28 samples/sec. 178.136 ms/step.
Train [24/40]. 359.26 samples/sec. 178.143 ms/step.
Train [32/40]. 359.26 samples/sec. 178.145 ms/step.
Train [40/40]. 359.25 samples/sec. 178.147 ms/step.
Train benchmark of maxvit_nano_rw_256.sw_in1k done. 356.32 samples/sec, 178.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running inference benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 317.73 samples/sec. 805.706 ms/step.
Infer [16/40]. 317.65 samples/sec. 805.912 ms/step.
Infer [24/40]. 317.62 samples/sec. 805.991 ms/step.
Infer [32/40]. 317.61 samples/sec. 806.031 ms/step.
Infer [40/40]. 317.60 samples/sec. 806.055 ms/step.
Inference benchmark of maxvit_rmlp_base_rw_224.sw_in12k done. 317.58 samples/sec, 806.05 ms/step
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 356.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 419.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 330.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 865.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 527.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 726.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 430.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k created, param count: 124457137
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 83.04 samples/sec. 289.033 ms/step.
Train [16/40]. 84.22 samples/sec. 284.977 ms/step.
Train [24/40]. 84.63 samples/sec. 283.587 ms/step.
Train [32/40]. 84.84 samples/sec. 282.900 ms/step.
Train [40/40]. 84.96 samples/sec. 282.490 ms/step.
Train benchmark of maxvit_rmlp_base_rw_224.sw_in12k done. 83.65 samples/sec, 282.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running inference benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 317.51 samples/sec. 806.280 ms/step.
Infer [16/40]. 317.51 samples/sec. 806.286 ms/step.
Infer [24/40]. 317.50 samples/sec. 806.299 ms/step.
Infer [32/40]. 317.49 samples/sec. 806.319 ms/step.
Infer [40/40]. 317.48 samples/sec. 806.342 ms/step.
Inference benchmark of maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k done. 317.47 samples/sec, 806.34 ms/step
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 292.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 372.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 286.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 377.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 358.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 866.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 547.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 749.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 419.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 932.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 85.29 samples/sec. 281.401 ms/step.
Train [16/40]. 85.35 samples/sec. 281.202 ms/step.
Train [24/40]. 85.38 samples/sec. 281.104 ms/step.
Train [32/40]. 85.39 samples/sec. 281.057 ms/step.
Train [40/40]. 85.41 samples/sec. 281.009 ms/step.
Train benchmark of maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k done. 84.09 samples/sec, 281.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running inference benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "Expected canUse32BitIndexMath(input) && canUse32BitIndexMath(output) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running inference benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 97.78 samples/sec. 1963.519 ms/step.
Infer [16/40]. 97.76 samples/sec. 1964.019 ms/step.
Infer [24/40]. 97.75 samples/sec. 1964.201 ms/step.
Infer [32/40]. 97.75 samples/sec. 1964.293 ms/step.
Infer [40/40]. 97.74 samples/sec. 1964.350 ms/step.
Inference benchmark of maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k done. 97.74 samples/sec, 1964.35 ms/step
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.38 GiB is free. Including non-PyTorch memory, this process has 20.26 GiB memory in use. Of the allocated memory 19.16 GiB is allocated by PyTorch, and 610.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 21.24 GiB is allocated by PyTorch, and 830.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 378.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 601.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 942.06 MiB is free. Including non-PyTorch memory, this process has 22.72 GiB memory in use. Of the allocated memory 21.57 GiB is allocated by PyTorch, and 673.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 637.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 730.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 312.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 580.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 467.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 401.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 308.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 634.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116135788
Running train benchmark on maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 27.56 samples/sec. 290.249 ms/step.
Train [16/40]. 27.61 samples/sec. 289.792 ms/step.
Train [24/40]. 27.63 samples/sec. 289.579 ms/step.
Train [32/40]. 27.64 samples/sec. 289.442 ms/step.
Train [40/40]. 27.65 samples/sec. 289.371 ms/step.
Train benchmark of maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k done. 27.24 samples/sec, 289.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_rmlp_nano_rw_256.sw_in1k created, param count: 15501452
Running inference benchmark on maxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1037.49 samples/sec. 246.748 ms/step.
Infer [16/40]. 1037.53 samples/sec. 246.739 ms/step.
Infer [24/40]. 1037.51 samples/sec. 246.745 ms/step.
Infer [32/40]. 1037.51 samples/sec. 246.746 ms/step.
Infer [40/40]. 1037.51 samples/sec. 246.745 ms/step.
Inference benchmark of maxvit_rmlp_nano_rw_256.sw_in1k done. 1037.33 samples/sec, 246.75 ms/step
Model maxvit_rmlp_nano_rw_256.sw_in1k created, param count: 15501452
Running train benchmark on maxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 859.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_nano_rw_256.sw_in1k created, param count: 15501452
Running train benchmark on maxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 664.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 373.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_rmlp_nano_rw_256.sw_in1k created, param count: 15501452
Running train benchmark on maxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 204.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 91.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_rmlp_nano_rw_256.sw_in1k created, param count: 15501452
Running train benchmark on maxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 95.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_rmlp_nano_rw_256.sw_in1k created, param count: 15501452
Running train benchmark on maxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 357.32 samples/sec. 179.109 ms/step.
Train [16/40]. 357.34 samples/sec. 179.103 ms/step.
Train [24/40]. 357.34 samples/sec. 179.103 ms/step.
Train [32/40]. 357.32 samples/sec. 179.111 ms/step.
Train [40/40]. 357.32 samples/sec. 179.109 ms/step.
Train benchmark of maxvit_rmlp_nano_rw_256.sw_in1k done. 354.07 samples/sec, 179.11 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_rmlp_pico_rw_256.sw_in1k created, param count: 7515980
Running inference benchmark on maxvit_rmlp_pico_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1430.48 samples/sec. 178.961 ms/step.
Infer [16/40]. 1430.34 samples/sec. 178.978 ms/step.
Infer [24/40]. 1430.28 samples/sec. 178.986 ms/step.
Infer [32/40]. 1430.24 samples/sec. 178.991 ms/step.
Infer [40/40]. 1430.24 samples/sec. 178.991 ms/step.
Inference benchmark of maxvit_rmlp_pico_rw_256.sw_in1k done. 1429.97 samples/sec, 178.99 ms/step
Model maxvit_rmlp_pico_rw_256.sw_in1k created, param count: 7515980
Running train benchmark on maxvit_rmlp_pico_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 156.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 77.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_pico_rw_256.sw_in1k created, param count: 7515980
Running train benchmark on maxvit_rmlp_pico_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 205.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_rmlp_pico_rw_256.sw_in1k created, param count: 7515980
Running train benchmark on maxvit_rmlp_pico_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 483.60 samples/sec. 264.681 ms/step.
Train [16/40]. 483.64 samples/sec. 264.661 ms/step.
Train [24/40]. 483.64 samples/sec. 264.662 ms/step.
Train [32/40]. 483.64 samples/sec. 264.662 ms/step.
Train [40/40]. 483.63 samples/sec. 264.663 ms/step.
Train benchmark of maxvit_rmlp_pico_rw_256.sw_in1k done. 478.97 samples/sec, 264.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_rmlp_small_rw_224.sw_in1k created, param count: 64895044
Running inference benchmark on maxvit_rmlp_small_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 591.26 samples/sec. 432.974 ms/step.
Infer [16/40]. 591.23 samples/sec. 432.995 ms/step.
Infer [24/40]. 591.23 samples/sec. 432.998 ms/step.
Infer [32/40]. 591.23 samples/sec. 432.996 ms/step.
Infer [40/40]. 591.22 samples/sec. 433.000 ms/step.
Inference benchmark of maxvit_rmlp_small_rw_224.sw_in1k done. 591.16 samples/sec, 433.00 ms/step
Model maxvit_rmlp_small_rw_224.sw_in1k created, param count: 64895044
Running train benchmark on maxvit_rmlp_small_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 790.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 22.01 GiB is allocated by PyTorch, and 369.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_small_rw_224.sw_in1k created, param count: 64895044
Running train benchmark on maxvit_rmlp_small_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 420.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 444.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_rmlp_small_rw_224.sw_in1k created, param count: 64895044
Running train benchmark on maxvit_rmlp_small_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 212.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 766.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_rmlp_small_rw_224.sw_in1k created, param count: 64895044
Running train benchmark on maxvit_rmlp_small_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 496.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_rmlp_small_rw_224.sw_in1k created, param count: 64895044
Running train benchmark on maxvit_rmlp_small_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 604.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_rmlp_small_rw_224.sw_in1k created, param count: 64895044
Running train benchmark on maxvit_rmlp_small_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 200.20 samples/sec. 239.759 ms/step.
Train [16/40]. 200.20 samples/sec. 239.755 ms/step.
Train [24/40]. 200.20 samples/sec. 239.755 ms/step.
Train [32/40]. 200.20 samples/sec. 239.757 ms/step.
Train [40/40]. 200.21 samples/sec. 239.752 ms/step.
Train benchmark of maxvit_rmlp_small_rw_224.sw_in1k done. 198.02 samples/sec, 239.75 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_rmlp_tiny_rw_256.sw_in1k created, param count: 29148896
Running inference benchmark on maxvit_rmlp_tiny_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 694.99 samples/sec. 368.349 ms/step.
Infer [16/40]. 694.97 samples/sec. 368.362 ms/step.
Infer [24/40]. 694.96 samples/sec. 368.365 ms/step.
Infer [32/40]. 694.96 samples/sec. 368.366 ms/step.
Infer [40/40]. 694.95 samples/sec. 368.371 ms/step.
Inference benchmark of maxvit_rmlp_tiny_rw_256.sw_in1k done. 694.86 samples/sec, 368.37 ms/step
Model maxvit_rmlp_tiny_rw_256.sw_in1k created, param count: 29148896
Running train benchmark on maxvit_rmlp_tiny_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 829.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_rmlp_tiny_rw_256.sw_in1k created, param count: 29148896
Running train benchmark on maxvit_rmlp_tiny_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 640.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 489.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_rmlp_tiny_rw_256.sw_in1k created, param count: 29148896
Running train benchmark on maxvit_rmlp_tiny_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 141.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_rmlp_tiny_rw_256.sw_in1k created, param count: 29148896
Running train benchmark on maxvit_rmlp_tiny_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 133.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_rmlp_tiny_rw_256.sw_in1k created, param count: 29148896
Running train benchmark on maxvit_rmlp_tiny_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 244.13 samples/sec. 262.158 ms/step.
Train [16/40]. 244.14 samples/sec. 262.149 ms/step.
Train [24/40]. 244.15 samples/sec. 262.138 ms/step.
Train [32/40]. 244.14 samples/sec. 262.143 ms/step.
Train [40/40]. 244.14 samples/sec. 262.142 ms/step.
Train benchmark of maxvit_rmlp_tiny_rw_256.sw_in1k done. 241.77 samples/sec, 262.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_small_tf_224.in1k created, param count: 68927956
Running inference benchmark on maxvit_small_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 509.38 samples/sec. 502.568 ms/step.
Infer [16/40]. 509.38 samples/sec. 502.574 ms/step.
Infer [24/40]. 509.38 samples/sec. 502.574 ms/step.
Infer [32/40]. 509.37 samples/sec. 502.579 ms/step.
Infer [40/40]. 509.37 samples/sec. 502.583 ms/step.
Inference benchmark of maxvit_small_tf_224.in1k done. 509.32 samples/sec, 502.58 ms/step
Model maxvit_small_tf_224.in1k created, param count: 68927956
Running train benchmark on maxvit_small_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.68 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.71 GiB is free. Including non-PyTorch memory, this process has 19.93 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 17.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_small_tf_224.in1k created, param count: 68927956
Running train benchmark on maxvit_small_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 486.06 MiB is free. Including non-PyTorch memory, this process has 23.17 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 314.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_small_tf_224.in1k created, param count: 68927956
Running train benchmark on maxvit_small_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 388.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_small_tf_224.in1k created, param count: 68927956
Running train benchmark on maxvit_small_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 462.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_small_tf_224.in1k created, param count: 68927956
Running train benchmark on maxvit_small_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 413.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_small_tf_224.in1k created, param count: 68927956
Running train benchmark on maxvit_small_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 180.80 samples/sec. 265.493 ms/step.
Train [16/40]. 180.80 samples/sec. 265.487 ms/step.
Train [24/40]. 180.80 samples/sec. 265.483 ms/step.
Train [32/40]. 180.80 samples/sec. 265.491 ms/step.
Train [40/40]. 180.79 samples/sec. 265.495 ms/step.
Train benchmark of maxvit_small_tf_224.in1k done. 179.08 samples/sec, 265.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running inference benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.43 GiB is free. Including non-PyTorch memory, this process has 19.21 GiB memory in use. Of the allocated memory 17.29 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running inference benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.68 GiB is free. Including non-PyTorch memory, this process has 14.96 GiB memory in use. Of the allocated memory 13.04 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running inference benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.48 GiB is free. Including non-PyTorch memory, this process has 17.16 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running inference benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
Infer [8/40]. 158.68 samples/sec. 604.996 ms/step.
Infer [16/40]. 158.68 samples/sec. 604.995 ms/step.
Infer [24/40]. 158.68 samples/sec. 605.001 ms/step.
Infer [32/40]. 158.68 samples/sec. 605.007 ms/step.
Infer [40/40]. 158.68 samples/sec. 605.009 ms/step.
Inference benchmark of maxvit_small_tf_384.in1k done. 158.66 samples/sec, 605.01 ms/step
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.10 GiB is free. Including non-PyTorch memory, this process has 16.54 GiB memory in use. Of the allocated memory 16.03 GiB is allocated by PyTorch, and 18.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 566.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 384.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the allocated memory 21.66 GiB is allocated by PyTorch, and 434.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 5.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.29 GiB is free. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 493.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 535.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 517.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 700.06 MiB is free. Including non-PyTorch memory, this process has 22.96 GiB memory in use. Of the allocated memory 21.99 GiB is allocated by PyTorch, and 485.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 404.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_small_tf_384.in1k created, param count: 69018676
Running train benchmark on maxvit_small_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 57.35 samples/sec. 278.984 ms/step.
Train [16/40]. 57.31 samples/sec. 279.166 ms/step.
Train [24/40]. 57.30 samples/sec. 279.215 ms/step.
Train [32/40]. 57.30 samples/sec. 279.240 ms/step.
Train [40/40]. 57.29 samples/sec. 279.258 ms/step.
Train benchmark of maxvit_small_tf_384.in1k done. 56.76 samples/sec, 279.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running inference benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.11 GiB is free. Including non-PyTorch memory, this process has 13.54 GiB memory in use. Of the allocated memory 10.53 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running inference benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 12.85 GiB is free. Including non-PyTorch memory, this process has 10.79 GiB memory in use. Of the allocated memory 7.97 GiB is allocated by PyTorch, and 2.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running inference benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.91 GiB is free. Including non-PyTorch memory, this process has 17.73 GiB memory in use. Of the allocated memory 15.41 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running inference benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 926.06 MiB is free. Including non-PyTorch memory, this process has 22.74 GiB memory in use. Of the allocated memory 20.62 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running inference benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
Infer [8/40]. 80.46 samples/sec. 795.414 ms/step.
Infer [16/40]. 80.45 samples/sec. 795.509 ms/step.
Infer [24/40]. 80.44 samples/sec. 795.585 ms/step.
Infer [32/40]. 80.44 samples/sec. 795.622 ms/step.
Infer [40/40]. 80.44 samples/sec. 795.646 ms/step.
Inference benchmark of maxvit_small_tf_512.in1k done. 80.43 samples/sec, 795.65 ms/step
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 358.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 15.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.40 GiB is free. Including non-PyTorch memory, this process has 22.24 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 471.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.28 GiB is free. Including non-PyTorch memory, this process has 15.36 GiB memory in use. Of the allocated memory 14.28 GiB is allocated by PyTorch, and 596.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.96 GiB is free. Including non-PyTorch memory, this process has 20.68 GiB memory in use. Of the allocated memory 19.78 GiB is allocated by PyTorch, and 409.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.53 GiB is free. Including non-PyTorch memory, this process has 20.11 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 340.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.62 GiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.03 GiB is allocated by PyTorch, and 508.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 706.06 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 461.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 332.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 782.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 532.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 252.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 285.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_small_tf_512.in1k created, param count: 69127540
Running train benchmark on maxvit_small_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
Train [8/40]. 29.09 samples/sec. 274.998 ms/step.
Train [16/40]. 29.09 samples/sec. 275.000 ms/step.
Train [24/40]. 29.09 samples/sec. 274.999 ms/step.
Train [32/40]. 29.09 samples/sec. 275.004 ms/step.
Train [40/40]. 29.09 samples/sec. 275.005 ms/step.
Train benchmark of maxvit_small_tf_512.in1k done. 28.82 samples/sec, 275.00 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_tiny_rw_224.sw_in1k created, param count: 29057312
Running inference benchmark on maxvit_tiny_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 901.27 samples/sec. 284.045 ms/step.
Infer [16/40]. 901.28 samples/sec. 284.039 ms/step.
Infer [24/40]. 901.28 samples/sec. 284.041 ms/step.
Infer [32/40]. 901.29 samples/sec. 284.037 ms/step.
Infer [40/40]. 901.29 samples/sec. 284.038 ms/step.
Inference benchmark of maxvit_tiny_rw_224.sw_in1k done. 901.16 samples/sec, 284.04 ms/step
Model maxvit_tiny_rw_224.sw_in1k created, param count: 29057312
Running train benchmark on maxvit_tiny_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 682.06 MiB is free. Including non-PyTorch memory, this process has 22.97 GiB memory in use. Of the allocated memory 22.32 GiB is allocated by PyTorch, and 164.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_tiny_rw_224.sw_in1k created, param count: 29057312
Running train benchmark on maxvit_tiny_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 438.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 544.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_tiny_rw_224.sw_in1k created, param count: 29057312
Running train benchmark on maxvit_tiny_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 350.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_tiny_rw_224.sw_in1k created, param count: 29057312
Running train benchmark on maxvit_tiny_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 450.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_tiny_rw_224.sw_in1k created, param count: 29057312
Running train benchmark on maxvit_tiny_rw_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 314.07 samples/sec. 203.777 ms/step.
Train [16/40]. 314.06 samples/sec. 203.781 ms/step.
Train [24/40]. 314.05 samples/sec. 203.788 ms/step.
Train [32/40]. 314.05 samples/sec. 203.787 ms/step.
Train [40/40]. 314.05 samples/sec. 203.792 ms/step.
Train benchmark of maxvit_tiny_rw_224.sw_in1k done. 310.72 samples/sec, 203.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_tiny_tf_224.in1k created, param count: 30916528
Running inference benchmark on maxvit_tiny_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 773.24 samples/sec. 331.074 ms/step.
Infer [16/40]. 773.26 samples/sec. 331.067 ms/step.
Infer [24/40]. 773.27 samples/sec. 331.062 ms/step.
Infer [32/40]. 773.26 samples/sec. 331.064 ms/step.
Infer [40/40]. 773.27 samples/sec. 331.063 ms/step.
Inference benchmark of maxvit_tiny_tf_224.in1k done. 773.16 samples/sec, 331.06 ms/step
Model maxvit_tiny_tf_224.in1k created, param count: 30916528
Running train benchmark on maxvit_tiny_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 168.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_tiny_tf_224.in1k created, param count: 30916528
Running train benchmark on maxvit_tiny_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 252.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_tiny_tf_224.in1k created, param count: 30916528
Running train benchmark on maxvit_tiny_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 111.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_tiny_tf_224.in1k created, param count: 30916528
Running train benchmark on maxvit_tiny_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 208.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_tiny_tf_224.in1k created, param count: 30916528
Running train benchmark on maxvit_tiny_tf_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 283.15 samples/sec. 226.027 ms/step.
Train [16/40]. 283.15 samples/sec. 226.031 ms/step.
Train [24/40]. 283.16 samples/sec. 226.020 ms/step.
Train [32/40]. 283.16 samples/sec. 226.022 ms/step.
Train [40/40]. 283.16 samples/sec. 226.020 ms/step.
Train benchmark of maxvit_tiny_tf_224.in1k done. 280.10 samples/sec, 226.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running inference benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running inference benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.64 GiB is free. Including non-PyTorch memory, this process has 18.00 GiB memory in use. Of the allocated memory 16.06 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running inference benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 240.28 samples/sec. 532.707 ms/step.
Infer [16/40]. 240.28 samples/sec. 532.708 ms/step.
Infer [24/40]. 240.28 samples/sec. 532.706 ms/step.
Infer [32/40]. 240.28 samples/sec. 532.706 ms/step.
Infer [40/40]. 240.28 samples/sec. 532.703 ms/step.
Inference benchmark of maxvit_tiny_tf_384.in1k done. 240.26 samples/sec, 532.70 ms/step
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.03 GiB is free. Including non-PyTorch memory, this process has 15.61 GiB memory in use. Of the allocated memory 15.04 GiB is allocated by PyTorch, and 75.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.90 GiB is free. Including non-PyTorch memory, this process has 18.74 GiB memory in use. Of the allocated memory 18.06 GiB is allocated by PyTorch, and 184.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.55 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.77 GiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.09 GiB is allocated by PyTorch, and 291.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 876.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 396.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 276.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 224.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 263.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 39.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_tiny_tf_384.in1k created, param count: 30977008
Running train benchmark on maxvit_tiny_tf_384.in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 88.85 samples/sec. 270.120 ms/step.
Train [16/40]. 88.85 samples/sec. 270.129 ms/step.
Train [24/40]. 88.85 samples/sec. 270.124 ms/step.
Train [32/40]. 88.85 samples/sec. 270.128 ms/step.
Train [40/40]. 88.85 samples/sec. 270.126 ms/step.
Train benchmark of maxvit_tiny_tf_384.in1k done. 88.03 samples/sec, 270.13 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running inference benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.19 GiB is free. Including non-PyTorch memory, this process has 13.45 GiB memory in use. Of the allocated memory 9.88 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running inference benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.19 GiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running inference benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 21.46 GiB memory in use. Of the allocated memory 19.01 GiB is allocated by PyTorch, and 1.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running inference benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
Infer [8/40]. 121.37 samples/sec. 790.965 ms/step.
Infer [16/40]. 121.37 samples/sec. 790.980 ms/step.
Infer [24/40]. 121.36 samples/sec. 791.046 ms/step.
Infer [32/40]. 121.35 samples/sec. 791.102 ms/step.
Infer [40/40]. 121.35 samples/sec. 791.130 ms/step.
Inference benchmark of maxvit_tiny_tf_512.in1k done. 121.34 samples/sec, 791.13 ms/step
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 444.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 74.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.87 GiB is free. Including non-PyTorch memory, this process has 20.77 GiB memory in use. Of the allocated memory 20.01 GiB is allocated by PyTorch, and 273.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 22.34 GiB memory in use. Of the allocated memory 21.39 GiB is allocated by PyTorch, and 464.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 822.06 MiB is free. Including non-PyTorch memory, this process has 22.84 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 276.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 215.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 170.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 668.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 136.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 782.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 129.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 42.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_tiny_tf_512.in1k created, param count: 31049584
Running train benchmark on maxvit_tiny_tf_512.in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
Train [8/40]. 44.78 samples/sec. 267.988 ms/step.
Train [16/40]. 44.78 samples/sec. 267.990 ms/step.
Train [24/40]. 44.78 samples/sec. 267.986 ms/step.
Train [32/40]. 44.78 samples/sec. 267.984 ms/step.
Train [40/40]. 44.78 samples/sec. 267.991 ms/step.
Train benchmark of maxvit_tiny_tf_512.in1k done. 44.36 samples/sec, 267.99 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running inference benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 27.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.61 GiB is free. Including non-PyTorch memory, this process has 18.03 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 130.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running inference benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 20.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.98 GiB is free. Including non-PyTorch memory, this process has 14.66 GiB memory in use. Of the allocated memory 13.51 GiB is allocated by PyTorch, and 676.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running inference benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.55 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 9.60 GiB is allocated by PyTorch, and 2.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running inference benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.26 GiB is free. Including non-PyTorch memory, this process has 18.38 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running inference benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.88 GiB is free. Including non-PyTorch memory, this process has 19.76 GiB memory in use. Of the allocated memory 17.51 GiB is allocated by PyTorch, and 1.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running inference benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
Infer [8/40]. 38.71 samples/sec. 1239.886 ms/step.
Infer [16/40]. 38.70 samples/sec. 1240.325 ms/step.
Infer [24/40]. 38.69 samples/sec. 1240.507 ms/step.
Infer [32/40]. 38.69 samples/sec. 1240.593 ms/step.
Infer [40/40]. 38.69 samples/sec. 1240.644 ms/step.
Inference benchmark of maxvit_xlarge_tf_384.in21k_ft_in1k done. 38.69 samples/sec, 1240.64 ms/step
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 132.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.86 GiB is free. Including non-PyTorch memory, this process has 18.78 GiB memory in use. Of the allocated memory 17.62 GiB is allocated by PyTorch, and 676.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.75 GiB is free. Including non-PyTorch memory, this process has 20.89 GiB memory in use. Of the allocated memory 19.94 GiB is allocated by PyTorch, and 465.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.46 GiB is free. Including non-PyTorch memory, this process has 19.18 GiB memory in use. Of the allocated memory 17.94 GiB is allocated by PyTorch, and 761.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.46 GiB is free. Including non-PyTorch memory, this process has 20.18 GiB memory in use. Of the allocated memory 19.31 GiB is allocated by PyTorch, and 386.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.46 GiB is free. Including non-PyTorch memory, this process has 21.18 GiB memory in use. Of the allocated memory 19.99 GiB is allocated by PyTorch, and 701.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 494.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 400.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 21.69 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 220.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 711.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 670.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 905.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 653.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 593.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model maxvit_xlarge_tf_384.in21k_ft_in1k created, param count: 475323472
Running train benchmark on maxvit_xlarge_tf_384.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 3.
Train [8/40]. 10.48 samples/sec. 286.349 ms/step.
Train [16/40]. 10.48 samples/sec. 286.329 ms/step.
Train [24/40]. 10.48 samples/sec. 286.334 ms/step.
Train [32/40]. 10.48 samples/sec. 286.360 ms/step.
Train [40/40]. 10.48 samples/sec. 286.353 ms/step.
Train benchmark of maxvit_xlarge_tf_384.in21k_ft_in1k done. 10.32 samples/sec, 286.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.47 GiB is free. Including non-PyTorch memory, this process has 15.17 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 131.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 21.60 GiB memory in use. Of the allocated memory 20.36 GiB is allocated by PyTorch, and 760.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.95 GiB is free. Including non-PyTorch memory, this process has 16.69 GiB memory in use. Of the allocated memory 15.68 GiB is allocated by PyTorch, and 530.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.71 GiB is free. Including non-PyTorch memory, this process has 16.93 GiB memory in use. Of the allocated memory 12.21 GiB is allocated by PyTorch, and 4.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 11.50 GiB is free. Including non-PyTorch memory, this process has 12.14 GiB memory in use. Of the allocated memory 8.74 GiB is allocated by PyTorch, and 2.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.80 GiB is free. Including non-PyTorch memory, this process has 16.84 GiB memory in use. Of the allocated memory 13.76 GiB is allocated by PyTorch, and 2.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.50 GiB is free. Including non-PyTorch memory, this process has 18.14 GiB memory in use. Of the allocated memory 15.77 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running inference benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
Infer [8/40]. 19.81 samples/sec. 1211.460 ms/step.
Infer [16/40]. 19.81 samples/sec. 1211.448 ms/step.
Infer [24/40]. 19.81 samples/sec. 1211.452 ms/step.
Infer [32/40]. 19.81 samples/sec. 1211.455 ms/step.
Infer [40/40]. 19.81 samples/sec. 1211.454 ms/step.
Inference benchmark of maxvit_xlarge_tf_512.in21k_ft_in1k done. 19.81 samples/sec, 1211.45 ms/step
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.71 GiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Of the allocated memory 15.30 GiB is allocated by PyTorch, and 131.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 22.17 GiB memory in use. Of the allocated memory 20.93 GiB is allocated by PyTorch, and 762.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 21.57 GiB memory in use. Of the allocated memory 20.56 GiB is allocated by PyTorch, and 530.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.93 GiB is free. Including non-PyTorch memory, this process has 21.71 GiB memory in use. Of the allocated memory 20.37 GiB is allocated by PyTorch, and 868.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.75 GiB is free. Including non-PyTorch memory, this process has 21.89 GiB memory in use. Of the allocated memory 20.93 GiB is allocated by PyTorch, and 473.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.24 GiB is free. Including non-PyTorch memory, this process has 17.40 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 773.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.13 GiB is free. Including non-PyTorch memory, this process has 18.52 GiB memory in use. Of the allocated memory 17.37 GiB is allocated by PyTorch, and 666.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 591.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 744.06 MiB is free. Including non-PyTorch memory, this process has 22.91 GiB memory in use. Of the allocated memory 21.61 GiB is allocated by PyTorch, and 823.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 700.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 268.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 610.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 604.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 706.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 281.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model maxvit_xlarge_tf_512.in21k_ft_in1k created, param count: 475769296
Running train benchmark on maxvit_xlarge_tf_512.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 2.
Train [8/40]. 6.20 samples/sec. 322.695 ms/step.
Train [16/40]. 6.20 samples/sec. 322.663 ms/step.
Train [24/40]. 6.20 samples/sec. 322.626 ms/step.
Train [32/40]. 6.20 samples/sec. 322.680 ms/step.
Train [40/40]. 6.20 samples/sec. 322.686 ms/step.
Train benchmark of maxvit_xlarge_tf_512.in21k_ft_in1k done. 6.11 samples/sec, 322.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxxvit_rmlp_nano_rw_256.sw_in1k created, param count: 16779628
Running inference benchmark on maxxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1209.06 samples/sec. 211.734 ms/step.
Infer [16/40]. 1209.08 samples/sec. 211.731 ms/step.
Infer [24/40]. 1209.07 samples/sec. 211.733 ms/step.
Infer [32/40]. 1209.07 samples/sec. 211.733 ms/step.
Infer [40/40]. 1209.06 samples/sec. 211.734 ms/step.
Inference benchmark of maxxvit_rmlp_nano_rw_256.sw_in1k done. 1208.84 samples/sec, 211.73 ms/step
Model maxxvit_rmlp_nano_rw_256.sw_in1k created, param count: 16779628
Running train benchmark on maxxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 396.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 94.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxxvit_rmlp_nano_rw_256.sw_in1k created, param count: 16779628
Running train benchmark on maxxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 100.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 90.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxxvit_rmlp_nano_rw_256.sw_in1k created, param count: 16779628
Running train benchmark on maxxvit_rmlp_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 388.74 samples/sec. 329.273 ms/step.
Train [16/40]. 388.72 samples/sec. 329.283 ms/step.
Train [24/40]. 388.65 samples/sec. 329.349 ms/step.
Train [32/40]. 388.50 samples/sec. 329.470 ms/step.
Train [40/40]. 388.42 samples/sec. 329.539 ms/step.
Train benchmark of maxxvit_rmlp_nano_rw_256.sw_in1k done. 386.11 samples/sec, 329.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxxvit_rmlp_small_rw_256.sw_in1k created, param count: 66010516
Running inference benchmark on maxxvit_rmlp_small_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 518.41 samples/sec. 493.821 ms/step.
Infer [16/40]. 518.40 samples/sec. 493.823 ms/step.
Infer [24/40]. 518.38 samples/sec. 493.849 ms/step.
Infer [32/40]. 518.33 samples/sec. 493.893 ms/step.
Infer [40/40]. 518.30 samples/sec. 493.923 ms/step.
Inference benchmark of maxxvit_rmlp_small_rw_256.sw_in1k done. 518.25 samples/sec, 493.92 ms/step
Model maxxvit_rmlp_small_rw_256.sw_in1k created, param count: 66010516
Running train benchmark on maxxvit_rmlp_small_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 22.15 GiB memory in use. Of the allocated memory 21.52 GiB is allocated by PyTorch, and 131.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxxvit_rmlp_small_rw_256.sw_in1k created, param count: 66010516
Running train benchmark on maxxvit_rmlp_small_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 240.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxxvit_rmlp_small_rw_256.sw_in1k created, param count: 66010516
Running train benchmark on maxxvit_rmlp_small_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 201.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxxvit_rmlp_small_rw_256.sw_in1k created, param count: 66010516
Running train benchmark on maxxvit_rmlp_small_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 219.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxxvit_rmlp_small_rw_256.sw_in1k created, param count: 66010516
Running train benchmark on maxxvit_rmlp_small_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 126.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxxvit_rmlp_small_rw_256.sw_in1k created, param count: 66010516
Running train benchmark on maxxvit_rmlp_small_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
Train [8/40]. 172.49 samples/sec. 278.271 ms/step.
Train [16/40]. 172.50 samples/sec. 278.268 ms/step.
Train [24/40]. 172.49 samples/sec. 278.275 ms/step.
Train [32/40]. 172.49 samples/sec. 278.278 ms/step.
Train [40/40]. 172.49 samples/sec. 278.281 ms/step.
Train benchmark of maxxvit_rmlp_small_rw_256.sw_in1k done. 170.98 samples/sec, 278.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxxvitv2_nano_rw_256.sw_in1k created, param count: 23696611
Running inference benchmark on maxxvitv2_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1222.16 samples/sec. 209.465 ms/step.
Infer [16/40]. 1222.15 samples/sec. 209.468 ms/step.
Infer [24/40]. 1222.03 samples/sec. 209.488 ms/step.
Infer [32/40]. 1221.75 samples/sec. 209.535 ms/step.
Infer [40/40]. 1221.57 samples/sec. 209.567 ms/step.
Inference benchmark of maxxvitv2_nano_rw_256.sw_in1k done. 1221.34 samples/sec, 209.57 ms/step
Model maxxvitv2_nano_rw_256.sw_in1k created, param count: 23696611
Running train benchmark on maxxvitv2_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 554.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 31.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxxvitv2_nano_rw_256.sw_in1k created, param count: 23696611
Running train benchmark on maxxvitv2_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 322.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxxvitv2_nano_rw_256.sw_in1k created, param count: 23696611
Running train benchmark on maxxvitv2_nano_rw_256.sw_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 324.37 samples/sec. 394.611 ms/step.
Train [16/40]. 324.46 samples/sec. 394.506 ms/step.
Train [24/40]. 324.50 samples/sec. 394.458 ms/step.
Train [32/40]. 324.54 samples/sec. 394.405 ms/step.
Train [40/40]. 324.52 samples/sec. 394.424 ms/step.
Train benchmark of maxxvitv2_nano_rw_256.sw_in1k done. 323.39 samples/sec, 394.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxxvitv2_rmlp_base_rw_224.sw_in12k created, param count: 127184037
Running inference benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 445.59 samples/sec. 574.518 ms/step.
Infer [16/40]. 445.58 samples/sec. 574.528 ms/step.
Infer [24/40]. 445.56 samples/sec. 574.558 ms/step.
Infer [32/40]. 445.54 samples/sec. 574.580 ms/step.
Infer [40/40]. 445.53 samples/sec. 574.590 ms/step.
Inference benchmark of maxxvitv2_rmlp_base_rw_224.sw_in12k done. 445.49 samples/sec, 574.59 ms/step
Model maxxvitv2_rmlp_base_rw_224.sw_in12k created, param count: 127184037
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 878.06 MiB is free. Including non-PyTorch memory, this process has 22.78 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 342.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k created, param count: 127184037
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 218.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 225.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k created, param count: 127184037
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 126.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 338.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k created, param count: 127184037
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 634.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k created, param count: 127184037
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 310.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k created, param count: 127184037
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 138.17 samples/sec. 347.392 ms/step.
Train [16/40]. 138.09 samples/sec. 347.602 ms/step.
Train [24/40]. 138.04 samples/sec. 347.734 ms/step.
Train [32/40]. 138.01 samples/sec. 347.796 ms/step.
Train [40/40]. 138.00 samples/sec. 347.827 ms/step.
Train benchmark of maxxvitv2_rmlp_base_rw_224.sw_in12k done. 136.84 samples/sec, 347.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116092512
Running inference benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 445.71 samples/sec. 574.370 ms/step.
Infer [16/40]. 445.71 samples/sec. 574.368 ms/step.
Infer [24/40]. 445.71 samples/sec. 574.368 ms/step.
Infer [32/40]. 445.71 samples/sec. 574.365 ms/step.
Infer [40/40]. 445.70 samples/sec. 574.371 ms/step.
Inference benchmark of maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k done. 445.66 samples/sec, 574.37 ms/step
Model maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 920.06 MiB is free. Including non-PyTorch memory, this process has 22.74 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 341.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 292.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 372.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 685.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 354.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 138.33 samples/sec. 346.985 ms/step.
Train [16/40]. 138.34 samples/sec. 346.964 ms/step.
Train [24/40]. 138.29 samples/sec. 347.101 ms/step.
Train [32/40]. 138.26 samples/sec. 347.181 ms/step.
Train [40/40]. 138.24 samples/sec. 347.223 ms/step.
Train benchmark of maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k done. 137.09 samples/sec, 347.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running inference benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.81 GiB is free. Including non-PyTorch memory, this process has 18.83 GiB memory in use. Of the allocated memory 18.32 GiB is allocated by PyTorch, and 21.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running inference benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 138.80 samples/sec. 1383.301 ms/step.
Infer [16/40]. 138.78 samples/sec. 1383.466 ms/step.
Infer [24/40]. 138.78 samples/sec. 1383.515 ms/step.
Infer [32/40]. 138.77 samples/sec. 1383.541 ms/step.
Infer [40/40]. 138.77 samples/sec. 1383.543 ms/step.
Inference benchmark of maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k done. 138.77 samples/sec, 1383.54 ms/step
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.03 GiB is free. Including non-PyTorch memory, this process has 20.61 GiB memory in use. Of the allocated memory 20.09 GiB is allocated by PyTorch, and 25.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.83 GiB memory in use. Of the allocated memory 21.11 GiB is allocated by PyTorch, and 231.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.03 GiB is free. Including non-PyTorch memory, this process has 21.61 GiB memory in use. Of the allocated memory 20.14 GiB is allocated by PyTorch, and 998.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 648.06 MiB is free. Including non-PyTorch memory, this process has 23.01 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 547.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 499.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 196.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 273.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 141.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k created, param count: 116092512
Running train benchmark on maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 43.14 samples/sec. 370.895 ms/step.
Train [16/40]. 43.14 samples/sec. 370.875 ms/step.
Train [24/40]. 43.14 samples/sec. 370.859 ms/step.
Train [32/40]. 43.14 samples/sec. 370.879 ms/step.
Train [40/40]. 43.13 samples/sec. 370.960 ms/step.
Train benchmark of maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k done. 42.80 samples/sec, 370.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mixer_b16_224.goog_in21k_ft_in1k created, param count: 59880472
Running inference benchmark on mixer_b16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1673.57 samples/sec. 152.967 ms/step.
Infer [16/40]. 1673.67 samples/sec. 152.957 ms/step.
Infer [24/40]. 1673.69 samples/sec. 152.955 ms/step.
Infer [32/40]. 1673.68 samples/sec. 152.957 ms/step.
Infer [40/40]. 1673.66 samples/sec. 152.958 ms/step.
Inference benchmark of mixer_b16_224.goog_in21k_ft_in1k done. 1673.29 samples/sec, 152.96 ms/step
Model mixer_b16_224.goog_in21k_ft_in1k created, param count: 59880472
Running train benchmark on mixer_b16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 416.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 31.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mixer_b16_224.goog_in21k_ft_in1k created, param count: 59880472
Running train benchmark on mixer_b16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 539.56 samples/sec. 355.849 ms/step.
Train [16/40]. 539.49 samples/sec. 355.891 ms/step.
Train [24/40]. 539.38 samples/sec. 355.962 ms/step.
Train [32/40]. 539.36 samples/sec. 355.981 ms/step.
Train [40/40]. 539.30 samples/sec. 356.020 ms/step.
Train benchmark of mixer_b16_224.goog_in21k_ft_in1k done. 537.66 samples/sec, 356.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mixer_b16_224.miil_in21k_ft_in1k created, param count: 59880472
Running inference benchmark on mixer_b16_224.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1673.53 samples/sec. 152.970 ms/step.
Infer [16/40]. 1673.34 samples/sec. 152.987 ms/step.
Infer [24/40]. 1673.29 samples/sec. 152.992 ms/step.
Infer [32/40]. 1673.28 samples/sec. 152.993 ms/step.
Infer [40/40]. 1673.20 samples/sec. 153.000 ms/step.
Inference benchmark of mixer_b16_224.miil_in21k_ft_in1k done. 1672.84 samples/sec, 153.00 ms/step
Model mixer_b16_224.miil_in21k_ft_in1k created, param count: 59880472
Running train benchmark on mixer_b16_224.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 416.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 31.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mixer_b16_224.miil_in21k_ft_in1k created, param count: 59880472
Running train benchmark on mixer_b16_224.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 539.18 samples/sec. 356.098 ms/step.
Train [16/40]. 539.21 samples/sec. 356.075 ms/step.
Train [24/40]. 539.22 samples/sec. 356.071 ms/step.
Train [32/40]. 539.25 samples/sec. 356.051 ms/step.
Train [40/40]. 539.26 samples/sec. 356.044 ms/step.
Train benchmark of mixer_b16_224.miil_in21k_ft_in1k done. 537.64 samples/sec, 356.04 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mixer_l16_224.goog_in21k_ft_in1k created, param count: 208196168
Running inference benchmark on mixer_l16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 531.64 samples/sec. 481.528 ms/step.
Infer [16/40]. 531.66 samples/sec. 481.507 ms/step.
Infer [24/40]. 531.66 samples/sec. 481.510 ms/step.
Infer [32/40]. 531.66 samples/sec. 481.511 ms/step.
Infer [40/40]. 531.66 samples/sec. 481.511 ms/step.
Inference benchmark of mixer_l16_224.goog_in21k_ft_in1k done. 531.61 samples/sec, 481.51 ms/step
Model mixer_l16_224.goog_in21k_ft_in1k created, param count: 208196168
Running train benchmark on mixer_l16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 14.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mixer_l16_224.goog_in21k_ft_in1k created, param count: 208196168
Running train benchmark on mixer_l16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 522.06 MiB is free. Including non-PyTorch memory, this process has 23.13 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 15.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mixer_l16_224.goog_in21k_ft_in1k created, param count: 208196168
Running train benchmark on mixer_l16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.09 GiB is allocated by PyTorch, and 51.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mixer_l16_224.goog_in21k_ft_in1k created, param count: 208196168
Running train benchmark on mixer_l16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 258.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 40.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mixer_l16_224.goog_in21k_ft_in1k created, param count: 208196168
Running train benchmark on mixer_l16_224.goog_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 176.00 samples/sec. 363.632 ms/step.
Train [16/40]. 175.95 samples/sec. 363.743 ms/step.
Train [24/40]. 175.94 samples/sec. 363.769 ms/step.
Train [32/40]. 175.93 samples/sec. 363.785 ms/step.
Train [40/40]. 175.92 samples/sec. 363.795 ms/step.
Train benchmark of mixer_l16_224.goog_in21k_ft_in1k done. 175.06 samples/sec, 363.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mixnet_l.ft_in1k created, param count: 7329252
Running inference benchmark on mixnet_l.ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2103.21 samples/sec. 121.719 ms/step.
Infer [16/40]. 2103.25 samples/sec. 121.716 ms/step.
Infer [24/40]. 2103.25 samples/sec. 121.716 ms/step.
Infer [32/40]. 2103.26 samples/sec. 121.716 ms/step.
Infer [40/40]. 2103.25 samples/sec. 121.716 ms/step.
Inference benchmark of mixnet_l.ft_in1k done. 2102.76 samples/sec, 121.72 ms/step
Model mixnet_l.ft_in1k created, param count: 7329252
Running train benchmark on mixnet_l.ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 159.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mixnet_l.ft_in1k created, param count: 7329252
Running train benchmark on mixnet_l.ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 583.57 samples/sec. 329.009 ms/step.
Train [16/40]. 583.55 samples/sec. 329.019 ms/step.
Train [24/40]. 583.53 samples/sec. 329.030 ms/step.
Train [32/40]. 583.51 samples/sec. 329.041 ms/step.
Train [40/40]. 583.52 samples/sec. 329.038 ms/step.
Train benchmark of mixnet_l.ft_in1k done. 580.67 samples/sec, 329.04 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mixnet_m.ft_in1k created, param count: 5014382
Running inference benchmark on mixnet_m.ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2847.94 samples/sec. 89.890 ms/step.
Infer [16/40]. 2847.71 samples/sec. 89.897 ms/step.
Infer [24/40]. 2847.64 samples/sec. 89.899 ms/step.
Infer [32/40]. 2847.64 samples/sec. 89.899 ms/step.
Infer [40/40]. 2847.61 samples/sec. 89.900 ms/step.
Inference benchmark of mixnet_m.ft_in1k done. 2846.77 samples/sec, 89.90 ms/step
Model mixnet_m.ft_in1k created, param count: 5014382
Running train benchmark on mixnet_m.ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 770.34 samples/sec. 332.323 ms/step.
Train [16/40]. 770.32 samples/sec. 332.330 ms/step.
Train [24/40]. 770.33 samples/sec. 332.324 ms/step.
Train [32/40]. 770.33 samples/sec. 332.323 ms/step.
Train [40/40]. 770.32 samples/sec. 332.328 ms/step.
Train benchmark of mixnet_m.ft_in1k done. 766.64 samples/sec, 332.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mixnet_s.ft_in1k created, param count: 4134606
Running inference benchmark on mixnet_s.ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3942.62 samples/sec. 64.932 ms/step.
Infer [16/40]. 3942.43 samples/sec. 64.935 ms/step.
Infer [24/40]. 3941.18 samples/sec. 64.955 ms/step.
Infer [32/40]. 3940.70 samples/sec. 64.963 ms/step.
Infer [40/40]. 3940.39 samples/sec. 64.968 ms/step.
Inference benchmark of mixnet_s.ft_in1k done. 3938.86 samples/sec, 64.97 ms/step
Model mixnet_s.ft_in1k created, param count: 4134606
Running train benchmark on mixnet_s.ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1062.83 samples/sec. 240.866 ms/step.
Train [16/40]. 1062.95 samples/sec. 240.839 ms/step.
Train [24/40]. 1062.91 samples/sec. 240.849 ms/step.
Train [32/40]. 1062.89 samples/sec. 240.854 ms/step.
Train [40/40]. 1062.92 samples/sec. 240.846 ms/step.
Train benchmark of mixnet_s.ft_in1k done. 1057.14 samples/sec, 240.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mixnet_xl.ra_in1k created, param count: 11896768
Running inference benchmark on mixnet_xl.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1518.58 samples/sec. 168.578 ms/step.
Infer [16/40]. 1518.45 samples/sec. 168.593 ms/step.
Infer [24/40]. 1518.44 samples/sec. 168.594 ms/step.
Infer [32/40]. 1518.44 samples/sec. 168.594 ms/step.
Infer [40/40]. 1518.44 samples/sec. 168.595 ms/step.
Inference benchmark of mixnet_xl.ra_in1k done. 1518.13 samples/sec, 168.59 ms/step
Model mixnet_xl.ra_in1k created, param count: 11896768
Running train benchmark on mixnet_xl.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 136.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mixnet_xl.ra_in1k created, param count: 11896768
Running train benchmark on mixnet_xl.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 248.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mixnet_xl.ra_in1k created, param count: 11896768
Running train benchmark on mixnet_xl.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 435.11 samples/sec. 294.178 ms/step.
Train [16/40]. 435.08 samples/sec. 294.198 ms/step.
Train [24/40]. 435.09 samples/sec. 294.189 ms/step.
Train [32/40]. 435.11 samples/sec. 294.179 ms/step.
Train [40/40]. 435.11 samples/sec. 294.179 ms/step.
Train benchmark of mixnet_xl.ra_in1k done. 432.48 samples/sec, 294.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mnasnet_100.rmsp_in1k created, param count: 4383312
Running inference benchmark on mnasnet_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6677.48 samples/sec. 38.338 ms/step.
Infer [16/40]. 6675.61 samples/sec. 38.349 ms/step.
Infer [24/40]. 6674.96 samples/sec. 38.352 ms/step.
Infer [32/40]. 6674.68 samples/sec. 38.354 ms/step.
Infer [40/40]. 6674.51 samples/sec. 38.355 ms/step.
Inference benchmark of mnasnet_100.rmsp_in1k done. 6670.14 samples/sec, 38.35 ms/step
Model mnasnet_100.rmsp_in1k created, param count: 4383312
Running train benchmark on mnasnet_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1775.95 samples/sec. 144.148 ms/step.
Train [16/40]. 1775.66 samples/sec. 144.172 ms/step.
Train [24/40]. 1775.68 samples/sec. 144.171 ms/step.
Train [32/40]. 1775.72 samples/sec. 144.167 ms/step.
Train [40/40]. 1775.64 samples/sec. 144.173 ms/step.
Train benchmark of mnasnet_100.rmsp_in1k done. 1766.72 samples/sec, 144.17 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mnasnet_small.lamb_in1k created, param count: 2030264
Running inference benchmark on mnasnet_small.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 18849.76 samples/sec. 13.581 ms/step.
Infer [16/40]. 18848.95 samples/sec. 13.582 ms/step.
Infer [24/40]. 18849.48 samples/sec. 13.581 ms/step.
Infer [32/40]. 18849.83 samples/sec. 13.581 ms/step.
Infer [40/40]. 18849.54 samples/sec. 13.581 ms/step.
Inference benchmark of mnasnet_small.lamb_in1k done. 18819.10 samples/sec, 13.58 ms/step
Model mnasnet_small.lamb_in1k created, param count: 2030264
Running train benchmark on mnasnet_small.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 4005.78 samples/sec. 63.908 ms/step.
Train [16/40]. 4005.54 samples/sec. 63.912 ms/step.
Train [24/40]. 4005.61 samples/sec. 63.910 ms/step.
Train [32/40]. 4005.64 samples/sec. 63.910 ms/step.
Train [40/40]. 4005.59 samples/sec. 63.911 ms/step.
Train benchmark of mnasnet_small.lamb_in1k done. 3963.21 samples/sec, 63.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv2_050.lamb_in1k created, param count: 1968680
Running inference benchmark on mobilenetv2_050.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 11419.75 samples/sec. 22.417 ms/step.
Infer [16/40]. 11419.48 samples/sec. 22.418 ms/step.
Infer [24/40]. 11418.75 samples/sec. 22.419 ms/step.
Infer [32/40]. 11418.23 samples/sec. 22.420 ms/step.
Infer [40/40]. 11418.02 samples/sec. 22.421 ms/step.
Inference benchmark of mobilenetv2_050.lamb_in1k done. 11405.76 samples/sec, 22.42 ms/step
Model mobilenetv2_050.lamb_in1k created, param count: 1968680
Running train benchmark on mobilenetv2_050.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2666.23 samples/sec. 96.016 ms/step.
Train [16/40]. 2666.05 samples/sec. 96.022 ms/step.
Train [24/40]. 2665.60 samples/sec. 96.038 ms/step.
Train [32/40]. 2665.71 samples/sec. 96.035 ms/step.
Train [40/40]. 2665.72 samples/sec. 96.034 ms/step.
Train benchmark of mobilenetv2_050.lamb_in1k done. 2648.35 samples/sec, 96.03 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv2_100.ra_in1k created, param count: 3504872
Running inference benchmark on mobilenetv2_100.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5764.32 samples/sec. 44.411 ms/step.
Infer [16/40]. 5763.86 samples/sec. 44.415 ms/step.
Infer [24/40]. 5763.68 samples/sec. 44.416 ms/step.
Infer [32/40]. 5763.70 samples/sec. 44.416 ms/step.
Infer [40/40]. 5763.68 samples/sec. 44.416 ms/step.
Inference benchmark of mobilenetv2_100.ra_in1k done. 5760.42 samples/sec, 44.42 ms/step
Model mobilenetv2_100.ra_in1k created, param count: 3504872
Running train benchmark on mobilenetv2_100.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1498.19 samples/sec. 170.873 ms/step.
Train [16/40]. 1498.27 samples/sec. 170.864 ms/step.
Train [24/40]. 1498.16 samples/sec. 170.877 ms/step.
Train [32/40]. 1498.25 samples/sec. 170.866 ms/step.
Train [40/40]. 1498.28 samples/sec. 170.863 ms/step.
Train benchmark of mobilenetv2_100.ra_in1k done. 1491.51 samples/sec, 170.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv2_110d.ra_in1k created, param count: 4516520
Running inference benchmark on mobilenetv2_110d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4368.41 samples/sec. 58.603 ms/step.
Infer [16/40]. 4368.28 samples/sec. 58.604 ms/step.
Infer [24/40]. 4368.22 samples/sec. 58.605 ms/step.
Infer [32/40]. 4368.24 samples/sec. 58.605 ms/step.
Infer [40/40]. 4368.19 samples/sec. 58.606 ms/step.
Inference benchmark of mobilenetv2_110d.ra_in1k done. 4366.27 samples/sec, 58.61 ms/step
Model mobilenetv2_110d.ra_in1k created, param count: 4516520
Running train benchmark on mobilenetv2_110d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 169.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilenetv2_110d.ra_in1k created, param count: 4516520
Running train benchmark on mobilenetv2_110d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 1170.84 samples/sec. 163.984 ms/step.
Train [16/40]. 1170.88 samples/sec. 163.980 ms/step.
Train [24/40]. 1170.84 samples/sec. 163.985 ms/step.
Train [32/40]. 1170.78 samples/sec. 163.993 ms/step.
Train [40/40]. 1170.76 samples/sec. 163.996 ms/step.
Train benchmark of mobilenetv2_110d.ra_in1k done. 1164.63 samples/sec, 164.00 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv2_120d.ra_in1k created, param count: 5831144
Running inference benchmark on mobilenetv2_120d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3169.65 samples/sec. 80.766 ms/step.
Infer [16/40]. 3169.47 samples/sec. 80.771 ms/step.
Infer [24/40]. 3169.53 samples/sec. 80.769 ms/step.
Infer [32/40]. 3169.47 samples/sec. 80.771 ms/step.
Infer [40/40]. 3169.57 samples/sec. 80.768 ms/step.
Inference benchmark of mobilenetv2_120d.ra_in1k done. 3168.51 samples/sec, 80.77 ms/step
Model mobilenetv2_120d.ra_in1k created, param count: 5831144
Running train benchmark on mobilenetv2_120d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 98.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilenetv2_120d.ra_in1k created, param count: 5831144
Running train benchmark on mobilenetv2_120d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 325.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilenetv2_120d.ra_in1k created, param count: 5831144
Running train benchmark on mobilenetv2_120d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 888.67 samples/sec. 144.036 ms/step.
Train [16/40]. 888.58 samples/sec. 144.050 ms/step.
Train [24/40]. 888.61 samples/sec. 144.046 ms/step.
Train [32/40]. 888.61 samples/sec. 144.045 ms/step.
Train [40/40]. 888.59 samples/sec. 144.048 ms/step.
Train benchmark of mobilenetv2_120d.ra_in1k done. 882.97 samples/sec, 144.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv2_140.ra_in1k created, param count: 6108776
Running inference benchmark on mobilenetv2_140.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3914.09 samples/sec. 65.405 ms/step.
Infer [16/40]. 3914.07 samples/sec. 65.405 ms/step.
Infer [24/40]. 3913.93 samples/sec. 65.407 ms/step.
Infer [32/40]. 3913.84 samples/sec. 65.409 ms/step.
Infer [40/40]. 3913.75 samples/sec. 65.410 ms/step.
Inference benchmark of mobilenetv2_140.ra_in1k done. 3912.22 samples/sec, 65.41 ms/step
Model mobilenetv2_140.ra_in1k created, param count: 6108776
Running train benchmark on mobilenetv2_140.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 216.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilenetv2_140.ra_in1k created, param count: 6108776
Running train benchmark on mobilenetv2_140.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 1052.58 samples/sec. 182.408 ms/step.
Train [16/40]. 1052.54 samples/sec. 182.416 ms/step.
Train [24/40]. 1052.54 samples/sec. 182.415 ms/step.
Train [32/40]. 1052.52 samples/sec. 182.420 ms/step.
Train [40/40]. 1052.51 samples/sec. 182.420 ms/step.
Train benchmark of mobilenetv2_140.ra_in1k done. 1047.94 samples/sec, 182.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv3_large_100.miil_in21k_ft_in1k created, param count: 5483032
Running inference benchmark on mobilenetv3_large_100.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 8088.89 samples/sec. 31.648 ms/step.
Infer [16/40]. 8087.78 samples/sec. 31.653 ms/step.
Infer [24/40]. 8087.32 samples/sec. 31.654 ms/step.
Infer [32/40]. 8087.09 samples/sec. 31.655 ms/step.
Infer [40/40]. 8087.20 samples/sec. 31.655 ms/step.
Inference benchmark of mobilenetv3_large_100.miil_in21k_ft_in1k done. 8080.74 samples/sec, 31.66 ms/step
Model mobilenetv3_large_100.miil_in21k_ft_in1k created, param count: 5483032
Running train benchmark on mobilenetv3_large_100.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2014.38 samples/sec. 127.086 ms/step.
Train [16/40]. 2014.30 samples/sec. 127.091 ms/step.
Train [24/40]. 2014.33 samples/sec. 127.089 ms/step.
Train [32/40]. 2014.35 samples/sec. 127.088 ms/step.
Train [40/40]. 2014.36 samples/sec. 127.088 ms/step.
Train benchmark of mobilenetv3_large_100.miil_in21k_ft_in1k done. 2002.82 samples/sec, 127.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv3_large_100.ra_in1k created, param count: 5483032
Running inference benchmark on mobilenetv3_large_100.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 8087.23 samples/sec. 31.655 ms/step.
Infer [16/40]. 8087.04 samples/sec. 31.656 ms/step.
Infer [24/40]. 8086.98 samples/sec. 31.656 ms/step.
Infer [32/40]. 8086.65 samples/sec. 31.657 ms/step.
Infer [40/40]. 8086.77 samples/sec. 31.657 ms/step.
Inference benchmark of mobilenetv3_large_100.ra_in1k done. 8080.31 samples/sec, 31.66 ms/step
Model mobilenetv3_large_100.ra_in1k created, param count: 5483032
Running train benchmark on mobilenetv3_large_100.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2013.74 samples/sec. 127.127 ms/step.
Train [16/40]. 2013.53 samples/sec. 127.140 ms/step.
Train [24/40]. 2013.50 samples/sec. 127.142 ms/step.
Train [32/40]. 2013.44 samples/sec. 127.145 ms/step.
Train [40/40]. 2013.41 samples/sec. 127.147 ms/step.
Train benchmark of mobilenetv3_large_100.ra_in1k done. 2001.96 samples/sec, 127.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv3_rw.rmsp_in1k created, param count: 5479918
Running inference benchmark on mobilenetv3_rw.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 8264.09 samples/sec. 30.977 ms/step.
Infer [16/40]. 8264.37 samples/sec. 30.976 ms/step.
Infer [24/40]. 8263.39 samples/sec. 30.980 ms/step.
Infer [32/40]. 8262.68 samples/sec. 30.983 ms/step.
Infer [40/40]. 8262.22 samples/sec. 30.984 ms/step.
Inference benchmark of mobilenetv3_rw.rmsp_in1k done. 8255.37 samples/sec, 30.98 ms/step
Model mobilenetv3_rw.rmsp_in1k created, param count: 5479918
Running train benchmark on mobilenetv3_rw.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2034.77 samples/sec. 125.813 ms/step.
Train [16/40]. 2034.65 samples/sec. 125.820 ms/step.
Train [24/40]. 2034.70 samples/sec. 125.817 ms/step.
Train [32/40]. 2034.66 samples/sec. 125.819 ms/step.
Train [40/40]. 2034.63 samples/sec. 125.821 ms/step.
Train benchmark of mobilenetv3_rw.rmsp_in1k done. 2023.04 samples/sec, 125.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv3_small_050.lamb_in1k created, param count: 1593224
Running inference benchmark on mobilenetv3_small_050.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 27997.97 samples/sec. 9.144 ms/step.
Infer [16/40]. 27974.39 samples/sec. 9.151 ms/step.
Infer [24/40]. 27976.83 samples/sec. 9.150 ms/step.
Infer [32/40]. 27963.03 samples/sec. 9.155 ms/step.
Infer [40/40]. 27964.14 samples/sec. 9.155 ms/step.
Inference benchmark of mobilenetv3_small_050.lamb_in1k done. 27902.53 samples/sec, 9.15 ms/step
Model mobilenetv3_small_050.lamb_in1k created, param count: 1593224
Running train benchmark on mobilenetv3_small_050.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 7248.79 samples/sec. 35.316 ms/step.
Train [16/40]. 7248.99 samples/sec. 35.315 ms/step.
Train [24/40]. 7248.93 samples/sec. 35.316 ms/step.
Train [32/40]. 7248.19 samples/sec. 35.319 ms/step.
Train [40/40]. 7248.75 samples/sec. 35.316 ms/step.
Train benchmark of mobilenetv3_small_050.lamb_in1k done. 7137.68 samples/sec, 35.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv3_small_075.lamb_in1k created, param count: 2041872
Running inference benchmark on mobilenetv3_small_075.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 28111.30 samples/sec. 9.107 ms/step.
Infer [16/40]. 28097.35 samples/sec. 9.111 ms/step.
Infer [24/40]. 28081.36 samples/sec. 9.116 ms/step.
Infer [32/40]. 28086.31 samples/sec. 9.115 ms/step.
Infer [40/40]. 28089.28 samples/sec. 9.114 ms/step.
Inference benchmark of mobilenetv3_small_075.lamb_in1k done. 28029.02 samples/sec, 9.11 ms/step
Model mobilenetv3_small_075.lamb_in1k created, param count: 2041872
Running train benchmark on mobilenetv3_small_075.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 6252.63 samples/sec. 40.943 ms/step.
Train [16/40]. 6251.22 samples/sec. 40.952 ms/step.
Train [24/40]. 6251.82 samples/sec. 40.948 ms/step.
Train [32/40]. 6251.11 samples/sec. 40.953 ms/step.
Train [40/40]. 6250.65 samples/sec. 40.956 ms/step.
Train benchmark of mobilenetv3_small_075.lamb_in1k done. 6168.54 samples/sec, 40.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilenetv3_small_100.lamb_in1k created, param count: 2542856
Running inference benchmark on mobilenetv3_small_100.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 27845.58 samples/sec. 9.194 ms/step.
Infer [16/40]. 27880.25 samples/sec. 9.182 ms/step.
Infer [24/40]. 27877.83 samples/sec. 9.183 ms/step.
Infer [32/40]. 27876.90 samples/sec. 9.183 ms/step.
Infer [40/40]. 27871.84 samples/sec. 9.185 ms/step.
Inference benchmark of mobilenetv3_small_100.lamb_in1k done. 27813.02 samples/sec, 9.19 ms/step
Model mobilenetv3_small_100.lamb_in1k created, param count: 2542856
Running train benchmark on mobilenetv3_small_100.lamb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 5875.65 samples/sec. 43.570 ms/step.
Train [16/40]. 5873.76 samples/sec. 43.584 ms/step.
Train [24/40]. 5872.07 samples/sec. 43.596 ms/step.
Train [32/40]. 5873.19 samples/sec. 43.588 ms/step.
Train [40/40]. 5874.07 samples/sec. 43.581 ms/step.
Train benchmark of mobilenetv3_small_100.lamb_in1k done. 5801.07 samples/sec, 43.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevit_s.cvnets_in1k created, param count: 5578632
Running inference benchmark on mobilevit_s.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2171.31 samples/sec. 117.901 ms/step.
Infer [16/40]. 2171.26 samples/sec. 117.904 ms/step.
Infer [24/40]. 2171.22 samples/sec. 117.906 ms/step.
Infer [32/40]. 2171.21 samples/sec. 117.907 ms/step.
Infer [40/40]. 2171.23 samples/sec. 117.906 ms/step.
Inference benchmark of mobilevit_s.cvnets_in1k done. 2170.68 samples/sec, 117.91 ms/step
Model mobilevit_s.cvnets_in1k created, param count: 5578632
Running train benchmark on mobilevit_s.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevit_s.cvnets_in1k created, param count: 5578632
Running train benchmark on mobilevit_s.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 486.06 MiB is free. Including non-PyTorch memory, this process has 23.17 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 184.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevit_s.cvnets_in1k created, param count: 5578632
Running train benchmark on mobilevit_s.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 594.40 samples/sec. 215.345 ms/step.
Train [16/40]. 594.40 samples/sec. 215.343 ms/step.
Train [24/40]. 594.42 samples/sec. 215.334 ms/step.
Train [32/40]. 594.45 samples/sec. 215.327 ms/step.
Train [40/40]. 594.45 samples/sec. 215.325 ms/step.
Train benchmark of mobilevit_s.cvnets_in1k done. 591.49 samples/sec, 215.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevit_xs.cvnets_in1k created, param count: 2317848
Running inference benchmark on mobilevit_xs.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2642.85 samples/sec. 96.865 ms/step.
Infer [16/40]. 2642.75 samples/sec. 96.869 ms/step.
Infer [24/40]. 2642.74 samples/sec. 96.869 ms/step.
Infer [32/40]. 2642.73 samples/sec. 96.870 ms/step.
Infer [40/40]. 2642.78 samples/sec. 96.868 ms/step.
Inference benchmark of mobilevit_xs.cvnets_in1k done. 2642.03 samples/sec, 96.87 ms/step
Model mobilevit_xs.cvnets_in1k created, param count: 2317848
Running train benchmark on mobilevit_xs.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 130.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevit_xs.cvnets_in1k created, param count: 2317848
Running train benchmark on mobilevit_xs.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.10 GiB is allocated by PyTorch, and 32.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevit_xs.cvnets_in1k created, param count: 2317848
Running train benchmark on mobilevit_xs.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 736.61 samples/sec. 173.770 ms/step.
Train [16/40]. 736.48 samples/sec. 173.800 ms/step.
Train [24/40]. 736.49 samples/sec. 173.798 ms/step.
Train [32/40]. 736.48 samples/sec. 173.800 ms/step.
Train [40/40]. 736.46 samples/sec. 173.804 ms/step.
Train benchmark of mobilevit_xs.cvnets_in1k done. 732.14 samples/sec, 173.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevit_xxs.cvnets_in1k created, param count: 1272024
Running inference benchmark on mobilevit_xxs.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 5937.21 samples/sec. 43.118 ms/step.
Infer [16/40]. 5937.32 samples/sec. 43.117 ms/step.
Infer [24/40]. 5937.44 samples/sec. 43.116 ms/step.
Infer [32/40]. 5937.42 samples/sec. 43.116 ms/step.
Infer [40/40]. 5937.44 samples/sec. 43.116 ms/step.
Inference benchmark of mobilevit_xxs.cvnets_in1k done. 5933.87 samples/sec, 43.12 ms/step
Model mobilevit_xxs.cvnets_in1k created, param count: 1272024
Running train benchmark on mobilevit_xxs.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Train [8/40]. 1481.02 samples/sec. 172.853 ms/step.
Train [16/40]. 1480.99 samples/sec. 172.858 ms/step.
Train [24/40]. 1480.96 samples/sec. 172.861 ms/step.
Train [32/40]. 1480.97 samples/sec. 172.860 ms/step.
Train [40/40]. 1480.97 samples/sec. 172.860 ms/step.
Train benchmark of mobilevit_xxs.cvnets_in1k done. 1472.65 samples/sec, 172.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_050.cvnets_in1k created, param count: 1370593
Running inference benchmark on mobilevitv2_050.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 5008.10 samples/sec. 51.117 ms/step.
Infer [16/40]. 5007.87 samples/sec. 51.120 ms/step.
Infer [24/40]. 5007.72 samples/sec. 51.121 ms/step.
Infer [32/40]. 5007.81 samples/sec. 51.120 ms/step.
Infer [40/40]. 5007.78 samples/sec. 51.120 ms/step.
Inference benchmark of mobilevitv2_050.cvnets_in1k done. 5005.28 samples/sec, 51.12 ms/step
Model mobilevitv2_050.cvnets_in1k created, param count: 1370593
Running train benchmark on mobilevitv2_050.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Train [8/40]. 1370.93 samples/sec. 186.735 ms/step.
Train [16/40]. 1370.55 samples/sec. 186.786 ms/step.
Train [24/40]. 1370.50 samples/sec. 186.793 ms/step.
Train [32/40]. 1370.43 samples/sec. 186.803 ms/step.
Train [40/40]. 1370.36 samples/sec. 186.813 ms/step.
Train benchmark of mobilevitv2_050.cvnets_in1k done. 1363.66 samples/sec, 186.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_075.cvnets_in1k created, param count: 2866009
Running inference benchmark on mobilevitv2_075.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 3215.13 samples/sec. 79.624 ms/step.
Infer [16/40]. 3215.14 samples/sec. 79.623 ms/step.
Infer [24/40]. 3215.08 samples/sec. 79.625 ms/step.
Infer [32/40]. 3215.02 samples/sec. 79.626 ms/step.
Infer [40/40]. 3215.00 samples/sec. 79.627 ms/step.
Inference benchmark of mobilevitv2_075.cvnets_in1k done. 3213.93 samples/sec, 79.63 ms/step
Model mobilevitv2_075.cvnets_in1k created, param count: 2866009
Running train benchmark on mobilevitv2_075.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 182.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 66.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_075.cvnets_in1k created, param count: 2866009
Running train benchmark on mobilevitv2_075.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
Train [8/40]. 927.27 samples/sec. 207.059 ms/step.
Train [16/40]. 927.22 samples/sec. 207.071 ms/step.
Train [24/40]. 927.25 samples/sec. 207.064 ms/step.
Train [32/40]. 927.25 samples/sec. 207.063 ms/step.
Train [40/40]. 927.27 samples/sec. 207.060 ms/step.
Train benchmark of mobilevitv2_075.cvnets_in1k done. 922.89 samples/sec, 207.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_100.cvnets_in1k created, param count: 4901841
Running inference benchmark on mobilevitv2_100.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 2374.26 samples/sec. 107.823 ms/step.
Infer [16/40]. 2374.21 samples/sec. 107.826 ms/step.
Infer [24/40]. 2374.25 samples/sec. 107.824 ms/step.
Infer [32/40]. 2374.23 samples/sec. 107.824 ms/step.
Infer [40/40]. 2374.20 samples/sec. 107.826 ms/step.
Inference benchmark of mobilevitv2_100.cvnets_in1k done. 2373.58 samples/sec, 107.83 ms/step
Model mobilevitv2_100.cvnets_in1k created, param count: 4901841
Running train benchmark on mobilevitv2_100.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 816.06 MiB is free. Including non-PyTorch memory, this process has 22.84 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 128.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_100.cvnets_in1k created, param count: 4901841
Running train benchmark on mobilevitv2_100.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 120.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_100.cvnets_in1k created, param count: 4901841
Running train benchmark on mobilevitv2_100.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 704.23 samples/sec. 181.758 ms/step.
Train [16/40]. 704.24 samples/sec. 181.756 ms/step.
Train [24/40]. 704.23 samples/sec. 181.759 ms/step.
Train [32/40]. 704.20 samples/sec. 181.766 ms/step.
Train [40/40]. 704.24 samples/sec. 181.756 ms/step.
Train benchmark of mobilevitv2_100.cvnets_in1k done. 700.64 samples/sec, 181.76 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_125.cvnets_in1k created, param count: 7478089
Running inference benchmark on mobilevitv2_125.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1868.09 samples/sec. 137.039 ms/step.
Infer [16/40]. 1868.06 samples/sec. 137.041 ms/step.
Infer [24/40]. 1868.03 samples/sec. 137.043 ms/step.
Infer [32/40]. 1868.03 samples/sec. 137.043 ms/step.
Infer [40/40]. 1868.02 samples/sec. 137.043 ms/step.
Inference benchmark of mobilevitv2_125.cvnets_in1k done. 1867.59 samples/sec, 137.04 ms/step
Model mobilevitv2_125.cvnets_in1k created, param count: 7478089
Running train benchmark on mobilevitv2_125.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 296.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 127.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_125.cvnets_in1k created, param count: 7478089
Running train benchmark on mobilevitv2_125.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 480.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 284.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 187.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_125.cvnets_in1k created, param count: 7478089
Running train benchmark on mobilevitv2_125.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 85.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_125.cvnets_in1k created, param count: 7478089
Running train benchmark on mobilevitv2_125.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
Train [8/40]. 553.29 samples/sec. 173.508 ms/step.
Train [16/40]. 553.43 samples/sec. 173.464 ms/step.
Train [24/40]. 553.46 samples/sec. 173.455 ms/step.
Train [32/40]. 553.48 samples/sec. 173.447 ms/step.
Train [40/40]. 553.54 samples/sec. 173.428 ms/step.
Train benchmark of mobilevitv2_125.cvnets_in1k done. 550.67 samples/sec, 173.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_150.cvnets_in1k created, param count: 10594753
Running inference benchmark on mobilevitv2_150.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1537.36 samples/sec. 166.520 ms/step.
Infer [16/40]. 1537.19 samples/sec. 166.538 ms/step.
Infer [24/40]. 1537.11 samples/sec. 166.547 ms/step.
Infer [32/40]. 1537.07 samples/sec. 166.550 ms/step.
Infer [40/40]. 1537.05 samples/sec. 166.553 ms/step.
Inference benchmark of mobilevitv2_150.cvnets_in1k done. 1536.74 samples/sec, 166.55 ms/step
Model mobilevitv2_150.cvnets_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.54 GiB is free. Including non-PyTorch memory, this process has 21.10 GiB memory in use. Of the allocated memory 20.49 GiB is allocated by PyTorch, and 108.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_150.cvnets_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 288.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 171.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_150.cvnets_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.12 GiB is allocated by PyTorch, and 22.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_150.cvnets_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
Train [8/40]. 453.47 samples/sec. 211.702 ms/step.
Train [16/40]. 453.31 samples/sec. 211.776 ms/step.
Train [24/40]. 453.23 samples/sec. 211.812 ms/step.
Train [32/40]. 453.19 samples/sec. 211.832 ms/step.
Train [40/40]. 453.21 samples/sec. 211.823 ms/step.
Train benchmark of mobilevitv2_150.cvnets_in1k done. 451.11 samples/sec, 211.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_150.cvnets_in22k_ft_in1k created, param count: 10594753
Running inference benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1537.05 samples/sec. 166.553 ms/step.
Infer [16/40]. 1537.12 samples/sec. 166.545 ms/step.
Infer [24/40]. 1537.15 samples/sec. 166.542 ms/step.
Infer [32/40]. 1537.16 samples/sec. 166.541 ms/step.
Infer [40/40]. 1537.13 samples/sec. 166.544 ms/step.
Inference benchmark of mobilevitv2_150.cvnets_in22k_ft_in1k done. 1536.82 samples/sec, 166.54 ms/step
Model mobilevitv2_150.cvnets_in22k_ft_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.54 GiB is free. Including non-PyTorch memory, this process has 21.10 GiB memory in use. Of the allocated memory 20.49 GiB is allocated by PyTorch, and 108.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 288.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 171.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.12 GiB is allocated by PyTorch, and 22.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
Train [8/40]. 453.57 samples/sec. 211.653 ms/step.
Train [16/40]. 453.58 samples/sec. 211.651 ms/step.
Train [24/40]. 453.47 samples/sec. 211.702 ms/step.
Train [32/40]. 453.42 samples/sec. 211.726 ms/step.
Train [40/40]. 453.38 samples/sec. 211.742 ms/step.
Train benchmark of mobilevitv2_150.cvnets_in22k_ft_in1k done. 451.30 samples/sec, 211.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running inference benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 21.33 GiB memory in use. Of the allocated memory 12.29 GiB is allocated by PyTorch, and 8.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running inference benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 663.36 samples/sec. 289.437 ms/step.
Infer [16/40]. 663.34 samples/sec. 289.445 ms/step.
Infer [24/40]. 663.30 samples/sec. 289.462 ms/step.
Infer [32/40]. 663.30 samples/sec. 289.463 ms/step.
Infer [40/40]. 663.30 samples/sec. 289.462 ms/step.
Inference benchmark of mobilevitv2_150.cvnets_in22k_ft_in1k_384 done. 663.20 samples/sec, 289.46 ms/step
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 638.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 108.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.89 GiB is allocated by PyTorch, and 231.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.14 GiB is free. Including non-PyTorch memory, this process has 20.50 GiB memory in use. Of the allocated memory 19.67 GiB is allocated by PyTorch, and 334.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 406.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.36 GiB is allocated by PyTorch, and 395.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 622.06 MiB is free. Including non-PyTorch memory, this process has 23.03 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 448.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 217.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model mobilevitv2_150.cvnets_in22k_ft_in1k_384 created, param count: 10594753
Running train benchmark on mobilevitv2_150.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 201.04 samples/sec. 159.171 ms/step.
Train [16/40]. 200.90 samples/sec. 159.287 ms/step.
Train [24/40]. 200.81 samples/sec. 159.358 ms/step.
Train [32/40]. 200.80 samples/sec. 159.360 ms/step.
Train [40/40]. 200.81 samples/sec. 159.357 ms/step.
Train benchmark of mobilevitv2_150.cvnets_in22k_ft_in1k_384 done. 199.75 samples/sec, 159.36 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_175.cvnets_in1k created, param count: 14251833
Running inference benchmark on mobilevitv2_175.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1297.99 samples/sec. 197.228 ms/step.
Infer [16/40]. 1298.02 samples/sec. 197.224 ms/step.
Infer [24/40]. 1298.07 samples/sec. 197.216 ms/step.
Infer [32/40]. 1298.05 samples/sec. 197.219 ms/step.
Infer [40/40]. 1298.04 samples/sec. 197.220 ms/step.
Inference benchmark of mobilevitv2_175.cvnets_in1k done. 1297.75 samples/sec, 197.22 ms/step
Model mobilevitv2_175.cvnets_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.66 GiB is free. Including non-PyTorch memory, this process has 20.98 GiB memory in use. Of the allocated memory 20.38 GiB is allocated by PyTorch, and 103.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_175.cvnets_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 672.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 474.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 163.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_175.cvnets_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 21.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_175.cvnets_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 131.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mobilevitv2_175.cvnets_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 387.81 samples/sec. 165.029 ms/step.
Train [16/40]. 387.78 samples/sec. 165.042 ms/step.
Train [24/40]. 387.77 samples/sec. 165.047 ms/step.
Train [32/40]. 387.73 samples/sec. 165.064 ms/step.
Train [40/40]. 387.72 samples/sec. 165.067 ms/step.
Train benchmark of mobilevitv2_175.cvnets_in1k done. 385.61 samples/sec, 165.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_175.cvnets_in22k_ft_in1k created, param count: 14251833
Running inference benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1298.52 samples/sec. 197.148 ms/step.
Infer [16/40]. 1298.46 samples/sec. 197.157 ms/step.
Infer [24/40]. 1298.45 samples/sec. 197.159 ms/step.
Infer [32/40]. 1298.41 samples/sec. 197.164 ms/step.
Infer [40/40]. 1298.41 samples/sec. 197.164 ms/step.
Inference benchmark of mobilevitv2_175.cvnets_in22k_ft_in1k done. 1298.15 samples/sec, 197.16 ms/step
Model mobilevitv2_175.cvnets_in22k_ft_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.66 GiB is free. Including non-PyTorch memory, this process has 20.98 GiB memory in use. Of the allocated memory 20.38 GiB is allocated by PyTorch, and 103.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 672.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 474.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 163.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 21.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 175.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 387.32 samples/sec. 165.238 ms/step.
Train [16/40]. 387.30 samples/sec. 165.247 ms/step.
Train [24/40]. 387.23 samples/sec. 165.277 ms/step.
Train [32/40]. 387.29 samples/sec. 165.250 ms/step.
Train [40/40]. 387.31 samples/sec. 165.243 ms/step.
Train benchmark of mobilevitv2_175.cvnets_in22k_ft_in1k done. 385.27 samples/sec, 165.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running inference benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.88 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.80 GiB is free. Including non-PyTorch memory, this process has 16.84 GiB memory in use. Of the allocated memory 14.27 GiB is allocated by PyTorch, and 2.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running inference benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.91 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.82 GiB is free. Including non-PyTorch memory, this process has 18.82 GiB memory in use. Of the allocated memory 10.72 GiB is allocated by PyTorch, and 7.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running inference benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 560.79 samples/sec. 228.248 ms/step.
Infer [16/40]. 560.81 samples/sec. 228.242 ms/step.
Infer [24/40]. 560.81 samples/sec. 228.240 ms/step.
Infer [32/40]. 560.81 samples/sec. 228.242 ms/step.
Infer [40/40]. 560.81 samples/sec. 228.241 ms/step.
Inference benchmark of mobilevitv2_175.cvnets_in22k_ft_in1k_384 done. 560.71 samples/sec, 228.24 ms/step
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.94 GiB. GPU 0 has a total capacty of 23.65 GiB of which 918.06 MiB is free. Including non-PyTorch memory, this process has 22.74 GiB memory in use. Of the allocated memory 22.15 GiB is allocated by PyTorch, and 103.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 23.65 GiB of which 402.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 223.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.94 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.84 GiB is free. Including non-PyTorch memory, this process has 19.80 GiB memory in use. Of the allocated memory 18.98 GiB is allocated by PyTorch, and 333.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 21.04 GiB memory in use. Of the allocated memory 20.16 GiB is allocated by PyTorch, and 389.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1008.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 902.06 MiB is free. Including non-PyTorch memory, this process has 22.76 GiB memory in use. Of the allocated memory 21.83 GiB is allocated by PyTorch, and 443.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 222.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model mobilevitv2_175.cvnets_in22k_ft_in1k_384 created, param count: 14251833
Running train benchmark on mobilevitv2_175.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 168.68 samples/sec. 189.710 ms/step.
Train [16/40]. 168.66 samples/sec. 189.734 ms/step.
Train [24/40]. 168.67 samples/sec. 189.724 ms/step.
Train [32/40]. 168.65 samples/sec. 189.740 ms/step.
Train [40/40]. 168.65 samples/sec. 189.738 ms/step.
Train benchmark of mobilevitv2_175.cvnets_in22k_ft_in1k_384 done. 167.84 samples/sec, 189.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_200.cvnets_in1k created, param count: 18449329
Running inference benchmark on mobilevitv2_200.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1119.40 samples/sec. 228.694 ms/step.
Infer [16/40]. 1119.35 samples/sec. 228.704 ms/step.
Infer [24/40]. 1119.30 samples/sec. 228.714 ms/step.
Infer [32/40]. 1119.31 samples/sec. 228.712 ms/step.
Infer [40/40]. 1119.32 samples/sec. 228.711 ms/step.
Inference benchmark of mobilevitv2_200.cvnets_in1k done. 1119.12 samples/sec, 228.71 ms/step
Model mobilevitv2_200.cvnets_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.80 GiB is free. Including non-PyTorch memory, this process has 19.84 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 77.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_200.cvnets_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.54 GiB is free. Including non-PyTorch memory, this process has 21.10 GiB memory in use. Of the allocated memory 20.48 GiB is allocated by PyTorch, and 129.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_200.cvnets_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 808.06 MiB is free. Including non-PyTorch memory, this process has 22.85 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 181.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_200.cvnets_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 109.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mobilevitv2_200.cvnets_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 337.75 samples/sec. 189.487 ms/step.
Train [16/40]. 337.77 samples/sec. 189.479 ms/step.
Train [24/40]. 337.76 samples/sec. 189.485 ms/step.
Train [32/40]. 337.72 samples/sec. 189.507 ms/step.
Train [40/40]. 337.73 samples/sec. 189.500 ms/step.
Train benchmark of mobilevitv2_200.cvnets_in1k done. 336.14 samples/sec, 189.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_200.cvnets_in22k_ft_in1k created, param count: 18449329
Running inference benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1119.44 samples/sec. 228.685 ms/step.
Infer [16/40]. 1119.50 samples/sec. 228.673 ms/step.
Infer [24/40]. 1119.49 samples/sec. 228.675 ms/step.
Infer [32/40]. 1119.48 samples/sec. 228.678 ms/step.
Infer [40/40]. 1119.48 samples/sec. 228.677 ms/step.
Inference benchmark of mobilevitv2_200.cvnets_in22k_ft_in1k done. 1119.28 samples/sec, 228.68 ms/step
Model mobilevitv2_200.cvnets_in22k_ft_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.80 GiB is free. Including non-PyTorch memory, this process has 19.84 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 77.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.54 GiB is free. Including non-PyTorch memory, this process has 21.10 GiB memory in use. Of the allocated memory 20.48 GiB is allocated by PyTorch, and 129.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 808.06 MiB is free. Including non-PyTorch memory, this process has 22.85 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 181.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 140.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 337.49 samples/sec. 189.636 ms/step.
Train [16/40]. 337.53 samples/sec. 189.614 ms/step.
Train [24/40]. 337.56 samples/sec. 189.598 ms/step.
Train [32/40]. 337.55 samples/sec. 189.601 ms/step.
Train [40/40]. 337.56 samples/sec. 189.596 ms/step.
Train benchmark of mobilevitv2_200.cvnets_in22k_ft_in1k done. 335.89 samples/sec, 189.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running inference benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.81 GiB is free. Including non-PyTorch memory, this process has 16.83 GiB memory in use. Of the allocated memory 16.26 GiB is allocated by PyTorch, and 77.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running inference benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 21.33 GiB memory in use. Of the allocated memory 12.21 GiB is allocated by PyTorch, and 8.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running inference benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 484.14 samples/sec. 264.389 ms/step.
Infer [16/40]. 484.13 samples/sec. 264.393 ms/step.
Infer [24/40]. 484.13 samples/sec. 264.390 ms/step.
Infer [32/40]. 484.13 samples/sec. 264.392 ms/step.
Infer [40/40]. 484.13 samples/sec. 264.394 ms/step.
Inference benchmark of mobilevitv2_200.cvnets_in22k_ft_in1k_384 done. 484.05 samples/sec, 264.39 ms/step
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 21.33 GiB memory in use. Of the allocated memory 20.76 GiB is allocated by PyTorch, and 77.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 636.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.34 GiB is allocated by PyTorch, and 189.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.18 GiB is free. Including non-PyTorch memory, this process has 22.46 GiB memory in use. Of the allocated memory 21.67 GiB is allocated by PyTorch, and 301.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.15 GiB is free. Including non-PyTorch memory, this process has 20.49 GiB memory in use. Of the allocated memory 19.65 GiB is allocated by PyTorch, and 354.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 410.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 632.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 435.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model mobilevitv2_200.cvnets_in22k_ft_in1k_384 created, param count: 18449329
Running train benchmark on mobilevitv2_200.cvnets_in22k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 147.48 samples/sec. 216.978 ms/step.
Train [16/40]. 147.43 samples/sec. 217.053 ms/step.
Train [24/40]. 147.42 samples/sec. 217.060 ms/step.
Train [32/40]. 147.42 samples/sec. 217.072 ms/step.
Train [40/40]. 147.42 samples/sec. 217.072 ms/step.
Train benchmark of mobilevitv2_200.cvnets_in22k_ft_in1k_384 done. 146.76 samples/sec, 217.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mvitv2_base.fb_in1k created, param count: 51472744
Running inference benchmark on mvitv2_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 731.44 samples/sec. 349.993 ms/step.
Infer [16/40]. 731.46 samples/sec. 349.983 ms/step.
Infer [24/40]. 731.53 samples/sec. 349.951 ms/step.
Infer [32/40]. 731.51 samples/sec. 349.963 ms/step.
Infer [40/40]. 731.49 samples/sec. 349.971 ms/step.
Inference benchmark of mvitv2_base.fb_in1k done. 731.40 samples/sec, 349.97 ms/step
Model mvitv2_base.fb_in1k created, param count: 51472744
Running train benchmark on mvitv2_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.11 GiB is free. Including non-PyTorch memory, this process has 22.53 GiB memory in use. Of the allocated memory 21.81 GiB is allocated by PyTorch, and 233.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mvitv2_base.fb_in1k created, param count: 51472744
Running train benchmark on mvitv2_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 394.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mvitv2_base.fb_in1k created, param count: 51472744
Running train benchmark on mvitv2_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 360.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mvitv2_base.fb_in1k created, param count: 51472744
Running train benchmark on mvitv2_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 424.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mvitv2_base.fb_in1k created, param count: 51472744
Running train benchmark on mvitv2_base.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 227.84 samples/sec. 280.901 ms/step.
Train [16/40]. 227.87 samples/sec. 280.864 ms/step.
Train [24/40]. 227.85 samples/sec. 280.881 ms/step.
Train [32/40]. 227.85 samples/sec. 280.881 ms/step.
Train [40/40]. 227.86 samples/sec. 280.877 ms/step.
Train benchmark of mvitv2_base.fb_in1k done. 225.34 samples/sec, 280.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mvitv2_base_cls.fb_inw21k created, param count: 65444032
Running inference benchmark on mvitv2_base_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 748.65 samples/sec. 341.948 ms/step.
Infer [16/40]. 748.64 samples/sec. 341.955 ms/step.
Infer [24/40]. 748.64 samples/sec. 341.954 ms/step.
Infer [32/40]. 748.63 samples/sec. 341.957 ms/step.
Infer [40/40]. 748.62 samples/sec. 341.961 ms/step.
Inference benchmark of mvitv2_base_cls.fb_inw21k done. 748.53 samples/sec, 341.96 ms/step
Model mvitv2_base_cls.fb_inw21k created, param count: 65444032
Running train benchmark on mvitv2_base_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 866.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 22.02 GiB is allocated by PyTorch, and 283.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mvitv2_base_cls.fb_inw21k created, param count: 65444032
Running train benchmark on mvitv2_base_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 492.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mvitv2_base_cls.fb_inw21k created, param count: 65444032
Running train benchmark on mvitv2_base_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 475.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mvitv2_base_cls.fb_inw21k created, param count: 65444032
Running train benchmark on mvitv2_base_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 392.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mvitv2_base_cls.fb_inw21k created, param count: 65444032
Running train benchmark on mvitv2_base_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 201.15 samples/sec. 318.178 ms/step.
Train [16/40]. 201.15 samples/sec. 318.174 ms/step.
Train [24/40]. 201.14 samples/sec. 318.182 ms/step.
Train [32/40]. 201.15 samples/sec. 318.168 ms/step.
Train [40/40]. 201.15 samples/sec. 318.178 ms/step.
Train benchmark of mvitv2_base_cls.fb_inw21k done. 198.98 samples/sec, 318.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running inference benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 102.95 samples/sec. 2486.676 ms/step.
Infer [16/40]. 102.95 samples/sec. 2486.744 ms/step.
Infer [24/40]. 102.95 samples/sec. 2486.693 ms/step.
Infer [32/40]. 102.95 samples/sec. 2486.702 ms/step.
Infer [40/40]. 102.95 samples/sec. 2486.683 ms/step.
Inference benchmark of mvitv2_huge_cls.fb_inw21k done. 102.95 samples/sec, 2486.68 ms/step
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 502.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 22.03 GiB is allocated by PyTorch, and 638.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 22.45 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 593.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 922.06 MiB is free. Including non-PyTorch memory, this process has 22.74 GiB memory in use. Of the allocated memory 20.55 GiB is allocated by PyTorch, and 1.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 624.06 MiB is free. Including non-PyTorch memory, this process has 23.03 GiB memory in use. Of the allocated memory 22.08 GiB is allocated by PyTorch, and 470.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 537.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 519.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 623.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 513.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.99 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 20.75 GiB is allocated by PyTorch, and 2.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model mvitv2_huge_cls.fb_inw21k created, param count: 694804128
Running train benchmark on mvitv2_huge_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 8.
Train [8/40]. 13.33 samples/sec. 600.300 ms/step.
Train [16/40]. 13.33 samples/sec. 600.337 ms/step.
Train [24/40]. 13.33 samples/sec. 600.269 ms/step.
Train [32/40]. 13.33 samples/sec. 600.227 ms/step.
Train [40/40]. 13.33 samples/sec. 600.205 ms/step.
Train benchmark of mvitv2_huge_cls.fb_inw21k done. 13.09 samples/sec, 600.21 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mvitv2_large.fb_in1k created, param count: 217992952
Running inference benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 231.40 samples/sec. 1106.314 ms/step.
Infer [16/40]. 231.40 samples/sec. 1106.328 ms/step.
Infer [24/40]. 231.40 samples/sec. 1106.328 ms/step.
Infer [32/40]. 231.40 samples/sec. 1106.324 ms/step.
Infer [40/40]. 231.39 samples/sec. 1106.361 ms/step.
Inference benchmark of mvitv2_large.fb_in1k done. 231.38 samples/sec, 1106.36 ms/step
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 852.06 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Of the allocated memory 19.97 GiB is allocated by PyTorch, and 2.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 21.81 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 868.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 910.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.64 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model mvitv2_large.fb_in1k created, param count: 217992952
Running train benchmark on mvitv2_large.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 63.74 samples/sec. 376.528 ms/step.
Train [16/40]. 63.73 samples/sec. 376.608 ms/step.
Train [24/40]. 63.72 samples/sec. 376.653 ms/step.
Train [32/40]. 63.72 samples/sec. 376.667 ms/step.
Train [40/40]. 63.71 samples/sec. 376.705 ms/step.
Train benchmark of mvitv2_large.fb_in1k done. 62.71 samples/sec, 376.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running inference benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 239.12 samples/sec. 1070.606 ms/step.
Infer [16/40]. 239.12 samples/sec. 1070.592 ms/step.
Infer [24/40]. 239.12 samples/sec. 1070.571 ms/step.
Infer [32/40]. 239.13 samples/sec. 1070.570 ms/step.
Infer [40/40]. 239.13 samples/sec. 1070.565 ms/step.
Inference benchmark of mvitv2_large_cls.fb_inw21k done. 239.12 samples/sec, 1070.57 ms/step
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 306.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 21.34 GiB is allocated by PyTorch, and 1.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 610.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 21.24 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 842.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 100.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 21.73 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.12 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model mvitv2_large_cls.fb_inw21k created, param count: 234583216
Running train benchmark on mvitv2_large_cls.fb_inw21k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 58.68 samples/sec. 409.024 ms/step.
Train [16/40]. 58.67 samples/sec. 409.058 ms/step.
Train [24/40]. 58.65 samples/sec. 409.220 ms/step.
Train [32/40]. 58.65 samples/sec. 409.239 ms/step.
Train [40/40]. 58.64 samples/sec. 409.249 ms/step.
Train benchmark of mvitv2_large_cls.fb_inw21k done. 57.73 samples/sec, 409.25 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mvitv2_small.fb_in1k created, param count: 34870216
Running inference benchmark on mvitv2_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1049.52 samples/sec. 243.922 ms/step.
Infer [16/40]. 1049.50 samples/sec. 243.926 ms/step.
Infer [24/40]. 1049.51 samples/sec. 243.924 ms/step.
Infer [32/40]. 1049.27 samples/sec. 243.979 ms/step.
Infer [40/40]. 1049.06 samples/sec. 244.029 ms/step.
Inference benchmark of mvitv2_small.fb_in1k done. 1048.89 samples/sec, 244.03 ms/step
Model mvitv2_small.fb_in1k created, param count: 34870216
Running train benchmark on mvitv2_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 315.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mvitv2_small.fb_in1k created, param count: 34870216
Running train benchmark on mvitv2_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 342.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mvitv2_small.fb_in1k created, param count: 34870216
Running train benchmark on mvitv2_small.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 310.46 samples/sec. 412.292 ms/step.
Train [16/40]. 310.46 samples/sec. 412.288 ms/step.
Train [24/40]. 310.47 samples/sec. 412.275 ms/step.
Train [32/40]. 310.47 samples/sec. 412.277 ms/step.
Train [40/40]. 310.48 samples/sec. 412.264 ms/step.
Train benchmark of mvitv2_small.fb_in1k done. 308.49 samples/sec, 412.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model mvitv2_tiny.fb_in1k created, param count: 24173320
Running inference benchmark on mvitv2_tiny.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1412.11 samples/sec. 181.289 ms/step.
Infer [16/40]. 1412.04 samples/sec. 181.298 ms/step.
Infer [24/40]. 1411.98 samples/sec. 181.306 ms/step.
Infer [32/40]. 1411.98 samples/sec. 181.305 ms/step.
Infer [40/40]. 1411.98 samples/sec. 181.305 ms/step.
Inference benchmark of mvitv2_tiny.fb_in1k done. 1411.71 samples/sec, 181.31 ms/step
Model mvitv2_tiny.fb_in1k created, param count: 24173320
Running train benchmark on mvitv2_tiny.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 312.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model mvitv2_tiny.fb_in1k created, param count: 24173320
Running train benchmark on mvitv2_tiny.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 289.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model mvitv2_tiny.fb_in1k created, param count: 24173320
Running train benchmark on mvitv2_tiny.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 413.62 samples/sec. 309.461 ms/step.
Train [16/40]. 413.66 samples/sec. 309.430 ms/step.
Train [24/40]. 413.68 samples/sec. 309.417 ms/step.
Train [32/40]. 413.69 samples/sec. 309.411 ms/step.
Train [40/40]. 413.68 samples/sec. 309.414 ms/step.
Train benchmark of mvitv2_tiny.fb_in1k done. 411.41 samples/sec, 309.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model nasnetalarge.tf_in1k created, param count: 88753150
Running inference benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 870.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 408.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 842.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running inference benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 192.
Infer [8/40]. 246.76 samples/sec. 778.081 ms/step.
Infer [16/40]. 246.76 samples/sec. 778.091 ms/step.
Infer [24/40]. 246.74 samples/sec. 778.152 ms/step.
Infer [32/40]. 246.73 samples/sec. 778.191 ms/step.
Infer [40/40]. 246.72 samples/sec. 778.202 ms/step.
Inference benchmark of nasnetalarge.tf_in1k done. 246.71 samples/sec, 778.20 ms/step
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 566.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 54.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 288.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 566.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 510.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 168.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 276.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 707.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 547.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 772.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 507.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model nasnetalarge.tf_in1k created, param count: 88753150
Running train benchmark on nasnetalarge.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 16.
Train [8/40]. 66.18 samples/sec. 241.780 ms/step.
Train [16/40]. 66.16 samples/sec. 241.841 ms/step.
Train [24/40]. 66.14 samples/sec. 241.910 ms/step.
Train [32/40]. 66.14 samples/sec. 241.925 ms/step.
Train [40/40]. 66.13 samples/sec. 241.935 ms/step.
Train benchmark of nasnetalarge.tf_in1k done. 65.31 samples/sec, 241.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model nest_base_jx.goog_in1k created, param count: 67723368
Running inference benchmark on nest_base_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 622.69 samples/sec. 411.118 ms/step.
Infer [16/40]. 622.70 samples/sec. 411.110 ms/step.
Infer [24/40]. 622.70 samples/sec. 411.114 ms/step.
Infer [32/40]. 622.69 samples/sec. 411.118 ms/step.
Infer [40/40]. 622.69 samples/sec. 411.117 ms/step.
Inference benchmark of nest_base_jx.goog_in1k done. 622.62 samples/sec, 411.12 ms/step
Model nest_base_jx.goog_in1k created, param count: 67723368
Running train benchmark on nest_base_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.04 GiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.82 GiB is allocated by PyTorch, and 289.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model nest_base_jx.goog_in1k created, param count: 67723368
Running train benchmark on nest_base_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 147.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model nest_base_jx.goog_in1k created, param count: 67723368
Running train benchmark on nest_base_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 265.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model nest_base_jx.goog_in1k created, param count: 67723368
Running train benchmark on nest_base_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 316.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model nest_base_jx.goog_in1k created, param count: 67723368
Running train benchmark on nest_base_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 220.15 samples/sec. 290.706 ms/step.
Train [16/40]. 220.16 samples/sec. 290.694 ms/step.
Train [24/40]. 220.16 samples/sec. 290.698 ms/step.
Train [32/40]. 220.16 samples/sec. 290.700 ms/step.
Train [40/40]. 220.15 samples/sec. 290.707 ms/step.
Train benchmark of nest_base_jx.goog_in1k done. 218.80 samples/sec, 290.71 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model nest_small_jx.goog_in1k created, param count: 38351176
Running inference benchmark on nest_small_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 872.39 samples/sec. 293.448 ms/step.
Infer [16/40]. 872.37 samples/sec. 293.452 ms/step.
Infer [24/40]. 872.39 samples/sec. 293.447 ms/step.
Infer [32/40]. 872.39 samples/sec. 293.448 ms/step.
Infer [40/40]. 872.40 samples/sec. 293.445 ms/step.
Inference benchmark of nest_small_jx.goog_in1k done. 872.27 samples/sec, 293.44 ms/step
Model nest_small_jx.goog_in1k created, param count: 38351176
Running train benchmark on nest_small_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 118.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model nest_small_jx.goog_in1k created, param count: 38351176
Running train benchmark on nest_small_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 239.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model nest_small_jx.goog_in1k created, param count: 38351176
Running train benchmark on nest_small_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 268.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model nest_small_jx.goog_in1k created, param count: 38351176
Running train benchmark on nest_small_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 312.84 samples/sec. 306.866 ms/step.
Train [16/40]. 312.84 samples/sec. 306.868 ms/step.
Train [24/40]. 312.84 samples/sec. 306.867 ms/step.
Train [32/40]. 312.84 samples/sec. 306.862 ms/step.
Train [40/40]. 312.84 samples/sec. 306.862 ms/step.
Train benchmark of nest_small_jx.goog_in1k done. 310.97 samples/sec, 306.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model nest_tiny_jx.goog_in1k created, param count: 17057608
Running inference benchmark on nest_tiny_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1363.42 samples/sec. 187.763 ms/step.
Infer [16/40]. 1363.37 samples/sec. 187.770 ms/step.
Infer [24/40]. 1363.36 samples/sec. 187.771 ms/step.
Infer [32/40]. 1363.25 samples/sec. 187.786 ms/step.
Infer [40/40]. 1363.15 samples/sec. 187.800 ms/step.
Inference benchmark of nest_tiny_jx.goog_in1k done. 1362.89 samples/sec, 187.80 ms/step
Model nest_tiny_jx.goog_in1k created, param count: 17057608
Running train benchmark on nest_tiny_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 171.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model nest_tiny_jx.goog_in1k created, param count: 17057608
Running train benchmark on nest_tiny_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 315.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model nest_tiny_jx.goog_in1k created, param count: 17057608
Running train benchmark on nest_tiny_jx.goog_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 482.68 samples/sec. 265.185 ms/step.
Train [16/40]. 482.69 samples/sec. 265.182 ms/step.
Train [24/40]. 482.69 samples/sec. 265.181 ms/step.
Train [32/40]. 482.69 samples/sec. 265.183 ms/step.
Train [40/40]. 482.69 samples/sec. 265.179 ms/step.
Train benchmark of nest_tiny_jx.goog_in1k done. 480.55 samples/sec, 265.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model nf_regnet_b1.ra2_in1k created, param count: 10223984
Running inference benchmark on nf_regnet_b1.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2692.97 samples/sec. 95.062 ms/step.
Infer [16/40]. 2692.68 samples/sec. 95.073 ms/step.
Infer [24/40]. 2692.58 samples/sec. 95.076 ms/step.
Infer [32/40]. 2692.40 samples/sec. 95.083 ms/step.
Infer [40/40]. 2692.48 samples/sec. 95.079 ms/step.
Inference benchmark of nf_regnet_b1.ra2_in1k done. 2691.74 samples/sec, 95.08 ms/step
Model nf_regnet_b1.ra2_in1k created, param count: 10223984
Running train benchmark on nf_regnet_b1.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 834.02 samples/sec. 306.948 ms/step.
Train [16/40]. 833.94 samples/sec. 306.975 ms/step.
Train [24/40]. 833.95 samples/sec. 306.972 ms/step.
Train [32/40]. 833.94 samples/sec. 306.975 ms/step.
Train [40/40]. 833.92 samples/sec. 306.984 ms/step.
Train benchmark of nf_regnet_b1.ra2_in1k done. 829.89 samples/sec, 306.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model nf_resnet50.ra2_in1k created, param count: 25557032
Running inference benchmark on nf_resnet50.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1150.97 samples/sec. 222.421 ms/step.
Infer [16/40]. 1150.99 samples/sec. 222.418 ms/step.
Infer [24/40]. 1150.99 samples/sec. 222.416 ms/step.
Infer [32/40]. 1150.96 samples/sec. 222.422 ms/step.
Infer [40/40]. 1150.97 samples/sec. 222.421 ms/step.
Inference benchmark of nf_resnet50.ra2_in1k done. 1150.77 samples/sec, 222.42 ms/step
Model nf_resnet50.ra2_in1k created, param count: 25557032
Running train benchmark on nf_resnet50.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 292.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model nf_resnet50.ra2_in1k created, param count: 25557032
Running train benchmark on nf_resnet50.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 467.85 samples/sec. 410.387 ms/step.
Train [16/40]. 467.85 samples/sec. 410.389 ms/step.
Train [24/40]. 467.81 samples/sec. 410.420 ms/step.
Train [32/40]. 467.84 samples/sec. 410.397 ms/step.
Train [40/40]. 467.83 samples/sec. 410.401 ms/step.
Train benchmark of nf_resnet50.ra2_in1k done. 466.58 samples/sec, 410.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model nfnet_l0.ra2_in1k created, param count: 35074488
Running inference benchmark on nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1096.84 samples/sec. 233.397 ms/step.
Infer [16/40]. 1096.79 samples/sec. 233.408 ms/step.
Infer [24/40]. 1096.76 samples/sec. 233.415 ms/step.
Infer [32/40]. 1096.78 samples/sec. 233.411 ms/step.
Infer [40/40]. 1096.77 samples/sec. 233.413 ms/step.
Inference benchmark of nfnet_l0.ra2_in1k done. 1096.58 samples/sec, 233.41 ms/step
Model nfnet_l0.ra2_in1k created, param count: 35074488
Running train benchmark on nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 512.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model nfnet_l0.ra2_in1k created, param count: 35074488
Running train benchmark on nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 294.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model nfnet_l0.ra2_in1k created, param count: 35074488
Running train benchmark on nfnet_l0.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 381.98 samples/sec. 335.100 ms/step.
Train [16/40]. 381.97 samples/sec. 335.107 ms/step.
Train [24/40]. 381.97 samples/sec. 335.108 ms/step.
Train [32/40]. 381.95 samples/sec. 335.121 ms/step.
Train [40/40]. 381.95 samples/sec. 335.124 ms/step.
Train benchmark of nfnet_l0.ra2_in1k done. 380.47 samples/sec, 335.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_b_224.in1k created, param count: 73764840
Running inference benchmark on pit_b_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1516.43 samples/sec. 168.817 ms/step.
Infer [16/40]. 1516.40 samples/sec. 168.821 ms/step.
Infer [24/40]. 1515.71 samples/sec. 168.897 ms/step.
Infer [32/40]. 1515.47 samples/sec. 168.925 ms/step.
Infer [40/40]. 1515.31 samples/sec. 168.943 ms/step.
Inference benchmark of pit_b_224.in1k done. 1514.99 samples/sec, 168.94 ms/step
Model pit_b_224.in1k created, param count: 73764840
Running train benchmark on pit_b_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 176.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pit_b_224.in1k created, param count: 73764840
Running train benchmark on pit_b_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 417.92 samples/sec. 459.418 ms/step.
Train [16/40]. 417.92 samples/sec. 459.420 ms/step.
Train [24/40]. 417.94 samples/sec. 459.391 ms/step.
Train [32/40]. 417.94 samples/sec. 459.394 ms/step.
Train [40/40]. 417.94 samples/sec. 459.394 ms/step.
Train benchmark of pit_b_224.in1k done. 416.90 samples/sec, 459.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_b_distilled_224.in1k created, param count: 74790096
Running inference benchmark on pit_b_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1511.23 samples/sec. 169.399 ms/step.
Infer [16/40]. 1511.15 samples/sec. 169.407 ms/step.
Infer [24/40]. 1510.75 samples/sec. 169.452 ms/step.
Infer [32/40]. 1510.54 samples/sec. 169.475 ms/step.
Infer [40/40]. 1510.45 samples/sec. 169.485 ms/step.
Inference benchmark of pit_b_distilled_224.in1k done. 1510.13 samples/sec, 169.49 ms/step
Model pit_b_distilled_224.in1k created, param count: 74790096
Running train benchmark on pit_b_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 133.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pit_b_distilled_224.in1k created, param count: 74790096
Running train benchmark on pit_b_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 416.71 samples/sec. 460.747 ms/step.
Train [16/40]. 416.71 samples/sec. 460.747 ms/step.
Train [24/40]. 416.71 samples/sec. 460.749 ms/step.
Train [32/40]. 416.71 samples/sec. 460.752 ms/step.
Train [40/40]. 416.70 samples/sec. 460.760 ms/step.
Train benchmark of pit_b_distilled_224.in1k done. 415.66 samples/sec, 460.76 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_s_224.in1k created, param count: 23461912
Running inference benchmark on pit_s_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4641.94 samples/sec. 55.149 ms/step.
Infer [16/40]. 4642.69 samples/sec. 55.140 ms/step.
Infer [24/40]. 4643.09 samples/sec. 55.136 ms/step.
Infer [32/40]. 4643.06 samples/sec. 55.136 ms/step.
Infer [40/40]. 4642.04 samples/sec. 55.148 ms/step.
Inference benchmark of pit_s_224.in1k done. 4639.87 samples/sec, 55.15 ms/step
Model pit_s_224.in1k created, param count: 23461912
Running train benchmark on pit_s_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1232.90 samples/sec. 207.640 ms/step.
Train [16/40]. 1232.89 samples/sec. 207.642 ms/step.
Train [24/40]. 1232.88 samples/sec. 207.644 ms/step.
Train [32/40]. 1232.90 samples/sec. 207.641 ms/step.
Train [40/40]. 1232.92 samples/sec. 207.637 ms/step.
Train benchmark of pit_s_224.in1k done. 1227.37 samples/sec, 207.64 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_s_distilled_224.in1k created, param count: 24039056
Running inference benchmark on pit_s_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4633.02 samples/sec. 55.256 ms/step.
Infer [16/40]. 4633.12 samples/sec. 55.254 ms/step.
Infer [24/40]. 4630.86 samples/sec. 55.281 ms/step.
Infer [32/40]. 4631.47 samples/sec. 55.274 ms/step.
Infer [40/40]. 4631.57 samples/sec. 55.273 ms/step.
Inference benchmark of pit_s_distilled_224.in1k done. 4629.43 samples/sec, 55.27 ms/step
Model pit_s_distilled_224.in1k created, param count: 24039056
Running train benchmark on pit_s_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1226.97 samples/sec. 208.644 ms/step.
Train [16/40]. 1226.94 samples/sec. 208.650 ms/step.
Train [24/40]. 1226.94 samples/sec. 208.649 ms/step.
Train [32/40]. 1226.97 samples/sec. 208.644 ms/step.
Train [40/40]. 1226.90 samples/sec. 208.655 ms/step.
Train benchmark of pit_s_distilled_224.in1k done. 1221.59 samples/sec, 208.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_ti_224.in1k created, param count: 4847272
Running inference benchmark on pit_ti_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 10634.64 samples/sec. 24.072 ms/step.
Infer [16/40]. 10633.78 samples/sec. 24.074 ms/step.
Infer [24/40]. 10633.11 samples/sec. 24.076 ms/step.
Infer [32/40]. 10633.77 samples/sec. 24.074 ms/step.
Infer [40/40]. 10634.32 samples/sec. 24.073 ms/step.
Inference benchmark of pit_ti_224.in1k done. 10623.42 samples/sec, 24.07 ms/step
Model pit_ti_224.in1k created, param count: 4847272
Running train benchmark on pit_ti_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2782.34 samples/sec. 92.009 ms/step.
Train [16/40]. 2782.42 samples/sec. 92.006 ms/step.
Train [24/40]. 2782.36 samples/sec. 92.008 ms/step.
Train [32/40]. 2782.33 samples/sec. 92.009 ms/step.
Train [40/40]. 2782.34 samples/sec. 92.009 ms/step.
Train benchmark of pit_ti_224.in1k done. 2761.77 samples/sec, 92.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_ti_distilled_224.in1k created, param count: 5104336
Running inference benchmark on pit_ti_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 10637.97 samples/sec. 24.065 ms/step.
Infer [16/40]. 10627.96 samples/sec. 24.087 ms/step.
Infer [24/40]. 10623.75 samples/sec. 24.097 ms/step.
Infer [32/40]. 10622.32 samples/sec. 24.100 ms/step.
Infer [40/40]. 10620.90 samples/sec. 24.103 ms/step.
Inference benchmark of pit_ti_distilled_224.in1k done. 10609.97 samples/sec, 24.10 ms/step
Model pit_ti_distilled_224.in1k created, param count: 5104336
Running train benchmark on pit_ti_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2764.38 samples/sec. 92.607 ms/step.
Train [16/40]. 2764.42 samples/sec. 92.605 ms/step.
Train [24/40]. 2764.32 samples/sec. 92.609 ms/step.
Train [32/40]. 2764.33 samples/sec. 92.608 ms/step.
Train [40/40]. 2764.29 samples/sec. 92.610 ms/step.
Train benchmark of pit_ti_distilled_224.in1k done. 2743.16 samples/sec, 92.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_xs_224.in1k created, param count: 10618888
Running inference benchmark on pit_xs_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7561.55 samples/sec. 33.856 ms/step.
Infer [16/40]. 7561.24 samples/sec. 33.857 ms/step.
Infer [24/40]. 7560.99 samples/sec. 33.858 ms/step.
Infer [32/40]. 7560.72 samples/sec. 33.859 ms/step.
Infer [40/40]. 7560.60 samples/sec. 33.860 ms/step.
Inference benchmark of pit_xs_224.in1k done. 7554.97 samples/sec, 33.86 ms/step
Model pit_xs_224.in1k created, param count: 10618888
Running train benchmark on pit_xs_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2007.28 samples/sec. 127.536 ms/step.
Train [16/40]. 2007.24 samples/sec. 127.538 ms/step.
Train [24/40]. 2007.30 samples/sec. 127.535 ms/step.
Train [32/40]. 2007.25 samples/sec. 127.538 ms/step.
Train [40/40]. 2007.27 samples/sec. 127.536 ms/step.
Train benchmark of pit_xs_224.in1k done. 1995.12 samples/sec, 127.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pit_xs_distilled_224.in1k created, param count: 11003984
Running inference benchmark on pit_xs_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7535.60 samples/sec. 33.972 ms/step.
Infer [16/40]. 7526.62 samples/sec. 34.013 ms/step.
Infer [24/40]. 7523.78 samples/sec. 34.025 ms/step.
Infer [32/40]. 7521.91 samples/sec. 34.034 ms/step.
Infer [40/40]. 7521.23 samples/sec. 34.037 ms/step.
Inference benchmark of pit_xs_distilled_224.in1k done. 7515.60 samples/sec, 34.04 ms/step
Model pit_xs_distilled_224.in1k created, param count: 11003984
Running train benchmark on pit_xs_distilled_224.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1995.52 samples/sec. 128.287 ms/step.
Train [16/40]. 1995.41 samples/sec. 128.295 ms/step.
Train [24/40]. 1995.44 samples/sec. 128.292 ms/step.
Train [32/40]. 1995.41 samples/sec. 128.294 ms/step.
Train [40/40]. 1995.41 samples/sec. 128.295 ms/step.
Train benchmark of pit_xs_distilled_224.in1k done. 1983.26 samples/sec, 128.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pnasnet5large.tf_in1k created, param count: 86057668
Running inference benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 256.
Infer [8/40]. 242.47 samples/sec. 1055.792 ms/step.
Infer [16/40]. 242.47 samples/sec. 1055.822 ms/step.
Infer [24/40]. 242.44 samples/sec. 1055.924 ms/step.
Infer [32/40]. 242.43 samples/sec. 1055.991 ms/step.
Infer [40/40]. 242.42 samples/sec. 1056.032 ms/step.
Inference benchmark of pnasnet5large.tf_in1k done. 242.41 samples/sec, 1056.03 ms/step
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 41.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 22.63 GiB memory in use. Of the allocated memory 21.83 GiB is allocated by PyTorch, and 313.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 736.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 458.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 186.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 682.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 422.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 465.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 464.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 418.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 511.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 598.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model pnasnet5large.tf_in1k created, param count: 86057668
Running train benchmark on pnasnet5large.tf_in1k for 40 steps w/ input size (3, 331, 331) and batch size 16.
Train [8/40]. 76.12 samples/sec. 210.206 ms/step.
Train [16/40]. 76.13 samples/sec. 210.178 ms/step.
Train [24/40]. 76.13 samples/sec. 210.172 ms/step.
Train [32/40]. 76.11 samples/sec. 210.210 ms/step.
Train [40/40]. 76.10 samples/sec. 210.237 ms/step.
Train benchmark of pnasnet5large.tf_in1k done. 75.23 samples/sec, 210.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformer_m36.sail_in1k created, param count: 56172520
Running inference benchmark on poolformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 951.49 samples/sec. 269.053 ms/step.
Infer [16/40]. 951.43 samples/sec. 269.069 ms/step.
Infer [24/40]. 951.42 samples/sec. 269.070 ms/step.
Infer [32/40]. 951.40 samples/sec. 269.076 ms/step.
Infer [40/40]. 951.40 samples/sec. 269.076 ms/step.
Inference benchmark of poolformer_m36.sail_in1k done. 951.25 samples/sec, 269.08 ms/step
Model poolformer_m36.sail_in1k created, param count: 56172520
Running train benchmark on poolformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 29.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformer_m36.sail_in1k created, param count: 56172520
Running train benchmark on poolformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 320.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 212.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model poolformer_m36.sail_in1k created, param count: 56172520
Running train benchmark on poolformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 165.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model poolformer_m36.sail_in1k created, param count: 56172520
Running train benchmark on poolformer_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 361.37 samples/sec. 265.656 ms/step.
Train [16/40]. 361.36 samples/sec. 265.661 ms/step.
Train [24/40]. 361.36 samples/sec. 265.661 ms/step.
Train [32/40]. 361.36 samples/sec. 265.660 ms/step.
Train [40/40]. 361.36 samples/sec. 265.663 ms/step.
Train benchmark of poolformer_m36.sail_in1k done. 359.29 samples/sec, 265.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformer_m48.sail_in1k created, param count: 73473448
Running inference benchmark on poolformer_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 717.52 samples/sec. 356.782 ms/step.
Infer [16/40]. 717.49 samples/sec. 356.801 ms/step.
Infer [24/40]. 717.47 samples/sec. 356.812 ms/step.
Infer [32/40]. 717.46 samples/sec. 356.816 ms/step.
Infer [40/40]. 717.45 samples/sec. 356.821 ms/step.
Inference benchmark of poolformer_m48.sail_in1k done. 717.36 samples/sec, 356.82 ms/step
Model poolformer_m48.sail_in1k created, param count: 73473448
Running train benchmark on poolformer_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.12 GiB is allocated by PyTorch, and 25.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformer_m48.sail_in1k created, param count: 73473448
Running train benchmark on poolformer_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 432.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 149.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model poolformer_m48.sail_in1k created, param count: 73473448
Running train benchmark on poolformer_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 156.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model poolformer_m48.sail_in1k created, param count: 73473448
Running train benchmark on poolformer_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 591.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model poolformer_m48.sail_in1k created, param count: 73473448
Running train benchmark on poolformer_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 277.70 samples/sec. 230.463 ms/step.
Train [16/40]. 277.70 samples/sec. 230.463 ms/step.
Train [24/40]. 277.70 samples/sec. 230.464 ms/step.
Train [32/40]. 277.70 samples/sec. 230.464 ms/step.
Train [40/40]. 277.71 samples/sec. 230.460 ms/step.
Train benchmark of poolformer_m48.sail_in1k done. 275.64 samples/sec, 230.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformer_s12.sail_in1k created, param count: 11915176
Running inference benchmark on poolformer_s12.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3986.27 samples/sec. 64.220 ms/step.
Infer [16/40]. 3984.56 samples/sec. 64.248 ms/step.
Infer [24/40]. 3983.85 samples/sec. 64.259 ms/step.
Infer [32/40]. 3983.55 samples/sec. 64.264 ms/step.
Infer [40/40]. 3983.38 samples/sec. 64.267 ms/step.
Inference benchmark of poolformer_s12.sail_in1k done. 3981.76 samples/sec, 64.27 ms/step
Model poolformer_s12.sail_in1k created, param count: 11915176
Running train benchmark on poolformer_s12.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1442.56 samples/sec. 177.462 ms/step.
Train [16/40]. 1442.54 samples/sec. 177.465 ms/step.
Train [24/40]. 1442.56 samples/sec. 177.462 ms/step.
Train [32/40]. 1442.50 samples/sec. 177.469 ms/step.
Train [40/40]. 1442.48 samples/sec. 177.472 ms/step.
Train benchmark of poolformer_s12.sail_in1k done. 1436.38 samples/sec, 177.47 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformer_s24.sail_in1k created, param count: 21388968
Running inference benchmark on poolformer_s24.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2049.53 samples/sec. 124.907 ms/step.
Infer [16/40]. 2049.46 samples/sec. 124.911 ms/step.
Infer [24/40]. 2049.51 samples/sec. 124.908 ms/step.
Infer [32/40]. 2049.48 samples/sec. 124.910 ms/step.
Infer [40/40]. 2049.46 samples/sec. 124.911 ms/step.
Inference benchmark of poolformer_s24.sail_in1k done. 2048.99 samples/sec, 124.91 ms/step
Model poolformer_s24.sail_in1k created, param count: 21388968
Running train benchmark on poolformer_s24.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 150.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformer_s24.sail_in1k created, param count: 21388968
Running train benchmark on poolformer_s24.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 753.52 samples/sec. 254.803 ms/step.
Train [16/40]. 753.44 samples/sec. 254.832 ms/step.
Train [24/40]. 753.39 samples/sec. 254.849 ms/step.
Train [32/40]. 753.35 samples/sec. 254.860 ms/step.
Train [40/40]. 753.34 samples/sec. 254.866 ms/step.
Train benchmark of poolformer_s24.sail_in1k done. 749.79 samples/sec, 254.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformer_s36.sail_in1k created, param count: 30862760
Running inference benchmark on poolformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1380.11 samples/sec. 185.493 ms/step.
Infer [16/40]. 1380.13 samples/sec. 185.490 ms/step.
Infer [24/40]. 1380.07 samples/sec. 185.498 ms/step.
Infer [32/40]. 1380.06 samples/sec. 185.499 ms/step.
Infer [40/40]. 1380.06 samples/sec. 185.499 ms/step.
Inference benchmark of poolformer_s36.sail_in1k done. 1379.81 samples/sec, 185.50 ms/step
Model poolformer_s36.sail_in1k created, param count: 30862760
Running train benchmark on poolformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 366.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 21.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformer_s36.sail_in1k created, param count: 30862760
Running train benchmark on poolformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 156.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model poolformer_s36.sail_in1k created, param count: 30862760
Running train benchmark on poolformer_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 526.06 samples/sec. 243.318 ms/step.
Train [16/40]. 525.96 samples/sec. 243.364 ms/step.
Train [24/40]. 525.91 samples/sec. 243.386 ms/step.
Train [32/40]. 525.90 samples/sec. 243.395 ms/step.
Train [40/40]. 525.89 samples/sec. 243.396 ms/step.
Train benchmark of poolformer_s36.sail_in1k done. 522.70 samples/sec, 243.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformerv2_m36.sail_in1k created, param count: 56077168
Running inference benchmark on poolformerv2_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 722.58 samples/sec. 354.287 ms/step.
Infer [16/40]. 722.56 samples/sec. 354.296 ms/step.
Infer [24/40]. 722.48 samples/sec. 354.337 ms/step.
Infer [32/40]. 722.34 samples/sec. 354.404 ms/step.
Infer [40/40]. 722.26 samples/sec. 354.442 ms/step.
Inference benchmark of poolformerv2_m36.sail_in1k done. 722.17 samples/sec, 354.44 ms/step
Model poolformerv2_m36.sail_in1k created, param count: 56077168
Running train benchmark on poolformerv2_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.20 GiB is allocated by PyTorch, and 905.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformerv2_m36.sail_in1k created, param count: 56077168
Running train benchmark on poolformerv2_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 578.06 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 726.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model poolformerv2_m36.sail_in1k created, param count: 56077168
Running train benchmark on poolformerv2_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 186.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model poolformerv2_m36.sail_in1k created, param count: 56077168
Running train benchmark on poolformerv2_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 410.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model poolformerv2_m36.sail_in1k created, param count: 56077168
Running train benchmark on poolformerv2_m36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 247.73 samples/sec. 258.341 ms/step.
Train [16/40]. 247.73 samples/sec. 258.348 ms/step.
Train [24/40]. 247.73 samples/sec. 258.351 ms/step.
Train [32/40]. 247.72 samples/sec. 258.355 ms/step.
Train [40/40]. 247.72 samples/sec. 258.356 ms/step.
Train benchmark of poolformerv2_m36.sail_in1k done. 246.39 samples/sec, 258.36 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformerv2_m48.sail_in1k created, param count: 73346056
Running inference benchmark on poolformerv2_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 545.44 samples/sec. 469.349 ms/step.
Infer [16/40]. 545.43 samples/sec. 469.358 ms/step.
Infer [24/40]. 545.42 samples/sec. 469.361 ms/step.
Infer [32/40]. 545.41 samples/sec. 469.367 ms/step.
Infer [40/40]. 545.33 samples/sec. 469.439 ms/step.
Inference benchmark of poolformerv2_m48.sail_in1k done. 545.28 samples/sec, 469.44 ms/step
Model poolformerv2_m48.sail_in1k created, param count: 73346056
Running train benchmark on poolformerv2_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 901.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformerv2_m48.sail_in1k created, param count: 73346056
Running train benchmark on poolformerv2_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 492.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 746.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model poolformerv2_m48.sail_in1k created, param count: 73346056
Running train benchmark on poolformerv2_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 148.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model poolformerv2_m48.sail_in1k created, param count: 73346056
Running train benchmark on poolformerv2_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 287.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model poolformerv2_m48.sail_in1k created, param count: 73346056
Running train benchmark on poolformerv2_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 433.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model poolformerv2_m48.sail_in1k created, param count: 73346056
Running train benchmark on poolformerv2_m48.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 186.65 samples/sec. 257.166 ms/step.
Train [16/40]. 186.65 samples/sec. 257.164 ms/step.
Train [24/40]. 186.64 samples/sec. 257.175 ms/step.
Train [32/40]. 186.65 samples/sec. 257.172 ms/step.
Train [40/40]. 186.65 samples/sec. 257.172 ms/step.
Train benchmark of poolformerv2_m48.sail_in1k done. 185.51 samples/sec, 257.17 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformerv2_s12.sail_in1k created, param count: 11891712
Running inference benchmark on poolformerv2_s12.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2945.39 samples/sec. 86.916 ms/step.
Infer [16/40]. 2943.53 samples/sec. 86.970 ms/step.
Infer [24/40]. 2942.71 samples/sec. 86.995 ms/step.
Infer [32/40]. 2942.43 samples/sec. 87.003 ms/step.
Infer [40/40]. 2942.24 samples/sec. 87.009 ms/step.
Inference benchmark of poolformerv2_s12.sail_in1k done. 2941.34 samples/sec, 87.01 ms/step
Model poolformerv2_s12.sail_in1k created, param count: 11891712
Running train benchmark on poolformerv2_s12.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 967.19 samples/sec. 264.683 ms/step.
Train [16/40]. 967.19 samples/sec. 264.684 ms/step.
Train [24/40]. 967.17 samples/sec. 264.688 ms/step.
Train [32/40]. 967.17 samples/sec. 264.689 ms/step.
Train [40/40]. 967.17 samples/sec. 264.690 ms/step.
Train benchmark of poolformerv2_s12.sail_in1k done. 964.15 samples/sec, 264.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformerv2_s24.sail_in1k created, param count: 21341464
Running inference benchmark on poolformerv2_s24.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1527.04 samples/sec. 167.644 ms/step.
Infer [16/40]. 1527.05 samples/sec. 167.643 ms/step.
Infer [24/40]. 1527.02 samples/sec. 167.647 ms/step.
Infer [32/40]. 1527.03 samples/sec. 167.646 ms/step.
Infer [40/40]. 1527.01 samples/sec. 167.648 ms/step.
Inference benchmark of poolformerv2_s24.sail_in1k done. 1526.71 samples/sec, 167.65 ms/step
Model poolformerv2_s24.sail_in1k created, param count: 21341464
Running train benchmark on poolformerv2_s24.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 363.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformerv2_s24.sail_in1k created, param count: 21341464
Running train benchmark on poolformerv2_s24.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 233.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model poolformerv2_s24.sail_in1k created, param count: 21341464
Running train benchmark on poolformerv2_s24.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 516.14 samples/sec. 247.996 ms/step.
Train [16/40]. 516.14 samples/sec. 247.996 ms/step.
Train [24/40]. 516.13 samples/sec. 247.999 ms/step.
Train [32/40]. 516.14 samples/sec. 247.997 ms/step.
Train [40/40]. 516.14 samples/sec. 247.994 ms/step.
Train benchmark of poolformerv2_s24.sail_in1k done. 513.86 samples/sec, 247.99 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model poolformerv2_s36.sail_in1k created, param count: 30791216
Running inference benchmark on poolformerv2_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1031.53 samples/sec. 248.175 ms/step.
Infer [16/40]. 1031.41 samples/sec. 248.204 ms/step.
Infer [24/40]. 1031.35 samples/sec. 248.218 ms/step.
Infer [32/40]. 1031.32 samples/sec. 248.226 ms/step.
Infer [40/40]. 1031.30 samples/sec. 248.231 ms/step.
Inference benchmark of poolformerv2_s36.sail_in1k done. 1031.13 samples/sec, 248.23 ms/step
Model poolformerv2_s36.sail_in1k created, param count: 30791216
Running train benchmark on poolformerv2_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 301.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model poolformerv2_s36.sail_in1k created, param count: 30791216
Running train benchmark on poolformerv2_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 137.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model poolformerv2_s36.sail_in1k created, param count: 30791216
Running train benchmark on poolformerv2_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 466.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model poolformerv2_s36.sail_in1k created, param count: 30791216
Running train benchmark on poolformerv2_s36.sail_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 355.67 samples/sec. 269.915 ms/step.
Train [16/40]. 355.67 samples/sec. 269.914 ms/step.
Train [24/40]. 355.68 samples/sec. 269.908 ms/step.
Train [32/40]. 355.68 samples/sec. 269.906 ms/step.
Train [40/40]. 355.68 samples/sec. 269.905 ms/step.
Train benchmark of poolformerv2_s36.sail_in1k done. 353.85 samples/sec, 269.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pvt_v2_b0.in1k created, param count: 3666760
Running inference benchmark on pvt_v2_b0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5546.61 samples/sec. 46.154 ms/step.
Infer [16/40]. 5546.90 samples/sec. 46.152 ms/step.
Infer [24/40]. 5546.67 samples/sec. 46.154 ms/step.
Infer [32/40]. 5546.65 samples/sec. 46.154 ms/step.
Infer [40/40]. 5546.45 samples/sec. 46.156 ms/step.
Inference benchmark of pvt_v2_b0.in1k done. 5543.33 samples/sec, 46.16 ms/step
Model pvt_v2_b0.in1k created, param count: 3666760
Running train benchmark on pvt_v2_b0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1034.84 samples/sec. 247.382 ms/step.
Train [16/40]. 1035.71 samples/sec. 247.173 ms/step.
Train [24/40]. 1035.46 samples/sec. 247.234 ms/step.
Train [32/40]. 1035.71 samples/sec. 247.173 ms/step.
Train [40/40]. 1035.59 samples/sec. 247.202 ms/step.
Train benchmark of pvt_v2_b0.in1k done. 1031.38 samples/sec, 247.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pvt_v2_b1.in1k created, param count: 14009000
Running inference benchmark on pvt_v2_b1.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3092.24 samples/sec. 82.788 ms/step.
Infer [16/40]. 3092.09 samples/sec. 82.792 ms/step.
Infer [24/40]. 3092.17 samples/sec. 82.790 ms/step.
Infer [32/40]. 3092.17 samples/sec. 82.790 ms/step.
Infer [40/40]. 3092.19 samples/sec. 82.789 ms/step.
Inference benchmark of pvt_v2_b1.in1k done. 3091.17 samples/sec, 82.79 ms/step
Model pvt_v2_b1.in1k created, param count: 14009000
Running train benchmark on pvt_v2_b1.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 438.32 samples/sec. 584.048 ms/step.
Train [16/40]. 438.23 samples/sec. 584.169 ms/step.
Train [24/40]. 438.21 samples/sec. 584.194 ms/step.
Train [32/40]. 438.20 samples/sec. 584.208 ms/step.
Train [40/40]. 438.19 samples/sec. 584.218 ms/step.
Train benchmark of pvt_v2_b1.in1k done. 437.46 samples/sec, 584.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pvt_v2_b2.in1k created, param count: 25362856
Running inference benchmark on pvt_v2_b2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1783.62 samples/sec. 143.529 ms/step.
Infer [16/40]. 1783.61 samples/sec. 143.529 ms/step.
Infer [24/40]. 1783.55 samples/sec. 143.534 ms/step.
Infer [32/40]. 1783.54 samples/sec. 143.535 ms/step.
Infer [40/40]. 1783.53 samples/sec. 143.536 ms/step.
Inference benchmark of pvt_v2_b2.in1k done. 1783.13 samples/sec, 143.54 ms/step
Model pvt_v2_b2.in1k created, param count: 25362856
Running train benchmark on pvt_v2_b2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 556.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 89.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pvt_v2_b2.in1k created, param count: 25362856
Running train benchmark on pvt_v2_b2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 32.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model pvt_v2_b2.in1k created, param count: 25362856
Running train benchmark on pvt_v2_b2.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 265.99 samples/sec. 481.213 ms/step.
Train [16/40]. 266.92 samples/sec. 479.535 ms/step.
Train [24/40]. 267.19 samples/sec. 479.056 ms/step.
Train [32/40]. 266.89 samples/sec. 479.590 ms/step.
Train [40/40]. 266.69 samples/sec. 479.950 ms/step.
Train benchmark of pvt_v2_b2.in1k done. 265.74 samples/sec, 479.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pvt_v2_b2_li.in1k created, param count: 22553512
Running inference benchmark on pvt_v2_b2_li.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1568.99 samples/sec. 163.162 ms/step.
Infer [16/40]. 1568.96 samples/sec. 163.166 ms/step.
Infer [24/40]. 1568.84 samples/sec. 163.178 ms/step.
Infer [32/40]. 1568.86 samples/sec. 163.175 ms/step.
Infer [40/40]. 1568.89 samples/sec. 163.173 ms/step.
Inference benchmark of pvt_v2_b2_li.in1k done. 1568.56 samples/sec, 163.17 ms/step
Model pvt_v2_b2_li.in1k created, param count: 22553512
Running train benchmark on pvt_v2_b2_li.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 584.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 29.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pvt_v2_b2_li.in1k created, param count: 22553512
Running train benchmark on pvt_v2_b2_li.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 51.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model pvt_v2_b2_li.in1k created, param count: 22553512
Running train benchmark on pvt_v2_b2_li.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 253.56 samples/sec. 504.808 ms/step.
Train [16/40]. 253.23 samples/sec. 505.468 ms/step.
Train [24/40]. 253.16 samples/sec. 505.610 ms/step.
Train [32/40]. 253.45 samples/sec. 505.034 ms/step.
Train [40/40]. 253.52 samples/sec. 504.898 ms/step.
Train benchmark of pvt_v2_b2_li.in1k done. 252.61 samples/sec, 504.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pvt_v2_b3.in1k created, param count: 45238696
Running inference benchmark on pvt_v2_b3.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1285.50 samples/sec. 199.144 ms/step.
Infer [16/40]. 1285.51 samples/sec. 199.143 ms/step.
Infer [24/40]. 1285.50 samples/sec. 199.145 ms/step.
Infer [32/40]. 1285.48 samples/sec. 199.147 ms/step.
Infer [40/40]. 1285.49 samples/sec. 199.146 ms/step.
Inference benchmark of pvt_v2_b3.in1k done. 1285.26 samples/sec, 199.15 ms/step
Model pvt_v2_b3.in1k created, param count: 45238696
Running train benchmark on pvt_v2_b3.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 460.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 109.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pvt_v2_b3.in1k created, param count: 45238696
Running train benchmark on pvt_v2_b3.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 42.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model pvt_v2_b3.in1k created, param count: 45238696
Running train benchmark on pvt_v2_b3.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 291.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model pvt_v2_b3.in1k created, param count: 45238696
Running train benchmark on pvt_v2_b3.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 244.44 samples/sec. 392.736 ms/step.
Train [16/40]. 244.43 samples/sec. 392.744 ms/step.
Train [24/40]. 244.43 samples/sec. 392.758 ms/step.
Train [32/40]. 244.44 samples/sec. 392.728 ms/step.
Train [40/40]. 244.45 samples/sec. 392.720 ms/step.
Train benchmark of pvt_v2_b3.in1k done. 242.83 samples/sec, 392.72 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pvt_v2_b4.in1k created, param count: 62556072
Running inference benchmark on pvt_v2_b4.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 913.41 samples/sec. 280.269 ms/step.
Infer [16/40]. 913.42 samples/sec. 280.266 ms/step.
Infer [24/40]. 913.43 samples/sec. 280.263 ms/step.
Infer [32/40]. 913.42 samples/sec. 280.266 ms/step.
Infer [40/40]. 913.43 samples/sec. 280.262 ms/step.
Inference benchmark of pvt_v2_b4.in1k done. 913.28 samples/sec, 280.26 ms/step
Model pvt_v2_b4.in1k created, param count: 62556072
Running train benchmark on pvt_v2_b4.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 396.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 105.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pvt_v2_b4.in1k created, param count: 62556072
Running train benchmark on pvt_v2_b4.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 99.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model pvt_v2_b4.in1k created, param count: 62556072
Running train benchmark on pvt_v2_b4.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 156.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model pvt_v2_b4.in1k created, param count: 62556072
Running train benchmark on pvt_v2_b4.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 268.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model pvt_v2_b4.in1k created, param count: 62556072
Running train benchmark on pvt_v2_b4.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 185.18 samples/sec. 345.603 ms/step.
Train [16/40]. 185.25 samples/sec. 345.480 ms/step.
Train [24/40]. 185.20 samples/sec. 345.572 ms/step.
Train [32/40]. 185.16 samples/sec. 345.652 ms/step.
Train [40/40]. 185.17 samples/sec. 345.634 ms/step.
Train benchmark of pvt_v2_b4.in1k done. 183.32 samples/sec, 345.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model pvt_v2_b5.in1k created, param count: 81956008
Running inference benchmark on pvt_v2_b5.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 923.31 samples/sec. 277.264 ms/step.
Infer [16/40]. 923.30 samples/sec. 277.265 ms/step.
Infer [24/40]. 923.29 samples/sec. 277.268 ms/step.
Infer [32/40]. 923.29 samples/sec. 277.270 ms/step.
Infer [40/40]. 923.30 samples/sec. 277.267 ms/step.
Inference benchmark of pvt_v2_b5.in1k done. 923.16 samples/sec, 277.27 ms/step
Model pvt_v2_b5.in1k created, param count: 81956008
Running train benchmark on pvt_v2_b5.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 44.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model pvt_v2_b5.in1k created, param count: 81956008
Running train benchmark on pvt_v2_b5.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 84.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model pvt_v2_b5.in1k created, param count: 81956008
Running train benchmark on pvt_v2_b5.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 373.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model pvt_v2_b5.in1k created, param count: 81956008
Running train benchmark on pvt_v2_b5.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 395.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model pvt_v2_b5.in1k created, param count: 81956008
Running train benchmark on pvt_v2_b5.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 197.23 samples/sec. 324.499 ms/step.
Train [16/40]. 197.20 samples/sec. 324.544 ms/step.
Train [24/40]. 197.26 samples/sec. 324.442 ms/step.
Train [32/40]. 197.21 samples/sec. 324.531 ms/step.
Train [40/40]. 197.21 samples/sec. 324.533 ms/step.
Train benchmark of pvt_v2_b5.in1k done. 194.76 samples/sec, 324.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetv_040.ra3_in1k created, param count: 20640640
Running inference benchmark on regnetv_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1202.54 samples/sec. 212.883 ms/step.
Infer [16/40]. 1202.47 samples/sec. 212.895 ms/step.
Infer [24/40]. 1202.53 samples/sec. 212.885 ms/step.
Infer [32/40]. 1202.59 samples/sec. 212.874 ms/step.
Infer [40/40]. 1202.56 samples/sec. 212.879 ms/step.
Inference benchmark of regnetv_040.ra3_in1k done. 1202.33 samples/sec, 212.88 ms/step
Model regnetv_040.ra3_in1k created, param count: 20640640
Running train benchmark on regnetv_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 590.06 MiB is free. Including non-PyTorch memory, this process has 23.06 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 89.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetv_040.ra3_in1k created, param count: 20640640
Running train benchmark on regnetv_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 205.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetv_040.ra3_in1k created, param count: 20640640
Running train benchmark on regnetv_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 392.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetv_040.ra3_in1k created, param count: 20640640
Running train benchmark on regnetv_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 907.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetv_040.ra3_in1k created, param count: 20640640
Running train benchmark on regnetv_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 357.47 samples/sec. 179.037 ms/step.
Train [16/40]. 357.43 samples/sec. 179.055 ms/step.
Train [24/40]. 357.42 samples/sec. 179.060 ms/step.
Train [32/40]. 357.41 samples/sec. 179.066 ms/step.
Train [40/40]. 357.40 samples/sec. 179.071 ms/step.
Train benchmark of regnetv_040.ra3_in1k done. 355.14 samples/sec, 179.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetv_064.ra3_in1k created, param count: 30576052
Running inference benchmark on regnetv_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 813.05 samples/sec. 314.865 ms/step.
Infer [16/40]. 813.00 samples/sec. 314.885 ms/step.
Infer [24/40]. 812.97 samples/sec. 314.893 ms/step.
Infer [32/40]. 812.84 samples/sec. 314.946 ms/step.
Infer [40/40]. 812.88 samples/sec. 314.929 ms/step.
Inference benchmark of regnetv_064.ra3_in1k done. 812.77 samples/sec, 314.93 ms/step
Model regnetv_064.ra3_in1k created, param count: 30576052
Running train benchmark on regnetv_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.09 GiB is allocated by PyTorch, and 41.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetv_064.ra3_in1k created, param count: 30576052
Running train benchmark on regnetv_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 189.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetv_064.ra3_in1k created, param count: 30576052
Running train benchmark on regnetv_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 209.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetv_064.ra3_in1k created, param count: 30576052
Running train benchmark on regnetv_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 301.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetv_064.ra3_in1k created, param count: 30576052
Running train benchmark on regnetv_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 237.32 samples/sec. 269.678 ms/step.
Train [16/40]. 237.32 samples/sec. 269.679 ms/step.
Train [24/40]. 237.32 samples/sec. 269.674 ms/step.
Train [32/40]. 237.34 samples/sec. 269.660 ms/step.
Train [40/40]. 237.32 samples/sec. 269.674 ms/step.
Train benchmark of regnetv_064.ra3_in1k done. 236.00 samples/sec, 269.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_002.pycls_in1k created, param count: 2684792
Running inference benchmark on regnetx_002.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 17298.59 samples/sec. 14.799 ms/step.
Infer [16/40]. 17297.41 samples/sec. 14.800 ms/step.
Infer [24/40]. 17296.70 samples/sec. 14.801 ms/step.
Infer [32/40]. 17296.03 samples/sec. 14.801 ms/step.
Infer [40/40]. 17296.10 samples/sec. 14.801 ms/step.
Inference benchmark of regnetx_002.pycls_in1k done. 17268.83 samples/sec, 14.80 ms/step
Model regnetx_002.pycls_in1k created, param count: 2684792
Running train benchmark on regnetx_002.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 3963.19 samples/sec. 64.594 ms/step.
Train [16/40]. 3963.24 samples/sec. 64.594 ms/step.
Train [24/40]. 3963.49 samples/sec. 64.589 ms/step.
Train [32/40]. 3963.52 samples/sec. 64.589 ms/step.
Train [40/40]. 3963.63 samples/sec. 64.587 ms/step.
Train benchmark of regnetx_002.pycls_in1k done. 3931.22 samples/sec, 64.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_004.pycls_in1k created, param count: 5157512
Running inference benchmark on regnetx_004.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 11821.90 samples/sec. 21.655 ms/step.
Infer [16/40]. 11824.01 samples/sec. 21.651 ms/step.
Infer [24/40]. 11821.65 samples/sec. 21.655 ms/step.
Infer [32/40]. 11816.37 samples/sec. 21.665 ms/step.
Infer [40/40]. 11816.36 samples/sec. 21.665 ms/step.
Inference benchmark of regnetx_004.pycls_in1k done. 11803.10 samples/sec, 21.66 ms/step
Model regnetx_004.pycls_in1k created, param count: 5157512
Running train benchmark on regnetx_004.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2842.75 samples/sec. 90.053 ms/step.
Train [16/40]. 2842.75 samples/sec. 90.054 ms/step.
Train [24/40]. 2842.61 samples/sec. 90.058 ms/step.
Train [32/40]. 2842.58 samples/sec. 90.059 ms/step.
Train [40/40]. 2842.63 samples/sec. 90.058 ms/step.
Train benchmark of regnetx_004.pycls_in1k done. 2819.84 samples/sec, 90.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_004_tv.tv2_in1k created, param count: 5495976
Running inference benchmark on regnetx_004_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 11578.30 samples/sec. 22.110 ms/step.
Infer [16/40]. 11572.70 samples/sec. 22.121 ms/step.
Infer [24/40]. 11564.24 samples/sec. 22.137 ms/step.
Infer [32/40]. 11567.41 samples/sec. 22.131 ms/step.
Infer [40/40]. 11570.48 samples/sec. 22.125 ms/step.
Inference benchmark of regnetx_004_tv.tv2_in1k done. 11557.67 samples/sec, 22.12 ms/step
Model regnetx_004_tv.tv2_in1k created, param count: 5495976
Running train benchmark on regnetx_004_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2766.48 samples/sec. 92.536 ms/step.
Train [16/40]. 2766.71 samples/sec. 92.529 ms/step.
Train [24/40]. 2766.61 samples/sec. 92.532 ms/step.
Train [32/40]. 2766.44 samples/sec. 92.538 ms/step.
Train [40/40]. 2766.44 samples/sec. 92.538 ms/step.
Train benchmark of regnetx_004_tv.tv2_in1k done. 2745.10 samples/sec, 92.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_006.pycls_in1k created, param count: 6196040
Running inference benchmark on regnetx_006.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 8564.62 samples/sec. 29.890 ms/step.
Infer [16/40]. 8562.13 samples/sec. 29.899 ms/step.
Infer [24/40]. 8560.75 samples/sec. 29.904 ms/step.
Infer [32/40]. 8560.50 samples/sec. 29.905 ms/step.
Infer [40/40]. 8560.66 samples/sec. 29.904 ms/step.
Inference benchmark of regnetx_006.pycls_in1k done. 8553.28 samples/sec, 29.90 ms/step
Model regnetx_006.pycls_in1k created, param count: 6196040
Running train benchmark on regnetx_006.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2216.73 samples/sec. 115.485 ms/step.
Train [16/40]. 2216.93 samples/sec. 115.475 ms/step.
Train [24/40]. 2216.89 samples/sec. 115.477 ms/step.
Train [32/40]. 2216.91 samples/sec. 115.476 ms/step.
Train [40/40]. 2216.83 samples/sec. 115.480 ms/step.
Train benchmark of regnetx_006.pycls_in1k done. 2204.80 samples/sec, 115.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_008.pycls_in1k created, param count: 7259656
Running inference benchmark on regnetx_008.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6441.15 samples/sec. 39.744 ms/step.
Infer [16/40]. 6439.71 samples/sec. 39.753 ms/step.
Infer [24/40]. 6438.76 samples/sec. 39.759 ms/step.
Infer [32/40]. 6438.69 samples/sec. 39.760 ms/step.
Infer [40/40]. 6438.83 samples/sec. 39.759 ms/step.
Inference benchmark of regnetx_008.pycls_in1k done. 6434.49 samples/sec, 39.76 ms/step
Model regnetx_008.pycls_in1k created, param count: 7259656
Running train benchmark on regnetx_008.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1689.61 samples/sec. 151.514 ms/step.
Train [16/40]. 1689.53 samples/sec. 151.521 ms/step.
Train [24/40]. 1689.48 samples/sec. 151.526 ms/step.
Train [32/40]. 1689.46 samples/sec. 151.527 ms/step.
Train [40/40]. 1689.46 samples/sec. 151.528 ms/step.
Train benchmark of regnetx_008.pycls_in1k done. 1681.91 samples/sec, 151.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_008.tv2_in1k created, param count: 7259656
Running inference benchmark on regnetx_008.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6440.15 samples/sec. 39.751 ms/step.
Infer [16/40]. 6439.68 samples/sec. 39.754 ms/step.
Infer [24/40]. 6440.26 samples/sec. 39.750 ms/step.
Infer [32/40]. 6440.34 samples/sec. 39.749 ms/step.
Infer [40/40]. 6439.76 samples/sec. 39.753 ms/step.
Inference benchmark of regnetx_008.tv2_in1k done. 6435.57 samples/sec, 39.75 ms/step
Model regnetx_008.tv2_in1k created, param count: 7259656
Running train benchmark on regnetx_008.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1689.60 samples/sec. 151.515 ms/step.
Train [16/40]. 1689.53 samples/sec. 151.521 ms/step.
Train [24/40]. 1689.56 samples/sec. 151.519 ms/step.
Train [32/40]. 1689.57 samples/sec. 151.517 ms/step.
Train [40/40]. 1689.59 samples/sec. 151.516 ms/step.
Train benchmark of regnetx_008.tv2_in1k done. 1682.03 samples/sec, 151.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_016.pycls_in1k created, param count: 9190136
Running inference benchmark on regnetx_016.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3913.96 samples/sec. 65.407 ms/step.
Infer [16/40]. 3913.67 samples/sec. 65.412 ms/step.
Infer [24/40]. 3913.66 samples/sec. 65.412 ms/step.
Infer [32/40]. 3913.69 samples/sec. 65.411 ms/step.
Infer [40/40]. 3913.60 samples/sec. 65.413 ms/step.
Inference benchmark of regnetx_016.pycls_in1k done. 3912.04 samples/sec, 65.41 ms/step
Model regnetx_016.pycls_in1k created, param count: 9190136
Running train benchmark on regnetx_016.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1034.41 samples/sec. 247.484 ms/step.
Train [16/40]. 1034.24 samples/sec. 247.524 ms/step.
Train [24/40]. 1034.28 samples/sec. 247.514 ms/step.
Train [32/40]. 1034.27 samples/sec. 247.518 ms/step.
Train [40/40]. 1034.24 samples/sec. 247.526 ms/step.
Train benchmark of regnetx_016.pycls_in1k done. 1030.44 samples/sec, 247.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_016.tv2_in1k created, param count: 9190136
Running inference benchmark on regnetx_016.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3912.75 samples/sec. 65.427 ms/step.
Infer [16/40]. 3912.75 samples/sec. 65.427 ms/step.
Infer [24/40]. 3913.04 samples/sec. 65.422 ms/step.
Infer [32/40]. 3913.27 samples/sec. 65.418 ms/step.
Infer [40/40]. 3913.31 samples/sec. 65.418 ms/step.
Inference benchmark of regnetx_016.tv2_in1k done. 3911.79 samples/sec, 65.42 ms/step
Model regnetx_016.tv2_in1k created, param count: 9190136
Running train benchmark on regnetx_016.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1034.69 samples/sec. 247.417 ms/step.
Train [16/40]. 1034.72 samples/sec. 247.410 ms/step.
Train [24/40]. 1034.75 samples/sec. 247.403 ms/step.
Train [32/40]. 1034.72 samples/sec. 247.409 ms/step.
Train [40/40]. 1034.73 samples/sec. 247.406 ms/step.
Train benchmark of regnetx_016.tv2_in1k done. 1030.99 samples/sec, 247.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_032.pycls_in1k created, param count: 15296552
Running inference benchmark on regnetx_032.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2400.79 samples/sec. 106.632 ms/step.
Infer [16/40]. 2400.28 samples/sec. 106.654 ms/step.
Infer [24/40]. 2400.39 samples/sec. 106.649 ms/step.
Infer [32/40]. 2400.25 samples/sec. 106.656 ms/step.
Infer [40/40]. 2400.34 samples/sec. 106.651 ms/step.
Inference benchmark of regnetx_032.pycls_in1k done. 2399.68 samples/sec, 106.65 ms/step
Model regnetx_032.pycls_in1k created, param count: 15296552
Running train benchmark on regnetx_032.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 20.66 GiB is allocated by PyTorch, and 2.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_032.pycls_in1k created, param count: 15296552
Running train benchmark on regnetx_032.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 714.47 samples/sec. 268.732 ms/step.
Train [16/40]. 714.13 samples/sec. 268.858 ms/step.
Train [24/40]. 714.35 samples/sec. 268.776 ms/step.
Train [32/40]. 714.30 samples/sec. 268.795 ms/step.
Train [40/40]. 714.33 samples/sec. 268.784 ms/step.
Train benchmark of regnetx_032.pycls_in1k done. 711.35 samples/sec, 268.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_032.tv2_in1k created, param count: 15296552
Running inference benchmark on regnetx_032.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2398.39 samples/sec. 106.738 ms/step.
Infer [16/40]. 2398.80 samples/sec. 106.720 ms/step.
Infer [24/40]. 2398.24 samples/sec. 106.745 ms/step.
Infer [32/40]. 2398.25 samples/sec. 106.745 ms/step.
Infer [40/40]. 2398.28 samples/sec. 106.743 ms/step.
Inference benchmark of regnetx_032.tv2_in1k done. 2397.60 samples/sec, 106.74 ms/step
Model regnetx_032.tv2_in1k created, param count: 15296552
Running train benchmark on regnetx_032.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 20.66 GiB is allocated by PyTorch, and 2.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_032.tv2_in1k created, param count: 15296552
Running train benchmark on regnetx_032.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 713.78 samples/sec. 268.990 ms/step.
Train [16/40]. 713.74 samples/sec. 269.007 ms/step.
Train [24/40]. 713.71 samples/sec. 269.017 ms/step.
Train [32/40]. 713.87 samples/sec. 268.958 ms/step.
Train [40/40]. 713.93 samples/sec. 268.935 ms/step.
Train benchmark of regnetx_032.tv2_in1k done. 711.00 samples/sec, 268.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_040.pycls_in1k created, param count: 22118248
Running inference benchmark on regnetx_040.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2206.89 samples/sec. 116.000 ms/step.
Infer [16/40]. 2207.04 samples/sec. 115.993 ms/step.
Infer [24/40]. 2207.09 samples/sec. 115.990 ms/step.
Infer [32/40]. 2207.00 samples/sec. 115.995 ms/step.
Infer [40/40]. 2206.93 samples/sec. 115.998 ms/step.
Inference benchmark of regnetx_040.pycls_in1k done. 2206.38 samples/sec, 116.00 ms/step
Model regnetx_040.pycls_in1k created, param count: 22118248
Running train benchmark on regnetx_040.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 317.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_040.pycls_in1k created, param count: 22118248
Running train benchmark on regnetx_040.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 620.87 samples/sec. 309.244 ms/step.
Train [16/40]. 621.02 samples/sec. 309.169 ms/step.
Train [24/40]. 620.98 samples/sec. 309.187 ms/step.
Train [32/40]. 620.91 samples/sec. 309.225 ms/step.
Train [40/40]. 620.88 samples/sec. 309.237 ms/step.
Train benchmark of regnetx_040.pycls_in1k done. 618.71 samples/sec, 309.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_064.pycls_in1k created, param count: 26209256
Running inference benchmark on regnetx_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1546.42 samples/sec. 165.543 ms/step.
Infer [16/40]. 1546.29 samples/sec. 165.557 ms/step.
Infer [24/40]. 1546.38 samples/sec. 165.548 ms/step.
Infer [32/40]. 1546.52 samples/sec. 165.533 ms/step.
Infer [40/40]. 1546.47 samples/sec. 165.538 ms/step.
Inference benchmark of regnetx_064.pycls_in1k done. 1546.15 samples/sec, 165.54 ms/step
Model regnetx_064.pycls_in1k created, param count: 26209256
Running train benchmark on regnetx_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 329.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_064.pycls_in1k created, param count: 26209256
Running train benchmark on regnetx_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 377.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetx_064.pycls_in1k created, param count: 26209256
Running train benchmark on regnetx_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 459.05 samples/sec. 278.834 ms/step.
Train [16/40]. 459.04 samples/sec. 278.845 ms/step.
Train [24/40]. 459.02 samples/sec. 278.853 ms/step.
Train [32/40]. 459.04 samples/sec. 278.841 ms/step.
Train [40/40]. 459.05 samples/sec. 278.838 ms/step.
Train benchmark of regnetx_064.pycls_in1k done. 457.53 samples/sec, 278.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_080.pycls_in1k created, param count: 39572648
Running inference benchmark on regnetx_080.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1588.27 samples/sec. 161.182 ms/step.
Infer [16/40]. 1588.19 samples/sec. 161.190 ms/step.
Infer [24/40]. 1587.70 samples/sec. 161.239 ms/step.
Infer [32/40]. 1587.83 samples/sec. 161.227 ms/step.
Infer [40/40]. 1587.85 samples/sec. 161.225 ms/step.
Inference benchmark of regnetx_080.pycls_in1k done. 1587.51 samples/sec, 161.22 ms/step
Model regnetx_080.pycls_in1k created, param count: 39572648
Running train benchmark on regnetx_080.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 230.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_080.pycls_in1k created, param count: 39572648
Running train benchmark on regnetx_080.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 472.56 samples/sec. 406.295 ms/step.
Train [16/40]. 472.60 samples/sec. 406.261 ms/step.
Train [24/40]. 472.54 samples/sec. 406.317 ms/step.
Train [32/40]. 472.65 samples/sec. 406.216 ms/step.
Train [40/40]. 472.62 samples/sec. 406.242 ms/step.
Train benchmark of regnetx_080.pycls_in1k done. 471.30 samples/sec, 406.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_080.tv2_in1k created, param count: 39572648
Running inference benchmark on regnetx_080.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1588.29 samples/sec. 161.180 ms/step.
Infer [16/40]. 1588.26 samples/sec. 161.182 ms/step.
Infer [24/40]. 1588.27 samples/sec. 161.182 ms/step.
Infer [32/40]. 1588.27 samples/sec. 161.182 ms/step.
Infer [40/40]. 1588.02 samples/sec. 161.207 ms/step.
Inference benchmark of regnetx_080.tv2_in1k done. 1587.68 samples/sec, 161.21 ms/step
Model regnetx_080.tv2_in1k created, param count: 39572648
Running train benchmark on regnetx_080.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 230.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_080.tv2_in1k created, param count: 39572648
Running train benchmark on regnetx_080.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 472.78 samples/sec. 406.111 ms/step.
Train [16/40]. 472.74 samples/sec. 406.145 ms/step.
Train [24/40]. 472.78 samples/sec. 406.113 ms/step.
Train [32/40]. 472.80 samples/sec. 406.087 ms/step.
Train [40/40]. 472.79 samples/sec. 406.103 ms/step.
Train benchmark of regnetx_080.tv2_in1k done. 471.46 samples/sec, 406.10 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_120.pycls_in1k created, param count: 46106056
Running inference benchmark on regnetx_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1057.53 samples/sec. 242.073 ms/step.
Infer [16/40]. 1057.45 samples/sec. 242.091 ms/step.
Infer [24/40]. 1057.50 samples/sec. 242.080 ms/step.
Infer [32/40]. 1057.45 samples/sec. 242.092 ms/step.
Infer [40/40]. 1057.45 samples/sec. 242.092 ms/step.
Inference benchmark of regnetx_120.pycls_in1k done. 1057.26 samples/sec, 242.09 ms/step
Model regnetx_120.pycls_in1k created, param count: 46106056
Running train benchmark on regnetx_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 254.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 17.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_120.pycls_in1k created, param count: 46106056
Running train benchmark on regnetx_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 111.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetx_120.pycls_in1k created, param count: 46106056
Running train benchmark on regnetx_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 331.71 samples/sec. 385.879 ms/step.
Train [16/40]. 331.61 samples/sec. 385.992 ms/step.
Train [24/40]. 331.55 samples/sec. 386.067 ms/step.
Train [32/40]. 331.46 samples/sec. 386.169 ms/step.
Train [40/40]. 331.47 samples/sec. 386.159 ms/step.
Train benchmark of regnetx_120.pycls_in1k done. 330.58 samples/sec, 386.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_160.pycls_in1k created, param count: 54278536
Running inference benchmark on regnetx_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 878.93 samples/sec. 291.262 ms/step.
Infer [16/40]. 878.94 samples/sec. 291.261 ms/step.
Infer [24/40]. 878.93 samples/sec. 291.263 ms/step.
Infer [32/40]. 878.92 samples/sec. 291.266 ms/step.
Infer [40/40]. 878.97 samples/sec. 291.248 ms/step.
Inference benchmark of regnetx_160.pycls_in1k done. 878.84 samples/sec, 291.25 ms/step
Model regnetx_160.pycls_in1k created, param count: 54278536
Running train benchmark on regnetx_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 25.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_160.pycls_in1k created, param count: 54278536
Running train benchmark on regnetx_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 128.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetx_160.pycls_in1k created, param count: 54278536
Running train benchmark on regnetx_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 384.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetx_160.pycls_in1k created, param count: 54278536
Running train benchmark on regnetx_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 278.08 samples/sec. 345.223 ms/step.
Train [16/40]. 278.08 samples/sec. 345.226 ms/step.
Train [24/40]. 278.09 samples/sec. 345.213 ms/step.
Train [32/40]. 278.09 samples/sec. 345.214 ms/step.
Train [40/40]. 278.07 samples/sec. 345.231 ms/step.
Train benchmark of regnetx_160.pycls_in1k done. 277.20 samples/sec, 345.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_160.tv2_in1k created, param count: 54278536
Running inference benchmark on regnetx_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 879.39 samples/sec. 291.111 ms/step.
Infer [16/40]. 879.26 samples/sec. 291.153 ms/step.
Infer [24/40]. 879.21 samples/sec. 291.171 ms/step.
Infer [32/40]. 879.19 samples/sec. 291.178 ms/step.
Infer [40/40]. 879.18 samples/sec. 291.182 ms/step.
Inference benchmark of regnetx_160.tv2_in1k done. 879.04 samples/sec, 291.18 ms/step
Model regnetx_160.tv2_in1k created, param count: 54278536
Running train benchmark on regnetx_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 25.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_160.tv2_in1k created, param count: 54278536
Running train benchmark on regnetx_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 128.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetx_160.tv2_in1k created, param count: 54278536
Running train benchmark on regnetx_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 340.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetx_160.tv2_in1k created, param count: 54278536
Running train benchmark on regnetx_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 278.17 samples/sec. 345.112 ms/step.
Train [16/40]. 278.18 samples/sec. 345.102 ms/step.
Train [24/40]. 278.17 samples/sec. 345.110 ms/step.
Train [32/40]. 278.18 samples/sec. 345.104 ms/step.
Train [40/40]. 278.18 samples/sec. 345.105 ms/step.
Train benchmark of regnetx_160.tv2_in1k done. 277.29 samples/sec, 345.11 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_320.pycls_in1k created, param count: 107811560
Running inference benchmark on regnetx_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 516.37 samples/sec. 495.771 ms/step.
Infer [16/40]. 516.37 samples/sec. 495.773 ms/step.
Infer [24/40]. 516.37 samples/sec. 495.767 ms/step.
Infer [32/40]. 516.36 samples/sec. 495.783 ms/step.
Infer [40/40]. 516.35 samples/sec. 495.784 ms/step.
Inference benchmark of regnetx_320.pycls_in1k done. 516.31 samples/sec, 495.78 ms/step
Model regnetx_320.pycls_in1k created, param count: 107811560
Running train benchmark on regnetx_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 22.54 GiB memory in use. Of the allocated memory 20.42 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_320.pycls_in1k created, param count: 107811560
Running train benchmark on regnetx_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 394.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetx_320.pycls_in1k created, param count: 107811560
Running train benchmark on regnetx_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 441.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetx_320.pycls_in1k created, param count: 107811560
Running train benchmark on regnetx_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 625.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetx_320.pycls_in1k created, param count: 107811560
Running train benchmark on regnetx_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 161.88 samples/sec. 395.348 ms/step.
Train [16/40]. 161.89 samples/sec. 395.337 ms/step.
Train [24/40]. 161.88 samples/sec. 395.346 ms/step.
Train [32/40]. 161.89 samples/sec. 395.340 ms/step.
Train [40/40]. 161.89 samples/sec. 395.341 ms/step.
Train benchmark of regnetx_320.pycls_in1k done. 161.41 samples/sec, 395.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetx_320.tv2_in1k created, param count: 107811560
Running inference benchmark on regnetx_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 516.47 samples/sec. 495.671 ms/step.
Infer [16/40]. 516.49 samples/sec. 495.657 ms/step.
Infer [24/40]. 516.48 samples/sec. 495.660 ms/step.
Infer [32/40]. 516.47 samples/sec. 495.675 ms/step.
Infer [40/40]. 516.47 samples/sec. 495.669 ms/step.
Inference benchmark of regnetx_320.tv2_in1k done. 516.42 samples/sec, 495.67 ms/step
Model regnetx_320.tv2_in1k created, param count: 107811560
Running train benchmark on regnetx_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 22.54 GiB memory in use. Of the allocated memory 20.42 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetx_320.tv2_in1k created, param count: 107811560
Running train benchmark on regnetx_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 397.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetx_320.tv2_in1k created, param count: 107811560
Running train benchmark on regnetx_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 446.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetx_320.tv2_in1k created, param count: 107811560
Running train benchmark on regnetx_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 651.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetx_320.tv2_in1k created, param count: 107811560
Running train benchmark on regnetx_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 161.88 samples/sec. 395.357 ms/step.
Train [16/40]. 161.87 samples/sec. 395.369 ms/step.
Train [24/40]. 161.88 samples/sec. 395.352 ms/step.
Train [32/40]. 161.89 samples/sec. 395.322 ms/step.
Train [40/40]. 161.90 samples/sec. 395.317 ms/step.
Train benchmark of regnetx_320.tv2_in1k done. 161.43 samples/sec, 395.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_002.pycls_in1k created, param count: 3162996
Running inference benchmark on regnety_002.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 16324.49 samples/sec. 15.682 ms/step.
Infer [16/40]. 16319.88 samples/sec. 15.686 ms/step.
Infer [24/40]. 16317.36 samples/sec. 15.689 ms/step.
Infer [32/40]. 16315.89 samples/sec. 15.690 ms/step.
Infer [40/40]. 16315.52 samples/sec. 15.691 ms/step.
Inference benchmark of regnety_002.pycls_in1k done. 16292.24 samples/sec, 15.69 ms/step
Model regnety_002.pycls_in1k created, param count: 3162996
Running train benchmark on regnety_002.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 3692.68 samples/sec. 69.326 ms/step.
Train [16/40]. 3692.99 samples/sec. 69.321 ms/step.
Train [24/40]. 3693.17 samples/sec. 69.317 ms/step.
Train [32/40]. 3692.95 samples/sec. 69.321 ms/step.
Train [40/40]. 3692.81 samples/sec. 69.324 ms/step.
Train benchmark of regnety_002.pycls_in1k done. 3658.09 samples/sec, 69.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_004.pycls_in1k created, param count: 4344144
Running inference benchmark on regnety_004.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 8447.04 samples/sec. 30.306 ms/step.
Infer [16/40]. 8446.06 samples/sec. 30.310 ms/step.
Infer [24/40]. 8441.97 samples/sec. 30.325 ms/step.
Infer [32/40]. 8440.04 samples/sec. 30.332 ms/step.
Infer [40/40]. 8438.50 samples/sec. 30.337 ms/step.
Inference benchmark of regnety_004.pycls_in1k done. 8431.79 samples/sec, 30.34 ms/step
Model regnety_004.pycls_in1k created, param count: 4344144
Running train benchmark on regnety_004.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2056.33 samples/sec. 124.493 ms/step.
Train [16/40]. 2056.48 samples/sec. 124.485 ms/step.
Train [24/40]. 2056.40 samples/sec. 124.489 ms/step.
Train [32/40]. 2056.47 samples/sec. 124.485 ms/step.
Train [40/40]. 2056.43 samples/sec. 124.488 ms/step.
Train benchmark of regnety_004.pycls_in1k done. 2043.22 samples/sec, 124.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_004.tv2_in1k created, param count: 4344144
Running inference benchmark on regnety_004.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 8447.25 samples/sec. 30.306 ms/step.
Infer [16/40]. 8446.16 samples/sec. 30.310 ms/step.
Infer [24/40]. 8446.35 samples/sec. 30.309 ms/step.
Infer [32/40]. 8446.26 samples/sec. 30.309 ms/step.
Infer [40/40]. 8444.72 samples/sec. 30.315 ms/step.
Inference benchmark of regnety_004.tv2_in1k done. 8437.97 samples/sec, 30.32 ms/step
Model regnety_004.tv2_in1k created, param count: 4344144
Running train benchmark on regnety_004.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2057.73 samples/sec. 124.409 ms/step.
Train [16/40]. 2057.84 samples/sec. 124.402 ms/step.
Train [24/40]. 2057.73 samples/sec. 124.409 ms/step.
Train [32/40]. 2057.62 samples/sec. 124.416 ms/step.
Train [40/40]. 2057.65 samples/sec. 124.414 ms/step.
Train benchmark of regnety_004.tv2_in1k done. 2044.31 samples/sec, 124.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_006.pycls_in1k created, param count: 6055160
Running inference benchmark on regnety_006.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7273.18 samples/sec. 35.198 ms/step.
Infer [16/40]. 7274.09 samples/sec. 35.193 ms/step.
Infer [24/40]. 7272.39 samples/sec. 35.202 ms/step.
Infer [32/40]. 7271.52 samples/sec. 35.206 ms/step.
Infer [40/40]. 7271.06 samples/sec. 35.208 ms/step.
Inference benchmark of regnety_006.pycls_in1k done. 7266.07 samples/sec, 35.21 ms/step
Model regnety_006.pycls_in1k created, param count: 6055160
Running train benchmark on regnety_006.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1836.87 samples/sec. 139.367 ms/step.
Train [16/40]. 1836.96 samples/sec. 139.361 ms/step.
Train [24/40]. 1836.89 samples/sec. 139.366 ms/step.
Train [32/40]. 1836.82 samples/sec. 139.371 ms/step.
Train [40/40]. 1836.75 samples/sec. 139.376 ms/step.
Train benchmark of regnety_006.pycls_in1k done. 1826.14 samples/sec, 139.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_008.pycls_in1k created, param count: 6263168
Running inference benchmark on regnety_008.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5823.05 samples/sec. 43.963 ms/step.
Infer [16/40]. 5824.01 samples/sec. 43.956 ms/step.
Infer [24/40]. 5823.87 samples/sec. 43.957 ms/step.
Infer [32/40]. 5823.84 samples/sec. 43.957 ms/step.
Infer [40/40]. 5823.49 samples/sec. 43.960 ms/step.
Inference benchmark of regnety_008.pycls_in1k done. 5820.27 samples/sec, 43.96 ms/step
Model regnety_008.pycls_in1k created, param count: 6263168
Running train benchmark on regnety_008.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1506.20 samples/sec. 169.964 ms/step.
Train [16/40]. 1506.20 samples/sec. 169.965 ms/step.
Train [24/40]. 1506.19 samples/sec. 169.966 ms/step.
Train [32/40]. 1506.20 samples/sec. 169.964 ms/step.
Train [40/40]. 1506.15 samples/sec. 169.970 ms/step.
Train benchmark of regnety_008.pycls_in1k done. 1498.78 samples/sec, 169.97 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_008_tv.tv2_in1k created, param count: 6432512
Running inference benchmark on regnety_008_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5585.51 samples/sec. 45.833 ms/step.
Infer [16/40]. 5584.98 samples/sec. 45.837 ms/step.
Infer [24/40]. 5584.17 samples/sec. 45.844 ms/step.
Infer [32/40]. 5583.61 samples/sec. 45.848 ms/step.
Infer [40/40]. 5583.97 samples/sec. 45.846 ms/step.
Inference benchmark of regnety_008_tv.tv2_in1k done. 5580.94 samples/sec, 45.85 ms/step
Model regnety_008_tv.tv2_in1k created, param count: 6432512
Running train benchmark on regnety_008_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1450.13 samples/sec. 176.536 ms/step.
Train [16/40]. 1450.36 samples/sec. 176.508 ms/step.
Train [24/40]. 1450.28 samples/sec. 176.517 ms/step.
Train [32/40]. 1450.30 samples/sec. 176.515 ms/step.
Train [40/40]. 1450.22 samples/sec. 176.525 ms/step.
Train benchmark of regnety_008_tv.tv2_in1k done. 1443.14 samples/sec, 176.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_016.pycls_in1k created, param count: 11202430
Running inference benchmark on regnety_016.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3514.74 samples/sec. 72.836 ms/step.
Infer [16/40]. 3514.19 samples/sec. 72.847 ms/step.
Infer [24/40]. 3514.29 samples/sec. 72.845 ms/step.
Infer [32/40]. 3514.22 samples/sec. 72.847 ms/step.
Infer [40/40]. 3514.11 samples/sec. 72.849 ms/step.
Inference benchmark of regnety_016.pycls_in1k done. 3512.84 samples/sec, 72.85 ms/step
Model regnety_016.pycls_in1k created, param count: 11202430
Running train benchmark on regnety_016.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 930.40 samples/sec. 275.152 ms/step.
Train [16/40]. 930.32 samples/sec. 275.175 ms/step.
Train [24/40]. 930.35 samples/sec. 275.167 ms/step.
Train [32/40]. 930.38 samples/sec. 275.156 ms/step.
Train [40/40]. 930.39 samples/sec. 275.153 ms/step.
Train benchmark of regnety_016.pycls_in1k done. 925.19 samples/sec, 275.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_016.tv2_in1k created, param count: 11202430
Running inference benchmark on regnety_016.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3516.77 samples/sec. 72.794 ms/step.
Infer [16/40]. 3516.73 samples/sec. 72.795 ms/step.
Infer [24/40]. 3516.40 samples/sec. 72.802 ms/step.
Infer [32/40]. 3516.35 samples/sec. 72.803 ms/step.
Infer [40/40]. 3516.29 samples/sec. 72.804 ms/step.
Inference benchmark of regnety_016.tv2_in1k done. 3515.01 samples/sec, 72.80 ms/step
Model regnety_016.tv2_in1k created, param count: 11202430
Running train benchmark on regnety_016.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 930.73 samples/sec. 275.052 ms/step.
Train [16/40]. 930.73 samples/sec. 275.053 ms/step.
Train [24/40]. 930.77 samples/sec. 275.042 ms/step.
Train [32/40]. 930.74 samples/sec. 275.050 ms/step.
Train [40/40]. 930.73 samples/sec. 275.053 ms/step.
Train benchmark of regnety_016.tv2_in1k done. 925.51 samples/sec, 275.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_032.pycls_in1k created, param count: 19436338
Running inference benchmark on regnety_032.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2370.81 samples/sec. 107.980 ms/step.
Infer [16/40]. 2370.67 samples/sec. 107.986 ms/step.
Infer [24/40]. 2370.69 samples/sec. 107.985 ms/step.
Infer [32/40]. 2370.55 samples/sec. 107.992 ms/step.
Infer [40/40]. 2370.52 samples/sec. 107.993 ms/step.
Inference benchmark of regnety_032.pycls_in1k done. 2369.90 samples/sec, 107.99 ms/step
Model regnety_032.pycls_in1k created, param count: 19436338
Running train benchmark on regnety_032.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 954.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_032.pycls_in1k created, param count: 19436338
Running train benchmark on regnety_032.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 641.47 samples/sec. 299.310 ms/step.
Train [16/40]. 641.50 samples/sec. 299.297 ms/step.
Train [24/40]. 641.46 samples/sec. 299.317 ms/step.
Train [32/40]. 641.42 samples/sec. 299.334 ms/step.
Train [40/40]. 641.41 samples/sec. 299.338 ms/step.
Train benchmark of regnety_032.pycls_in1k done. 638.55 samples/sec, 299.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_032.ra_in1k created, param count: 19436338
Running inference benchmark on regnety_032.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1407.67 samples/sec. 181.861 ms/step.
Infer [16/40]. 1407.63 samples/sec. 181.865 ms/step.
Infer [24/40]. 1407.58 samples/sec. 181.873 ms/step.
Infer [32/40]. 1407.59 samples/sec. 181.872 ms/step.
Infer [40/40]. 1407.56 samples/sec. 181.874 ms/step.
Inference benchmark of regnety_032.ra_in1k done. 1407.30 samples/sec, 181.87 ms/step
Model regnety_032.ra_in1k created, param count: 19436338
Running train benchmark on regnety_032.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 291.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_032.ra_in1k created, param count: 19436338
Running train benchmark on regnety_032.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 279.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_032.ra_in1k created, param count: 19436338
Running train benchmark on regnety_032.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 380.75 samples/sec. 336.175 ms/step.
Train [16/40]. 380.77 samples/sec. 336.161 ms/step.
Train [24/40]. 380.78 samples/sec. 336.149 ms/step.
Train [32/40]. 380.80 samples/sec. 336.137 ms/step.
Train [40/40]. 380.79 samples/sec. 336.143 ms/step.
Train benchmark of regnety_032.ra_in1k done. 379.27 samples/sec, 336.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_032.tv2_in1k created, param count: 19436338
Running inference benchmark on regnety_032.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2369.46 samples/sec. 108.041 ms/step.
Infer [16/40]. 2369.39 samples/sec. 108.045 ms/step.
Infer [24/40]. 2369.41 samples/sec. 108.044 ms/step.
Infer [32/40]. 2369.42 samples/sec. 108.043 ms/step.
Infer [40/40]. 2369.44 samples/sec. 108.043 ms/step.
Inference benchmark of regnety_032.tv2_in1k done. 2368.84 samples/sec, 108.04 ms/step
Model regnety_032.tv2_in1k created, param count: 19436338
Running train benchmark on regnety_032.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 954.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_032.tv2_in1k created, param count: 19436338
Running train benchmark on regnety_032.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 641.47 samples/sec. 299.313 ms/step.
Train [16/40]. 641.44 samples/sec. 299.327 ms/step.
Train [24/40]. 641.44 samples/sec. 299.328 ms/step.
Train [32/40]. 641.42 samples/sec. 299.335 ms/step.
Train [40/40]. 641.39 samples/sec. 299.350 ms/step.
Train benchmark of regnety_032.tv2_in1k done. 638.58 samples/sec, 299.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_040.pycls_in1k created, param count: 20646656
Running inference benchmark on regnety_040.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2002.69 samples/sec. 127.828 ms/step.
Infer [16/40]. 2002.84 samples/sec. 127.818 ms/step.
Infer [24/40]. 2002.93 samples/sec. 127.813 ms/step.
Infer [32/40]. 2002.93 samples/sec. 127.813 ms/step.
Infer [40/40]. 2002.93 samples/sec. 127.813 ms/step.
Inference benchmark of regnety_040.pycls_in1k done. 2002.47 samples/sec, 127.81 ms/step
Model regnety_040.pycls_in1k created, param count: 20646656
Running train benchmark on regnety_040.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 410.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_040.pycls_in1k created, param count: 20646656
Running train benchmark on regnety_040.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 597.62 samples/sec. 321.273 ms/step.
Train [16/40]. 597.58 samples/sec. 321.299 ms/step.
Train [24/40]. 597.56 samples/sec. 321.307 ms/step.
Train [32/40]. 597.57 samples/sec. 321.304 ms/step.
Train [40/40]. 597.56 samples/sec. 321.306 ms/step.
Train benchmark of regnety_040.pycls_in1k done. 595.02 samples/sec, 321.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_040.ra3_in1k created, param count: 20646656
Running inference benchmark on regnety_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1189.22 samples/sec. 215.267 ms/step.
Infer [16/40]. 1189.17 samples/sec. 215.276 ms/step.
Infer [24/40]. 1189.17 samples/sec. 215.276 ms/step.
Infer [32/40]. 1189.20 samples/sec. 215.271 ms/step.
Infer [40/40]. 1189.19 samples/sec. 215.272 ms/step.
Inference benchmark of regnety_040.ra3_in1k done. 1188.97 samples/sec, 215.27 ms/step
Model regnety_040.ra3_in1k created, param count: 20646656
Running train benchmark on regnety_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 257.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_040.ra3_in1k created, param count: 20646656
Running train benchmark on regnety_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 271.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_040.ra3_in1k created, param count: 20646656
Running train benchmark on regnety_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.11 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_040.ra3_in1k created, param count: 20646656
Running train benchmark on regnety_040.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 360.37 samples/sec. 266.390 ms/step.
Train [16/40]. 360.36 samples/sec. 266.398 ms/step.
Train [24/40]. 360.35 samples/sec. 266.409 ms/step.
Train [32/40]. 360.33 samples/sec. 266.423 ms/step.
Train [40/40]. 360.33 samples/sec. 266.421 ms/step.
Train benchmark of regnety_040.ra3_in1k done. 358.49 samples/sec, 266.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_064.pycls_in1k created, param count: 30583252
Running inference benchmark on regnety_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1312.82 samples/sec. 195.000 ms/step.
Infer [16/40]. 1312.58 samples/sec. 195.035 ms/step.
Infer [24/40]. 1312.42 samples/sec. 195.060 ms/step.
Infer [32/40]. 1312.38 samples/sec. 195.066 ms/step.
Infer [40/40]. 1312.32 samples/sec. 195.074 ms/step.
Inference benchmark of regnety_064.pycls_in1k done. 1312.08 samples/sec, 195.07 ms/step
Model regnety_064.pycls_in1k created, param count: 30583252
Running train benchmark on regnety_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 92.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_064.pycls_in1k created, param count: 30583252
Running train benchmark on regnety_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 818.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_064.pycls_in1k created, param count: 30583252
Running train benchmark on regnety_064.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 397.85 samples/sec. 321.726 ms/step.
Train [16/40]. 397.81 samples/sec. 321.764 ms/step.
Train [24/40]. 397.80 samples/sec. 321.770 ms/step.
Train [32/40]. 397.79 samples/sec. 321.778 ms/step.
Train [40/40]. 397.79 samples/sec. 321.777 ms/step.
Train benchmark of regnety_064.pycls_in1k done. 395.90 samples/sec, 321.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_064.ra3_in1k created, param count: 30583252
Running inference benchmark on regnety_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 805.52 samples/sec. 317.808 ms/step.
Infer [16/40]. 805.70 samples/sec. 317.737 ms/step.
Infer [24/40]. 805.71 samples/sec. 317.734 ms/step.
Infer [32/40]. 805.74 samples/sec. 317.721 ms/step.
Infer [40/40]. 805.72 samples/sec. 317.727 ms/step.
Inference benchmark of regnety_064.ra3_in1k done. 805.61 samples/sec, 317.73 ms/step
Model regnety_064.ra3_in1k created, param count: 30583252
Running train benchmark on regnety_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 52.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_064.ra3_in1k created, param count: 30583252
Running train benchmark on regnety_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 181.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_064.ra3_in1k created, param count: 30583252
Running train benchmark on regnety_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 387.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_064.ra3_in1k created, param count: 30583252
Running train benchmark on regnety_064.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 239.40 samples/sec. 400.995 ms/step.
Train [16/40]. 239.34 samples/sec. 401.103 ms/step.
Train [24/40]. 239.36 samples/sec. 401.074 ms/step.
Train [32/40]. 239.33 samples/sec. 401.115 ms/step.
Train [40/40]. 239.36 samples/sec. 401.077 ms/step.
Train benchmark of regnety_064.ra3_in1k done. 238.40 samples/sec, 401.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_080.pycls_in1k created, param count: 39180068
Running inference benchmark on regnety_080.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1274.84 samples/sec. 200.809 ms/step.
Infer [16/40]. 1274.80 samples/sec. 200.816 ms/step.
Infer [24/40]. 1274.76 samples/sec. 200.822 ms/step.
Infer [32/40]. 1274.71 samples/sec. 200.830 ms/step.
Infer [40/40]. 1274.76 samples/sec. 200.823 ms/step.
Inference benchmark of regnety_080.pycls_in1k done. 1274.53 samples/sec, 200.82 ms/step
Model regnety_080.pycls_in1k created, param count: 39180068
Running train benchmark on regnety_080.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 205.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_080.pycls_in1k created, param count: 39180068
Running train benchmark on regnety_080.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 97.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_080.pycls_in1k created, param count: 39180068
Running train benchmark on regnety_080.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 378.91 samples/sec. 337.814 ms/step.
Train [16/40]. 378.87 samples/sec. 337.843 ms/step.
Train [24/40]. 378.83 samples/sec. 337.883 ms/step.
Train [32/40]. 378.80 samples/sec. 337.906 ms/step.
Train [40/40]. 378.79 samples/sec. 337.920 ms/step.
Train benchmark of regnety_080.pycls_in1k done. 377.40 samples/sec, 337.92 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_080.ra3_in1k created, param count: 39180068
Running inference benchmark on regnety_080.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 771.97 samples/sec. 331.618 ms/step.
Infer [16/40]. 772.01 samples/sec. 331.600 ms/step.
Infer [24/40]. 772.02 samples/sec. 331.596 ms/step.
Infer [32/40]. 772.04 samples/sec. 331.591 ms/step.
Infer [40/40]. 772.03 samples/sec. 331.595 ms/step.
Inference benchmark of regnety_080.ra3_in1k done. 771.92 samples/sec, 331.60 ms/step
Model regnety_080.ra3_in1k created, param count: 39180068
Running train benchmark on regnety_080.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.21 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.79 GiB is free. Including non-PyTorch memory, this process has 21.85 GiB memory in use. Of the allocated memory 21.33 GiB is allocated by PyTorch, and 28.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_080.ra3_in1k created, param count: 39180068
Running train benchmark on regnety_080.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 442.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_080.ra3_in1k created, param count: 39180068
Running train benchmark on regnety_080.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 287.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_080.ra3_in1k created, param count: 39180068
Running train benchmark on regnety_080.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 473.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_080.ra3_in1k created, param count: 39180068
Running train benchmark on regnety_080.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 230.87 samples/sec. 277.212 ms/step.
Train [16/40]. 230.88 samples/sec. 277.200 ms/step.
Train [24/40]. 230.88 samples/sec. 277.203 ms/step.
Train [32/40]. 230.88 samples/sec. 277.204 ms/step.
Train [40/40]. 230.87 samples/sec. 277.217 ms/step.
Train benchmark of regnety_080.ra3_in1k done. 229.89 samples/sec, 277.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_080_tv.tv2_in1k created, param count: 39381472
Running inference benchmark on regnety_080_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1184.34 samples/sec. 216.154 ms/step.
Infer [16/40]. 1184.17 samples/sec. 216.185 ms/step.
Infer [24/40]. 1184.14 samples/sec. 216.191 ms/step.
Infer [32/40]. 1184.10 samples/sec. 216.199 ms/step.
Infer [40/40]. 1184.07 samples/sec. 216.204 ms/step.
Inference benchmark of regnety_080_tv.tv2_in1k done. 1183.85 samples/sec, 216.20 ms/step
Model regnety_080_tv.tv2_in1k created, param count: 39381472
Running train benchmark on regnety_080_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 15.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_080_tv.tv2_in1k created, param count: 39381472
Running train benchmark on regnety_080_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 158.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_080_tv.tv2_in1k created, param count: 39381472
Running train benchmark on regnety_080_tv.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 353.92 samples/sec. 361.662 ms/step.
Train [16/40]. 353.94 samples/sec. 361.641 ms/step.
Train [24/40]. 353.95 samples/sec. 361.630 ms/step.
Train [32/40]. 353.94 samples/sec. 361.642 ms/step.
Train [40/40]. 353.94 samples/sec. 361.643 ms/step.
Train benchmark of regnety_080_tv.tv2_in1k done. 352.73 samples/sec, 361.64 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_120.pycls_in1k created, param count: 51822544
Running inference benchmark on regnety_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 984.75 samples/sec. 259.965 ms/step.
Infer [16/40]. 984.67 samples/sec. 259.985 ms/step.
Infer [24/40]. 984.70 samples/sec. 259.978 ms/step.
Infer [32/40]. 984.66 samples/sec. 259.988 ms/step.
Infer [40/40]. 984.65 samples/sec. 259.991 ms/step.
Inference benchmark of regnety_120.pycls_in1k done. 984.49 samples/sec, 259.99 ms/step
Model regnety_120.pycls_in1k created, param count: 51822544
Running train benchmark on regnety_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 216.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 32.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_120.pycls_in1k created, param count: 51822544
Running train benchmark on regnety_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 98.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_120.pycls_in1k created, param count: 51822544
Running train benchmark on regnety_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 360.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_120.pycls_in1k created, param count: 51822544
Running train benchmark on regnety_120.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 304.19 samples/sec. 315.589 ms/step.
Train [16/40]. 304.15 samples/sec. 315.633 ms/step.
Train [24/40]. 304.04 samples/sec. 315.748 ms/step.
Train [32/40]. 304.07 samples/sec. 315.714 ms/step.
Train [40/40]. 304.07 samples/sec. 315.715 ms/step.
Train benchmark of regnety_120.pycls_in1k done. 302.79 samples/sec, 315.71 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_120.sw_in12k created, param count: 76072405
Running inference benchmark on regnety_120.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 595.31 samples/sec. 430.028 ms/step.
Infer [16/40]. 595.31 samples/sec. 430.027 ms/step.
Infer [24/40]. 595.32 samples/sec. 430.024 ms/step.
Infer [32/40]. 595.31 samples/sec. 430.030 ms/step.
Infer [40/40]. 595.31 samples/sec. 430.028 ms/step.
Inference benchmark of regnety_120.sw_in12k done. 595.25 samples/sec, 430.03 ms/step
Model regnety_120.sw_in12k created, param count: 76072405
Running train benchmark on regnety_120.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 286.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_120.sw_in12k created, param count: 76072405
Running train benchmark on regnety_120.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 298.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 241.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_120.sw_in12k created, param count: 76072405
Running train benchmark on regnety_120.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 169.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_120.sw_in12k created, param count: 76072405
Running train benchmark on regnety_120.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 337.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_120.sw_in12k created, param count: 76072405
Running train benchmark on regnety_120.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 182.23 samples/sec. 351.209 ms/step.
Train [16/40]. 182.19 samples/sec. 351.280 ms/step.
Train [24/40]. 182.23 samples/sec. 351.206 ms/step.
Train [32/40]. 182.22 samples/sec. 351.219 ms/step.
Train [40/40]. 182.24 samples/sec. 351.194 ms/step.
Train benchmark of regnety_120.sw_in12k done. 181.56 samples/sec, 351.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_120.sw_in12k_ft_in1k created, param count: 51822544
Running inference benchmark on regnety_120.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 595.58 samples/sec. 429.834 ms/step.
Infer [16/40]. 595.61 samples/sec. 429.809 ms/step.
Infer [24/40]. 595.57 samples/sec. 429.840 ms/step.
Infer [32/40]. 595.56 samples/sec. 429.848 ms/step.
Infer [40/40]. 595.55 samples/sec. 429.855 ms/step.
Inference benchmark of regnety_120.sw_in12k_ft_in1k done. 595.48 samples/sec, 429.86 ms/step
Model regnety_120.sw_in12k_ft_in1k created, param count: 51822544
Running train benchmark on regnety_120.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 368.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 29.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_120.sw_in12k_ft_in1k created, param count: 51822544
Running train benchmark on regnety_120.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 380.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 253.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_120.sw_in12k_ft_in1k created, param count: 51822544
Running train benchmark on regnety_120.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 202.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_120.sw_in12k_ft_in1k created, param count: 51822544
Running train benchmark on regnety_120.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 337.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_120.sw_in12k_ft_in1k created, param count: 51822544
Running train benchmark on regnety_120.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 182.98 samples/sec. 349.766 ms/step.
Train [16/40]. 182.88 samples/sec. 349.948 ms/step.
Train [24/40]. 182.93 samples/sec. 349.857 ms/step.
Train [32/40]. 182.91 samples/sec. 349.895 ms/step.
Train [40/40]. 182.93 samples/sec. 349.860 ms/step.
Train benchmark of regnety_120.sw_in12k_ft_in1k done. 182.24 samples/sec, 349.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.deit_in1k created, param count: 83590140
Running inference benchmark on regnety_160.deit_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 515.81 samples/sec. 496.305 ms/step.
Infer [16/40]. 515.79 samples/sec. 496.329 ms/step.
Infer [24/40]. 515.78 samples/sec. 496.334 ms/step.
Infer [32/40]. 515.78 samples/sec. 496.335 ms/step.
Infer [40/40]. 515.79 samples/sec. 496.325 ms/step.
Inference benchmark of regnety_160.deit_in1k done. 515.74 samples/sec, 496.32 ms/step
Model regnety_160.deit_in1k created, param count: 83590140
Running train benchmark on regnety_160.deit_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 260.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 13.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.deit_in1k created, param count: 83590140
Running train benchmark on regnety_160.deit_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 243.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.deit_in1k created, param count: 83590140
Running train benchmark on regnety_160.deit_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 780.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 608.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 136.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.deit_in1k created, param count: 83590140
Running train benchmark on regnety_160.deit_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 781.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_160.deit_in1k created, param count: 83590140
Running train benchmark on regnety_160.deit_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 155.49 samples/sec. 411.591 ms/step.
Train [16/40]. 155.49 samples/sec. 411.606 ms/step.
Train [24/40]. 155.49 samples/sec. 411.595 ms/step.
Train [32/40]. 155.52 samples/sec. 411.525 ms/step.
Train [40/40]. 155.53 samples/sec. 411.484 ms/step.
Train benchmark of regnety_160.deit_in1k done. 155.05 samples/sec, 411.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.lion_in12k_ft_in1k created, param count: 83590140
Running inference benchmark on regnety_160.lion_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 515.81 samples/sec. 496.309 ms/step.
Infer [16/40]. 515.78 samples/sec. 496.336 ms/step.
Infer [24/40]. 515.80 samples/sec. 496.316 ms/step.
Infer [32/40]. 515.78 samples/sec. 496.336 ms/step.
Infer [40/40]. 515.78 samples/sec. 496.334 ms/step.
Inference benchmark of regnety_160.lion_in12k_ft_in1k done. 515.73 samples/sec, 496.33 ms/step
Model regnety_160.lion_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.lion_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 260.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 13.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.lion_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.lion_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 243.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.lion_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.lion_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 780.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 608.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 136.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.lion_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.lion_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 638.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_160.lion_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.lion_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 155.45 samples/sec. 411.714 ms/step.
Train [16/40]. 155.48 samples/sec. 411.621 ms/step.
Train [24/40]. 155.47 samples/sec. 411.666 ms/step.
Train [32/40]. 155.49 samples/sec. 411.604 ms/step.
Train [40/40]. 155.48 samples/sec. 411.616 ms/step.
Train benchmark of regnety_160.lion_in12k_ft_in1k done. 155.00 samples/sec, 411.62 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.pycls_in1k created, param count: 83590140
Running inference benchmark on regnety_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 846.96 samples/sec. 302.257 ms/step.
Infer [16/40]. 847.10 samples/sec. 302.206 ms/step.
Infer [24/40]. 847.08 samples/sec. 302.214 ms/step.
Infer [32/40]. 847.14 samples/sec. 302.194 ms/step.
Infer [40/40]. 847.15 samples/sec. 302.189 ms/step.
Inference benchmark of regnety_160.pycls_in1k done. 847.03 samples/sec, 302.19 ms/step
Model regnety_160.pycls_in1k created, param count: 83590140
Running train benchmark on regnety_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.pycls_in1k created, param count: 83590140
Running train benchmark on regnety_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 293.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.pycls_in1k created, param count: 83590140
Running train benchmark on regnety_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 897.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.pycls_in1k created, param count: 83590140
Running train benchmark on regnety_160.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 257.33 samples/sec. 373.059 ms/step.
Train [16/40]. 257.37 samples/sec. 373.008 ms/step.
Train [24/40]. 257.40 samples/sec. 372.956 ms/step.
Train [32/40]. 257.40 samples/sec. 372.957 ms/step.
Train [40/40]. 257.39 samples/sec. 372.973 ms/step.
Train benchmark of regnety_160.pycls_in1k done. 256.51 samples/sec, 372.97 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.sw_in12k created, param count: 116323665
Running inference benchmark on regnety_160.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 515.49 samples/sec. 496.614 ms/step.
Infer [16/40]. 515.49 samples/sec. 496.614 ms/step.
Infer [24/40]. 515.50 samples/sec. 496.604 ms/step.
Infer [32/40]. 515.49 samples/sec. 496.612 ms/step.
Infer [40/40]. 515.50 samples/sec. 496.606 ms/step.
Inference benchmark of regnety_160.sw_in12k done. 515.45 samples/sec, 496.61 ms/step
Model regnety_160.sw_in12k created, param count: 116323665
Running train benchmark on regnety_160.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 26.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.sw_in12k created, param count: 116323665
Running train benchmark on regnety_160.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 408.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 403.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.sw_in12k created, param count: 116323665
Running train benchmark on regnety_160.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 228.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 391.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.sw_in12k created, param count: 116323665
Running train benchmark on regnety_160.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 886.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_160.sw_in12k created, param count: 116323665
Running train benchmark on regnety_160.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 154.82 samples/sec. 413.375 ms/step.
Train [16/40]. 154.82 samples/sec. 413.395 ms/step.
Train [24/40]. 154.80 samples/sec. 413.427 ms/step.
Train [32/40]. 154.80 samples/sec. 413.427 ms/step.
Train [40/40]. 154.79 samples/sec. 413.453 ms/step.
Train benchmark of regnety_160.sw_in12k done. 154.30 samples/sec, 413.45 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.sw_in12k_ft_in1k created, param count: 83590140
Running inference benchmark on regnety_160.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 515.73 samples/sec. 496.386 ms/step.
Infer [16/40]. 515.74 samples/sec. 496.377 ms/step.
Infer [24/40]. 515.74 samples/sec. 496.376 ms/step.
Infer [32/40]. 515.73 samples/sec. 496.382 ms/step.
Infer [40/40]. 515.74 samples/sec. 496.372 ms/step.
Inference benchmark of regnety_160.sw_in12k_ft_in1k done. 515.69 samples/sec, 496.37 ms/step
Model regnety_160.sw_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 260.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 13.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.sw_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 243.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.sw_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 780.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 608.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 136.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.sw_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 610.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_160.sw_in12k_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 155.61 samples/sec. 411.285 ms/step.
Train [16/40]. 155.59 samples/sec. 411.348 ms/step.
Train [24/40]. 155.59 samples/sec. 411.337 ms/step.
Train [32/40]. 155.57 samples/sec. 411.385 ms/step.
Train [40/40]. 155.56 samples/sec. 411.409 ms/step.
Train benchmark of regnety_160.sw_in12k_ft_in1k done. 155.07 samples/sec, 411.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running inference benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.88 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.63 GiB is free. Including non-PyTorch memory, this process has 17.01 GiB memory in use. Of the allocated memory 9.75 GiB is allocated by PyTorch, and 6.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running inference benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 293.46 samples/sec. 654.257 ms/step.
Infer [16/40]. 293.43 samples/sec. 654.319 ms/step.
Infer [24/40]. 293.43 samples/sec. 654.328 ms/step.
Infer [32/40]. 293.42 samples/sec. 654.357 ms/step.
Infer [40/40]. 293.42 samples/sec. 654.363 ms/step.
Inference benchmark of regnety_160.swag_ft_in1k done. 293.39 samples/sec, 654.36 ms/step
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 23.65 GiB of which 454.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 9.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.34 GiB is free. Including non-PyTorch memory, this process has 22.30 GiB memory in use. Of the allocated memory 21.54 GiB is allocated by PyTorch, and 279.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1008.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 646.06 MiB is free. Including non-PyTorch memory, this process has 23.01 GiB memory in use. Of the allocated memory 22.34 GiB is allocated by PyTorch, and 179.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 338.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 372.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 757.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_160.swag_ft_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 90.32 samples/sec. 354.279 ms/step.
Train [16/40]. 90.32 samples/sec. 354.290 ms/step.
Train [24/40]. 90.33 samples/sec. 354.270 ms/step.
Train [32/40]. 90.32 samples/sec. 354.288 ms/step.
Train [40/40]. 90.32 samples/sec. 354.298 ms/step.
Train benchmark of regnety_160.swag_ft_in1k done. 90.00 samples/sec, 354.30 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.swag_lc_in1k created, param count: 83590140
Running inference benchmark on regnety_160.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 847.62 samples/sec. 302.023 ms/step.
Infer [16/40]. 847.42 samples/sec. 302.092 ms/step.
Infer [24/40]. 847.37 samples/sec. 302.110 ms/step.
Infer [32/40]. 847.29 samples/sec. 302.141 ms/step.
Infer [40/40]. 847.26 samples/sec. 302.149 ms/step.
Inference benchmark of regnety_160.swag_lc_in1k done. 847.13 samples/sec, 302.15 ms/step
Model regnety_160.swag_lc_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.swag_lc_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 291.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.swag_lc_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 890.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.swag_lc_in1k created, param count: 83590140
Running train benchmark on regnety_160.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 257.34 samples/sec. 373.051 ms/step.
Train [16/40]. 257.28 samples/sec. 373.129 ms/step.
Train [24/40]. 257.30 samples/sec. 373.110 ms/step.
Train [32/40]. 257.31 samples/sec. 373.096 ms/step.
Train [40/40]. 257.31 samples/sec. 373.091 ms/step.
Train benchmark of regnety_160.swag_lc_in1k done. 256.44 samples/sec, 373.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_160.tv2_in1k created, param count: 83590140
Running inference benchmark on regnety_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 847.14 samples/sec. 302.193 ms/step.
Infer [16/40]. 847.18 samples/sec. 302.178 ms/step.
Infer [24/40]. 847.25 samples/sec. 302.155 ms/step.
Infer [32/40]. 847.24 samples/sec. 302.157 ms/step.
Infer [40/40]. 847.24 samples/sec. 302.159 ms/step.
Inference benchmark of regnety_160.tv2_in1k done. 847.11 samples/sec, 302.16 ms/step
Model regnety_160.tv2_in1k created, param count: 83590140
Running train benchmark on regnety_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 106.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_160.tv2_in1k created, param count: 83590140
Running train benchmark on regnety_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 291.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_160.tv2_in1k created, param count: 83590140
Running train benchmark on regnety_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 890.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_160.tv2_in1k created, param count: 83590140
Running train benchmark on regnety_160.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 257.48 samples/sec. 372.846 ms/step.
Train [16/40]. 257.44 samples/sec. 372.906 ms/step.
Train [24/40]. 257.46 samples/sec. 372.873 ms/step.
Train [32/40]. 257.44 samples/sec. 372.899 ms/step.
Train [40/40]. 257.40 samples/sec. 372.955 ms/step.
Train benchmark of regnety_160.tv2_in1k done. 256.52 samples/sec, 372.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_320.pycls_in1k created, param count: 145046770
Running inference benchmark on regnety_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 561.47 samples/sec. 455.946 ms/step.
Infer [16/40]. 561.40 samples/sec. 456.000 ms/step.
Infer [24/40]. 561.36 samples/sec. 456.037 ms/step.
Infer [32/40]. 561.34 samples/sec. 456.048 ms/step.
Infer [40/40]. 561.33 samples/sec. 456.062 ms/step.
Inference benchmark of regnety_320.pycls_in1k done. 561.27 samples/sec, 456.06 ms/step
Model regnety_320.pycls_in1k created, param count: 145046770
Running train benchmark on regnety_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 534.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 722.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.pycls_in1k created, param count: 145046770
Running train benchmark on regnety_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 352.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 478.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_320.pycls_in1k created, param count: 145046770
Running train benchmark on regnety_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 355.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_320.pycls_in1k created, param count: 145046770
Running train benchmark on regnety_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 570.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_320.pycls_in1k created, param count: 145046770
Running train benchmark on regnety_320.pycls_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 162.58 samples/sec. 393.649 ms/step.
Train [16/40]. 162.58 samples/sec. 393.664 ms/step.
Train [24/40]. 162.57 samples/sec. 393.675 ms/step.
Train [32/40]. 162.57 samples/sec. 393.679 ms/step.
Train [40/40]. 162.57 samples/sec. 393.668 ms/step.
Train benchmark of regnety_320.pycls_in1k done. 162.00 samples/sec, 393.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_320.seer created, param count: 141333770
Running inference benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 561.69 samples/sec. 455.767 ms/step.
Infer [16/40]. 561.76 samples/sec. 455.707 ms/step.
Infer [24/40]. 561.80 samples/sec. 455.679 ms/step.
Infer [32/40]. 561.77 samples/sec. 455.699 ms/step.
Infer [40/40]. 561.75 samples/sec. 455.720 ms/step.
Inference benchmark of regnety_320.seer done. 561.68 samples/sec, 455.72 ms/step
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 534.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 721.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 411.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 427.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 561.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model regnety_320.seer created, param count: 141333770
Running train benchmark on regnety_320.seer for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running inference benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 8.16 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.86 GiB is free. Including non-PyTorch memory, this process has 15.78 GiB memory in use. Of the allocated memory 10.27 GiB is allocated by PyTorch, and 5.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running inference benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 199.68 samples/sec. 961.533 ms/step.
Infer [16/40]. 199.65 samples/sec. 961.670 ms/step.
Infer [24/40]. 199.62 samples/sec. 961.818 ms/step.
Infer [32/40]. 199.60 samples/sec. 961.907 ms/step.
Infer [40/40]. 199.59 samples/sec. 961.973 ms/step.
Inference benchmark of regnety_320.seer_ft_in1k done. 199.58 samples/sec, 961.97 ms/step
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.53 GiB is free. Including non-PyTorch memory, this process has 22.11 GiB memory in use. Of the allocated memory 21.59 GiB is allocated by PyTorch, and 25.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 424.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 283.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacty of 23.65 GiB of which 720.06 MiB is free. Including non-PyTorch memory, this process has 22.94 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 153.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 586.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 355.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 310.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 592.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 462.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 21.72 GiB is allocated by PyTorch, and 994.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 21.85 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_320.seer_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 56.55 samples/sec. 424.367 ms/step.
Train [16/40]. 56.55 samples/sec. 424.387 ms/step.
Train [24/40]. 56.55 samples/sec. 424.388 ms/step.
Train [32/40]. 56.55 samples/sec. 424.393 ms/step.
Train [40/40]. 56.55 samples/sec. 424.421 ms/step.
Train benchmark of regnety_320.seer_ft_in1k done. 56.36 samples/sec, 424.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running inference benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.82 GiB is free. Including non-PyTorch memory, this process has 17.82 GiB memory in use. Of the allocated memory 9.15 GiB is allocated by PyTorch, and 8.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running inference benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 199.71 samples/sec. 961.402 ms/step.
Infer [16/40]. 199.71 samples/sec. 961.418 ms/step.
Infer [24/40]. 199.69 samples/sec. 961.486 ms/step.
Infer [32/40]. 199.69 samples/sec. 961.512 ms/step.
Infer [40/40]. 199.68 samples/sec. 961.527 ms/step.
Inference benchmark of regnety_320.swag_ft_in1k done. 199.67 samples/sec, 961.53 ms/step
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.53 GiB is free. Including non-PyTorch memory, this process has 22.11 GiB memory in use. Of the allocated memory 21.59 GiB is allocated by PyTorch, and 25.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 424.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 283.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacty of 23.65 GiB of which 720.06 MiB is free. Including non-PyTorch memory, this process has 22.94 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 153.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 586.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 355.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 390.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 511.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 364.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 21.72 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 21.75 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_320.swag_ft_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 56.55 samples/sec. 424.411 ms/step.
Train [16/40]. 56.55 samples/sec. 424.435 ms/step.
Train [24/40]. 56.54 samples/sec. 424.456 ms/step.
Train [32/40]. 56.54 samples/sec. 424.446 ms/step.
Train [40/40]. 56.55 samples/sec. 424.439 ms/step.
Train benchmark of regnety_320.swag_ft_in1k done. 56.36 samples/sec, 424.44 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_320.swag_lc_in1k created, param count: 145046770
Running inference benchmark on regnety_320.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 561.94 samples/sec. 455.566 ms/step.
Infer [16/40]. 561.86 samples/sec. 455.626 ms/step.
Infer [24/40]. 561.85 samples/sec. 455.642 ms/step.
Infer [32/40]. 561.85 samples/sec. 455.636 ms/step.
Infer [40/40]. 561.84 samples/sec. 455.649 ms/step.
Inference benchmark of regnety_320.swag_lc_in1k done. 561.78 samples/sec, 455.65 ms/step
Model regnety_320.swag_lc_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 534.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 722.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.swag_lc_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 396.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_320.swag_lc_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 419.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_320.swag_lc_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 516.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_320.swag_lc_in1k created, param count: 145046770
Running train benchmark on regnety_320.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 162.66 samples/sec. 393.447 ms/step.
Train [16/40]. 162.66 samples/sec. 393.449 ms/step.
Train [24/40]. 162.67 samples/sec. 393.428 ms/step.
Train [32/40]. 162.66 samples/sec. 393.448 ms/step.
Train [40/40]. 162.66 samples/sec. 393.459 ms/step.
Train benchmark of regnety_320.swag_lc_in1k done. 162.11 samples/sec, 393.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_320.tv2_in1k created, param count: 145046770
Running inference benchmark on regnety_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 561.87 samples/sec. 455.622 ms/step.
Infer [16/40]. 561.86 samples/sec. 455.627 ms/step.
Infer [24/40]. 561.85 samples/sec. 455.638 ms/step.
Infer [32/40]. 561.85 samples/sec. 455.638 ms/step.
Infer [40/40]. 561.84 samples/sec. 455.642 ms/step.
Inference benchmark of regnety_320.tv2_in1k done. 561.79 samples/sec, 455.64 ms/step
Model regnety_320.tv2_in1k created, param count: 145046770
Running train benchmark on regnety_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 534.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 722.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_320.tv2_in1k created, param count: 145046770
Running train benchmark on regnety_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 396.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_320.tv2_in1k created, param count: 145046770
Running train benchmark on regnety_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 419.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_320.tv2_in1k created, param count: 145046770
Running train benchmark on regnety_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 516.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_320.tv2_in1k created, param count: 145046770
Running train benchmark on regnety_320.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 162.71 samples/sec. 393.345 ms/step.
Train [16/40]. 162.70 samples/sec. 393.350 ms/step.
Train [24/40]. 162.71 samples/sec. 393.337 ms/step.
Train [32/40]. 162.71 samples/sec. 393.347 ms/step.
Train [40/40]. 162.70 samples/sec. 393.361 ms/step.
Train benchmark of regnety_320.tv2_in1k done. 162.15 samples/sec, 393.36 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_640.seer created, param count: 276457786
Running inference benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 340.04 samples/sec. 752.861 ms/step.
Infer [16/40]. 339.98 samples/sec. 752.996 ms/step.
Infer [24/40]. 339.95 samples/sec. 753.053 ms/step.
Infer [32/40]. 339.95 samples/sec. 753.063 ms/step.
Infer [40/40]. 339.93 samples/sec. 753.098 ms/step.
Inference benchmark of regnety_640.seer done. 339.90 samples/sec, 753.10 ms/step
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1006.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 512.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 87.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 566.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 282.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 164.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.11 GiB is allocated by PyTorch, and 904.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 584.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model regnety_640.seer created, param count: 276457786
Running train benchmark on regnety_640.seer for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running inference benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 11.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.94 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 66.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running inference benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 8.65 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.26 GiB is free. Including non-PyTorch memory, this process has 17.38 GiB memory in use. Of the allocated memory 10.87 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running inference benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 121.17 samples/sec. 1056.347 ms/step.
Infer [16/40]. 121.29 samples/sec. 1055.290 ms/step.
Infer [24/40]. 121.36 samples/sec. 1054.698 ms/step.
Infer [32/40]. 121.43 samples/sec. 1054.116 ms/step.
Infer [40/40]. 121.53 samples/sec. 1053.235 ms/step.
Inference benchmark of regnety_640.seer_ft_in1k done. 121.52 samples/sec, 1053.23 ms/step
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 11.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.81 GiB is free. Including non-PyTorch memory, this process has 15.83 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 66.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 23.65 GiB of which 258.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 372.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacty of 23.65 GiB of which 340.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 235.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 451.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 554.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 330.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 416.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 761.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 563.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model regnety_640.seer_ft_in1k created, param count: 281378786
Running train benchmark on regnety_640.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 34.81 samples/sec. 459.674 ms/step.
Train [16/40]. 34.80 samples/sec. 459.709 ms/step.
Train [24/40]. 34.80 samples/sec. 459.713 ms/step.
Train [32/40]. 34.80 samples/sec. 459.720 ms/step.
Train [40/40]. 34.80 samples/sec. 459.731 ms/step.
Train benchmark of regnety_640.seer_ft_in1k done. 34.70 samples/sec, 459.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_1280.seer created, param count: 637419894
Running inference benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 176.06 samples/sec. 1454.048 ms/step.
Infer [16/40]. 176.02 samples/sec. 1454.369 ms/step.
Infer [24/40]. 176.03 samples/sec. 1454.281 ms/step.
Infer [32/40]. 176.00 samples/sec. 1454.528 ms/step.
Infer [40/40]. 175.98 samples/sec. 1454.743 ms/step.
Inference benchmark of regnety_1280.seer done. 175.97 samples/sec, 1454.74 ms/step
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 740.06 MiB is free. Including non-PyTorch memory, this process has 22.92 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 168.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 795.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 998.06 MiB is free. Including non-PyTorch memory, this process has 22.67 GiB memory in use. Of the allocated memory 21.02 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 21.59 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 21.38 GiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 20.32 GiB is allocated by PyTorch, and 2.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model regnety_1280.seer created, param count: 637419894
Running train benchmark on regnety_1280.seer for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 18.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 460.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 168.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.92 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.65 GiB is free. Including non-PyTorch memory, this process has 18.99 GiB memory in use. Of the allocated memory 17.51 GiB is allocated by PyTorch, and 1006.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.28 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the allocated memory 12.49 GiB is allocated by PyTorch, and 9.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.42 GiB is free. Including non-PyTorch memory, this process has 18.22 GiB memory in use. Of the allocated memory 9.97 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Infer [8/40]. 62.94 samples/sec. 1016.894 ms/step.
Infer [16/40]. 62.93 samples/sec. 1017.044 ms/step.
Infer [24/40]. 62.92 samples/sec. 1017.168 ms/step.
Infer [32/40]. 62.91 samples/sec. 1017.289 ms/step.
Infer [40/40]. 62.91 samples/sec. 1017.388 ms/step.
Inference benchmark of regnety_1280.seer_ft_in1k done. 62.90 samples/sec, 1017.39 ms/step
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 18.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 17.89 GiB is free. Including non-PyTorch memory, this process has 5.75 GiB memory in use. Of the allocated memory 5.09 GiB is allocated by PyTorch, and 168.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.92 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.80 GiB is free. Including non-PyTorch memory, this process has 19.84 GiB memory in use. Of the allocated memory 18.36 GiB is allocated by PyTorch, and 1006.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.28 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.21 GiB is free. Including non-PyTorch memory, this process has 14.43 GiB memory in use. Of the allocated memory 13.05 GiB is allocated by PyTorch, and 903.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 20.83 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacty of 23.65 GiB of which 358.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 21.66 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 21.21 GiB is allocated by PyTorch, and 1.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 156.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 21.18 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 21.21 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 20.49 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model regnety_1280.seer_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 17.07 samples/sec. 468.600 ms/step.
Train [16/40]. 17.07 samples/sec. 468.598 ms/step.
Train [24/40]. 17.07 samples/sec. 468.614 ms/step.
Train [32/40]. 17.07 samples/sec. 468.635 ms/step.
Train [40/40]. 17.07 samples/sec. 468.644 ms/step.
Train benchmark of regnety_1280.seer_ft_in1k done. 17.01 samples/sec, 468.64 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 18.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 460.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 168.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.92 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.65 GiB is free. Including non-PyTorch memory, this process has 18.99 GiB memory in use. Of the allocated memory 17.51 GiB is allocated by PyTorch, and 1006.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.28 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the allocated memory 12.49 GiB is allocated by PyTorch, and 9.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 6.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.53 GiB is free. Including non-PyTorch memory, this process has 19.11 GiB memory in use. Of the allocated memory 9.97 GiB is allocated by PyTorch, and 8.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Infer [8/40]. 62.98 samples/sec. 1016.268 ms/step.
Infer [16/40]. 62.95 samples/sec. 1016.688 ms/step.
Infer [24/40]. 62.94 samples/sec. 1016.832 ms/step.
Infer [32/40]. 62.93 samples/sec. 1016.966 ms/step.
Infer [40/40]. 62.93 samples/sec. 1017.033 ms/step.
Inference benchmark of regnety_1280.swag_ft_in1k done. 62.93 samples/sec, 1017.03 ms/step
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 18.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 17.89 GiB is free. Including non-PyTorch memory, this process has 5.75 GiB memory in use. Of the allocated memory 5.09 GiB is allocated by PyTorch, and 168.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.92 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.80 GiB is free. Including non-PyTorch memory, this process has 19.84 GiB memory in use. Of the allocated memory 18.36 GiB is allocated by PyTorch, and 1006.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 9.28 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.21 GiB is free. Including non-PyTorch memory, this process has 14.43 GiB memory in use. Of the allocated memory 13.05 GiB is allocated by PyTorch, and 903.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 20.83 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacty of 23.65 GiB of which 358.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 21.66 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 21.21 GiB is allocated by PyTorch, and 1.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 230.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 21.39 GiB is allocated by PyTorch, and 1.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 21.21 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 21.09 GiB is allocated by PyTorch, and 1.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 19.20 GiB is allocated by PyTorch, and 3.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model regnety_1280.swag_ft_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 6.
Train [8/40]. 16.31 samples/sec. 367.905 ms/step.
Train [16/40]. 16.31 samples/sec. 367.895 ms/step.
Train [24/40]. 16.31 samples/sec. 367.925 ms/step.
Train [32/40]. 16.31 samples/sec. 367.906 ms/step.
Train [40/40]. 16.31 samples/sec. 367.913 ms/step.
Train benchmark of regnety_1280.swag_ft_in1k done. 16.24 samples/sec, 367.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running inference benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 176.23 samples/sec. 1452.624 ms/step.
Infer [16/40]. 176.16 samples/sec. 1453.247 ms/step.
Infer [24/40]. 176.12 samples/sec. 1453.576 ms/step.
Infer [32/40]. 176.09 samples/sec. 1453.807 ms/step.
Infer [40/40]. 176.05 samples/sec. 1454.143 ms/step.
Inference benchmark of regnety_1280.swag_lc_in1k done. 176.04 samples/sec, 1454.14 ms/step
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 710.06 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 169.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 308.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 797.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 968.06 MiB is free. Including non-PyTorch memory, this process has 22.70 GiB memory in use. Of the allocated memory 21.05 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.02 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 556.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.01 GiB is allocated by PyTorch, and 894.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 21.51 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 20.34 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_1280.swag_lc_in1k created, param count: 644812894
Running train benchmark on regnety_1280.swag_lc_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 49.61 samples/sec. 483.800 ms/step.
Train [16/40]. 49.60 samples/sec. 483.891 ms/step.
Train [24/40]. 49.60 samples/sec. 483.843 ms/step.
Train [32/40]. 49.60 samples/sec. 483.840 ms/step.
Train [40/40]. 49.60 samples/sec. 483.848 ms/step.
Train benchmark of regnety_1280.swag_lc_in1k done. 49.43 samples/sec, 483.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running inference benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 26.23 GiB. GPU 0 has a total capacty of 23.65 GiB of which 16.62 GiB is free. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 178.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running inference benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 19.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 16.67 GiB is free. Including non-PyTorch memory, this process has 6.97 GiB memory in use. Of the allocated memory 5.97 GiB is allocated by PyTorch, and 513.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running inference benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 13.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.04 GiB is free. Including non-PyTorch memory, this process has 19.61 GiB memory in use. Of the allocated memory 18.69 GiB is allocated by PyTorch, and 430.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running inference benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.84 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.21 GiB is free. Including non-PyTorch memory, this process has 16.43 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 731.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running inference benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 6.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.78 GiB is free. Including non-PyTorch memory, this process has 18.86 GiB memory in use. Of the allocated memory 11.75 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running inference benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
Infer [8/40]. 35.86 samples/sec. 1338.520 ms/step.
Infer [16/40]. 35.85 samples/sec. 1338.942 ms/step.
Infer [24/40]. 35.84 samples/sec. 1339.399 ms/step.
Infer [32/40]. 35.83 samples/sec. 1339.678 ms/step.
Infer [40/40]. 35.83 samples/sec. 1339.838 ms/step.
Inference benchmark of regnety_2560.seer_ft_in1k done. 35.82 samples/sec, 1339.84 ms/step
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 26.23 GiB. GPU 0 has a total capacty of 23.65 GiB of which 15.49 GiB is free. Including non-PyTorch memory, this process has 8.15 GiB memory in use. Of the allocated memory 7.48 GiB is allocated by PyTorch, and 178.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 19.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 15.83 GiB is free. Including non-PyTorch memory, this process has 7.81 GiB memory in use. Of the allocated memory 6.81 GiB is allocated by PyTorch, and 513.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 13.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.47 GiB is free. Including non-PyTorch memory, this process has 20.17 GiB memory in use. Of the allocated memory 19.25 GiB is allocated by PyTorch, and 430.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 9.84 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.79 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 15.64 GiB is allocated by PyTorch, and 731.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacty of 23.65 GiB of which 830.06 MiB is free. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 21.86 GiB is allocated by PyTorch, and 483.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 1.23 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 22.51 GiB memory in use. Of the allocated memory 21.29 GiB is allocated by PyTorch, and 739.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 840.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 569.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 316.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 862.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 688.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 917.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 2.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.89 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model regnety_2560.seer_ft_in1k created, param count: 1282601138
Running train benchmark on regnety_2560.seer_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 4.
Train [8/40]. 8.38 samples/sec. 477.215 ms/step.
Train [16/40]. 8.38 samples/sec. 477.147 ms/step.
Train [24/40]. 8.38 samples/sec. 477.203 ms/step.
Train [32/40]. 8.38 samples/sec. 477.194 ms/step.
Train [40/40]. 8.38 samples/sec. 477.180 ms/step.
Train benchmark of regnety_2560.seer_ft_in1k done. 8.35 samples/sec, 477.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_040.ra3_in1k created, param count: 27116800
Running inference benchmark on regnetz_040.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 754.35 samples/sec. 339.365 ms/step.
Infer [16/40]. 754.33 samples/sec. 339.376 ms/step.
Infer [24/40]. 754.20 samples/sec. 339.432 ms/step.
Infer [32/40]. 754.10 samples/sec. 339.479 ms/step.
Infer [40/40]. 753.97 samples/sec. 339.538 ms/step.
Inference benchmark of regnetz_040.ra3_in1k done. 753.88 samples/sec, 339.54 ms/step
Model regnetz_040.ra3_in1k created, param count: 27116800
Running train benchmark on regnetz_040.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1008.06 MiB is free. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 70.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_040.ra3_in1k created, param count: 27116800
Running train benchmark on regnetz_040.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 156.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_040.ra3_in1k created, param count: 27116800
Running train benchmark on regnetz_040.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 128.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_040.ra3_in1k created, param count: 27116800
Running train benchmark on regnetz_040.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 227.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_040.ra3_in1k created, param count: 27116800
Running train benchmark on regnetz_040.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 154.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnetz_040.ra3_in1k created, param count: 27116800
Running train benchmark on regnetz_040.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 186.64 samples/sec. 257.185 ms/step.
Train [16/40]. 186.64 samples/sec. 257.186 ms/step.
Train [24/40]. 186.64 samples/sec. 257.180 ms/step.
Train [32/40]. 186.64 samples/sec. 257.184 ms/step.
Train [40/40]. 186.63 samples/sec. 257.188 ms/step.
Train benchmark of regnetz_040.ra3_in1k done. 185.56 samples/sec, 257.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_040_h.ra3_in1k created, param count: 28938880
Running inference benchmark on regnetz_040_h.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 751.05 samples/sec. 340.858 ms/step.
Infer [16/40]. 750.98 samples/sec. 340.886 ms/step.
Infer [24/40]. 750.85 samples/sec. 340.947 ms/step.
Infer [32/40]. 750.80 samples/sec. 340.969 ms/step.
Infer [40/40]. 750.70 samples/sec. 341.015 ms/step.
Inference benchmark of regnetz_040_h.ra3_in1k done. 750.62 samples/sec, 341.01 ms/step
Model regnetz_040_h.ra3_in1k created, param count: 28938880
Running train benchmark on regnetz_040_h.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1008.06 MiB is free. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 63.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_040_h.ra3_in1k created, param count: 28938880
Running train benchmark on regnetz_040_h.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 168.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_040_h.ra3_in1k created, param count: 28938880
Running train benchmark on regnetz_040_h.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 288.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 210.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_040_h.ra3_in1k created, param count: 28938880
Running train benchmark on regnetz_040_h.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 172.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 240.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_040_h.ra3_in1k created, param count: 28938880
Running train benchmark on regnetz_040_h.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 159.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnetz_040_h.ra3_in1k created, param count: 28938880
Running train benchmark on regnetz_040_h.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 185.99 samples/sec. 258.075 ms/step.
Train [16/40]. 185.98 samples/sec. 258.099 ms/step.
Train [24/40]. 185.96 samples/sec. 258.117 ms/step.
Train [32/40]. 185.96 samples/sec. 258.121 ms/step.
Train [40/40]. 185.96 samples/sec. 258.125 ms/step.
Train benchmark of regnetz_040_h.ra3_in1k done. 184.88 samples/sec, 258.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_b16.ra3_in1k created, param count: 9715480
Running inference benchmark on regnetz_b16.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1794.43 samples/sec. 142.663 ms/step.
Infer [16/40]. 1794.24 samples/sec. 142.679 ms/step.
Infer [24/40]. 1794.21 samples/sec. 142.682 ms/step.
Infer [32/40]. 1794.22 samples/sec. 142.680 ms/step.
Infer [40/40]. 1794.32 samples/sec. 142.673 ms/step.
Inference benchmark of regnetz_b16.ra3_in1k done. 1793.93 samples/sec, 142.67 ms/step
Model regnetz_b16.ra3_in1k created, param count: 9715480
Running train benchmark on regnetz_b16.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 328.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 215.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_b16.ra3_in1k created, param count: 9715480
Running train benchmark on regnetz_b16.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 233.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_b16.ra3_in1k created, param count: 9715480
Running train benchmark on regnetz_b16.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 377.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_b16.ra3_in1k created, param count: 9715480
Running train benchmark on regnetz_b16.ra3_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 457.13 samples/sec. 210.007 ms/step.
Train [16/40]. 457.13 samples/sec. 210.006 ms/step.
Train [24/40]. 457.13 samples/sec. 210.007 ms/step.
Train [32/40]. 457.05 samples/sec. 210.044 ms/step.
Train [40/40]. 457.03 samples/sec. 210.054 ms/step.
Train benchmark of regnetz_b16.ra3_in1k done. 454.54 samples/sec, 210.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_c16.ra3_in1k created, param count: 13459880
Running inference benchmark on regnetz_c16.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 1145.47 samples/sec. 223.489 ms/step.
Infer [16/40]. 1145.35 samples/sec. 223.512 ms/step.
Infer [24/40]. 1145.27 samples/sec. 223.528 ms/step.
Infer [32/40]. 1145.23 samples/sec. 223.536 ms/step.
Infer [40/40]. 1145.18 samples/sec. 223.546 ms/step.
Inference benchmark of regnetz_c16.ra3_in1k done. 1144.98 samples/sec, 223.55 ms/step
Model regnetz_c16.ra3_in1k created, param count: 13459880
Running train benchmark on regnetz_c16.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 208.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 123.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_c16.ra3_in1k created, param count: 13459880
Running train benchmark on regnetz_c16.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 450.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 286.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 237.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_c16.ra3_in1k created, param count: 13459880
Running train benchmark on regnetz_c16.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 126.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 147.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_c16.ra3_in1k created, param count: 13459880
Running train benchmark on regnetz_c16.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 333.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_c16.ra3_in1k created, param count: 13459880
Running train benchmark on regnetz_c16.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
Train [8/40]. 288.21 samples/sec. 222.058 ms/step.
Train [16/40]. 288.18 samples/sec. 222.083 ms/step.
Train [24/40]. 288.15 samples/sec. 222.105 ms/step.
Train [32/40]. 288.21 samples/sec. 222.061 ms/step.
Train [40/40]. 288.22 samples/sec. 222.051 ms/step.
Train benchmark of regnetz_c16.ra3_in1k done. 286.71 samples/sec, 222.05 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running inference benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 461.12 samples/sec. 555.174 ms/step.
Infer [16/40]. 461.10 samples/sec. 555.197 ms/step.
Infer [24/40]. 461.09 samples/sec. 555.209 ms/step.
Infer [32/40]. 461.09 samples/sec. 555.210 ms/step.
Infer [40/40]. 461.07 samples/sec. 555.235 ms/step.
Inference benchmark of regnetz_c16_evos.ch_in1k done. 461.03 samples/sec, 555.24 ms/step
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running train benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.35 GiB is free. Including non-PyTorch memory, this process has 21.29 GiB memory in use. Of the allocated memory 20.67 GiB is allocated by PyTorch, and 124.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running train benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 224.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running train benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 576.06 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 305.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running train benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 128.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running train benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 200.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running train benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 345.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnetz_c16_evos.ch_in1k created, param count: 13487816
Running train benchmark on regnetz_c16_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
Train [8/40]. 121.30 samples/sec. 263.812 ms/step.
Train [16/40]. 121.31 samples/sec. 263.783 ms/step.
Train [24/40]. 121.31 samples/sec. 263.795 ms/step.
Train [32/40]. 121.30 samples/sec. 263.810 ms/step.
Train [40/40]. 121.30 samples/sec. 263.801 ms/step.
Train benchmark of regnetz_c16_evos.ch_in1k done. 120.50 samples/sec, 263.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_d8.ra3_in1k created, param count: 23373792
Running inference benchmark on regnetz_d8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 755.64 samples/sec. 338.785 ms/step.
Infer [16/40]. 755.65 samples/sec. 338.780 ms/step.
Infer [24/40]. 755.53 samples/sec. 338.833 ms/step.
Infer [32/40]. 755.53 samples/sec. 338.834 ms/step.
Infer [40/40]. 755.53 samples/sec. 338.835 ms/step.
Inference benchmark of regnetz_d8.ra3_in1k done. 755.43 samples/sec, 338.83 ms/step
Model regnetz_d8.ra3_in1k created, param count: 23373792
Running train benchmark on regnetz_d8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 990.06 MiB is free. Including non-PyTorch memory, this process has 22.67 GiB memory in use. Of the allocated memory 22.08 GiB is allocated by PyTorch, and 103.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_d8.ra3_in1k created, param count: 23373792
Running train benchmark on regnetz_d8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.11 GiB is free. Including non-PyTorch memory, this process has 22.53 GiB memory in use. Of the allocated memory 21.86 GiB is allocated by PyTorch, and 182.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_d8.ra3_in1k created, param count: 23373792
Running train benchmark on regnetz_d8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 259.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_d8.ra3_in1k created, param count: 23373792
Running train benchmark on regnetz_d8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 290.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 308.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_d8.ra3_in1k created, param count: 23373792
Running train benchmark on regnetz_d8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 220.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnetz_d8.ra3_in1k created, param count: 23373792
Running train benchmark on regnetz_d8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 186.04 samples/sec. 258.012 ms/step.
Train [16/40]. 186.04 samples/sec. 258.015 ms/step.
Train [24/40]. 186.03 samples/sec. 258.025 ms/step.
Train [32/40]. 186.04 samples/sec. 258.016 ms/step.
Train [40/40]. 186.03 samples/sec. 258.016 ms/step.
Train benchmark of regnetz_d8.ra3_in1k done. 185.07 samples/sec, 258.02 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running inference benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 298.83 samples/sec. 856.680 ms/step.
Infer [16/40]. 298.95 samples/sec. 856.325 ms/step.
Infer [24/40]. 298.94 samples/sec. 856.370 ms/step.
Infer [32/40]. 298.96 samples/sec. 856.294 ms/step.
Infer [40/40]. 298.94 samples/sec. 856.352 ms/step.
Inference benchmark of regnetz_d8_evos.ch_in1k done. 298.93 samples/sec, 856.35 ms/step
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 22.09 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 106.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 980.06 MiB is free. Including non-PyTorch memory, this process has 22.68 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 189.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 800.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 378.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 265.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 220.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 161.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 388.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 130.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 149.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 83.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnetz_d8_evos.ch_in1k created, param count: 23464296
Running train benchmark on regnetz_d8_evos.ch_in1k for 40 steps w/ input size (3, 320, 320) and batch size 24.
Train [8/40]. 77.60 samples/sec. 309.292 ms/step.
Train [16/40]. 77.59 samples/sec. 309.304 ms/step.
Train [24/40]. 77.60 samples/sec. 309.295 ms/step.
Train [32/40]. 77.60 samples/sec. 309.287 ms/step.
Train [40/40]. 77.60 samples/sec. 309.277 ms/step.
Train benchmark of regnetz_d8_evos.ch_in1k done. 77.14 samples/sec, 309.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_d32.ra3_in1k created, param count: 27576288
Running inference benchmark on regnetz_d32.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 765.53 samples/sec. 334.408 ms/step.
Infer [16/40]. 765.48 samples/sec. 334.432 ms/step.
Infer [24/40]. 765.43 samples/sec. 334.450 ms/step.
Infer [32/40]. 765.42 samples/sec. 334.458 ms/step.
Infer [40/40]. 765.40 samples/sec. 334.465 ms/step.
Inference benchmark of regnetz_d32.ra3_in1k done. 765.30 samples/sec, 334.46 ms/step
Model regnetz_d32.ra3_in1k created, param count: 27576288
Running train benchmark on regnetz_d32.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 990.06 MiB is free. Including non-PyTorch memory, this process has 22.67 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 86.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_d32.ra3_in1k created, param count: 27576288
Running train benchmark on regnetz_d32.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.11 GiB is free. Including non-PyTorch memory, this process has 22.53 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 164.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_d32.ra3_in1k created, param count: 27576288
Running train benchmark on regnetz_d32.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 238.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_d32.ra3_in1k created, param count: 27576288
Running train benchmark on regnetz_d32.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 288.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_d32.ra3_in1k created, param count: 27576288
Running train benchmark on regnetz_d32.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 199.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnetz_d32.ra3_in1k created, param count: 27576288
Running train benchmark on regnetz_d32.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 198.88 samples/sec. 241.355 ms/step.
Train [16/40]. 198.83 samples/sec. 241.411 ms/step.
Train [24/40]. 198.83 samples/sec. 241.414 ms/step.
Train [32/40]. 198.83 samples/sec. 241.418 ms/step.
Train [40/40]. 198.82 samples/sec. 241.427 ms/step.
Train benchmark of regnetz_d32.ra3_in1k done. 197.76 samples/sec, 241.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running inference benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 422.09 samples/sec. 606.500 ms/step.
Infer [16/40]. 422.13 samples/sec. 606.450 ms/step.
Infer [24/40]. 422.16 samples/sec. 606.407 ms/step.
Infer [32/40]. 422.16 samples/sec. 606.408 ms/step.
Infer [40/40]. 422.18 samples/sec. 606.376 ms/step.
Inference benchmark of regnetz_e8.ra3_in1k done. 422.15 samples/sec, 606.38 ms/step
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacty of 23.65 GiB of which 538.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 23.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 598.06 MiB is free. Including non-PyTorch memory, this process has 23.06 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 286.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 426.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 183.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 272.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 502.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 471.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 458.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model regnetz_e8.ra3_in1k created, param count: 57698176
Running train benchmark on regnetz_e8.ra3_in1k for 40 steps w/ input size (3, 320, 320) and batch size 24.
Train [8/40]. 103.71 samples/sec. 231.411 ms/step.
Train [16/40]. 103.72 samples/sec. 231.389 ms/step.
Train [24/40]. 103.73 samples/sec. 231.373 ms/step.
Train [32/40]. 103.73 samples/sec. 231.377 ms/step.
Train [40/40]. 103.73 samples/sec. 231.373 ms/step.
Train benchmark of regnetz_e8.ra3_in1k done. 103.07 samples/sec, 231.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_a2.rvgg_in1k created, param count: 28210600
Running inference benchmark on repvgg_a2.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2856.24 samples/sec. 89.628 ms/step.
Infer [16/40]. 2855.43 samples/sec. 89.654 ms/step.
Infer [24/40]. 2855.74 samples/sec. 89.644 ms/step.
Infer [32/40]. 2855.80 samples/sec. 89.642 ms/step.
Infer [40/40]. 2856.12 samples/sec. 89.632 ms/step.
Inference benchmark of repvgg_a2.rvgg_in1k done. 2855.20 samples/sec, 89.63 ms/step
Model repvgg_a2.rvgg_in1k created, param count: 28210600
Running train benchmark on repvgg_a2.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 864.93 samples/sec. 295.979 ms/step.
Train [16/40]. 864.95 samples/sec. 295.971 ms/step.
Train [24/40]. 864.96 samples/sec. 295.969 ms/step.
Train [32/40]. 864.96 samples/sec. 295.966 ms/step.
Train [40/40]. 864.97 samples/sec. 295.965 ms/step.
Train benchmark of repvgg_a2.rvgg_in1k done. 862.23 samples/sec, 295.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_b0.rvgg_in1k created, param count: 15817960
Running inference benchmark on repvgg_b0.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2861.34 samples/sec. 89.469 ms/step.
Infer [16/40]. 2854.94 samples/sec. 89.669 ms/step.
Infer [24/40]. 2855.52 samples/sec. 89.651 ms/step.
Infer [32/40]. 2866.32 samples/sec. 89.313 ms/step.
Infer [40/40]. 2865.90 samples/sec. 89.326 ms/step.
Inference benchmark of repvgg_b0.rvgg_in1k done. 2865.04 samples/sec, 89.33 ms/step
Model repvgg_b0.rvgg_in1k created, param count: 15817960
Running train benchmark on repvgg_b0.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 960.57 samples/sec. 266.508 ms/step.
Train [16/40]. 960.28 samples/sec. 266.589 ms/step.
Train [24/40]. 960.51 samples/sec. 266.526 ms/step.
Train [32/40]. 960.16 samples/sec. 266.622 ms/step.
Train [40/40]. 960.62 samples/sec. 266.494 ms/step.
Train benchmark of repvgg_b0.rvgg_in1k done. 956.92 samples/sec, 266.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_b1.rvgg_in1k created, param count: 57415016
Running inference benchmark on repvgg_b1.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1481.46 samples/sec. 172.803 ms/step.
Infer [16/40]. 1481.21 samples/sec. 172.832 ms/step.
Infer [24/40]. 1480.86 samples/sec. 172.872 ms/step.
Infer [32/40]. 1480.83 samples/sec. 172.876 ms/step.
Infer [40/40]. 1481.06 samples/sec. 172.850 ms/step.
Inference benchmark of repvgg_b1.rvgg_in1k done. 1480.75 samples/sec, 172.85 ms/step
Model repvgg_b1.rvgg_in1k created, param count: 57415016
Running train benchmark on repvgg_b1.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 462.48 samples/sec. 553.533 ms/step.
Train [16/40]. 462.49 samples/sec. 553.531 ms/step.
Train [24/40]. 462.46 samples/sec. 553.559 ms/step.
Train [32/40]. 462.45 samples/sec. 553.569 ms/step.
Train [40/40]. 462.45 samples/sec. 553.570 ms/step.
Train benchmark of repvgg_b1.rvgg_in1k done. 461.54 samples/sec, 553.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_b1g4.rvgg_in1k created, param count: 39966056
Running inference benchmark on repvgg_b1g4.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1729.21 samples/sec. 148.044 ms/step.
Infer [16/40]. 1728.78 samples/sec. 148.081 ms/step.
Infer [24/40]. 1728.48 samples/sec. 148.107 ms/step.
Infer [32/40]. 1728.52 samples/sec. 148.103 ms/step.
Infer [40/40]. 1728.42 samples/sec. 148.112 ms/step.
Inference benchmark of repvgg_b1g4.rvgg_in1k done. 1728.04 samples/sec, 148.11 ms/step
Model repvgg_b1g4.rvgg_in1k created, param count: 39966056
Running train benchmark on repvgg_b1g4.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 518.75 samples/sec. 493.493 ms/step.
Train [16/40]. 518.72 samples/sec. 493.526 ms/step.
Train [24/40]. 518.72 samples/sec. 493.524 ms/step.
Train [32/40]. 518.75 samples/sec. 493.498 ms/step.
Train [40/40]. 518.76 samples/sec. 493.486 ms/step.
Train benchmark of repvgg_b1g4.rvgg_in1k done. 517.59 samples/sec, 493.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_b2.rvgg_in1k created, param count: 89022376
Running inference benchmark on repvgg_b2.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1071.33 samples/sec. 238.956 ms/step.
Infer [16/40]. 1071.52 samples/sec. 238.912 ms/step.
Infer [24/40]. 1071.35 samples/sec. 238.950 ms/step.
Infer [32/40]. 1071.34 samples/sec. 238.953 ms/step.
Infer [40/40]. 1071.35 samples/sec. 238.952 ms/step.
Inference benchmark of repvgg_b2.rvgg_in1k done. 1071.16 samples/sec, 238.95 ms/step
Model repvgg_b2.rvgg_in1k created, param count: 89022376
Running train benchmark on repvgg_b2.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 333.06 samples/sec. 768.636 ms/step.
Train [16/40]. 333.06 samples/sec. 768.625 ms/step.
Train [24/40]. 333.03 samples/sec. 768.697 ms/step.
Train [32/40]. 333.01 samples/sec. 768.751 ms/step.
Train [40/40]. 332.99 samples/sec. 768.798 ms/step.
Train benchmark of repvgg_b2.rvgg_in1k done. 332.51 samples/sec, 768.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_b2g4.rvgg_in1k created, param count: 61758376
Running inference benchmark on repvgg_b2g4.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1252.91 samples/sec. 204.325 ms/step.
Infer [16/40]. 1253.02 samples/sec. 204.306 ms/step.
Infer [24/40]. 1252.97 samples/sec. 204.314 ms/step.
Infer [32/40]. 1252.92 samples/sec. 204.322 ms/step.
Infer [40/40]. 1252.89 samples/sec. 204.328 ms/step.
Inference benchmark of repvgg_b2g4.rvgg_in1k done. 1252.66 samples/sec, 204.33 ms/step
Model repvgg_b2g4.rvgg_in1k created, param count: 61758376
Running train benchmark on repvgg_b2g4.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 375.94 samples/sec. 680.957 ms/step.
Train [16/40]. 375.86 samples/sec. 681.099 ms/step.
Train [24/40]. 375.89 samples/sec. 681.053 ms/step.
Train [32/40]. 375.86 samples/sec. 681.111 ms/step.
Train [40/40]. 375.84 samples/sec. 681.143 ms/step.
Train benchmark of repvgg_b2g4.rvgg_in1k done. 375.23 samples/sec, 681.14 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_b3.rvgg_in1k created, param count: 123085288
Running inference benchmark on repvgg_b3.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 832.87 samples/sec. 307.372 ms/step.
Infer [16/40]. 832.56 samples/sec. 307.484 ms/step.
Infer [24/40]. 833.31 samples/sec. 307.208 ms/step.
Infer [32/40]. 833.18 samples/sec. 307.255 ms/step.
Infer [40/40]. 833.28 samples/sec. 307.219 ms/step.
Inference benchmark of repvgg_b3.rvgg_in1k done. 833.16 samples/sec, 307.22 ms/step
Model repvgg_b3.rvgg_in1k created, param count: 123085288
Running train benchmark on repvgg_b3.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 793.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model repvgg_b3.rvgg_in1k created, param count: 123085288
Running train benchmark on repvgg_b3.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 267.79 samples/sec. 716.975 ms/step.
Train [16/40]. 267.78 samples/sec. 716.998 ms/step.
Train [24/40]. 267.78 samples/sec. 717.001 ms/step.
Train [32/40]. 267.75 samples/sec. 717.082 ms/step.
Train [40/40]. 267.70 samples/sec. 717.215 ms/step.
Train benchmark of repvgg_b3.rvgg_in1k done. 267.29 samples/sec, 717.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model repvgg_b3g4.rvgg_in1k created, param count: 83825128
Running inference benchmark on repvgg_b3g4.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 984.01 samples/sec. 260.161 ms/step.
Infer [16/40]. 984.68 samples/sec. 259.984 ms/step.
Infer [24/40]. 984.90 samples/sec. 259.926 ms/step.
Infer [32/40]. 984.32 samples/sec. 260.077 ms/step.
Infer [40/40]. 985.11 samples/sec. 259.871 ms/step.
Inference benchmark of repvgg_b3g4.rvgg_in1k done. 984.95 samples/sec, 259.87 ms/step
Model repvgg_b3g4.rvgg_in1k created, param count: 83825128
Running train benchmark on repvgg_b3g4.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.34 GiB is allocated by PyTorch, and 808.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model repvgg_b3g4.rvgg_in1k created, param count: 83825128
Running train benchmark on repvgg_b3g4.rvgg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 310.06 samples/sec. 619.240 ms/step.
Train [16/40]. 310.06 samples/sec. 619.241 ms/step.
Train [24/40]. 310.05 samples/sec. 619.250 ms/step.
Train [32/40]. 310.06 samples/sec. 619.241 ms/step.
Train [40/40]. 310.06 samples/sec. 619.235 ms/step.
Train benchmark of repvgg_b3g4.rvgg_in1k done. 309.52 samples/sec, 619.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net50_14w_8s.in1k created, param count: 25059816
Running inference benchmark on res2net50_14w_8s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1941.12 samples/sec. 131.882 ms/step.
Infer [16/40]. 1941.06 samples/sec. 131.886 ms/step.
Infer [24/40]. 1941.08 samples/sec. 131.885 ms/step.
Infer [32/40]. 1941.07 samples/sec. 131.886 ms/step.
Infer [40/40]. 1940.87 samples/sec. 131.899 ms/step.
Inference benchmark of res2net50_14w_8s.in1k done. 1940.44 samples/sec, 131.90 ms/step
Model res2net50_14w_8s.in1k created, param count: 25059816
Running train benchmark on res2net50_14w_8s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 112.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net50_14w_8s.in1k created, param count: 25059816
Running train benchmark on res2net50_14w_8s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 593.13 samples/sec. 323.706 ms/step.
Train [16/40]. 593.10 samples/sec. 323.723 ms/step.
Train [24/40]. 593.12 samples/sec. 323.711 ms/step.
Train [32/40]. 593.15 samples/sec. 323.696 ms/step.
Train [40/40]. 593.18 samples/sec. 323.679 ms/step.
Train benchmark of res2net50_14w_8s.in1k done. 589.92 samples/sec, 323.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net50_26w_4s.in1k created, param count: 25699120
Running inference benchmark on res2net50_26w_4s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1920.42 samples/sec. 133.304 ms/step.
Infer [16/40]. 1920.40 samples/sec. 133.306 ms/step.
Infer [24/40]. 1920.44 samples/sec. 133.303 ms/step.
Infer [32/40]. 1920.47 samples/sec. 133.301 ms/step.
Infer [40/40]. 1920.49 samples/sec. 133.299 ms/step.
Inference benchmark of res2net50_26w_4s.in1k done. 1920.07 samples/sec, 133.30 ms/step
Model res2net50_26w_4s.in1k created, param count: 25699120
Running train benchmark on res2net50_26w_4s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 155.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net50_26w_4s.in1k created, param count: 25699120
Running train benchmark on res2net50_26w_4s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 598.69 samples/sec. 320.702 ms/step.
Train [16/40]. 598.59 samples/sec. 320.753 ms/step.
Train [24/40]. 598.59 samples/sec. 320.755 ms/step.
Train [32/40]. 598.58 samples/sec. 320.759 ms/step.
Train [40/40]. 598.58 samples/sec. 320.761 ms/step.
Train benchmark of res2net50_26w_4s.in1k done. 596.23 samples/sec, 320.76 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net50_26w_6s.in1k created, param count: 37051448
Running inference benchmark on res2net50_26w_6s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1540.12 samples/sec. 166.220 ms/step.
Infer [16/40]. 1540.16 samples/sec. 166.217 ms/step.
Infer [24/40]. 1540.19 samples/sec. 166.213 ms/step.
Infer [32/40]. 1540.20 samples/sec. 166.212 ms/step.
Infer [40/40]. 1540.21 samples/sec. 166.211 ms/step.
Inference benchmark of res2net50_26w_6s.in1k done. 1539.91 samples/sec, 166.21 ms/step
Model res2net50_26w_6s.in1k created, param count: 37051448
Running train benchmark on res2net50_26w_6s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 98.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net50_26w_6s.in1k created, param count: 37051448
Running train benchmark on res2net50_26w_6s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 150.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model res2net50_26w_6s.in1k created, param count: 37051448
Running train benchmark on res2net50_26w_6s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 474.16 samples/sec. 269.951 ms/step.
Train [16/40]. 474.13 samples/sec. 269.970 ms/step.
Train [24/40]. 474.11 samples/sec. 269.982 ms/step.
Train [32/40]. 474.09 samples/sec. 269.994 ms/step.
Train [40/40]. 474.06 samples/sec. 270.008 ms/step.
Train benchmark of res2net50_26w_6s.in1k done. 471.48 samples/sec, 270.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net50_26w_8s.in1k created, param count: 48403776
Running inference benchmark on res2net50_26w_8s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1261.44 samples/sec. 202.942 ms/step.
Infer [16/40]. 1261.47 samples/sec. 202.938 ms/step.
Infer [24/40]. 1261.46 samples/sec. 202.939 ms/step.
Infer [32/40]. 1261.44 samples/sec. 202.943 ms/step.
Infer [40/40]. 1261.42 samples/sec. 202.947 ms/step.
Inference benchmark of res2net50_26w_8s.in1k done. 1261.19 samples/sec, 202.95 ms/step
Model res2net50_26w_8s.in1k created, param count: 48403776
Running train benchmark on res2net50_26w_8s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 78.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net50_26w_8s.in1k created, param count: 48403776
Running train benchmark on res2net50_26w_8s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 478.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 344.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 119.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model res2net50_26w_8s.in1k created, param count: 48403776
Running train benchmark on res2net50_26w_8s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 404.12 samples/sec. 316.739 ms/step.
Train [16/40]. 404.15 samples/sec. 316.711 ms/step.
Train [24/40]. 404.14 samples/sec. 316.722 ms/step.
Train [32/40]. 404.13 samples/sec. 316.732 ms/step.
Train [40/40]. 404.11 samples/sec. 316.743 ms/step.
Train benchmark of res2net50_26w_8s.in1k done. 401.84 samples/sec, 316.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net50_48w_2s.in1k created, param count: 25287304
Running inference benchmark on res2net50_48w_2s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2074.33 samples/sec. 123.413 ms/step.
Infer [16/40]. 2074.06 samples/sec. 123.430 ms/step.
Infer [24/40]. 2073.90 samples/sec. 123.439 ms/step.
Infer [32/40]. 2073.78 samples/sec. 123.446 ms/step.
Infer [40/40]. 2073.71 samples/sec. 123.450 ms/step.
Inference benchmark of res2net50_48w_2s.in1k done. 2073.19 samples/sec, 123.45 ms/step
Model res2net50_48w_2s.in1k created, param count: 25287304
Running train benchmark on res2net50_48w_2s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 230.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net50_48w_2s.in1k created, param count: 25287304
Running train benchmark on res2net50_48w_2s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 654.00 samples/sec. 293.576 ms/step.
Train [16/40]. 654.00 samples/sec. 293.578 ms/step.
Train [24/40]. 654.03 samples/sec. 293.565 ms/step.
Train [32/40]. 654.00 samples/sec. 293.576 ms/step.
Train [40/40]. 654.02 samples/sec. 293.570 ms/step.
Train benchmark of res2net50_48w_2s.in1k done. 651.81 samples/sec, 293.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net50d.in1k created, param count: 25718352
Running inference benchmark on res2net50d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1836.18 samples/sec. 139.420 ms/step.
Infer [16/40]. 1835.76 samples/sec. 139.452 ms/step.
Infer [24/40]. 1835.53 samples/sec. 139.469 ms/step.
Infer [32/40]. 1835.48 samples/sec. 139.473 ms/step.
Infer [40/40]. 1835.45 samples/sec. 139.476 ms/step.
Inference benchmark of res2net50d.in1k done. 1835.04 samples/sec, 139.48 ms/step
Model res2net50d.in1k created, param count: 25718352
Running train benchmark on res2net50d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 158.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 103.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net50d.in1k created, param count: 25718352
Running train benchmark on res2net50d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 564.08 samples/sec. 340.378 ms/step.
Train [16/40]. 564.10 samples/sec. 340.366 ms/step.
Train [24/40]. 564.08 samples/sec. 340.378 ms/step.
Train [32/40]. 564.07 samples/sec. 340.386 ms/step.
Train [40/40]. 564.06 samples/sec. 340.387 ms/step.
Train benchmark of res2net50d.in1k done. 561.90 samples/sec, 340.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net101_26w_4s.in1k created, param count: 45206688
Running inference benchmark on res2net101_26w_4s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1207.71 samples/sec. 211.971 ms/step.
Infer [16/40]. 1207.71 samples/sec. 211.972 ms/step.
Infer [24/40]. 1207.70 samples/sec. 211.973 ms/step.
Infer [32/40]. 1207.71 samples/sec. 211.972 ms/step.
Infer [40/40]. 1207.73 samples/sec. 211.968 ms/step.
Inference benchmark of res2net101_26w_4s.in1k done. 1207.51 samples/sec, 211.97 ms/step
Model res2net101_26w_4s.in1k created, param count: 45206688
Running train benchmark on res2net101_26w_4s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 163.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net101_26w_4s.in1k created, param count: 45206688
Running train benchmark on res2net101_26w_4s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 172.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model res2net101_26w_4s.in1k created, param count: 45206688
Running train benchmark on res2net101_26w_4s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 390.06 samples/sec. 328.150 ms/step.
Train [16/40]. 390.05 samples/sec. 328.165 ms/step.
Train [24/40]. 390.06 samples/sec. 328.154 ms/step.
Train [32/40]. 390.05 samples/sec. 328.161 ms/step.
Train [40/40]. 390.05 samples/sec. 328.163 ms/step.
Train benchmark of res2net101_26w_4s.in1k done. 387.77 samples/sec, 328.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2net101d.in1k created, param count: 45225920
Running inference benchmark on res2net101d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1173.03 samples/sec. 218.237 ms/step.
Infer [16/40]. 1173.03 samples/sec. 218.237 ms/step.
Infer [24/40]. 1173.03 samples/sec. 218.239 ms/step.
Infer [32/40]. 1173.00 samples/sec. 218.243 ms/step.
Infer [40/40]. 1172.98 samples/sec. 218.248 ms/step.
Inference benchmark of res2net101d.in1k done. 1172.77 samples/sec, 218.25 ms/step
Model res2net101d.in1k created, param count: 45225920
Running train benchmark on res2net101d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 110.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2net101d.in1k created, param count: 45225920
Running train benchmark on res2net101d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 232.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model res2net101d.in1k created, param count: 45225920
Running train benchmark on res2net101d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 373.41 samples/sec. 342.786 ms/step.
Train [16/40]. 373.40 samples/sec. 342.793 ms/step.
Train [24/40]. 373.41 samples/sec. 342.787 ms/step.
Train [32/40]. 373.41 samples/sec. 342.787 ms/step.
Train [40/40]. 373.41 samples/sec. 342.785 ms/step.
Train benchmark of res2net101d.in1k done. 371.28 samples/sec, 342.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model res2next50.in1k created, param count: 24671464
Running inference benchmark on res2next50.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1811.09 samples/sec. 141.351 ms/step.
Infer [16/40]. 1810.97 samples/sec. 141.360 ms/step.
Infer [24/40]. 1810.93 samples/sec. 141.364 ms/step.
Infer [32/40]. 1810.93 samples/sec. 141.364 ms/step.
Infer [40/40]. 1810.86 samples/sec. 141.369 ms/step.
Inference benchmark of res2next50.in1k done. 1810.45 samples/sec, 141.37 ms/step
Model res2next50.in1k created, param count: 24671464
Running train benchmark on res2next50.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 91.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model res2next50.in1k created, param count: 24671464
Running train benchmark on res2next50.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 559.92 samples/sec. 342.908 ms/step.
Train [16/40]. 559.93 samples/sec. 342.903 ms/step.
Train [24/40]. 559.92 samples/sec. 342.907 ms/step.
Train [32/40]. 559.92 samples/sec. 342.909 ms/step.
Train [40/40]. 559.91 samples/sec. 342.909 ms/step.
Train benchmark of res2next50.in1k done. 557.77 samples/sec, 342.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_12_224.fb_dino created, param count: 15350872
Running inference benchmark on resmlp_12_224.fb_dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4681.77 samples/sec. 54.680 ms/step.
Infer [16/40]. 4681.46 samples/sec. 54.684 ms/step.
Infer [24/40]. 4681.37 samples/sec. 54.685 ms/step.
Infer [32/40]. 4681.48 samples/sec. 54.684 ms/step.
Infer [40/40]. 4681.50 samples/sec. 54.683 ms/step.
Inference benchmark of resmlp_12_224.fb_dino done. 4679.28 samples/sec, 54.68 ms/step
Model resmlp_12_224.fb_dino created, param count: 15350872
Running train benchmark on resmlp_12_224.fb_dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1603.64 samples/sec. 159.637 ms/step.
Train [16/40]. 1603.52 samples/sec. 159.649 ms/step.
Train [24/40]. 1603.59 samples/sec. 159.641 ms/step.
Train [32/40]. 1603.61 samples/sec. 159.640 ms/step.
Train [40/40]. 1603.62 samples/sec. 159.639 ms/step.
Train benchmark of resmlp_12_224.fb_dino done. 1595.65 samples/sec, 159.64 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_12_224.fb_distilled_in1k created, param count: 15350872
Running inference benchmark on resmlp_12_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4682.30 samples/sec. 54.674 ms/step.
Infer [16/40]. 4682.45 samples/sec. 54.672 ms/step.
Infer [24/40]. 4682.46 samples/sec. 54.672 ms/step.
Infer [32/40]. 4682.54 samples/sec. 54.671 ms/step.
Infer [40/40]. 4682.53 samples/sec. 54.671 ms/step.
Inference benchmark of resmlp_12_224.fb_distilled_in1k done. 4680.36 samples/sec, 54.67 ms/step
Model resmlp_12_224.fb_distilled_in1k created, param count: 15350872
Running train benchmark on resmlp_12_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1603.54 samples/sec. 159.647 ms/step.
Train [16/40]. 1603.65 samples/sec. 159.636 ms/step.
Train [24/40]. 1603.69 samples/sec. 159.632 ms/step.
Train [32/40]. 1603.71 samples/sec. 159.630 ms/step.
Train [40/40]. 1603.72 samples/sec. 159.629 ms/step.
Train benchmark of resmlp_12_224.fb_distilled_in1k done. 1595.97 samples/sec, 159.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_12_224.fb_in1k created, param count: 15350872
Running inference benchmark on resmlp_12_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4685.47 samples/sec. 54.637 ms/step.
Infer [16/40]. 4684.22 samples/sec. 54.652 ms/step.
Infer [24/40]. 4683.76 samples/sec. 54.657 ms/step.
Infer [32/40]. 4683.50 samples/sec. 54.660 ms/step.
Infer [40/40]. 4683.24 samples/sec. 54.663 ms/step.
Inference benchmark of resmlp_12_224.fb_in1k done. 4681.09 samples/sec, 54.66 ms/step
Model resmlp_12_224.fb_in1k created, param count: 15350872
Running train benchmark on resmlp_12_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1603.79 samples/sec. 159.622 ms/step.
Train [16/40]. 1603.72 samples/sec. 159.629 ms/step.
Train [24/40]. 1603.73 samples/sec. 159.628 ms/step.
Train [32/40]. 1603.74 samples/sec. 159.627 ms/step.
Train [40/40]. 1603.74 samples/sec. 159.627 ms/step.
Train benchmark of resmlp_12_224.fb_in1k done. 1595.94 samples/sec, 159.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_24_224.fb_dino created, param count: 30020680
Running inference benchmark on resmlp_24_224.fb_dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2374.74 samples/sec. 107.801 ms/step.
Infer [16/40]. 2374.87 samples/sec. 107.795 ms/step.
Infer [24/40]. 2374.96 samples/sec. 107.791 ms/step.
Infer [32/40]. 2375.03 samples/sec. 107.788 ms/step.
Infer [40/40]. 2375.05 samples/sec. 107.787 ms/step.
Inference benchmark of resmlp_24_224.fb_dino done. 2374.40 samples/sec, 107.79 ms/step
Model resmlp_24_224.fb_dino created, param count: 30020680
Running train benchmark on resmlp_24_224.fb_dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 252.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 20.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_24_224.fb_dino created, param count: 30020680
Running train benchmark on resmlp_24_224.fb_dino for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 726.61 samples/sec. 264.241 ms/step.
Train [16/40]. 726.63 samples/sec. 264.233 ms/step.
Train [24/40]. 726.61 samples/sec. 264.242 ms/step.
Train [32/40]. 726.61 samples/sec. 264.239 ms/step.
Train [40/40]. 726.61 samples/sec. 264.241 ms/step.
Train benchmark of resmlp_24_224.fb_dino done. 722.68 samples/sec, 264.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_24_224.fb_distilled_in1k created, param count: 30020680
Running inference benchmark on resmlp_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2372.70 samples/sec. 107.894 ms/step.
Infer [16/40]. 2372.70 samples/sec. 107.894 ms/step.
Infer [24/40]. 2372.65 samples/sec. 107.896 ms/step.
Infer [32/40]. 2372.64 samples/sec. 107.897 ms/step.
Infer [40/40]. 2372.63 samples/sec. 107.897 ms/step.
Inference benchmark of resmlp_24_224.fb_distilled_in1k done. 2371.99 samples/sec, 107.90 ms/step
Model resmlp_24_224.fb_distilled_in1k created, param count: 30020680
Running train benchmark on resmlp_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 252.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 20.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_24_224.fb_distilled_in1k created, param count: 30020680
Running train benchmark on resmlp_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 726.46 samples/sec. 264.295 ms/step.
Train [16/40]. 726.47 samples/sec. 264.291 ms/step.
Train [24/40]. 726.48 samples/sec. 264.288 ms/step.
Train [32/40]. 726.47 samples/sec. 264.293 ms/step.
Train [40/40]. 726.48 samples/sec. 264.288 ms/step.
Train benchmark of resmlp_24_224.fb_distilled_in1k done. 722.45 samples/sec, 264.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_24_224.fb_in1k created, param count: 30020680
Running inference benchmark on resmlp_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2372.41 samples/sec. 107.907 ms/step.
Infer [16/40]. 2372.42 samples/sec. 107.907 ms/step.
Infer [24/40]. 2372.40 samples/sec. 107.908 ms/step.
Infer [32/40]. 2372.45 samples/sec. 107.905 ms/step.
Infer [40/40]. 2372.51 samples/sec. 107.902 ms/step.
Inference benchmark of resmlp_24_224.fb_in1k done. 2371.84 samples/sec, 107.90 ms/step
Model resmlp_24_224.fb_in1k created, param count: 30020680
Running train benchmark on resmlp_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 252.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 20.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_24_224.fb_in1k created, param count: 30020680
Running train benchmark on resmlp_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 726.56 samples/sec. 264.258 ms/step.
Train [16/40]. 726.50 samples/sec. 264.282 ms/step.
Train [24/40]. 726.53 samples/sec. 264.271 ms/step.
Train [32/40]. 726.53 samples/sec. 264.269 ms/step.
Train [40/40]. 726.55 samples/sec. 264.263 ms/step.
Train benchmark of resmlp_24_224.fb_in1k done. 722.69 samples/sec, 264.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_36_224.fb_distilled_in1k created, param count: 44690488
Running inference benchmark on resmlp_36_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1588.86 samples/sec. 161.122 ms/step.
Infer [16/40]. 1588.82 samples/sec. 161.125 ms/step.
Infer [24/40]. 1588.81 samples/sec. 161.127 ms/step.
Infer [32/40]. 1588.78 samples/sec. 161.130 ms/step.
Infer [40/40]. 1588.75 samples/sec. 161.133 ms/step.
Inference benchmark of resmlp_36_224.fb_distilled_in1k done. 1588.41 samples/sec, 161.13 ms/step
Model resmlp_36_224.fb_distilled_in1k created, param count: 44690488
Running train benchmark on resmlp_36_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 210.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 6.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_36_224.fb_distilled_in1k created, param count: 44690488
Running train benchmark on resmlp_36_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 203.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resmlp_36_224.fb_distilled_in1k created, param count: 44690488
Running train benchmark on resmlp_36_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 560.62 samples/sec. 228.317 ms/step.
Train [16/40]. 560.61 samples/sec. 228.322 ms/step.
Train [24/40]. 560.58 samples/sec. 228.333 ms/step.
Train [32/40]. 560.57 samples/sec. 228.338 ms/step.
Train [40/40]. 560.58 samples/sec. 228.337 ms/step.
Train benchmark of resmlp_36_224.fb_distilled_in1k done. 556.42 samples/sec, 228.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_36_224.fb_in1k created, param count: 44690488
Running inference benchmark on resmlp_36_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1588.70 samples/sec. 161.138 ms/step.
Infer [16/40]. 1588.69 samples/sec. 161.139 ms/step.
Infer [24/40]. 1588.69 samples/sec. 161.139 ms/step.
Infer [32/40]. 1588.68 samples/sec. 161.140 ms/step.
Infer [40/40]. 1588.65 samples/sec. 161.143 ms/step.
Inference benchmark of resmlp_36_224.fb_in1k done. 1588.32 samples/sec, 161.14 ms/step
Model resmlp_36_224.fb_in1k created, param count: 44690488
Running train benchmark on resmlp_36_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 210.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 6.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_36_224.fb_in1k created, param count: 44690488
Running train benchmark on resmlp_36_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 203.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resmlp_36_224.fb_in1k created, param count: 44690488
Running train benchmark on resmlp_36_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 560.15 samples/sec. 228.512 ms/step.
Train [16/40]. 560.13 samples/sec. 228.517 ms/step.
Train [24/40]. 560.13 samples/sec. 228.520 ms/step.
Train [32/40]. 560.12 samples/sec. 228.522 ms/step.
Train [40/40]. 560.12 samples/sec. 228.523 ms/step.
Train benchmark of resmlp_36_224.fb_in1k done. 555.96 samples/sec, 228.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running inference benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 224.02 samples/sec. 1142.755 ms/step.
Infer [16/40]. 224.02 samples/sec. 1142.757 ms/step.
Infer [24/40]. 224.02 samples/sec. 1142.743 ms/step.
Infer [32/40]. 224.00 samples/sec. 1142.866 ms/step.
Infer [40/40]. 223.95 samples/sec. 1143.114 ms/step.
Inference benchmark of resmlp_big_24_224.fb_distilled_in1k done. 223.94 samples/sec, 1143.11 ms/step
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 40.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 92.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 664.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 108.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 198.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 144.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 311.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 109.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resmlp_big_24_224.fb_distilled_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 71.24 samples/sec. 336.888 ms/step.
Train [16/40]. 71.23 samples/sec. 336.950 ms/step.
Train [24/40]. 71.22 samples/sec. 336.979 ms/step.
Train [32/40]. 71.22 samples/sec. 336.985 ms/step.
Train [40/40]. 71.22 samples/sec. 336.988 ms/step.
Train benchmark of resmlp_big_24_224.fb_distilled_in1k done. 70.90 samples/sec, 336.99 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running inference benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 224.02 samples/sec. 1142.734 ms/step.
Infer [16/40]. 224.03 samples/sec. 1142.729 ms/step.
Infer [24/40]. 223.94 samples/sec. 1143.149 ms/step.
Infer [32/40]. 223.89 samples/sec. 1143.401 ms/step.
Infer [40/40]. 223.87 samples/sec. 1143.546 ms/step.
Inference benchmark of resmlp_big_24_224.fb_in1k done. 223.85 samples/sec, 1143.55 ms/step
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 40.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 92.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 664.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 108.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 198.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 144.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 311.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 109.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resmlp_big_24_224.fb_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 71.25 samples/sec. 336.822 ms/step.
Train [16/40]. 71.26 samples/sec. 336.810 ms/step.
Train [24/40]. 71.26 samples/sec. 336.810 ms/step.
Train [32/40]. 71.26 samples/sec. 336.807 ms/step.
Train [40/40]. 71.26 samples/sec. 336.805 ms/step.
Train benchmark of resmlp_big_24_224.fb_in1k done. 70.95 samples/sec, 336.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running inference benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 224.02 samples/sec. 1142.739 ms/step.
Infer [16/40]. 224.03 samples/sec. 1142.722 ms/step.
Infer [24/40]. 224.03 samples/sec. 1142.700 ms/step.
Infer [32/40]. 224.04 samples/sec. 1142.675 ms/step.
Infer [40/40]. 224.04 samples/sec. 1142.660 ms/step.
Inference benchmark of resmlp_big_24_224.fb_in22k_ft_in1k done. 224.03 samples/sec, 1142.66 ms/step
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 658.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 40.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 92.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 664.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 108.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 198.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 144.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 311.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 109.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resmlp_big_24_224.fb_in22k_ft_in1k created, param count: 129138280
Running train benchmark on resmlp_big_24_224.fb_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 71.25 samples/sec. 336.843 ms/step.
Train [16/40]. 71.25 samples/sec. 336.832 ms/step.
Train [24/40]. 71.25 samples/sec. 336.848 ms/step.
Train [32/40]. 71.24 samples/sec. 336.879 ms/step.
Train [40/40]. 71.24 samples/sec. 336.895 ms/step.
Train benchmark of resmlp_big_24_224.fb_in22k_ft_in1k done. 70.93 samples/sec, 336.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest14d.gluon_in1k created, param count: 10611688
Running inference benchmark on resnest14d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3251.04 samples/sec. 78.744 ms/step.
Infer [16/40]. 3250.83 samples/sec. 78.749 ms/step.
Infer [24/40]. 3250.87 samples/sec. 78.748 ms/step.
Infer [32/40]. 3250.81 samples/sec. 78.750 ms/step.
Infer [40/40]. 3250.68 samples/sec. 78.753 ms/step.
Inference benchmark of resnest14d.gluon_in1k done. 3249.57 samples/sec, 78.75 ms/step
Model resnest14d.gluon_in1k created, param count: 10611688
Running train benchmark on resnest14d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 987.57 samples/sec. 259.223 ms/step.
Train [16/40]. 987.46 samples/sec. 259.250 ms/step.
Train [24/40]. 987.36 samples/sec. 259.276 ms/step.
Train [32/40]. 987.32 samples/sec. 259.287 ms/step.
Train [40/40]. 987.33 samples/sec. 259.285 ms/step.
Train benchmark of resnest14d.gluon_in1k done. 984.64 samples/sec, 259.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest26d.gluon_in1k created, param count: 17069448
Running inference benchmark on resnest26d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2332.61 samples/sec. 109.748 ms/step.
Infer [16/40]. 2332.20 samples/sec. 109.767 ms/step.
Infer [24/40]. 2331.98 samples/sec. 109.778 ms/step.
Infer [32/40]. 2331.83 samples/sec. 109.785 ms/step.
Infer [40/40]. 2331.76 samples/sec. 109.788 ms/step.
Inference benchmark of resnest26d.gluon_in1k done. 2331.12 samples/sec, 109.79 ms/step
Model resnest26d.gluon_in1k created, param count: 17069448
Running train benchmark on resnest26d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 722.48 samples/sec. 354.333 ms/step.
Train [16/40]. 722.52 samples/sec. 354.314 ms/step.
Train [24/40]. 722.52 samples/sec. 354.318 ms/step.
Train [32/40]. 722.51 samples/sec. 354.320 ms/step.
Train [40/40]. 722.50 samples/sec. 354.325 ms/step.
Train benchmark of resnest26d.gluon_in1k done. 720.54 samples/sec, 354.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest50d.in1k created, param count: 27483240
Running inference benchmark on resnest50d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1570.04 samples/sec. 163.054 ms/step.
Infer [16/40]. 1569.88 samples/sec. 163.070 ms/step.
Infer [24/40]. 1569.89 samples/sec. 163.069 ms/step.
Infer [32/40]. 1569.89 samples/sec. 163.069 ms/step.
Infer [40/40]. 1569.89 samples/sec. 163.069 ms/step.
Inference benchmark of resnest50d.in1k done. 1569.57 samples/sec, 163.07 ms/step
Model resnest50d.in1k created, param count: 27483240
Running train benchmark on resnest50d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 60.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnest50d.in1k created, param count: 27483240
Running train benchmark on resnest50d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 101.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnest50d.in1k created, param count: 27483240
Running train benchmark on resnest50d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 501.55 samples/sec. 255.211 ms/step.
Train [16/40]. 501.58 samples/sec. 255.196 ms/step.
Train [24/40]. 501.44 samples/sec. 255.263 ms/step.
Train [32/40]. 501.39 samples/sec. 255.290 ms/step.
Train [40/40]. 501.43 samples/sec. 255.270 ms/step.
Train benchmark of resnest50d.in1k done. 498.91 samples/sec, 255.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest50d_1s4x24d.in1k created, param count: 25677000
Running inference benchmark on resnest50d_1s4x24d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1853.28 samples/sec. 138.133 ms/step.
Infer [16/40]. 1852.60 samples/sec. 138.184 ms/step.
Infer [24/40]. 1852.49 samples/sec. 138.193 ms/step.
Infer [32/40]. 1852.33 samples/sec. 138.204 ms/step.
Infer [40/40]. 1852.39 samples/sec. 138.200 ms/step.
Inference benchmark of resnest50d_1s4x24d.in1k done. 1851.99 samples/sec, 138.20 ms/step
Model resnest50d_1s4x24d.in1k created, param count: 25677000
Running train benchmark on resnest50d_1s4x24d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 285.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnest50d_1s4x24d.in1k created, param count: 25677000
Running train benchmark on resnest50d_1s4x24d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 554.27 samples/sec. 346.403 ms/step.
Train [16/40]. 554.24 samples/sec. 346.422 ms/step.
Train [24/40]. 554.24 samples/sec. 346.420 ms/step.
Train [32/40]. 554.25 samples/sec. 346.415 ms/step.
Train [40/40]. 554.25 samples/sec. 346.412 ms/step.
Train benchmark of resnest50d_1s4x24d.in1k done. 552.10 samples/sec, 346.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest50d_4s2x40d.in1k created, param count: 30417592
Running inference benchmark on resnest50d_4s2x40d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1275.88 samples/sec. 200.645 ms/step.
Infer [16/40]. 1275.72 samples/sec. 200.671 ms/step.
Infer [24/40]. 1275.62 samples/sec. 200.688 ms/step.
Infer [32/40]. 1275.55 samples/sec. 200.698 ms/step.
Infer [40/40]. 1275.52 samples/sec. 200.703 ms/step.
Inference benchmark of resnest50d_4s2x40d.in1k done. 1275.28 samples/sec, 200.70 ms/step
Model resnest50d_4s2x40d.in1k created, param count: 30417592
Running train benchmark on resnest50d_4s2x40d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 268.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 672.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnest50d_4s2x40d.in1k created, param count: 30417592
Running train benchmark on resnest50d_4s2x40d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 637.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnest50d_4s2x40d.in1k created, param count: 30417592
Running train benchmark on resnest50d_4s2x40d.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 402.83 samples/sec. 317.756 ms/step.
Train [16/40]. 402.80 samples/sec. 317.773 ms/step.
Train [24/40]. 402.79 samples/sec. 317.784 ms/step.
Train [32/40]. 402.78 samples/sec. 317.789 ms/step.
Train [40/40]. 402.79 samples/sec. 317.786 ms/step.
Train benchmark of resnest50d_4s2x40d.in1k done. 401.07 samples/sec, 317.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest101e.in1k created, param count: 48275016
Running inference benchmark on resnest101e.in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 775.48 samples/sec. 330.119 ms/step.
Infer [16/40]. 775.49 samples/sec. 330.113 ms/step.
Infer [24/40]. 775.45 samples/sec. 330.130 ms/step.
Infer [32/40]. 775.43 samples/sec. 330.138 ms/step.
Infer [40/40]. 775.42 samples/sec. 330.145 ms/step.
Inference benchmark of resnest101e.in1k done. 775.31 samples/sec, 330.14 ms/step
Model resnest101e.in1k created, param count: 48275016
Running train benchmark on resnest101e.in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 17.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnest101e.in1k created, param count: 48275016
Running train benchmark on resnest101e.in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 312.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 97.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnest101e.in1k created, param count: 48275016
Running train benchmark on resnest101e.in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 212.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnest101e.in1k created, param count: 48275016
Running train benchmark on resnest101e.in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 628.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnest101e.in1k created, param count: 48275016
Running train benchmark on resnest101e.in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 265.57 samples/sec. 240.995 ms/step.
Train [16/40]. 265.62 samples/sec. 240.945 ms/step.
Train [24/40]. 265.64 samples/sec. 240.930 ms/step.
Train [32/40]. 265.62 samples/sec. 240.944 ms/step.
Train [40/40]. 265.63 samples/sec. 240.940 ms/step.
Train benchmark of resnest101e.in1k done. 263.49 samples/sec, 240.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest200e.in1k created, param count: 70201544
Running inference benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 259.89 samples/sec. 985.014 ms/step.
Infer [16/40]. 259.89 samples/sec. 985.023 ms/step.
Infer [24/40]. 259.90 samples/sec. 985.008 ms/step.
Infer [32/40]. 259.89 samples/sec. 985.023 ms/step.
Infer [40/40]. 259.90 samples/sec. 985.009 ms/step.
Inference benchmark of resnest200e.in1k done. 259.88 samples/sec, 985.01 ms/step
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.45 GiB is free. Including non-PyTorch memory, this process has 22.19 GiB memory in use. Of the allocated memory 21.67 GiB is allocated by PyTorch, and 27.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 244.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 274.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 287.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 230.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 340.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 634.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 592.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 425.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnest200e.in1k created, param count: 70201544
Running train benchmark on resnest200e.in1k for 40 steps w/ input size (3, 320, 320) and batch size 24.
Train [8/40]. 90.67 samples/sec. 264.694 ms/step.
Train [16/40]. 90.66 samples/sec. 264.711 ms/step.
Train [24/40]. 90.66 samples/sec. 264.738 ms/step.
Train [32/40]. 90.66 samples/sec. 264.729 ms/step.
Train [40/40]. 90.65 samples/sec. 264.742 ms/step.
Train benchmark of resnest200e.in1k done. 89.59 samples/sec, 264.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnest269e.in1k created, param count: 110929480
Running inference benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
Infer [8/40]. 122.51 samples/sec. 2089.597 ms/step.
Infer [16/40]. 122.50 samples/sec. 2089.756 ms/step.
Infer [24/40]. 122.50 samples/sec. 2089.837 ms/step.
Infer [32/40]. 122.50 samples/sec. 2089.861 ms/step.
Infer [40/40]. 122.50 samples/sec. 2089.875 ms/step.
Inference benchmark of resnest269e.in1k done. 122.49 samples/sec, 2089.88 ms/step
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 34.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 124.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 441.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 522.06 MiB is free. Including non-PyTorch memory, this process has 23.13 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 505.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1014.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 934.06 MiB is free. Including non-PyTorch memory, this process has 22.73 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 318.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 358.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 363.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 360.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 263.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 419.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model resnest269e.in1k created, param count: 110929480
Running train benchmark on resnest269e.in1k for 40 steps w/ input size (3, 416, 416) and batch size 12.
Train [8/40]. 37.97 samples/sec. 316.027 ms/step.
Train [16/40]. 37.96 samples/sec. 316.120 ms/step.
Train [24/40]. 37.97 samples/sec. 316.076 ms/step.
Train [32/40]. 37.95 samples/sec. 316.177 ms/step.
Train [40/40]. 37.94 samples/sec. 316.258 ms/step.
Train benchmark of resnest269e.in1k done. 37.43 samples/sec, 316.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet10t.c3_in1k created, param count: 5435488
Running inference benchmark on resnet10t.c3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 9787.99 samples/sec. 26.155 ms/step.
Infer [16/40]. 9781.25 samples/sec. 26.173 ms/step.
Infer [24/40]. 9781.40 samples/sec. 26.172 ms/step.
Infer [32/40]. 9780.94 samples/sec. 26.173 ms/step.
Infer [40/40]. 9781.44 samples/sec. 26.172 ms/step.
Inference benchmark of resnet10t.c3_in1k done. 9772.18 samples/sec, 26.17 ms/step
Model resnet10t.c3_in1k created, param count: 5435488
Running train benchmark on resnet10t.c3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2644.27 samples/sec. 96.813 ms/step.
Train [16/40]. 2644.11 samples/sec. 96.819 ms/step.
Train [24/40]. 2643.62 samples/sec. 96.837 ms/step.
Train [32/40]. 2643.81 samples/sec. 96.830 ms/step.
Train [40/40]. 2643.93 samples/sec. 96.826 ms/step.
Train benchmark of resnet10t.c3_in1k done. 2634.84 samples/sec, 96.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet14t.c3_in1k created, param count: 10081632
Running inference benchmark on resnet14t.c3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5098.74 samples/sec. 50.208 ms/step.
Infer [16/40]. 5098.35 samples/sec. 50.212 ms/step.
Infer [24/40]. 5097.17 samples/sec. 50.224 ms/step.
Infer [32/40]. 5096.63 samples/sec. 50.229 ms/step.
Infer [40/40]. 5096.41 samples/sec. 50.231 ms/step.
Inference benchmark of resnet14t.c3_in1k done. 5093.87 samples/sec, 50.23 ms/step
Model resnet14t.c3_in1k created, param count: 10081632
Running train benchmark on resnet14t.c3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1466.50 samples/sec. 174.566 ms/step.
Train [16/40]. 1466.37 samples/sec. 174.581 ms/step.
Train [24/40]. 1466.46 samples/sec. 174.570 ms/step.
Train [32/40]. 1466.53 samples/sec. 174.561 ms/step.
Train [40/40]. 1466.57 samples/sec. 174.557 ms/step.
Train benchmark of resnet14t.c3_in1k done. 1462.50 samples/sec, 174.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18.a1_in1k created, param count: 11689512
Running inference benchmark on resnet18.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 4997.53 samples/sec. 51.225 ms/step.
Infer [16/40]. 4997.42 samples/sec. 51.226 ms/step.
Infer [24/40]. 4997.36 samples/sec. 51.227 ms/step.
Infer [32/40]. 4997.33 samples/sec. 51.227 ms/step.
Infer [40/40]. 4997.37 samples/sec. 51.227 ms/step.
Inference benchmark of resnet18.a1_in1k done. 4994.88 samples/sec, 51.23 ms/step
Model resnet18.a1_in1k created, param count: 11689512
Running train benchmark on resnet18.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1415.45 samples/sec. 180.861 ms/step.
Train [16/40]. 1414.92 samples/sec. 180.929 ms/step.
Train [24/40]. 1415.53 samples/sec. 180.851 ms/step.
Train [32/40]. 1415.70 samples/sec. 180.830 ms/step.
Train [40/40]. 1415.60 samples/sec. 180.843 ms/step.
Train benchmark of resnet18.a1_in1k done. 1411.76 samples/sec, 180.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18.a2_in1k created, param count: 11689512
Running inference benchmark on resnet18.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 5004.61 samples/sec. 51.153 ms/step.
Infer [16/40]. 5001.18 samples/sec. 51.188 ms/step.
Infer [24/40]. 4999.55 samples/sec. 51.205 ms/step.
Infer [32/40]. 4998.88 samples/sec. 51.211 ms/step.
Infer [40/40]. 4998.49 samples/sec. 51.215 ms/step.
Inference benchmark of resnet18.a2_in1k done. 4996.00 samples/sec, 51.22 ms/step
Model resnet18.a2_in1k created, param count: 11689512
Running train benchmark on resnet18.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1417.67 samples/sec. 180.578 ms/step.
Train [16/40]. 1418.71 samples/sec. 180.445 ms/step.
Train [24/40]. 1417.98 samples/sec. 180.539 ms/step.
Train [32/40]. 1417.61 samples/sec. 180.586 ms/step.
Train [40/40]. 1417.63 samples/sec. 180.583 ms/step.
Train benchmark of resnet18.a2_in1k done. 1413.80 samples/sec, 180.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18.a3_in1k created, param count: 11689512
Running inference benchmark on resnet18.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7437.91 samples/sec. 34.418 ms/step.
Infer [16/40]. 7431.93 samples/sec. 34.446 ms/step.
Infer [24/40]. 7431.20 samples/sec. 34.449 ms/step.
Infer [32/40]. 7431.08 samples/sec. 34.450 ms/step.
Infer [40/40]. 7431.22 samples/sec. 34.449 ms/step.
Inference benchmark of resnet18.a3_in1k done. 7425.91 samples/sec, 34.45 ms/step
Model resnet18.a3_in1k created, param count: 11689512
Running train benchmark on resnet18.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2257.76 samples/sec. 113.387 ms/step.
Train [16/40]. 2256.82 samples/sec. 113.434 ms/step.
Train [24/40]. 2256.35 samples/sec. 113.458 ms/step.
Train [32/40]. 2256.17 samples/sec. 113.467 ms/step.
Train [40/40]. 2256.13 samples/sec. 113.469 ms/step.
Train benchmark of resnet18.a3_in1k done. 2248.20 samples/sec, 113.47 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18.fb_ssl_yfcc100m_ft_in1k created, param count: 11689512
Running inference benchmark on resnet18.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7436.24 samples/sec. 34.426 ms/step.
Infer [16/40]. 7430.74 samples/sec. 34.451 ms/step.
Infer [24/40]. 7431.00 samples/sec. 34.450 ms/step.
Infer [32/40]. 7429.68 samples/sec. 34.456 ms/step.
Infer [40/40]. 7430.61 samples/sec. 34.452 ms/step.
Inference benchmark of resnet18.fb_ssl_yfcc100m_ft_in1k done. 7425.25 samples/sec, 34.45 ms/step
Model resnet18.fb_ssl_yfcc100m_ft_in1k created, param count: 11689512
Running train benchmark on resnet18.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2257.27 samples/sec. 113.411 ms/step.
Train [16/40]. 2257.52 samples/sec. 113.399 ms/step.
Train [24/40]. 2257.35 samples/sec. 113.407 ms/step.
Train [32/40]. 2257.16 samples/sec. 113.417 ms/step.
Train [40/40]. 2257.14 samples/sec. 113.418 ms/step.
Train benchmark of resnet18.fb_ssl_yfcc100m_ft_in1k done. 2249.44 samples/sec, 113.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18.fb_swsl_ig1b_ft_in1k created, param count: 11689512
Running inference benchmark on resnet18.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7440.41 samples/sec. 34.407 ms/step.
Infer [16/40]. 7442.08 samples/sec. 34.399 ms/step.
Infer [24/40]. 7442.71 samples/sec. 34.396 ms/step.
Infer [32/40]. 7442.02 samples/sec. 34.399 ms/step.
Infer [40/40]. 7439.77 samples/sec. 34.410 ms/step.
Inference benchmark of resnet18.fb_swsl_ig1b_ft_in1k done. 7434.31 samples/sec, 34.41 ms/step
Model resnet18.fb_swsl_ig1b_ft_in1k created, param count: 11689512
Running train benchmark on resnet18.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2257.11 samples/sec. 113.419 ms/step.
Train [16/40]. 2257.18 samples/sec. 113.416 ms/step.
Train [24/40]. 2257.39 samples/sec. 113.405 ms/step.
Train [32/40]. 2257.10 samples/sec. 113.420 ms/step.
Train [40/40]. 2257.01 samples/sec. 113.424 ms/step.
Train benchmark of resnet18.fb_swsl_ig1b_ft_in1k done. 2249.09 samples/sec, 113.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18.gluon_in1k created, param count: 11689512
Running inference benchmark on resnet18.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7447.17 samples/sec. 34.375 ms/step.
Infer [16/40]. 7442.36 samples/sec. 34.398 ms/step.
Infer [24/40]. 7440.24 samples/sec. 34.408 ms/step.
Infer [32/40]. 7439.44 samples/sec. 34.411 ms/step.
Infer [40/40]. 7436.09 samples/sec. 34.427 ms/step.
Inference benchmark of resnet18.gluon_in1k done. 7430.61 samples/sec, 34.43 ms/step
Model resnet18.gluon_in1k created, param count: 11689512
Running train benchmark on resnet18.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2255.55 samples/sec. 113.498 ms/step.
Train [16/40]. 2256.00 samples/sec. 113.475 ms/step.
Train [24/40]. 2256.22 samples/sec. 113.464 ms/step.
Train [32/40]. 2256.43 samples/sec. 113.454 ms/step.
Train [40/40]. 2256.34 samples/sec. 113.458 ms/step.
Train benchmark of resnet18.gluon_in1k done. 2248.35 samples/sec, 113.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18.tv_in1k created, param count: 11689512
Running inference benchmark on resnet18.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7444.63 samples/sec. 34.387 ms/step.
Infer [16/40]. 7443.83 samples/sec. 34.391 ms/step.
Infer [24/40]. 7441.20 samples/sec. 34.403 ms/step.
Infer [32/40]. 7438.29 samples/sec. 34.417 ms/step.
Infer [40/40]. 7438.04 samples/sec. 34.418 ms/step.
Inference benchmark of resnet18.tv_in1k done. 7432.59 samples/sec, 34.42 ms/step
Model resnet18.tv_in1k created, param count: 11689512
Running train benchmark on resnet18.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2256.88 samples/sec. 113.431 ms/step.
Train [16/40]. 2257.02 samples/sec. 113.424 ms/step.
Train [24/40]. 2256.82 samples/sec. 113.434 ms/step.
Train [32/40]. 2256.88 samples/sec. 113.431 ms/step.
Train [40/40]. 2256.82 samples/sec. 113.434 ms/step.
Train benchmark of resnet18.tv_in1k done. 2248.85 samples/sec, 113.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet18d.ra2_in1k created, param count: 11708744
Running inference benchmark on resnet18d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 4093.76 samples/sec. 62.534 ms/step.
Infer [16/40]. 4093.42 samples/sec. 62.539 ms/step.
Infer [24/40]. 4093.26 samples/sec. 62.542 ms/step.
Infer [32/40]. 4093.27 samples/sec. 62.542 ms/step.
Infer [40/40]. 4093.26 samples/sec. 62.542 ms/step.
Inference benchmark of resnet18d.ra2_in1k done. 4091.54 samples/sec, 62.54 ms/step
Model resnet18d.ra2_in1k created, param count: 11708744
Running train benchmark on resnet18d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 1123.15 samples/sec. 227.931 ms/step.
Train [16/40]. 1122.08 samples/sec. 228.149 ms/step.
Train [24/40]. 1122.02 samples/sec. 228.161 ms/step.
Train [32/40]. 1121.60 samples/sec. 228.244 ms/step.
Train [40/40]. 1121.70 samples/sec. 228.226 ms/step.
Train benchmark of resnet18d.ra2_in1k done. 1118.85 samples/sec, 228.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet26.bt_in1k created, param count: 15995176
Running inference benchmark on resnet26.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2270.41 samples/sec. 112.755 ms/step.
Infer [16/40]. 2270.30 samples/sec. 112.760 ms/step.
Infer [24/40]. 2270.30 samples/sec. 112.760 ms/step.
Infer [32/40]. 2270.18 samples/sec. 112.766 ms/step.
Infer [40/40]. 2269.86 samples/sec. 112.782 ms/step.
Inference benchmark of resnet26.bt_in1k done. 2269.28 samples/sec, 112.78 ms/step
Model resnet26.bt_in1k created, param count: 15995176
Running train benchmark on resnet26.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 687.65 samples/sec. 372.280 ms/step.
Train [16/40]. 687.80 samples/sec. 372.202 ms/step.
Train [24/40]. 687.90 samples/sec. 372.147 ms/step.
Train [32/40]. 688.10 samples/sec. 372.041 ms/step.
Train [40/40]. 688.07 samples/sec. 372.055 ms/step.
Train benchmark of resnet26.bt_in1k done. 686.75 samples/sec, 372.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet26d.bt_in1k created, param count: 16014408
Running inference benchmark on resnet26d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2065.41 samples/sec. 123.946 ms/step.
Infer [16/40]. 2065.45 samples/sec. 123.944 ms/step.
Infer [24/40]. 2065.21 samples/sec. 123.958 ms/step.
Infer [32/40]. 2064.94 samples/sec. 123.974 ms/step.
Infer [40/40]. 2064.74 samples/sec. 123.987 ms/step.
Inference benchmark of resnet26d.bt_in1k done. 2064.24 samples/sec, 123.99 ms/step
Model resnet26d.bt_in1k created, param count: 16014408
Running train benchmark on resnet26d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 220.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet26d.bt_in1k created, param count: 16014408
Running train benchmark on resnet26d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
Train [8/40]. 617.80 samples/sec. 310.780 ms/step.
Train [16/40]. 617.82 samples/sec. 310.770 ms/step.
Train [24/40]. 617.70 samples/sec. 310.832 ms/step.
Train [32/40]. 617.81 samples/sec. 310.775 ms/step.
Train [40/40]. 617.70 samples/sec. 310.830 ms/step.
Train benchmark of resnet26d.bt_in1k done. 616.27 samples/sec, 310.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet26t.ra2_in1k created, param count: 16011872
Running inference benchmark on resnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 1713.40 samples/sec. 149.410 ms/step.
Infer [16/40]. 1713.36 samples/sec. 149.414 ms/step.
Infer [24/40]. 1713.40 samples/sec. 149.411 ms/step.
Infer [32/40]. 1713.41 samples/sec. 149.409 ms/step.
Infer [40/40]. 1713.38 samples/sec. 149.412 ms/step.
Inference benchmark of resnet26t.ra2_in1k done. 1713.02 samples/sec, 149.41 ms/step
Model resnet26t.ra2_in1k created, param count: 16011872
Running train benchmark on resnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 800.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 86.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet26t.ra2_in1k created, param count: 16011872
Running train benchmark on resnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 91.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet26t.ra2_in1k created, param count: 16011872
Running train benchmark on resnet26t.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
Train [8/40]. 516.31 samples/sec. 247.912 ms/step.
Train [16/40]. 516.39 samples/sec. 247.876 ms/step.
Train [24/40]. 516.39 samples/sec. 247.874 ms/step.
Train [32/40]. 516.41 samples/sec. 247.867 ms/step.
Train [40/40]. 516.35 samples/sec. 247.892 ms/step.
Train benchmark of resnet26t.ra2_in1k done. 514.94 samples/sec, 247.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet32ts.ra2_in1k created, param count: 17963616
Running inference benchmark on resnet32ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1806.01 samples/sec. 141.749 ms/step.
Infer [16/40]. 1806.03 samples/sec. 141.747 ms/step.
Infer [24/40]. 1805.96 samples/sec. 141.753 ms/step.
Infer [32/40]. 1805.89 samples/sec. 141.758 ms/step.
Infer [40/40]. 1805.86 samples/sec. 141.761 ms/step.
Inference benchmark of resnet32ts.ra2_in1k done. 1805.46 samples/sec, 141.76 ms/step
Model resnet32ts.ra2_in1k created, param count: 17963616
Running train benchmark on resnet32ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 616.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.15 GiB is allocated by PyTorch, and 398.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet32ts.ra2_in1k created, param count: 17963616
Running train benchmark on resnet32ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 344.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 201.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet32ts.ra2_in1k created, param count: 17963616
Running train benchmark on resnet32ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 508.50 samples/sec. 251.720 ms/step.
Train [16/40]. 508.55 samples/sec. 251.698 ms/step.
Train [24/40]. 508.55 samples/sec. 251.697 ms/step.
Train [32/40]. 508.55 samples/sec. 251.694 ms/step.
Train [40/40]. 508.56 samples/sec. 251.693 ms/step.
Train benchmark of resnet32ts.ra2_in1k done. 507.03 samples/sec, 251.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet33ts.ra2_in1k created, param count: 19676256
Running inference benchmark on resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1783.64 samples/sec. 143.527 ms/step.
Infer [16/40]. 1783.57 samples/sec. 143.533 ms/step.
Infer [24/40]. 1783.58 samples/sec. 143.532 ms/step.
Infer [32/40]. 1783.55 samples/sec. 143.534 ms/step.
Infer [40/40]. 1783.51 samples/sec. 143.537 ms/step.
Inference benchmark of resnet33ts.ra2_in1k done. 1783.12 samples/sec, 143.54 ms/step
Model resnet33ts.ra2_in1k created, param count: 19676256
Running train benchmark on resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 616.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 392.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet33ts.ra2_in1k created, param count: 19676256
Running train benchmark on resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 324.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 215.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet33ts.ra2_in1k created, param count: 19676256
Running train benchmark on resnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 502.29 samples/sec. 254.831 ms/step.
Train [16/40]. 502.31 samples/sec. 254.821 ms/step.
Train [24/40]. 502.32 samples/sec. 254.820 ms/step.
Train [32/40]. 502.32 samples/sec. 254.819 ms/step.
Train [40/40]. 502.31 samples/sec. 254.820 ms/step.
Train benchmark of resnet33ts.ra2_in1k done. 500.80 samples/sec, 254.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet34.a1_in1k created, param count: 21797672
Running inference benchmark on resnet34.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2933.13 samples/sec. 87.279 ms/step.
Infer [16/40]. 2933.07 samples/sec. 87.281 ms/step.
Infer [24/40]. 2933.09 samples/sec. 87.280 ms/step.
Infer [32/40]. 2933.05 samples/sec. 87.281 ms/step.
Infer [40/40]. 2932.90 samples/sec. 87.286 ms/step.
Inference benchmark of resnet34.a1_in1k done. 2931.98 samples/sec, 87.29 ms/step
Model resnet34.a1_in1k created, param count: 21797672
Running train benchmark on resnet34.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 845.66 samples/sec. 302.723 ms/step.
Train [16/40]. 845.57 samples/sec. 302.756 ms/step.
Train [24/40]. 845.44 samples/sec. 302.802 ms/step.
Train [32/40]. 845.66 samples/sec. 302.722 ms/step.
Train [40/40]. 845.66 samples/sec. 302.723 ms/step.
Train benchmark of resnet34.a1_in1k done. 843.46 samples/sec, 302.72 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet34.a2_in1k created, param count: 21797672
Running inference benchmark on resnet34.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2933.14 samples/sec. 87.278 ms/step.
Infer [16/40]. 2932.98 samples/sec. 87.283 ms/step.
Infer [24/40]. 2932.88 samples/sec. 87.286 ms/step.
Infer [32/40]. 2932.86 samples/sec. 87.287 ms/step.
Infer [40/40]. 2932.78 samples/sec. 87.289 ms/step.
Inference benchmark of resnet34.a2_in1k done. 2931.84 samples/sec, 87.29 ms/step
Model resnet34.a2_in1k created, param count: 21797672
Running train benchmark on resnet34.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 844.55 samples/sec. 303.119 ms/step.
Train [16/40]. 845.34 samples/sec. 302.838 ms/step.
Train [24/40]. 845.23 samples/sec. 302.877 ms/step.
Train [32/40]. 845.19 samples/sec. 302.890 ms/step.
Train [40/40]. 845.40 samples/sec. 302.815 ms/step.
Train benchmark of resnet34.a2_in1k done. 843.21 samples/sec, 302.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet34.a3_in1k created, param count: 21797672
Running inference benchmark on resnet34.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4033.82 samples/sec. 63.463 ms/step.
Infer [16/40]. 4025.30 samples/sec. 63.598 ms/step.
Infer [24/40]. 4014.53 samples/sec. 63.768 ms/step.
Infer [32/40]. 4018.13 samples/sec. 63.711 ms/step.
Infer [40/40]. 4004.70 samples/sec. 63.925 ms/step.
Inference benchmark of resnet34.a3_in1k done. 4003.06 samples/sec, 63.92 ms/step
Model resnet34.a3_in1k created, param count: 21797672
Running train benchmark on resnet34.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1296.93 samples/sec. 197.389 ms/step.
Train [16/40]. 1295.07 samples/sec. 197.673 ms/step.
Train [24/40]. 1294.40 samples/sec. 197.775 ms/step.
Train [32/40]. 1294.63 samples/sec. 197.740 ms/step.
Train [40/40]. 1294.52 samples/sec. 197.757 ms/step.
Train benchmark of resnet34.a3_in1k done. 1290.01 samples/sec, 197.76 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet34.bt_in1k created, param count: 21797672
Running inference benchmark on resnet34.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2933.24 samples/sec. 87.275 ms/step.
Infer [16/40]. 2933.07 samples/sec. 87.280 ms/step.
Infer [24/40]. 2933.01 samples/sec. 87.282 ms/step.
Infer [32/40]. 2932.89 samples/sec. 87.286 ms/step.
Infer [40/40]. 2932.88 samples/sec. 87.286 ms/step.
Inference benchmark of resnet34.bt_in1k done. 2931.95 samples/sec, 87.29 ms/step
Model resnet34.bt_in1k created, param count: 21797672
Running train benchmark on resnet34.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 845.80 samples/sec. 302.672 ms/step.
Train [16/40]. 845.23 samples/sec. 302.875 ms/step.
Train [24/40]. 845.30 samples/sec. 302.851 ms/step.
Train [32/40]. 845.94 samples/sec. 302.621 ms/step.
Train [40/40]. 846.08 samples/sec. 302.571 ms/step.
Train benchmark of resnet34.bt_in1k done. 843.91 samples/sec, 302.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet34.gluon_in1k created, param count: 21797672
Running inference benchmark on resnet34.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3996.19 samples/sec. 64.061 ms/step.
Infer [16/40]. 3975.46 samples/sec. 64.395 ms/step.
Infer [24/40]. 3972.97 samples/sec. 64.435 ms/step.
Infer [32/40]. 3968.61 samples/sec. 64.506 ms/step.
Infer [40/40]. 3983.15 samples/sec. 64.271 ms/step.
Inference benchmark of resnet34.gluon_in1k done. 3981.52 samples/sec, 64.27 ms/step
Model resnet34.gluon_in1k created, param count: 21797672
Running train benchmark on resnet34.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1295.54 samples/sec. 197.601 ms/step.
Train [16/40]. 1294.58 samples/sec. 197.748 ms/step.
Train [24/40]. 1294.49 samples/sec. 197.761 ms/step.
Train [32/40]. 1294.29 samples/sec. 197.792 ms/step.
Train [40/40]. 1294.95 samples/sec. 197.691 ms/step.
Train benchmark of resnet34.gluon_in1k done. 1290.68 samples/sec, 197.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet34.tv_in1k created, param count: 21797672
Running inference benchmark on resnet34.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4003.39 samples/sec. 63.946 ms/step.
Infer [16/40]. 4016.74 samples/sec. 63.733 ms/step.
Infer [24/40]. 4002.82 samples/sec. 63.955 ms/step.
Infer [32/40]. 3994.04 samples/sec. 64.095 ms/step.
Infer [40/40]. 4001.30 samples/sec. 63.979 ms/step.
Inference benchmark of resnet34.tv_in1k done. 3999.68 samples/sec, 63.98 ms/step
Model resnet34.tv_in1k created, param count: 21797672
Running train benchmark on resnet34.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1294.17 samples/sec. 197.811 ms/step.
Train [16/40]. 1293.62 samples/sec. 197.894 ms/step.
Train [24/40]. 1293.82 samples/sec. 197.864 ms/step.
Train [32/40]. 1294.07 samples/sec. 197.826 ms/step.
Train [40/40]. 1294.27 samples/sec. 197.794 ms/step.
Train benchmark of resnet34.tv_in1k done. 1289.95 samples/sec, 197.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet34d.ra2_in1k created, param count: 21816904
Running inference benchmark on resnet34d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2594.98 samples/sec. 98.652 ms/step.
Infer [16/40]. 2594.94 samples/sec. 98.653 ms/step.
Infer [24/40]. 2594.87 samples/sec. 98.656 ms/step.
Infer [32/40]. 2594.80 samples/sec. 98.659 ms/step.
Infer [40/40]. 2594.76 samples/sec. 98.660 ms/step.
Inference benchmark of resnet34d.ra2_in1k done. 2594.00 samples/sec, 98.66 ms/step
Model resnet34d.ra2_in1k created, param count: 21816904
Running train benchmark on resnet34d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Train [8/40]. 729.55 samples/sec. 350.901 ms/step.
Train [16/40]. 730.30 samples/sec. 350.543 ms/step.
Train [24/40]. 730.50 samples/sec. 350.445 ms/step.
Train [32/40]. 730.57 samples/sec. 350.412 ms/step.
Train [40/40]. 730.71 samples/sec. 350.345 ms/step.
Train benchmark of resnet34d.ra2_in1k done. 729.01 samples/sec, 350.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.a1_in1k created, param count: 25557032
Running inference benchmark on resnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1398.83 samples/sec. 183.010 ms/step.
Infer [16/40]. 1398.90 samples/sec. 183.000 ms/step.
Infer [24/40]. 1398.89 samples/sec. 183.003 ms/step.
Infer [32/40]. 1398.87 samples/sec. 183.005 ms/step.
Infer [40/40]. 1398.89 samples/sec. 183.002 ms/step.
Inference benchmark of resnet50.a1_in1k done. 1398.61 samples/sec, 183.00 ms/step
Model resnet50.a1_in1k created, param count: 25557032
Running train benchmark on resnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.a1_in1k created, param count: 25557032
Running train benchmark on resnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.a1_in1k created, param count: 25557032
Running train benchmark on resnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.80 samples/sec. 289.725 ms/step.
Train [16/40]. 441.79 samples/sec. 289.732 ms/step.
Train [24/40]. 441.71 samples/sec. 289.784 ms/step.
Train [32/40]. 441.72 samples/sec. 289.775 ms/step.
Train [40/40]. 441.71 samples/sec. 289.780 ms/step.
Train benchmark of resnet50.a1_in1k done. 440.26 samples/sec, 289.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.a1h_in1k created, param count: 25557032
Running inference benchmark on resnet50.a1h_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2220.06 samples/sec. 115.312 ms/step.
Infer [16/40]. 2220.30 samples/sec. 115.300 ms/step.
Infer [24/40]. 2220.32 samples/sec. 115.299 ms/step.
Infer [32/40]. 2220.45 samples/sec. 115.292 ms/step.
Infer [40/40]. 2220.43 samples/sec. 115.293 ms/step.
Inference benchmark of resnet50.a1h_in1k done. 2219.87 samples/sec, 115.29 ms/step
Model resnet50.a1h_in1k created, param count: 25557032
Running train benchmark on resnet50.a1h_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.73 samples/sec. 361.209 ms/step.
Train [16/40]. 708.76 samples/sec. 361.196 ms/step.
Train [24/40]. 708.77 samples/sec. 361.190 ms/step.
Train [32/40]. 708.76 samples/sec. 361.193 ms/step.
Train [40/40]. 708.76 samples/sec. 361.196 ms/step.
Train benchmark of resnet50.a1h_in1k done. 706.82 samples/sec, 361.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.a2_in1k created, param count: 25557032
Running inference benchmark on resnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.65 samples/sec. 182.903 ms/step.
Infer [16/40]. 1399.62 samples/sec. 182.907 ms/step.
Infer [24/40]. 1399.58 samples/sec. 182.911 ms/step.
Infer [32/40]. 1399.58 samples/sec. 182.912 ms/step.
Infer [40/40]. 1399.52 samples/sec. 182.919 ms/step.
Inference benchmark of resnet50.a2_in1k done. 1399.26 samples/sec, 182.92 ms/step
Model resnet50.a2_in1k created, param count: 25557032
Running train benchmark on resnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.a2_in1k created, param count: 25557032
Running train benchmark on resnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.a2_in1k created, param count: 25557032
Running train benchmark on resnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.67 samples/sec. 289.812 ms/step.
Train [16/40]. 441.70 samples/sec. 289.789 ms/step.
Train [24/40]. 441.68 samples/sec. 289.803 ms/step.
Train [32/40]. 441.66 samples/sec. 289.818 ms/step.
Train [40/40]. 441.63 samples/sec. 289.833 ms/step.
Train benchmark of resnet50.a2_in1k done. 440.17 samples/sec, 289.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.a3_in1k created, param count: 25557032
Running inference benchmark on resnet50.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2221.16 samples/sec. 115.255 ms/step.
Infer [16/40]. 2221.51 samples/sec. 115.237 ms/step.
Infer [24/40]. 2221.31 samples/sec. 115.247 ms/step.
Infer [32/40]. 2221.27 samples/sec. 115.250 ms/step.
Infer [40/40]. 2220.97 samples/sec. 115.265 ms/step.
Inference benchmark of resnet50.a3_in1k done. 2220.41 samples/sec, 115.27 ms/step
Model resnet50.a3_in1k created, param count: 25557032
Running train benchmark on resnet50.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.85 samples/sec. 361.150 ms/step.
Train [16/40]. 708.86 samples/sec. 361.141 ms/step.
Train [24/40]. 708.89 samples/sec. 361.126 ms/step.
Train [32/40]. 708.89 samples/sec. 361.128 ms/step.
Train [40/40]. 708.86 samples/sec. 361.146 ms/step.
Train benchmark of resnet50.a3_in1k done. 706.92 samples/sec, 361.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.am_in1k created, param count: 25557032
Running inference benchmark on resnet50.am_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2220.58 samples/sec. 115.285 ms/step.
Infer [16/40]. 2221.04 samples/sec. 115.262 ms/step.
Infer [24/40]. 2221.16 samples/sec. 115.255 ms/step.
Infer [32/40]. 2221.11 samples/sec. 115.258 ms/step.
Infer [40/40]. 2221.06 samples/sec. 115.260 ms/step.
Inference benchmark of resnet50.am_in1k done. 2220.52 samples/sec, 115.26 ms/step
Model resnet50.am_in1k created, param count: 25557032
Running train benchmark on resnet50.am_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.83 samples/sec. 361.159 ms/step.
Train [16/40]. 708.83 samples/sec. 361.159 ms/step.
Train [24/40]. 708.81 samples/sec. 361.171 ms/step.
Train [32/40]. 708.79 samples/sec. 361.179 ms/step.
Train [40/40]. 708.77 samples/sec. 361.188 ms/step.
Train benchmark of resnet50.am_in1k done. 706.85 samples/sec, 361.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.b1k_in1k created, param count: 25557032
Running inference benchmark on resnet50.b1k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.04 samples/sec. 182.982 ms/step.
Infer [16/40]. 1399.01 samples/sec. 182.987 ms/step.
Infer [24/40]. 1399.02 samples/sec. 182.985 ms/step.
Infer [32/40]. 1399.02 samples/sec. 182.986 ms/step.
Infer [40/40]. 1399.00 samples/sec. 182.988 ms/step.
Inference benchmark of resnet50.b1k_in1k done. 1398.73 samples/sec, 182.99 ms/step
Model resnet50.b1k_in1k created, param count: 25557032
Running train benchmark on resnet50.b1k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.b1k_in1k created, param count: 25557032
Running train benchmark on resnet50.b1k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.b1k_in1k created, param count: 25557032
Running train benchmark on resnet50.b1k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.71 samples/sec. 289.783 ms/step.
Train [16/40]. 441.71 samples/sec. 289.785 ms/step.
Train [24/40]. 441.67 samples/sec. 289.808 ms/step.
Train [32/40]. 441.68 samples/sec. 289.803 ms/step.
Train [40/40]. 441.69 samples/sec. 289.797 ms/step.
Train benchmark of resnet50.b1k_in1k done. 440.24 samples/sec, 289.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.b2k_in1k created, param count: 25557032
Running inference benchmark on resnet50.b2k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.16 samples/sec. 182.967 ms/step.
Infer [16/40]. 1399.10 samples/sec. 182.975 ms/step.
Infer [24/40]. 1399.07 samples/sec. 182.978 ms/step.
Infer [32/40]. 1399.05 samples/sec. 182.981 ms/step.
Infer [40/40]. 1399.03 samples/sec. 182.984 ms/step.
Inference benchmark of resnet50.b2k_in1k done. 1398.75 samples/sec, 182.98 ms/step
Model resnet50.b2k_in1k created, param count: 25557032
Running train benchmark on resnet50.b2k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.b2k_in1k created, param count: 25557032
Running train benchmark on resnet50.b2k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.b2k_in1k created, param count: 25557032
Running train benchmark on resnet50.b2k_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.46 samples/sec. 289.945 ms/step.
Train [16/40]. 441.56 samples/sec. 289.879 ms/step.
Train [24/40]. 441.53 samples/sec. 289.900 ms/step.
Train [32/40]. 441.55 samples/sec. 289.890 ms/step.
Train [40/40]. 441.57 samples/sec. 289.876 ms/step.
Train benchmark of resnet50.b2k_in1k done. 440.10 samples/sec, 289.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.bt_in1k created, param count: 25557032
Running inference benchmark on resnet50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.36 samples/sec. 182.940 ms/step.
Infer [16/40]. 1399.30 samples/sec. 182.948 ms/step.
Infer [24/40]. 1399.15 samples/sec. 182.968 ms/step.
Infer [32/40]. 1399.11 samples/sec. 182.973 ms/step.
Infer [40/40]. 1399.10 samples/sec. 182.975 ms/step.
Inference benchmark of resnet50.bt_in1k done. 1398.82 samples/sec, 182.97 ms/step
Model resnet50.bt_in1k created, param count: 25557032
Running train benchmark on resnet50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.bt_in1k created, param count: 25557032
Running train benchmark on resnet50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.bt_in1k created, param count: 25557032
Running train benchmark on resnet50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.63 samples/sec. 289.836 ms/step.
Train [16/40]. 441.65 samples/sec. 289.825 ms/step.
Train [24/40]. 441.67 samples/sec. 289.811 ms/step.
Train [32/40]. 441.63 samples/sec. 289.836 ms/step.
Train [40/40]. 441.65 samples/sec. 289.825 ms/step.
Train benchmark of resnet50.bt_in1k done. 440.18 samples/sec, 289.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.c1_in1k created, param count: 25557032
Running inference benchmark on resnet50.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.40 samples/sec. 182.936 ms/step.
Infer [16/40]. 1399.36 samples/sec. 182.940 ms/step.
Infer [24/40]. 1399.32 samples/sec. 182.946 ms/step.
Infer [32/40]. 1399.29 samples/sec. 182.949 ms/step.
Infer [40/40]. 1399.30 samples/sec. 182.949 ms/step.
Inference benchmark of resnet50.c1_in1k done. 1399.01 samples/sec, 182.95 ms/step
Model resnet50.c1_in1k created, param count: 25557032
Running train benchmark on resnet50.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.c1_in1k created, param count: 25557032
Running train benchmark on resnet50.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.c1_in1k created, param count: 25557032
Running train benchmark on resnet50.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.58 samples/sec. 289.870 ms/step.
Train [16/40]. 441.72 samples/sec. 289.774 ms/step.
Train [24/40]. 441.75 samples/sec. 289.754 ms/step.
Train [32/40]. 441.77 samples/sec. 289.743 ms/step.
Train [40/40]. 441.76 samples/sec. 289.753 ms/step.
Train benchmark of resnet50.c1_in1k done. 440.28 samples/sec, 289.75 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.c2_in1k created, param count: 25557032
Running inference benchmark on resnet50.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.52 samples/sec. 182.920 ms/step.
Infer [16/40]. 1399.48 samples/sec. 182.925 ms/step.
Infer [24/40]. 1399.47 samples/sec. 182.926 ms/step.
Infer [32/40]. 1399.46 samples/sec. 182.927 ms/step.
Infer [40/40]. 1399.44 samples/sec. 182.931 ms/step.
Inference benchmark of resnet50.c2_in1k done. 1399.16 samples/sec, 182.93 ms/step
Model resnet50.c2_in1k created, param count: 25557032
Running train benchmark on resnet50.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.c2_in1k created, param count: 25557032
Running train benchmark on resnet50.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.c2_in1k created, param count: 25557032
Running train benchmark on resnet50.c2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.84 samples/sec. 289.700 ms/step.
Train [16/40]. 441.88 samples/sec. 289.670 ms/step.
Train [24/40]. 441.81 samples/sec. 289.716 ms/step.
Train [32/40]. 441.79 samples/sec. 289.732 ms/step.
Train [40/40]. 441.77 samples/sec. 289.745 ms/step.
Train benchmark of resnet50.c2_in1k done. 440.30 samples/sec, 289.75 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.d_in1k created, param count: 25557032
Running inference benchmark on resnet50.d_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.22 samples/sec. 182.959 ms/step.
Infer [16/40]. 1399.28 samples/sec. 182.951 ms/step.
Infer [24/40]. 1399.31 samples/sec. 182.948 ms/step.
Infer [32/40]. 1399.34 samples/sec. 182.944 ms/step.
Infer [40/40]. 1399.34 samples/sec. 182.943 ms/step.
Inference benchmark of resnet50.d_in1k done. 1399.06 samples/sec, 182.94 ms/step
Model resnet50.d_in1k created, param count: 25557032
Running train benchmark on resnet50.d_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.d_in1k created, param count: 25557032
Running train benchmark on resnet50.d_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.d_in1k created, param count: 25557032
Running train benchmark on resnet50.d_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.74 samples/sec. 289.763 ms/step.
Train [16/40]. 441.81 samples/sec. 289.719 ms/step.
Train [24/40]. 441.84 samples/sec. 289.698 ms/step.
Train [32/40]. 441.80 samples/sec. 289.726 ms/step.
Train [40/40]. 441.81 samples/sec. 289.715 ms/step.
Train benchmark of resnet50.d_in1k done. 440.37 samples/sec, 289.71 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.fb_ssl_yfcc100m_ft_in1k created, param count: 25557032
Running inference benchmark on resnet50.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2221.44 samples/sec. 115.241 ms/step.
Infer [16/40]. 2221.56 samples/sec. 115.234 ms/step.
Infer [24/40]. 2221.80 samples/sec. 115.222 ms/step.
Infer [32/40]. 2221.63 samples/sec. 115.231 ms/step.
Infer [40/40]. 2221.69 samples/sec. 115.228 ms/step.
Inference benchmark of resnet50.fb_ssl_yfcc100m_ft_in1k done. 2221.13 samples/sec, 115.23 ms/step
Model resnet50.fb_ssl_yfcc100m_ft_in1k created, param count: 25557032
Running train benchmark on resnet50.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.83 samples/sec. 361.157 ms/step.
Train [16/40]. 708.83 samples/sec. 361.157 ms/step.
Train [24/40]. 708.83 samples/sec. 361.160 ms/step.
Train [32/40]. 708.84 samples/sec. 361.152 ms/step.
Train [40/40]. 708.82 samples/sec. 361.163 ms/step.
Train benchmark of resnet50.fb_ssl_yfcc100m_ft_in1k done. 706.90 samples/sec, 361.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.fb_swsl_ig1b_ft_in1k created, param count: 25557032
Running inference benchmark on resnet50.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2220.81 samples/sec. 115.273 ms/step.
Infer [16/40]. 2220.73 samples/sec. 115.277 ms/step.
Infer [24/40]. 2220.48 samples/sec. 115.290 ms/step.
Infer [32/40]. 2220.49 samples/sec. 115.290 ms/step.
Infer [40/40]. 2220.26 samples/sec. 115.302 ms/step.
Inference benchmark of resnet50.fb_swsl_ig1b_ft_in1k done. 2219.70 samples/sec, 115.30 ms/step
Model resnet50.fb_swsl_ig1b_ft_in1k created, param count: 25557032
Running train benchmark on resnet50.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.82 samples/sec. 361.163 ms/step.
Train [16/40]. 708.78 samples/sec. 361.181 ms/step.
Train [24/40]. 708.75 samples/sec. 361.197 ms/step.
Train [32/40]. 708.76 samples/sec. 361.195 ms/step.
Train [40/40]. 708.74 samples/sec. 361.205 ms/step.
Train benchmark of resnet50.fb_swsl_ig1b_ft_in1k done. 706.82 samples/sec, 361.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.gluon_in1k created, param count: 25557032
Running inference benchmark on resnet50.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2220.50 samples/sec. 115.290 ms/step.
Infer [16/40]. 2220.68 samples/sec. 115.280 ms/step.
Infer [24/40]. 2220.88 samples/sec. 115.269 ms/step.
Infer [32/40]. 2220.84 samples/sec. 115.272 ms/step.
Infer [40/40]. 2220.75 samples/sec. 115.276 ms/step.
Inference benchmark of resnet50.gluon_in1k done. 2220.20 samples/sec, 115.28 ms/step
Model resnet50.gluon_in1k created, param count: 25557032
Running train benchmark on resnet50.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.85 samples/sec. 361.151 ms/step.
Train [16/40]. 708.85 samples/sec. 361.151 ms/step.
Train [24/40]. 708.85 samples/sec. 361.151 ms/step.
Train [32/40]. 708.83 samples/sec. 361.158 ms/step.
Train [40/40]. 708.82 samples/sec. 361.161 ms/step.
Train benchmark of resnet50.gluon_in1k done. 706.90 samples/sec, 361.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.ra_in1k created, param count: 25557032
Running inference benchmark on resnet50.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.62 samples/sec. 182.906 ms/step.
Infer [16/40]. 1399.32 samples/sec. 182.947 ms/step.
Infer [24/40]. 1399.24 samples/sec. 182.956 ms/step.
Infer [32/40]. 1399.19 samples/sec. 182.963 ms/step.
Infer [40/40]. 1399.14 samples/sec. 182.969 ms/step.
Inference benchmark of resnet50.ra_in1k done. 1398.86 samples/sec, 182.97 ms/step
Model resnet50.ra_in1k created, param count: 25557032
Running train benchmark on resnet50.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.ra_in1k created, param count: 25557032
Running train benchmark on resnet50.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.ra_in1k created, param count: 25557032
Running train benchmark on resnet50.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.60 samples/sec. 289.855 ms/step.
Train [16/40]. 441.60 samples/sec. 289.853 ms/step.
Train [24/40]. 441.60 samples/sec. 289.856 ms/step.
Train [32/40]. 441.60 samples/sec. 289.855 ms/step.
Train [40/40]. 441.61 samples/sec. 289.846 ms/step.
Train benchmark of resnet50.ra_in1k done. 440.16 samples/sec, 289.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.ram_in1k created, param count: 25557032
Running inference benchmark on resnet50.ram_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1399.70 samples/sec. 182.896 ms/step.
Infer [16/40]. 1399.62 samples/sec. 182.907 ms/step.
Infer [24/40]. 1399.49 samples/sec. 182.923 ms/step.
Infer [32/40]. 1399.40 samples/sec. 182.936 ms/step.
Infer [40/40]. 1399.32 samples/sec. 182.946 ms/step.
Inference benchmark of resnet50.ram_in1k done. 1399.04 samples/sec, 182.95 ms/step
Model resnet50.ram_in1k created, param count: 25557032
Running train benchmark on resnet50.ram_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50.ram_in1k created, param count: 25557032
Running train benchmark on resnet50.ram_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50.ram_in1k created, param count: 25557032
Running train benchmark on resnet50.ram_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.64 samples/sec. 289.826 ms/step.
Train [16/40]. 441.64 samples/sec. 289.829 ms/step.
Train [24/40]. 441.66 samples/sec. 289.816 ms/step.
Train [32/40]. 441.62 samples/sec. 289.841 ms/step.
Train [40/40]. 441.60 samples/sec. 289.853 ms/step.
Train benchmark of resnet50.ram_in1k done. 440.14 samples/sec, 289.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.tv2_in1k created, param count: 25557032
Running inference benchmark on resnet50.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2220.47 samples/sec. 115.291 ms/step.
Infer [16/40]. 2220.31 samples/sec. 115.299 ms/step.
Infer [24/40]. 2220.59 samples/sec. 115.285 ms/step.
Infer [32/40]. 2220.44 samples/sec. 115.292 ms/step.
Infer [40/40]. 2220.35 samples/sec. 115.297 ms/step.
Inference benchmark of resnet50.tv2_in1k done. 2219.80 samples/sec, 115.30 ms/step
Model resnet50.tv2_in1k created, param count: 25557032
Running train benchmark on resnet50.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.79 samples/sec. 361.177 ms/step.
Train [16/40]. 708.72 samples/sec. 361.215 ms/step.
Train [24/40]. 708.73 samples/sec. 361.210 ms/step.
Train [32/40]. 708.73 samples/sec. 361.211 ms/step.
Train [40/40]. 708.75 samples/sec. 361.201 ms/step.
Train benchmark of resnet50.tv2_in1k done. 706.82 samples/sec, 361.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50.tv_in1k created, param count: 25557032
Running inference benchmark on resnet50.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2221.20 samples/sec. 115.253 ms/step.
Infer [16/40]. 2220.91 samples/sec. 115.268 ms/step.
Infer [24/40]. 2220.48 samples/sec. 115.291 ms/step.
Infer [32/40]. 2220.43 samples/sec. 115.293 ms/step.
Infer [40/40]. 2220.38 samples/sec. 115.296 ms/step.
Inference benchmark of resnet50.tv_in1k done. 2219.82 samples/sec, 115.30 ms/step
Model resnet50.tv_in1k created, param count: 25557032
Running train benchmark on resnet50.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 708.85 samples/sec. 361.148 ms/step.
Train [16/40]. 708.87 samples/sec. 361.139 ms/step.
Train [24/40]. 708.84 samples/sec. 361.156 ms/step.
Train [32/40]. 708.81 samples/sec. 361.171 ms/step.
Train [40/40]. 708.80 samples/sec. 361.176 ms/step.
Train benchmark of resnet50.tv_in1k done. 706.88 samples/sec, 361.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50_gn.a1h_in1k created, param count: 25557032
Running inference benchmark on resnet50_gn.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1259.34 samples/sec. 203.280 ms/step.
Infer [16/40]. 1259.38 samples/sec. 203.275 ms/step.
Infer [24/40]. 1259.38 samples/sec. 203.275 ms/step.
Infer [32/40]. 1259.32 samples/sec. 203.284 ms/step.
Infer [40/40]. 1259.25 samples/sec. 203.296 ms/step.
Inference benchmark of resnet50_gn.a1h_in1k done. 1259.03 samples/sec, 203.30 ms/step
Model resnet50_gn.a1h_in1k created, param count: 25557032
Running train benchmark on resnet50_gn.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 598.06 MiB is free. Including non-PyTorch memory, this process has 23.06 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 62.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50_gn.a1h_in1k created, param count: 25557032
Running train benchmark on resnet50_gn.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 135.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50_gn.a1h_in1k created, param count: 25557032
Running train benchmark on resnet50_gn.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 446.15 samples/sec. 286.897 ms/step.
Train [16/40]. 446.06 samples/sec. 286.955 ms/step.
Train [24/40]. 446.10 samples/sec. 286.932 ms/step.
Train [32/40]. 446.08 samples/sec. 286.947 ms/step.
Train [40/40]. 446.10 samples/sec. 286.931 ms/step.
Train benchmark of resnet50_gn.a1h_in1k done. 444.62 samples/sec, 286.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50c.gluon_in1k created, param count: 25576264
Running inference benchmark on resnet50c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2100.29 samples/sec. 121.888 ms/step.
Infer [16/40]. 2099.99 samples/sec. 121.905 ms/step.
Infer [24/40]. 2099.87 samples/sec. 121.913 ms/step.
Infer [32/40]. 2099.90 samples/sec. 121.911 ms/step.
Infer [40/40]. 2099.98 samples/sec. 121.906 ms/step.
Inference benchmark of resnet50c.gluon_in1k done. 2099.48 samples/sec, 121.91 ms/step
Model resnet50c.gluon_in1k created, param count: 25576264
Running train benchmark on resnet50c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 654.48 samples/sec. 391.148 ms/step.
Train [16/40]. 654.43 samples/sec. 391.181 ms/step.
Train [24/40]. 654.43 samples/sec. 391.182 ms/step.
Train [32/40]. 654.41 samples/sec. 391.194 ms/step.
Train [40/40]. 654.40 samples/sec. 391.197 ms/step.
Train benchmark of resnet50c.gluon_in1k done. 652.71 samples/sec, 391.20 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50d.a1_in1k created, param count: 25576264
Running inference benchmark on resnet50d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1316.20 samples/sec. 194.499 ms/step.
Infer [16/40]. 1316.19 samples/sec. 194.501 ms/step.
Infer [24/40]. 1316.18 samples/sec. 194.502 ms/step.
Infer [32/40]. 1316.17 samples/sec. 194.503 ms/step.
Infer [40/40]. 1316.17 samples/sec. 194.504 ms/step.
Inference benchmark of resnet50d.a1_in1k done. 1315.91 samples/sec, 194.50 ms/step
Model resnet50d.a1_in1k created, param count: 25576264
Running train benchmark on resnet50d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 223.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50d.a1_in1k created, param count: 25576264
Running train benchmark on resnet50d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 73.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50d.a1_in1k created, param count: 25576264
Running train benchmark on resnet50d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 409.73 samples/sec. 312.404 ms/step.
Train [16/40]. 409.73 samples/sec. 312.403 ms/step.
Train [24/40]. 409.74 samples/sec. 312.390 ms/step.
Train [32/40]. 409.73 samples/sec. 312.398 ms/step.
Train [40/40]. 409.71 samples/sec. 312.413 ms/step.
Train benchmark of resnet50d.a1_in1k done. 408.41 samples/sec, 312.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50d.a2_in1k created, param count: 25576264
Running inference benchmark on resnet50d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1316.19 samples/sec. 194.500 ms/step.
Infer [16/40]. 1316.14 samples/sec. 194.508 ms/step.
Infer [24/40]. 1316.16 samples/sec. 194.505 ms/step.
Infer [32/40]. 1316.17 samples/sec. 194.504 ms/step.
Infer [40/40]. 1316.16 samples/sec. 194.505 ms/step.
Inference benchmark of resnet50d.a2_in1k done. 1315.90 samples/sec, 194.50 ms/step
Model resnet50d.a2_in1k created, param count: 25576264
Running train benchmark on resnet50d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 223.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50d.a2_in1k created, param count: 25576264
Running train benchmark on resnet50d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 73.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50d.a2_in1k created, param count: 25576264
Running train benchmark on resnet50d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 409.56 samples/sec. 312.530 ms/step.
Train [16/40]. 409.58 samples/sec. 312.513 ms/step.
Train [24/40]. 409.53 samples/sec. 312.550 ms/step.
Train [32/40]. 409.54 samples/sec. 312.548 ms/step.
Train [40/40]. 409.52 samples/sec. 312.558 ms/step.
Train benchmark of resnet50d.a2_in1k done. 408.21 samples/sec, 312.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50d.a3_in1k created, param count: 25576264
Running inference benchmark on resnet50d.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2105.63 samples/sec. 121.579 ms/step.
Infer [16/40]. 2105.91 samples/sec. 121.563 ms/step.
Infer [24/40]. 2106.25 samples/sec. 121.543 ms/step.
Infer [32/40]. 2106.18 samples/sec. 121.547 ms/step.
Infer [40/40]. 2106.04 samples/sec. 121.555 ms/step.
Inference benchmark of resnet50d.a3_in1k done. 2105.53 samples/sec, 121.56 ms/step
Model resnet50d.a3_in1k created, param count: 25576264
Running train benchmark on resnet50d.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 660.53 samples/sec. 387.567 ms/step.
Train [16/40]. 660.47 samples/sec. 387.603 ms/step.
Train [24/40]. 660.47 samples/sec. 387.604 ms/step.
Train [32/40]. 660.43 samples/sec. 387.625 ms/step.
Train [40/40]. 660.44 samples/sec. 387.623 ms/step.
Train benchmark of resnet50d.a3_in1k done. 658.70 samples/sec, 387.62 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50d.gluon_in1k created, param count: 25576264
Running inference benchmark on resnet50d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2106.54 samples/sec. 121.526 ms/step.
Infer [16/40]. 2106.44 samples/sec. 121.532 ms/step.
Infer [24/40]. 2106.48 samples/sec. 121.530 ms/step.
Infer [32/40]. 2106.19 samples/sec. 121.547 ms/step.
Infer [40/40]. 2106.05 samples/sec. 121.554 ms/step.
Inference benchmark of resnet50d.gluon_in1k done. 2105.53 samples/sec, 121.55 ms/step
Model resnet50d.gluon_in1k created, param count: 25576264
Running train benchmark on resnet50d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 660.42 samples/sec. 387.632 ms/step.
Train [16/40]. 660.46 samples/sec. 387.612 ms/step.
Train [24/40]. 660.46 samples/sec. 387.609 ms/step.
Train [32/40]. 660.46 samples/sec. 387.607 ms/step.
Train [40/40]. 660.46 samples/sec. 387.610 ms/step.
Train benchmark of resnet50d.gluon_in1k done. 658.72 samples/sec, 387.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50d.ra2_in1k created, param count: 25576264
Running inference benchmark on resnet50d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1316.75 samples/sec. 194.418 ms/step.
Infer [16/40]. 1316.65 samples/sec. 194.434 ms/step.
Infer [24/40]. 1316.52 samples/sec. 194.452 ms/step.
Infer [32/40]. 1316.47 samples/sec. 194.460 ms/step.
Infer [40/40]. 1316.44 samples/sec. 194.465 ms/step.
Inference benchmark of resnet50d.ra2_in1k done. 1316.18 samples/sec, 194.47 ms/step
Model resnet50d.ra2_in1k created, param count: 25576264
Running train benchmark on resnet50d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 223.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50d.ra2_in1k created, param count: 25576264
Running train benchmark on resnet50d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 73.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet50d.ra2_in1k created, param count: 25576264
Running train benchmark on resnet50d.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 409.46 samples/sec. 312.608 ms/step.
Train [16/40]. 409.55 samples/sec. 312.534 ms/step.
Train [24/40]. 409.52 samples/sec. 312.559 ms/step.
Train [32/40]. 409.52 samples/sec. 312.562 ms/step.
Train [40/40]. 409.52 samples/sec. 312.563 ms/step.
Train benchmark of resnet50d.ra2_in1k done. 408.23 samples/sec, 312.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet50s.gluon_in1k created, param count: 25680808
Running inference benchmark on resnet50s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1835.84 samples/sec. 139.445 ms/step.
Infer [16/40]. 1835.71 samples/sec. 139.456 ms/step.
Infer [24/40]. 1835.57 samples/sec. 139.466 ms/step.
Infer [32/40]. 1835.68 samples/sec. 139.458 ms/step.
Infer [40/40]. 1835.75 samples/sec. 139.452 ms/step.
Inference benchmark of resnet50s.gluon_in1k done. 1835.34 samples/sec, 139.45 ms/step
Model resnet50s.gluon_in1k created, param count: 25680808
Running train benchmark on resnet50s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 59.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet50s.gluon_in1k created, param count: 25680808
Running train benchmark on resnet50s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 578.89 samples/sec. 331.668 ms/step.
Train [16/40]. 579.03 samples/sec. 331.590 ms/step.
Train [24/40]. 579.01 samples/sec. 331.599 ms/step.
Train [32/40]. 579.01 samples/sec. 331.601 ms/step.
Train [40/40]. 579.00 samples/sec. 331.605 ms/step.
Train benchmark of resnet50s.gluon_in1k done. 577.25 samples/sec, 331.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet51q.ra2_in1k created, param count: 35696920
Running inference benchmark on resnet51q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1290.55 samples/sec. 198.365 ms/step.
Infer [16/40]. 1290.58 samples/sec. 198.361 ms/step.
Infer [24/40]. 1290.52 samples/sec. 198.369 ms/step.
Infer [32/40]. 1290.52 samples/sec. 198.369 ms/step.
Infer [40/40]. 1290.50 samples/sec. 198.373 ms/step.
Inference benchmark of resnet51q.ra2_in1k done. 1290.25 samples/sec, 198.37 ms/step
Model resnet51q.ra2_in1k created, param count: 35696920
Running train benchmark on resnet51q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 454.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 7.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet51q.ra2_in1k created, param count: 35696920
Running train benchmark on resnet51q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 237.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet51q.ra2_in1k created, param count: 35696920
Running train benchmark on resnet51q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 140.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet51q.ra2_in1k created, param count: 35696920
Running train benchmark on resnet51q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 358.77 samples/sec. 267.580 ms/step.
Train [16/40]. 358.77 samples/sec. 267.583 ms/step.
Train [24/40]. 358.77 samples/sec. 267.582 ms/step.
Train [32/40]. 358.77 samples/sec. 267.579 ms/step.
Train [40/40]. 358.76 samples/sec. 267.587 ms/step.
Train benchmark of resnet51q.ra2_in1k done. 357.49 samples/sec, 267.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet61q.ra2_in1k created, param count: 36846968
Running inference benchmark on resnet61q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1207.49 samples/sec. 212.010 ms/step.
Infer [16/40]. 1207.46 samples/sec. 212.015 ms/step.
Infer [24/40]. 1207.45 samples/sec. 212.017 ms/step.
Infer [32/40]. 1207.46 samples/sec. 212.015 ms/step.
Infer [40/40]. 1207.42 samples/sec. 212.023 ms/step.
Inference benchmark of resnet61q.ra2_in1k done. 1207.19 samples/sec, 212.02 ms/step
Model resnet61q.ra2_in1k created, param count: 36846968
Running train benchmark on resnet61q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 610.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 7.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet61q.ra2_in1k created, param count: 36846968
Running train benchmark on resnet61q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 224.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet61q.ra2_in1k created, param count: 36846968
Running train benchmark on resnet61q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 126.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet61q.ra2_in1k created, param count: 36846968
Running train benchmark on resnet61q.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 327.48 samples/sec. 293.147 ms/step.
Train [16/40]. 327.47 samples/sec. 293.156 ms/step.
Train [24/40]. 327.44 samples/sec. 293.179 ms/step.
Train [32/40]. 327.41 samples/sec. 293.209 ms/step.
Train [40/40]. 327.40 samples/sec. 293.218 ms/step.
Train benchmark of resnet61q.ra2_in1k done. 326.22 samples/sec, 293.22 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101.a1_in1k created, param count: 44549160
Running inference benchmark on resnet101.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 861.87 samples/sec. 297.027 ms/step.
Infer [16/40]. 861.89 samples/sec. 297.022 ms/step.
Infer [24/40]. 861.79 samples/sec. 297.055 ms/step.
Infer [32/40]. 861.73 samples/sec. 297.075 ms/step.
Infer [40/40]. 861.69 samples/sec. 297.089 ms/step.
Inference benchmark of resnet101.a1_in1k done. 861.57 samples/sec, 297.09 ms/step
Model resnet101.a1_in1k created, param count: 44549160
Running train benchmark on resnet101.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 566.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 22.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101.a1_in1k created, param count: 44549160
Running train benchmark on resnet101.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 106.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101.a1_in1k created, param count: 44549160
Running train benchmark on resnet101.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 245.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet101.a1_in1k created, param count: 44549160
Running train benchmark on resnet101.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 288.12 samples/sec. 333.196 ms/step.
Train [16/40]. 288.12 samples/sec. 333.194 ms/step.
Train [24/40]. 288.11 samples/sec. 333.207 ms/step.
Train [32/40]. 288.12 samples/sec. 333.196 ms/step.
Train [40/40]. 288.09 samples/sec. 333.227 ms/step.
Train benchmark of resnet101.a1_in1k done. 286.81 samples/sec, 333.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101.a1h_in1k created, param count: 44549160
Running inference benchmark on resnet101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 861.63 samples/sec. 297.111 ms/step.
Infer [16/40]. 861.59 samples/sec. 297.126 ms/step.
Infer [24/40]. 861.59 samples/sec. 297.125 ms/step.
Infer [32/40]. 861.59 samples/sec. 297.125 ms/step.
Infer [40/40]. 861.57 samples/sec. 297.132 ms/step.
Inference benchmark of resnet101.a1h_in1k done. 861.44 samples/sec, 297.13 ms/step
Model resnet101.a1h_in1k created, param count: 44549160
Running train benchmark on resnet101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 566.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 22.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101.a1h_in1k created, param count: 44549160
Running train benchmark on resnet101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 110.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101.a1h_in1k created, param count: 44549160
Running train benchmark on resnet101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 245.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet101.a1h_in1k created, param count: 44549160
Running train benchmark on resnet101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 288.23 samples/sec. 333.067 ms/step.
Train [16/40]. 288.17 samples/sec. 333.134 ms/step.
Train [24/40]. 288.13 samples/sec. 333.182 ms/step.
Train [32/40]. 288.11 samples/sec. 333.206 ms/step.
Train [40/40]. 288.12 samples/sec. 333.192 ms/step.
Train benchmark of resnet101.a1h_in1k done. 286.87 samples/sec, 333.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101.a2_in1k created, param count: 44549160
Running inference benchmark on resnet101.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 861.60 samples/sec. 297.121 ms/step.
Infer [16/40]. 861.57 samples/sec. 297.133 ms/step.
Infer [24/40]. 861.55 samples/sec. 297.139 ms/step.
Infer [32/40]. 861.54 samples/sec. 297.141 ms/step.
Infer [40/40]. 861.54 samples/sec. 297.144 ms/step.
Inference benchmark of resnet101.a2_in1k done. 861.40 samples/sec, 297.14 ms/step
Model resnet101.a2_in1k created, param count: 44549160
Running train benchmark on resnet101.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 566.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 22.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101.a2_in1k created, param count: 44549160
Running train benchmark on resnet101.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 110.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101.a2_in1k created, param count: 44549160
Running train benchmark on resnet101.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 245.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet101.a2_in1k created, param count: 44549160
Running train benchmark on resnet101.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 288.05 samples/sec. 333.272 ms/step.
Train [16/40]. 288.03 samples/sec. 333.293 ms/step.
Train [24/40]. 288.04 samples/sec. 333.288 ms/step.
Train [32/40]. 288.04 samples/sec. 333.286 ms/step.
Train [40/40]. 288.06 samples/sec. 333.261 ms/step.
Train benchmark of resnet101.a2_in1k done. 286.78 samples/sec, 333.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101.a3_in1k created, param count: 44549160
Running inference benchmark on resnet101.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1306.02 samples/sec. 196.016 ms/step.
Infer [16/40]. 1305.72 samples/sec. 196.060 ms/step.
Infer [24/40]. 1305.70 samples/sec. 196.064 ms/step.
Infer [32/40]. 1305.78 samples/sec. 196.051 ms/step.
Infer [40/40]. 1305.87 samples/sec. 196.038 ms/step.
Inference benchmark of resnet101.a3_in1k done. 1305.61 samples/sec, 196.04 ms/step
Model resnet101.a3_in1k created, param count: 44549160
Running train benchmark on resnet101.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 60.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101.a3_in1k created, param count: 44549160
Running train benchmark on resnet101.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 287.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101.a3_in1k created, param count: 44549160
Running train benchmark on resnet101.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 480.23 samples/sec. 266.538 ms/step.
Train [16/40]. 480.29 samples/sec. 266.507 ms/step.
Train [24/40]. 480.30 samples/sec. 266.498 ms/step.
Train [32/40]. 480.30 samples/sec. 266.501 ms/step.
Train [40/40]. 480.31 samples/sec. 266.495 ms/step.
Train benchmark of resnet101.a3_in1k done. 477.74 samples/sec, 266.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101.gluon_in1k created, param count: 44549160
Running inference benchmark on resnet101.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1306.20 samples/sec. 195.988 ms/step.
Infer [16/40]. 1306.42 samples/sec. 195.956 ms/step.
Infer [24/40]. 1306.30 samples/sec. 195.974 ms/step.
Infer [32/40]. 1306.28 samples/sec. 195.977 ms/step.
Infer [40/40]. 1306.17 samples/sec. 195.993 ms/step.
Inference benchmark of resnet101.gluon_in1k done. 1305.91 samples/sec, 195.99 ms/step
Model resnet101.gluon_in1k created, param count: 44549160
Running train benchmark on resnet101.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 60.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101.gluon_in1k created, param count: 44549160
Running train benchmark on resnet101.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 287.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101.gluon_in1k created, param count: 44549160
Running train benchmark on resnet101.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 480.33 samples/sec. 266.481 ms/step.
Train [16/40]. 480.32 samples/sec. 266.487 ms/step.
Train [24/40]. 480.34 samples/sec. 266.477 ms/step.
Train [32/40]. 480.31 samples/sec. 266.494 ms/step.
Train [40/40]. 480.33 samples/sec. 266.485 ms/step.
Train benchmark of resnet101.gluon_in1k done. 477.73 samples/sec, 266.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101.tv2_in1k created, param count: 44549160
Running inference benchmark on resnet101.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1305.79 samples/sec. 196.050 ms/step.
Infer [16/40]. 1305.97 samples/sec. 196.023 ms/step.
Infer [24/40]. 1306.29 samples/sec. 195.975 ms/step.
Infer [32/40]. 1306.18 samples/sec. 195.992 ms/step.
Infer [40/40]. 1305.94 samples/sec. 196.028 ms/step.
Inference benchmark of resnet101.tv2_in1k done. 1305.68 samples/sec, 196.03 ms/step
Model resnet101.tv2_in1k created, param count: 44549160
Running train benchmark on resnet101.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 60.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101.tv2_in1k created, param count: 44549160
Running train benchmark on resnet101.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 287.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101.tv2_in1k created, param count: 44549160
Running train benchmark on resnet101.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 480.33 samples/sec. 266.485 ms/step.
Train [16/40]. 480.31 samples/sec. 266.494 ms/step.
Train [24/40]. 480.33 samples/sec. 266.483 ms/step.
Train [32/40]. 480.32 samples/sec. 266.487 ms/step.
Train [40/40]. 480.32 samples/sec. 266.490 ms/step.
Train benchmark of resnet101.tv2_in1k done. 477.74 samples/sec, 266.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101.tv_in1k created, param count: 44549160
Running inference benchmark on resnet101.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1306.69 samples/sec. 195.915 ms/step.
Infer [16/40]. 1306.55 samples/sec. 195.936 ms/step.
Infer [24/40]. 1306.36 samples/sec. 195.965 ms/step.
Infer [32/40]. 1306.40 samples/sec. 195.959 ms/step.
Infer [40/40]. 1306.35 samples/sec. 195.966 ms/step.
Inference benchmark of resnet101.tv_in1k done. 1306.09 samples/sec, 195.97 ms/step
Model resnet101.tv_in1k created, param count: 44549160
Running train benchmark on resnet101.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 60.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101.tv_in1k created, param count: 44549160
Running train benchmark on resnet101.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 287.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101.tv_in1k created, param count: 44549160
Running train benchmark on resnet101.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 480.37 samples/sec. 266.463 ms/step.
Train [16/40]. 480.31 samples/sec. 266.492 ms/step.
Train [24/40]. 480.30 samples/sec. 266.501 ms/step.
Train [32/40]. 480.29 samples/sec. 266.507 ms/step.
Train [40/40]. 480.29 samples/sec. 266.506 ms/step.
Train benchmark of resnet101.tv_in1k done. 477.71 samples/sec, 266.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101c.gluon_in1k created, param count: 44568392
Running inference benchmark on resnet101c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1262.88 samples/sec. 202.710 ms/step.
Infer [16/40]. 1263.02 samples/sec. 202.688 ms/step.
Infer [24/40]. 1263.17 samples/sec. 202.665 ms/step.
Infer [32/40]. 1263.08 samples/sec. 202.679 ms/step.
Infer [40/40]. 1263.19 samples/sec. 202.661 ms/step.
Inference benchmark of resnet101c.gluon_in1k done. 1262.94 samples/sec, 202.66 ms/step
Model resnet101c.gluon_in1k created, param count: 44568392
Running train benchmark on resnet101c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 56.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101c.gluon_in1k created, param count: 44568392
Running train benchmark on resnet101c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 253.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101c.gluon_in1k created, param count: 44568392
Running train benchmark on resnet101c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 453.32 samples/sec. 282.361 ms/step.
Train [16/40]. 453.33 samples/sec. 282.353 ms/step.
Train [24/40]. 453.35 samples/sec. 282.342 ms/step.
Train [32/40]. 453.36 samples/sec. 282.339 ms/step.
Train [40/40]. 453.33 samples/sec. 282.353 ms/step.
Train benchmark of resnet101c.gluon_in1k done. 451.01 samples/sec, 282.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101d.gluon_in1k created, param count: 44568392
Running inference benchmark on resnet101d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1267.02 samples/sec. 202.049 ms/step.
Infer [16/40]. 1265.61 samples/sec. 202.274 ms/step.
Infer [24/40]. 1265.14 samples/sec. 202.349 ms/step.
Infer [32/40]. 1265.00 samples/sec. 202.372 ms/step.
Infer [40/40]. 1264.91 samples/sec. 202.387 ms/step.
Inference benchmark of resnet101d.gluon_in1k done. 1264.67 samples/sec, 202.39 ms/step
Model resnet101d.gluon_in1k created, param count: 44568392
Running train benchmark on resnet101d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 52.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101d.gluon_in1k created, param count: 44568392
Running train benchmark on resnet101d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 249.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101d.gluon_in1k created, param count: 44568392
Running train benchmark on resnet101d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 455.45 samples/sec. 281.038 ms/step.
Train [16/40]. 455.47 samples/sec. 281.031 ms/step.
Train [24/40]. 455.46 samples/sec. 281.033 ms/step.
Train [32/40]. 455.47 samples/sec. 281.031 ms/step.
Train [40/40]. 455.45 samples/sec. 281.042 ms/step.
Train benchmark of resnet101d.gluon_in1k done. 453.11 samples/sec, 281.04 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101d.ra2_in1k created, param count: 44568392
Running inference benchmark on resnet101d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 711.21 samples/sec. 359.948 ms/step.
Infer [16/40]. 711.21 samples/sec. 359.950 ms/step.
Infer [24/40]. 711.20 samples/sec. 359.957 ms/step.
Infer [32/40]. 711.17 samples/sec. 359.970 ms/step.
Infer [40/40]. 711.15 samples/sec. 359.978 ms/step.
Inference benchmark of resnet101d.ra2_in1k done. 711.06 samples/sec, 359.98 ms/step
Model resnet101d.ra2_in1k created, param count: 44568392
Running train benchmark on resnet101d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 20.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101d.ra2_in1k created, param count: 44568392
Running train benchmark on resnet101d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 418.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 369.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101d.ra2_in1k created, param count: 44568392
Running train benchmark on resnet101d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 292.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet101d.ra2_in1k created, param count: 44568392
Running train benchmark on resnet101d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 233.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnet101d.ra2_in1k created, param count: 44568392
Running train benchmark on resnet101d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
Train [8/40]. 237.71 samples/sec. 269.241 ms/step.
Train [16/40]. 237.70 samples/sec. 269.246 ms/step.
Train [24/40]. 237.69 samples/sec. 269.260 ms/step.
Train [32/40]. 237.69 samples/sec. 269.263 ms/step.
Train [40/40]. 237.69 samples/sec. 269.259 ms/step.
Train benchmark of resnet101d.ra2_in1k done. 236.41 samples/sec, 269.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet101s.gluon_in1k created, param count: 44672936
Running inference benchmark on resnet101s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1162.00 samples/sec. 220.310 ms/step.
Infer [16/40]. 1162.27 samples/sec. 220.259 ms/step.
Infer [24/40]. 1162.14 samples/sec. 220.284 ms/step.
Infer [32/40]. 1162.04 samples/sec. 220.303 ms/step.
Infer [40/40]. 1162.05 samples/sec. 220.301 ms/step.
Inference benchmark of resnet101s.gluon_in1k done. 1161.83 samples/sec, 220.30 ms/step
Model resnet101s.gluon_in1k created, param count: 44672936
Running train benchmark on resnet101s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 69.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet101s.gluon_in1k created, param count: 44672936
Running train benchmark on resnet101s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 213.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet101s.gluon_in1k created, param count: 44672936
Running train benchmark on resnet101s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 408.45 samples/sec. 313.379 ms/step.
Train [16/40]. 408.46 samples/sec. 313.369 ms/step.
Train [24/40]. 408.46 samples/sec. 313.374 ms/step.
Train [32/40]. 408.45 samples/sec. 313.378 ms/step.
Train [40/40]. 408.46 samples/sec. 313.374 ms/step.
Train benchmark of resnet101s.gluon_in1k done. 406.51 samples/sec, 313.37 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152.a1_in1k created, param count: 60192808
Running inference benchmark on resnet152.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 603.46 samples/sec. 424.221 ms/step.
Infer [16/40]. 603.34 samples/sec. 424.304 ms/step.
Infer [24/40]. 603.29 samples/sec. 424.340 ms/step.
Infer [32/40]. 603.27 samples/sec. 424.353 ms/step.
Infer [40/40]. 603.26 samples/sec. 424.362 ms/step.
Inference benchmark of resnet152.a1_in1k done. 603.19 samples/sec, 424.36 ms/step
Model resnet152.a1_in1k created, param count: 60192808
Running train benchmark on resnet152.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 494.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 34.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152.a1_in1k created, param count: 60192808
Running train benchmark on resnet152.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 250.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152.a1_in1k created, param count: 60192808
Running train benchmark on resnet152.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 251.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet152.a1_in1k created, param count: 60192808
Running train benchmark on resnet152.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 288.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnet152.a1_in1k created, param count: 60192808
Running train benchmark on resnet152.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 211.37 samples/sec. 302.791 ms/step.
Train [16/40]. 211.38 samples/sec. 302.774 ms/step.
Train [24/40]. 211.38 samples/sec. 302.767 ms/step.
Train [32/40]. 211.38 samples/sec. 302.765 ms/step.
Train [40/40]. 211.39 samples/sec. 302.763 ms/step.
Train benchmark of resnet152.a1_in1k done. 210.08 samples/sec, 302.76 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152.a1h_in1k created, param count: 60192808
Running inference benchmark on resnet152.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 603.48 samples/sec. 424.205 ms/step.
Infer [16/40]. 603.49 samples/sec. 424.202 ms/step.
Infer [24/40]. 603.48 samples/sec. 424.203 ms/step.
Infer [32/40]. 603.41 samples/sec. 424.258 ms/step.
Infer [40/40]. 603.36 samples/sec. 424.292 ms/step.
Inference benchmark of resnet152.a1h_in1k done. 603.29 samples/sec, 424.29 ms/step
Model resnet152.a1h_in1k created, param count: 60192808
Running train benchmark on resnet152.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 494.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 34.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152.a1h_in1k created, param count: 60192808
Running train benchmark on resnet152.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 250.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152.a1h_in1k created, param count: 60192808
Running train benchmark on resnet152.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 251.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet152.a1h_in1k created, param count: 60192808
Running train benchmark on resnet152.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 288.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnet152.a1h_in1k created, param count: 60192808
Running train benchmark on resnet152.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 211.23 samples/sec. 302.985 ms/step.
Train [16/40]. 211.23 samples/sec. 302.986 ms/step.
Train [24/40]. 211.24 samples/sec. 302.971 ms/step.
Train [32/40]. 211.24 samples/sec. 302.969 ms/step.
Train [40/40]. 211.24 samples/sec. 302.974 ms/step.
Train benchmark of resnet152.a1h_in1k done. 209.94 samples/sec, 302.97 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152.a2_in1k created, param count: 60192808
Running inference benchmark on resnet152.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 603.23 samples/sec. 424.381 ms/step.
Infer [16/40]. 603.23 samples/sec. 424.379 ms/step.
Infer [24/40]. 603.22 samples/sec. 424.388 ms/step.
Infer [32/40]. 603.21 samples/sec. 424.397 ms/step.
Infer [40/40]. 603.21 samples/sec. 424.397 ms/step.
Inference benchmark of resnet152.a2_in1k done. 603.14 samples/sec, 424.40 ms/step
Model resnet152.a2_in1k created, param count: 60192808
Running train benchmark on resnet152.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 494.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 34.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152.a2_in1k created, param count: 60192808
Running train benchmark on resnet152.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 250.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152.a2_in1k created, param count: 60192808
Running train benchmark on resnet152.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 251.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet152.a2_in1k created, param count: 60192808
Running train benchmark on resnet152.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 288.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnet152.a2_in1k created, param count: 60192808
Running train benchmark on resnet152.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 211.24 samples/sec. 302.978 ms/step.
Train [16/40]. 211.24 samples/sec. 302.976 ms/step.
Train [24/40]. 211.23 samples/sec. 302.991 ms/step.
Train [32/40]. 211.23 samples/sec. 302.985 ms/step.
Train [40/40]. 211.23 samples/sec. 302.986 ms/step.
Train benchmark of resnet152.a2_in1k done. 209.92 samples/sec, 302.99 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152.a3_in1k created, param count: 60192808
Running inference benchmark on resnet152.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 907.46 samples/sec. 282.106 ms/step.
Infer [16/40]. 907.30 samples/sec. 282.155 ms/step.
Infer [24/40]. 907.28 samples/sec. 282.163 ms/step.
Infer [32/40]. 907.26 samples/sec. 282.168 ms/step.
Infer [40/40]. 907.12 samples/sec. 282.211 ms/step.
Inference benchmark of resnet152.a3_in1k done. 906.98 samples/sec, 282.21 ms/step
Model resnet152.a3_in1k created, param count: 60192808
Running train benchmark on resnet152.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 54.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152.a3_in1k created, param count: 60192808
Running train benchmark on resnet152.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 217.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152.a3_in1k created, param count: 60192808
Running train benchmark on resnet152.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 341.33 samples/sec. 374.999 ms/step.
Train [16/40]. 341.32 samples/sec. 375.013 ms/step.
Train [24/40]. 341.33 samples/sec. 375.007 ms/step.
Train [32/40]. 341.32 samples/sec. 375.015 ms/step.
Train [40/40]. 341.33 samples/sec. 375.004 ms/step.
Train benchmark of resnet152.a3_in1k done. 339.52 samples/sec, 375.00 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152.gluon_in1k created, param count: 60192808
Running inference benchmark on resnet152.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 907.34 samples/sec. 282.142 ms/step.
Infer [16/40]. 907.09 samples/sec. 282.220 ms/step.
Infer [24/40]. 907.07 samples/sec. 282.228 ms/step.
Infer [32/40]. 907.02 samples/sec. 282.241 ms/step.
Infer [40/40]. 906.97 samples/sec. 282.259 ms/step.
Inference benchmark of resnet152.gluon_in1k done. 906.82 samples/sec, 282.26 ms/step
Model resnet152.gluon_in1k created, param count: 60192808
Running train benchmark on resnet152.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 54.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152.gluon_in1k created, param count: 60192808
Running train benchmark on resnet152.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 217.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152.gluon_in1k created, param count: 60192808
Running train benchmark on resnet152.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 341.44 samples/sec. 374.878 ms/step.
Train [16/40]. 341.47 samples/sec. 374.849 ms/step.
Train [24/40]. 341.48 samples/sec. 374.842 ms/step.
Train [32/40]. 341.48 samples/sec. 374.837 ms/step.
Train [40/40]. 341.49 samples/sec. 374.833 ms/step.
Train benchmark of resnet152.gluon_in1k done. 339.69 samples/sec, 374.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152.tv2_in1k created, param count: 60192808
Running inference benchmark on resnet152.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 907.02 samples/sec. 282.243 ms/step.
Infer [16/40]. 906.86 samples/sec. 282.294 ms/step.
Infer [24/40]. 906.80 samples/sec. 282.311 ms/step.
Infer [32/40]. 906.76 samples/sec. 282.324 ms/step.
Infer [40/40]. 906.80 samples/sec. 282.312 ms/step.
Inference benchmark of resnet152.tv2_in1k done. 906.66 samples/sec, 282.31 ms/step
Model resnet152.tv2_in1k created, param count: 60192808
Running train benchmark on resnet152.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 54.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152.tv2_in1k created, param count: 60192808
Running train benchmark on resnet152.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 217.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152.tv2_in1k created, param count: 60192808
Running train benchmark on resnet152.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 341.44 samples/sec. 374.882 ms/step.
Train [16/40]. 341.44 samples/sec. 374.881 ms/step.
Train [24/40]. 341.44 samples/sec. 374.883 ms/step.
Train [32/40]. 341.44 samples/sec. 374.883 ms/step.
Train [40/40]. 341.43 samples/sec. 374.891 ms/step.
Train benchmark of resnet152.tv2_in1k done. 339.65 samples/sec, 374.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152.tv_in1k created, param count: 60192808
Running inference benchmark on resnet152.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 907.25 samples/sec. 282.170 ms/step.
Infer [16/40]. 907.29 samples/sec. 282.158 ms/step.
Infer [24/40]. 907.19 samples/sec. 282.191 ms/step.
Infer [32/40]. 907.14 samples/sec. 282.205 ms/step.
Infer [40/40]. 907.10 samples/sec. 282.218 ms/step.
Inference benchmark of resnet152.tv_in1k done. 906.96 samples/sec, 282.22 ms/step
Model resnet152.tv_in1k created, param count: 60192808
Running train benchmark on resnet152.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.08 GiB is allocated by PyTorch, and 54.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152.tv_in1k created, param count: 60192808
Running train benchmark on resnet152.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 217.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152.tv_in1k created, param count: 60192808
Running train benchmark on resnet152.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 341.45 samples/sec. 374.873 ms/step.
Train [16/40]. 341.41 samples/sec. 374.916 ms/step.
Train [24/40]. 341.42 samples/sec. 374.905 ms/step.
Train [32/40]. 341.42 samples/sec. 374.908 ms/step.
Train [40/40]. 341.42 samples/sec. 374.906 ms/step.
Train benchmark of resnet152.tv_in1k done. 339.64 samples/sec, 374.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152c.gluon_in1k created, param count: 60212040
Running inference benchmark on resnet152c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 886.46 samples/sec. 288.788 ms/step.
Infer [16/40]. 886.25 samples/sec. 288.857 ms/step.
Infer [24/40]. 886.09 samples/sec. 288.908 ms/step.
Infer [32/40]. 886.02 samples/sec. 288.933 ms/step.
Infer [40/40]. 885.98 samples/sec. 288.944 ms/step.
Inference benchmark of resnet152c.gluon_in1k done. 885.85 samples/sec, 288.94 ms/step
Model resnet152c.gluon_in1k created, param count: 60212040
Running train benchmark on resnet152c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 46.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152c.gluon_in1k created, param count: 60212040
Running train benchmark on resnet152c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 200.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152c.gluon_in1k created, param count: 60212040
Running train benchmark on resnet152c.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 327.35 samples/sec. 391.019 ms/step.
Train [16/40]. 327.34 samples/sec. 391.025 ms/step.
Train [24/40]. 327.33 samples/sec. 391.048 ms/step.
Train [32/40]. 327.33 samples/sec. 391.042 ms/step.
Train [40/40]. 327.33 samples/sec. 391.041 ms/step.
Train benchmark of resnet152c.gluon_in1k done. 325.62 samples/sec, 391.04 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152d.gluon_in1k created, param count: 60212040
Running inference benchmark on resnet152d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 887.44 samples/sec. 288.470 ms/step.
Infer [16/40]. 887.34 samples/sec. 288.502 ms/step.
Infer [24/40]. 887.29 samples/sec. 288.519 ms/step.
Infer [32/40]. 887.23 samples/sec. 288.539 ms/step.
Infer [40/40]. 887.20 samples/sec. 288.549 ms/step.
Inference benchmark of resnet152d.gluon_in1k done. 887.06 samples/sec, 288.55 ms/step
Model resnet152d.gluon_in1k created, param count: 60212040
Running train benchmark on resnet152d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 46.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152d.gluon_in1k created, param count: 60212040
Running train benchmark on resnet152d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 196.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152d.gluon_in1k created, param count: 60212040
Running train benchmark on resnet152d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 514.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet152d.gluon_in1k created, param count: 60212040
Running train benchmark on resnet152d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 332.70 samples/sec. 288.551 ms/step.
Train [16/40]. 332.67 samples/sec. 288.571 ms/step.
Train [24/40]. 332.66 samples/sec. 288.581 ms/step.
Train [32/40]. 332.65 samples/sec. 288.589 ms/step.
Train [40/40]. 332.66 samples/sec. 288.582 ms/step.
Train benchmark of resnet152d.gluon_in1k done. 330.48 samples/sec, 288.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152d.ra2_in1k created, param count: 60212040
Running inference benchmark on resnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 506.56 samples/sec. 505.370 ms/step.
Infer [16/40]. 506.55 samples/sec. 505.381 ms/step.
Infer [24/40]. 506.47 samples/sec. 505.456 ms/step.
Infer [32/40]. 506.44 samples/sec. 505.491 ms/step.
Infer [40/40]. 506.41 samples/sec. 505.517 ms/step.
Inference benchmark of resnet152d.ra2_in1k done. 506.36 samples/sec, 505.52 ms/step
Model resnet152d.ra2_in1k created, param count: 60212040
Running train benchmark on resnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 22.02 GiB is allocated by PyTorch, and 32.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152d.ra2_in1k created, param count: 60212040
Running train benchmark on resnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 326.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 400.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152d.ra2_in1k created, param count: 60212040
Running train benchmark on resnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 473.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet152d.ra2_in1k created, param count: 60212040
Running train benchmark on resnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 341.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnet152d.ra2_in1k created, param count: 60212040
Running train benchmark on resnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 999.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnet152d.ra2_in1k created, param count: 60212040
Running train benchmark on resnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
Train [8/40]. 175.00 samples/sec. 274.279 ms/step.
Train [16/40]. 175.01 samples/sec. 274.267 ms/step.
Train [24/40]. 175.01 samples/sec. 274.265 ms/step.
Train [32/40]. 175.01 samples/sec. 274.265 ms/step.
Train [40/40]. 175.01 samples/sec. 274.269 ms/step.
Train benchmark of resnet152d.ra2_in1k done. 173.85 samples/sec, 274.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet152s.gluon_in1k created, param count: 60316584
Running inference benchmark on resnet152s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 834.23 samples/sec. 306.871 ms/step.
Infer [16/40]. 833.49 samples/sec. 307.141 ms/step.
Infer [24/40]. 833.31 samples/sec. 307.209 ms/step.
Infer [32/40]. 833.15 samples/sec. 307.269 ms/step.
Infer [40/40]. 833.08 samples/sec. 307.295 ms/step.
Inference benchmark of resnet152s.gluon_in1k done. 832.96 samples/sec, 307.30 ms/step
Model resnet152s.gluon_in1k created, param count: 60316584
Running train benchmark on resnet152s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 298.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 74.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet152s.gluon_in1k created, param count: 60316584
Running train benchmark on resnet152s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 158.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet152s.gluon_in1k created, param count: 60316584
Running train benchmark on resnet152s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 443.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet152s.gluon_in1k created, param count: 60316584
Running train benchmark on resnet152s.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 307.88 samples/sec. 311.814 ms/step.
Train [16/40]. 307.88 samples/sec. 311.807 ms/step.
Train [24/40]. 307.88 samples/sec. 311.806 ms/step.
Train [32/40]. 307.88 samples/sec. 311.812 ms/step.
Train [40/40]. 307.87 samples/sec. 311.821 ms/step.
Train benchmark of resnet152s.gluon_in1k done. 305.99 samples/sec, 311.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnet200d.ra2_in1k created, param count: 64693064
Running inference benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 364.46 samples/sec. 702.403 ms/step.
Infer [16/40]. 364.47 samples/sec. 702.386 ms/step.
Infer [24/40]. 364.47 samples/sec. 702.385 ms/step.
Infer [32/40]. 364.48 samples/sec. 702.380 ms/step.
Infer [40/40]. 364.47 samples/sec. 702.383 ms/step.
Inference benchmark of resnet200d.ra2_in1k done. 364.45 samples/sec, 702.38 ms/step
Model resnet200d.ra2_in1k created, param count: 64693064
Running train benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 22.56 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 33.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnet200d.ra2_in1k created, param count: 64693064
Running train benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 302.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 407.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnet200d.ra2_in1k created, param count: 64693064
Running train benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 100.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 483.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnet200d.ra2_in1k created, param count: 64693064
Running train benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 21.63 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnet200d.ra2_in1k created, param count: 64693064
Running train benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 388.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnet200d.ra2_in1k created, param count: 64693064
Running train benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 327.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnet200d.ra2_in1k created, param count: 64693064
Running train benchmark on resnet200d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
Train [8/40]. 129.07 samples/sec. 247.930 ms/step.
Train [16/40]. 129.07 samples/sec. 247.934 ms/step.
Train [24/40]. 129.07 samples/sec. 247.933 ms/step.
Train [32/40]. 129.07 samples/sec. 247.936 ms/step.
Train [40/40]. 129.07 samples/sec. 247.935 ms/step.
Train benchmark of resnet200d.ra2_in1k done. 127.95 samples/sec, 247.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetaa50.a1h_in1k created, param count: 25557032
Running inference benchmark on resnetaa50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1294.38 samples/sec. 197.778 ms/step.
Infer [16/40]. 1294.41 samples/sec. 197.774 ms/step.
Infer [24/40]. 1294.42 samples/sec. 197.772 ms/step.
Infer [32/40]. 1294.40 samples/sec. 197.774 ms/step.
Infer [40/40]. 1294.40 samples/sec. 197.775 ms/step.
Inference benchmark of resnetaa50.a1h_in1k done. 1294.14 samples/sec, 197.78 ms/step
Model resnetaa50.a1h_in1k created, param count: 25557032
Running train benchmark on resnetaa50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 63.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetaa50.a1h_in1k created, param count: 25557032
Running train benchmark on resnetaa50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 66.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetaa50.a1h_in1k created, param count: 25557032
Running train benchmark on resnetaa50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 406.49 samples/sec. 314.894 ms/step.
Train [16/40]. 406.45 samples/sec. 314.921 ms/step.
Train [24/40]. 406.42 samples/sec. 314.942 ms/step.
Train [32/40]. 406.42 samples/sec. 314.947 ms/step.
Train [40/40]. 406.42 samples/sec. 314.945 ms/step.
Train benchmark of resnetaa50.a1h_in1k done. 405.11 samples/sec, 314.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetaa50d.d_in12k created, param count: 47748493
Running inference benchmark on resnetaa50d.d_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1222.84 samples/sec. 209.349 ms/step.
Infer [16/40]. 1222.66 samples/sec. 209.379 ms/step.
Infer [24/40]. 1222.58 samples/sec. 209.393 ms/step.
Infer [32/40]. 1222.53 samples/sec. 209.402 ms/step.
Infer [40/40]. 1222.49 samples/sec. 209.409 ms/step.
Inference benchmark of resnetaa50d.d_in12k done. 1222.25 samples/sec, 209.41 ms/step
Model resnetaa50d.d_in12k created, param count: 47748493
Running train benchmark on resnetaa50d.d_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 344.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 70.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetaa50d.d_in12k created, param count: 47748493
Running train benchmark on resnetaa50d.d_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 110.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetaa50d.d_in12k created, param count: 47748493
Running train benchmark on resnetaa50d.d_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 377.55 samples/sec. 339.024 ms/step.
Train [16/40]. 377.54 samples/sec. 339.038 ms/step.
Train [24/40]. 377.49 samples/sec. 339.082 ms/step.
Train [32/40]. 377.47 samples/sec. 339.100 ms/step.
Train [40/40]. 377.47 samples/sec. 339.101 ms/step.
Train benchmark of resnetaa50d.d_in12k done. 376.29 samples/sec, 339.10 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetaa50d.sw_in12k created, param count: 47748493
Running inference benchmark on resnetaa50d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1222.44 samples/sec. 209.416 ms/step.
Infer [16/40]. 1222.39 samples/sec. 209.425 ms/step.
Infer [24/40]. 1222.37 samples/sec. 209.428 ms/step.
Infer [32/40]. 1222.40 samples/sec. 209.424 ms/step.
Infer [40/40]. 1222.42 samples/sec. 209.421 ms/step.
Inference benchmark of resnetaa50d.sw_in12k done. 1222.19 samples/sec, 209.42 ms/step
Model resnetaa50d.sw_in12k created, param count: 47748493
Running train benchmark on resnetaa50d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 344.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 70.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetaa50d.sw_in12k created, param count: 47748493
Running train benchmark on resnetaa50d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 170.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 110.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetaa50d.sw_in12k created, param count: 47748493
Running train benchmark on resnetaa50d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 377.46 samples/sec. 339.112 ms/step.
Train [16/40]. 377.46 samples/sec. 339.106 ms/step.
Train [24/40]. 377.45 samples/sec. 339.121 ms/step.
Train [32/40]. 377.44 samples/sec. 339.124 ms/step.
Train [40/40]. 377.44 samples/sec. 339.130 ms/step.
Train benchmark of resnetaa50d.sw_in12k done. 376.27 samples/sec, 339.13 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetaa50d.sw_in12k_ft_in1k created, param count: 25576264
Running inference benchmark on resnetaa50d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1223.83 samples/sec. 209.180 ms/step.
Infer [16/40]. 1223.82 samples/sec. 209.180 ms/step.
Infer [24/40]. 1223.77 samples/sec. 209.189 ms/step.
Infer [32/40]. 1223.64 samples/sec. 209.212 ms/step.
Infer [40/40]. 1223.57 samples/sec. 209.223 ms/step.
Inference benchmark of resnetaa50d.sw_in12k_ft_in1k done. 1223.34 samples/sec, 209.22 ms/step
Model resnetaa50d.sw_in12k_ft_in1k created, param count: 25576264
Running train benchmark on resnetaa50d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 438.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 61.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetaa50d.sw_in12k_ft_in1k created, param count: 25576264
Running train benchmark on resnetaa50d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 120.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetaa50d.sw_in12k_ft_in1k created, param count: 25576264
Running train benchmark on resnetaa50d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 379.02 samples/sec. 337.710 ms/step.
Train [16/40]. 379.10 samples/sec. 337.638 ms/step.
Train [24/40]. 379.05 samples/sec. 337.687 ms/step.
Train [32/40]. 379.06 samples/sec. 337.676 ms/step.
Train [40/40]. 379.04 samples/sec. 337.692 ms/step.
Train benchmark of resnetaa50d.sw_in12k_ft_in1k done. 377.88 samples/sec, 337.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetaa101d.sw_in12k created, param count: 66740621
Running inference benchmark on resnetaa101d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 791.25 samples/sec. 323.540 ms/step.
Infer [16/40]. 791.21 samples/sec. 323.554 ms/step.
Infer [24/40]. 791.21 samples/sec. 323.555 ms/step.
Infer [32/40]. 791.21 samples/sec. 323.554 ms/step.
Infer [40/40]. 791.21 samples/sec. 323.555 ms/step.
Inference benchmark of resnetaa101d.sw_in12k done. 791.10 samples/sec, 323.56 ms/step
Model resnetaa101d.sw_in12k created, param count: 66740621
Running train benchmark on resnetaa101d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 310.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 31.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetaa101d.sw_in12k created, param count: 66740621
Running train benchmark on resnetaa101d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 149.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetaa101d.sw_in12k created, param count: 66740621
Running train benchmark on resnetaa101d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 226.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetaa101d.sw_in12k created, param count: 66740621
Running train benchmark on resnetaa101d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 258.27 samples/sec. 371.706 ms/step.
Train [16/40]. 258.26 samples/sec. 371.723 ms/step.
Train [24/40]. 258.24 samples/sec. 371.744 ms/step.
Train [32/40]. 258.23 samples/sec. 371.763 ms/step.
Train [40/40]. 258.22 samples/sec. 371.775 ms/step.
Train benchmark of resnetaa101d.sw_in12k done. 257.15 samples/sec, 371.77 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetaa101d.sw_in12k_ft_in1k created, param count: 44568392
Running inference benchmark on resnetaa101d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 791.57 samples/sec. 323.409 ms/step.
Infer [16/40]. 791.55 samples/sec. 323.417 ms/step.
Infer [24/40]. 791.52 samples/sec. 323.427 ms/step.
Infer [32/40]. 791.53 samples/sec. 323.426 ms/step.
Infer [40/40]. 791.53 samples/sec. 323.426 ms/step.
Inference benchmark of resnetaa101d.sw_in12k_ft_in1k done. 791.41 samples/sec, 323.43 ms/step
Model resnetaa101d.sw_in12k_ft_in1k created, param count: 44568392
Running train benchmark on resnetaa101d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 404.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 22.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetaa101d.sw_in12k_ft_in1k created, param count: 44568392
Running train benchmark on resnetaa101d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 159.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetaa101d.sw_in12k_ft_in1k created, param count: 44568392
Running train benchmark on resnetaa101d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 206.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetaa101d.sw_in12k_ft_in1k created, param count: 44568392
Running train benchmark on resnetaa101d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 259.30 samples/sec. 370.229 ms/step.
Train [16/40]. 259.29 samples/sec. 370.236 ms/step.
Train [24/40]. 259.30 samples/sec. 370.232 ms/step.
Train [32/40]. 259.26 samples/sec. 370.281 ms/step.
Train [40/40]. 259.25 samples/sec. 370.302 ms/step.
Train benchmark of resnetaa101d.sw_in12k_ft_in1k done. 258.17 samples/sec, 370.30 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetblur50.bt_in1k created, param count: 25557032
Running inference benchmark on resnetblur50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1221.79 samples/sec. 209.529 ms/step.
Infer [16/40]. 1221.66 samples/sec. 209.550 ms/step.
Infer [24/40]. 1221.55 samples/sec. 209.570 ms/step.
Infer [32/40]. 1221.48 samples/sec. 209.583 ms/step.
Infer [40/40]. 1221.45 samples/sec. 209.587 ms/step.
Inference benchmark of resnetblur50.bt_in1k done. 1221.22 samples/sec, 209.59 ms/step
Model resnetblur50.bt_in1k created, param count: 25557032
Running train benchmark on resnetblur50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 242.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 58.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetblur50.bt_in1k created, param count: 25557032
Running train benchmark on resnetblur50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 170.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetblur50.bt_in1k created, param count: 25557032
Running train benchmark on resnetblur50.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 386.79 samples/sec. 330.933 ms/step.
Train [16/40]. 386.79 samples/sec. 330.928 ms/step.
Train [24/40]. 386.81 samples/sec. 330.915 ms/step.
Train [32/40]. 386.81 samples/sec. 330.915 ms/step.
Train [40/40]. 386.82 samples/sec. 330.901 ms/step.
Train benchmark of resnetblur50.bt_in1k done. 385.61 samples/sec, 330.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetrs50.tf_in1k created, param count: 35691912
Running inference benchmark on resnetrs50.tf_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1813.23 samples/sec. 141.184 ms/step.
Infer [16/40]. 1813.67 samples/sec. 141.150 ms/step.
Infer [24/40]. 1813.71 samples/sec. 141.147 ms/step.
Infer [32/40]. 1813.64 samples/sec. 141.153 ms/step.
Infer [40/40]. 1813.65 samples/sec. 141.152 ms/step.
Inference benchmark of resnetrs50.tf_in1k done. 1813.24 samples/sec, 141.15 ms/step
Model resnetrs50.tf_in1k created, param count: 35691912
Running train benchmark on resnetrs50.tf_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 92.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetrs50.tf_in1k created, param count: 35691912
Running train benchmark on resnetrs50.tf_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 547.80 samples/sec. 350.492 ms/step.
Train [16/40]. 547.80 samples/sec. 350.495 ms/step.
Train [24/40]. 547.78 samples/sec. 350.503 ms/step.
Train [32/40]. 547.78 samples/sec. 350.508 ms/step.
Train [40/40]. 547.77 samples/sec. 350.511 ms/step.
Train benchmark of resnetrs50.tf_in1k done. 545.75 samples/sec, 350.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetrs101.tf_in1k created, param count: 63618696
Running inference benchmark on resnetrs101.tf_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 711.83 samples/sec. 359.634 ms/step.
Infer [16/40]. 711.84 samples/sec. 359.632 ms/step.
Infer [24/40]. 711.83 samples/sec. 359.636 ms/step.
Infer [32/40]. 711.82 samples/sec. 359.640 ms/step.
Infer [40/40]. 711.81 samples/sec. 359.644 ms/step.
Inference benchmark of resnetrs101.tf_in1k done. 711.72 samples/sec, 359.64 ms/step
Model resnetrs101.tf_in1k created, param count: 63618696
Running train benchmark on resnetrs101.tf_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 496.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 17.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetrs101.tf_in1k created, param count: 63618696
Running train benchmark on resnetrs101.tf_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 249.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetrs101.tf_in1k created, param count: 63618696
Running train benchmark on resnetrs101.tf_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 242.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetrs101.tf_in1k created, param count: 63618696
Running train benchmark on resnetrs101.tf_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 276.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetrs101.tf_in1k created, param count: 63618696
Running train benchmark on resnetrs101.tf_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 224.03 samples/sec. 285.671 ms/step.
Train [16/40]. 224.04 samples/sec. 285.659 ms/step.
Train [24/40]. 224.03 samples/sec. 285.678 ms/step.
Train [32/40]. 224.03 samples/sec. 285.672 ms/step.
Train [40/40]. 224.03 samples/sec. 285.677 ms/step.
Train benchmark of resnetrs101.tf_in1k done. 222.57 samples/sec, 285.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetrs152.tf_in1k created, param count: 86621576
Running inference benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 428.59 samples/sec. 597.304 ms/step.
Infer [16/40]. 428.59 samples/sec. 597.302 ms/step.
Infer [24/40]. 428.59 samples/sec. 597.306 ms/step.
Infer [32/40]. 428.59 samples/sec. 597.313 ms/step.
Infer [40/40]. 428.58 samples/sec. 597.319 ms/step.
Inference benchmark of resnetrs152.tf_in1k done. 428.55 samples/sec, 597.32 ms/step
Model resnetrs152.tf_in1k created, param count: 86621576
Running train benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 224.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 26.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetrs152.tf_in1k created, param count: 86621576
Running train benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 360.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 264.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetrs152.tf_in1k created, param count: 86621576
Running train benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 380.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 416.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetrs152.tf_in1k created, param count: 86621576
Running train benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 626.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetrs152.tf_in1k created, param count: 86621576
Running train benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 702.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetrs152.tf_in1k created, param count: 86621576
Running train benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetrs152.tf_in1k created, param count: 86621576
Running train benchmark on resnetrs152.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
Train [8/40]. 139.76 samples/sec. 228.969 ms/step.
Train [16/40]. 139.69 samples/sec. 229.074 ms/step.
Train [24/40]. 139.68 samples/sec. 229.100 ms/step.
Train [32/40]. 139.67 samples/sec. 229.110 ms/step.
Train [40/40]. 139.67 samples/sec. 229.113 ms/step.
Train benchmark of resnetrs152.tf_in1k done. 138.26 samples/sec, 229.11 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetrs200.tf_in1k created, param count: 93209992
Running inference benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 305.39 samples/sec. 838.260 ms/step.
Infer [16/40]. 305.36 samples/sec. 838.360 ms/step.
Infer [24/40]. 305.34 samples/sec. 838.406 ms/step.
Infer [32/40]. 305.33 samples/sec. 838.427 ms/step.
Infer [40/40]. 305.33 samples/sec. 838.440 ms/step.
Inference benchmark of resnetrs200.tf_in1k done. 305.31 samples/sec, 838.44 ms/step
Model resnetrs200.tf_in1k created, param count: 93209992
Running train benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 202.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 23.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetrs200.tf_in1k created, param count: 93209992
Running train benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 312.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 287.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetrs200.tf_in1k created, param count: 93209992
Running train benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 334.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 437.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetrs200.tf_in1k created, param count: 93209992
Running train benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 929.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetrs200.tf_in1k created, param count: 93209992
Running train benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.12 GiB is allocated by PyTorch, and 877.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetrs200.tf_in1k created, param count: 93209992
Running train benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 720.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetrs200.tf_in1k created, param count: 93209992
Running train benchmark on resnetrs200.tf_in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
Train [8/40]. 67.26 samples/sec. 475.750 ms/step.
Train [16/40]. 80.18 samples/sec. 399.101 ms/step.
Train [24/40]. 85.66 samples/sec. 373.550 ms/step.
Train [32/40]. 88.70 samples/sec. 360.780 ms/step.
Train [40/40]. 90.62 samples/sec. 353.124 ms/step.
Train benchmark of resnetrs200.tf_in1k done. 89.83 samples/sec, 353.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetrs270.tf_in1k created, param count: 129861448
Running inference benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 256.
Infer [8/40]. 194.45 samples/sec. 1316.526 ms/step.
Infer [16/40]. 194.42 samples/sec. 1316.737 ms/step.
Infer [24/40]. 194.41 samples/sec. 1316.837 ms/step.
Infer [32/40]. 194.40 samples/sec. 1316.901 ms/step.
Infer [40/40]. 194.39 samples/sec. 1316.937 ms/step.
Inference benchmark of resnetrs270.tf_in1k done. 194.38 samples/sec, 1316.94 ms/step
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 534.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 23.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 352.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 484.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 292.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 687.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 418.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 355.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 21.58 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 728.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 756.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetrs270.tf_in1k created, param count: 129861448
Running train benchmark on resnetrs270.tf_in1k for 40 steps w/ input size (3, 352, 352) and batch size 16.
Train [8/40]. 55.84 samples/sec. 286.538 ms/step.
Train [16/40]. 55.85 samples/sec. 286.484 ms/step.
Train [24/40]. 55.85 samples/sec. 286.494 ms/step.
Train [32/40]. 55.85 samples/sec. 286.499 ms/step.
Train [40/40]. 55.85 samples/sec. 286.501 ms/step.
Train benchmark of resnetrs270.tf_in1k done. 55.14 samples/sec, 286.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetrs350.tf_in1k created, param count: 163956168
Running inference benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 130.36 samples/sec. 1963.802 ms/step.
Infer [16/40]. 130.34 samples/sec. 1964.038 ms/step.
Infer [24/40]. 130.32 samples/sec. 1964.356 ms/step.
Infer [32/40]. 130.31 samples/sec. 1964.515 ms/step.
Infer [40/40]. 130.31 samples/sec. 1964.614 ms/step.
Inference benchmark of resnetrs350.tf_in1k done. 130.30 samples/sec, 1964.61 ms/step
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 714.06 MiB is free. Including non-PyTorch memory, this process has 22.94 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 20.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 758.06 MiB is free. Including non-PyTorch memory, this process has 22.90 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 369.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 324.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 411.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 715.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 156.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 568.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.06 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 691.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 402.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model resnetrs350.tf_in1k created, param count: 163956168
Running train benchmark on resnetrs350.tf_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
Train [8/40]. 36.36 samples/sec. 329.989 ms/step.
Train [16/40]. 36.36 samples/sec. 330.024 ms/step.
Train [24/40]. 36.37 samples/sec. 329.960 ms/step.
Train [32/40]. 36.37 samples/sec. 329.986 ms/step.
Train [40/40]. 36.36 samples/sec. 330.071 ms/step.
Train benchmark of resnetrs350.tf_in1k done. 35.87 samples/sec, 330.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetrs420.tf_in1k created, param count: 191891656
Running inference benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
Infer [8/40]. 94.03 samples/sec. 2722.498 ms/step.
Infer [16/40]. 94.03 samples/sec. 2722.647 ms/step.
Infer [24/40]. 94.02 samples/sec. 2722.725 ms/step.
Infer [32/40]. 94.02 samples/sec. 2722.761 ms/step.
Infer [40/40]. 94.02 samples/sec. 2722.797 ms/step.
Inference benchmark of resnetrs420.tf_in1k done. 94.02 samples/sec, 2722.80 ms/step
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.64 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 21.56 GiB memory in use. Of the allocated memory 21.04 GiB is allocated by PyTorch, and 25.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 23.65 GiB of which 830.06 MiB is free. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 438.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 377.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 492.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 454.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 234.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 604.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 368.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 160.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 344.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 433.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 543.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 341.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model resnetrs420.tf_in1k created, param count: 191891656
Running train benchmark on resnetrs420.tf_in1k for 40 steps w/ input size (3, 416, 416) and batch size 8.
Train [8/40]. 21.80 samples/sec. 367.008 ms/step.
Train [16/40]. 21.79 samples/sec. 367.139 ms/step.
Train [24/40]. 21.79 samples/sec. 367.123 ms/step.
Train [32/40]. 21.79 samples/sec. 367.075 ms/step.
Train [40/40]. 21.79 samples/sec. 367.072 ms/step.
Train benchmark of resnetrs420.tf_in1k done. 21.48 samples/sec, 367.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_50.a1h_in1k created, param count: 25549352
Running inference benchmark on resnetv2_50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1479.59 samples/sec. 173.021 ms/step.
Infer [16/40]. 1479.41 samples/sec. 173.042 ms/step.
Infer [24/40]. 1479.33 samples/sec. 173.051 ms/step.
Infer [32/40]. 1479.27 samples/sec. 173.058 ms/step.
Infer [40/40]. 1479.25 samples/sec. 173.060 ms/step.
Inference benchmark of resnetv2_50.a1h_in1k done. 1478.94 samples/sec, 173.06 ms/step
Model resnetv2_50.a1h_in1k created, param count: 25549352
Running train benchmark on resnetv2_50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 274.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 63.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_50.a1h_in1k created, param count: 25549352
Running train benchmark on resnetv2_50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 193.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_50.a1h_in1k created, param count: 25549352
Running train benchmark on resnetv2_50.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 471.42 samples/sec. 271.520 ms/step.
Train [16/40]. 471.36 samples/sec. 271.554 ms/step.
Train [24/40]. 471.35 samples/sec. 271.560 ms/step.
Train [32/40]. 471.32 samples/sec. 271.575 ms/step.
Train [40/40]. 471.32 samples/sec. 271.577 ms/step.
Train benchmark of resnetv2_50.a1h_in1k done. 469.64 samples/sec, 271.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_50d_evos.ah_in1k created, param count: 25591368
Running inference benchmark on resnetv2_50d_evos.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 645.20 samples/sec. 396.776 ms/step.
Infer [16/40]. 645.21 samples/sec. 396.771 ms/step.
Infer [24/40]. 645.21 samples/sec. 396.769 ms/step.
Infer [32/40]. 645.20 samples/sec. 396.773 ms/step.
Infer [40/40]. 645.20 samples/sec. 396.774 ms/step.
Inference benchmark of resnetv2_50d_evos.ah_in1k done. 645.12 samples/sec, 396.77 ms/step
Model resnetv2_50d_evos.ah_in1k created, param count: 25591368
Running train benchmark on resnetv2_50d_evos.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 22.42 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 55.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_50d_evos.ah_in1k created, param count: 25591368
Running train benchmark on resnetv2_50d_evos.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 862.06 MiB is free. Including non-PyTorch memory, this process has 22.80 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 161.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_50d_evos.ah_in1k created, param count: 25591368
Running train benchmark on resnetv2_50d_evos.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 556.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 228.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_50d_evos.ah_in1k created, param count: 25591368
Running train benchmark on resnetv2_50d_evos.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 101.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_50d_evos.ah_in1k created, param count: 25591368
Running train benchmark on resnetv2_50d_evos.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 216.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_50d_evos.ah_in1k created, param count: 25591368
Running train benchmark on resnetv2_50d_evos.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 180.16 samples/sec. 266.437 ms/step.
Train [16/40]. 180.14 samples/sec. 266.460 ms/step.
Train [24/40]. 180.14 samples/sec. 266.463 ms/step.
Train [32/40]. 180.13 samples/sec. 266.468 ms/step.
Train [40/40]. 180.13 samples/sec. 266.474 ms/step.
Train benchmark of resnetv2_50d_evos.ah_in1k done. 179.14 samples/sec, 266.47 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_50d_gn.ah_in1k created, param count: 25568584
Running inference benchmark on resnetv2_50d_gn.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1264.23 samples/sec. 202.494 ms/step.
Infer [16/40]. 1264.23 samples/sec. 202.495 ms/step.
Infer [24/40]. 1264.24 samples/sec. 202.494 ms/step.
Infer [32/40]. 1264.25 samples/sec. 202.491 ms/step.
Infer [40/40]. 1264.25 samples/sec. 202.492 ms/step.
Inference benchmark of resnetv2_50d_gn.ah_in1k done. 1263.98 samples/sec, 202.49 ms/step
Model resnetv2_50d_gn.ah_in1k created, param count: 25568584
Running train benchmark on resnetv2_50d_gn.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 596.06 MiB is free. Including non-PyTorch memory, this process has 23.06 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 64.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_50d_gn.ah_in1k created, param count: 25568584
Running train benchmark on resnetv2_50d_gn.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 230.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 64.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_50d_gn.ah_in1k created, param count: 25568584
Running train benchmark on resnetv2_50d_gn.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 441.87 samples/sec. 289.675 ms/step.
Train [16/40]. 441.90 samples/sec. 289.659 ms/step.
Train [24/40]. 441.91 samples/sec. 289.651 ms/step.
Train [32/40]. 441.91 samples/sec. 289.654 ms/step.
Train [40/40]. 441.92 samples/sec. 289.647 ms/step.
Train benchmark of resnetv2_50d_gn.ah_in1k done. 440.34 samples/sec, 289.65 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_50x1_bit.goog_distilled_in1k created, param count: 25549352
Running inference benchmark on resnetv2_50x1_bit.goog_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2075.23 samples/sec. 123.360 ms/step.
Infer [16/40]. 2075.17 samples/sec. 123.364 ms/step.
Infer [24/40]. 2075.14 samples/sec. 123.365 ms/step.
Infer [32/40]. 2075.15 samples/sec. 123.365 ms/step.
Infer [40/40]. 2075.09 samples/sec. 123.368 ms/step.
Inference benchmark of resnetv2_50x1_bit.goog_distilled_in1k done. 2074.57 samples/sec, 123.37 ms/step
Model resnetv2_50x1_bit.goog_distilled_in1k created, param count: 25549352
Running train benchmark on resnetv2_50x1_bit.goog_distilled_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 749.80 samples/sec. 341.425 ms/step.
Train [16/40]. 749.78 samples/sec. 341.433 ms/step.
Train [24/40]. 749.80 samples/sec. 341.426 ms/step.
Train [32/40]. 749.79 samples/sec. 341.428 ms/step.
Train [40/40]. 749.79 samples/sec. 341.429 ms/step.
Train benchmark of resnetv2_50x1_bit.goog_distilled_in1k done. 747.31 samples/sec, 341.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_50x1_bit.goog_in21k_ft_in1k created, param count: 25549352
Running inference benchmark on resnetv2_50x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 560.48 samples/sec. 456.753 ms/step.
Infer [16/40]. 560.47 samples/sec. 456.761 ms/step.
Infer [24/40]. 560.46 samples/sec. 456.770 ms/step.
Infer [32/40]. 560.45 samples/sec. 456.777 ms/step.
Infer [40/40]. 560.44 samples/sec. 456.782 ms/step.
Inference benchmark of resnetv2_50x1_bit.goog_in21k_ft_in1k done. 560.38 samples/sec, 456.78 ms/step
Model resnetv2_50x1_bit.goog_in21k_ft_in1k created, param count: 25549352
Running train benchmark on resnetv2_50x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 932.06 MiB is free. Including non-PyTorch memory, this process has 22.73 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 56.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_50x1_bit.goog_in21k_ft_in1k created, param count: 25549352
Running train benchmark on resnetv2_50x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.64 GiB is free. Including non-PyTorch memory, this process has 22.00 GiB memory in use. Of the allocated memory 21.26 GiB is allocated by PyTorch, and 249.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_50x1_bit.goog_in21k_ft_in1k created, param count: 25549352
Running train benchmark on resnetv2_50x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 712.06 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 204.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_50x1_bit.goog_in21k_ft_in1k created, param count: 25549352
Running train benchmark on resnetv2_50x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 107.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_50x1_bit.goog_in21k_ft_in1k created, param count: 25549352
Running train benchmark on resnetv2_50x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
Train [8/40]. 199.45 samples/sec. 320.875 ms/step.
Train [16/40]. 199.45 samples/sec. 320.875 ms/step.
Train [24/40]. 199.46 samples/sec. 320.872 ms/step.
Train [32/40]. 199.46 samples/sec. 320.873 ms/step.
Train [40/40]. 199.46 samples/sec. 320.874 ms/step.
Train benchmark of resnetv2_50x1_bit.goog_in21k_ft_in1k done. 198.77 samples/sec, 320.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running inference benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 892.06 MiB is free. Including non-PyTorch memory, this process has 22.77 GiB memory in use. Of the allocated memory 19.78 GiB is allocated by PyTorch, and 2.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running inference benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.13 GiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 15.04 GiB is allocated by PyTorch, and 3.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running inference benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.38 GiB is free. Including non-PyTorch memory, this process has 20.26 GiB memory in use. Of the allocated memory 16.05 GiB is allocated by PyTorch, and 3.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running inference benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
Infer [8/40]. 133.67 samples/sec. 718.168 ms/step.
Infer [16/40]. 133.67 samples/sec. 718.201 ms/step.
Infer [24/40]. 133.68 samples/sec. 718.159 ms/step.
Infer [32/40]. 133.67 samples/sec. 718.176 ms/step.
Infer [40/40]. 133.68 samples/sec. 718.120 ms/step.
Inference benchmark of resnetv2_50x3_bit.goog_in21k_ft_in1k done. 133.67 samples/sec, 718.12 ms/step
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.17 GiB is free. Including non-PyTorch memory, this process has 20.47 GiB memory in use. Of the allocated memory 19.94 GiB is allocated by PyTorch, and 33.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 702.06 MiB is free. Including non-PyTorch memory, this process has 22.96 GiB memory in use. Of the allocated memory 22.06 GiB is allocated by PyTorch, and 409.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.29 GiB is free. Including non-PyTorch memory, this process has 20.35 GiB memory in use. Of the allocated memory 19.58 GiB is allocated by PyTorch, and 282.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 23.65 GiB of which 924.06 MiB is free. Including non-PyTorch memory, this process has 22.74 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 466.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the allocated memory 21.70 GiB is allocated by PyTorch, and 391.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 501.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 264.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 474.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 545.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetv2_50x3_bit.goog_in21k_ft_in1k created, param count: 217319080
Running train benchmark on resnetv2_50x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
Train [8/40]. 45.09 samples/sec. 354.849 ms/step.
Train [16/40]. 45.07 samples/sec. 355.007 ms/step.
Train [24/40]. 45.07 samples/sec. 354.980 ms/step.
Train [32/40]. 45.07 samples/sec. 355.003 ms/step.
Train [40/40]. 45.07 samples/sec. 354.984 ms/step.
Train benchmark of resnetv2_50x3_bit.goog_in21k_ft_in1k done. 44.93 samples/sec, 354.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_101.a1h_in1k created, param count: 44541480
Running inference benchmark on resnetv2_101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 891.48 samples/sec. 287.164 ms/step.
Infer [16/40]. 891.47 samples/sec. 287.166 ms/step.
Infer [24/40]. 891.34 samples/sec. 287.207 ms/step.
Infer [32/40]. 891.26 samples/sec. 287.232 ms/step.
Infer [40/40]. 891.22 samples/sec. 287.247 ms/step.
Inference benchmark of resnetv2_101.a1h_in1k done. 891.06 samples/sec, 287.25 ms/step
Model resnetv2_101.a1h_in1k created, param count: 44541480
Running train benchmark on resnetv2_101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 24.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_101.a1h_in1k created, param count: 44541480
Running train benchmark on resnetv2_101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 218.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 121.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_101.a1h_in1k created, param count: 44541480
Running train benchmark on resnetv2_101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 284.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_101.a1h_in1k created, param count: 44541480
Running train benchmark on resnetv2_101.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 301.53 samples/sec. 318.371 ms/step.
Train [16/40]. 301.53 samples/sec. 318.378 ms/step.
Train [24/40]. 301.52 samples/sec. 318.392 ms/step.
Train [32/40]. 301.51 samples/sec. 318.394 ms/step.
Train [40/40]. 301.51 samples/sec. 318.394 ms/step.
Train benchmark of resnetv2_101.a1h_in1k done. 300.16 samples/sec, 318.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_101x1_bit.goog_in21k_ft_in1k created, param count: 44541480
Running inference benchmark on resnetv2_101x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 354.97 samples/sec. 721.189 ms/step.
Infer [16/40]. 354.97 samples/sec. 721.194 ms/step.
Infer [24/40]. 354.94 samples/sec. 721.249 ms/step.
Infer [32/40]. 354.91 samples/sec. 721.311 ms/step.
Infer [40/40]. 354.89 samples/sec. 721.345 ms/step.
Inference benchmark of resnetv2_101x1_bit.goog_in21k_ft_in1k done. 354.86 samples/sec, 721.35 ms/step
Model resnetv2_101x1_bit.goog_in21k_ft_in1k created, param count: 44541480
Running train benchmark on resnetv2_101x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 898.06 MiB is free. Including non-PyTorch memory, this process has 22.76 GiB memory in use. Of the allocated memory 22.25 GiB is allocated by PyTorch, and 17.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_101x1_bit.goog_in21k_ft_in1k created, param count: 44541480
Running train benchmark on resnetv2_101x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.53 GiB is free. Including non-PyTorch memory, this process has 22.11 GiB memory in use. Of the allocated memory 21.33 GiB is allocated by PyTorch, and 291.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_101x1_bit.goog_in21k_ft_in1k created, param count: 44541480
Running train benchmark on resnetv2_101x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.32 GiB is allocated by PyTorch, and 786.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_101x1_bit.goog_in21k_ft_in1k created, param count: 44541480
Running train benchmark on resnetv2_101x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 230.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 232.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_101x1_bit.goog_in21k_ft_in1k created, param count: 44541480
Running train benchmark on resnetv2_101x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 264.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_101x1_bit.goog_in21k_ft_in1k created, param count: 44541480
Running train benchmark on resnetv2_101x1_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
Train [8/40]. 126.47 samples/sec. 379.530 ms/step.
Train [16/40]. 126.47 samples/sec. 379.546 ms/step.
Train [24/40]. 126.47 samples/sec. 379.547 ms/step.
Train [32/40]. 126.47 samples/sec. 379.549 ms/step.
Train [40/40]. 126.47 samples/sec. 379.543 ms/step.
Train benchmark of resnetv2_101x1_bit.goog_in21k_ft_in1k done. 125.94 samples/sec, 379.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running inference benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 20.41 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running inference benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.43 GiB is free. Including non-PyTorch memory, this process has 20.21 GiB memory in use. Of the allocated memory 15.68 GiB is allocated by PyTorch, and 4.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running inference benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.61 GiB is free. Including non-PyTorch memory, this process has 21.04 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running inference benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
Infer [8/40]. 77.91 samples/sec. 1232.165 ms/step.
Infer [16/40]. 77.91 samples/sec. 1232.227 ms/step.
Infer [24/40]. 77.89 samples/sec. 1232.515 ms/step.
Infer [32/40]. 77.88 samples/sec. 1232.683 ms/step.
Infer [40/40]. 77.88 samples/sec. 1232.725 ms/step.
Inference benchmark of resnetv2_101x3_bit.goog_in21k_ft_in1k done. 77.87 samples/sec, 1232.72 ms/step
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 9.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.47 GiB is free. Including non-PyTorch memory, this process has 21.17 GiB memory in use. Of the allocated memory 20.58 GiB is allocated by PyTorch, and 96.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 6.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.88 GiB is free. Including non-PyTorch memory, this process has 16.76 GiB memory in use. Of the allocated memory 15.80 GiB is allocated by PyTorch, and 472.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 4.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 21.04 GiB memory in use. Of the allocated memory 20.21 GiB is allocated by PyTorch, and 335.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 569.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 392.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 438.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 270.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 596.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 404.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 408.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 278.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model resnetv2_101x3_bit.goog_in21k_ft_in1k created, param count: 387934888
Running train benchmark on resnetv2_101x3_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 12.
Train [8/40]. 25.91 samples/sec. 463.089 ms/step.
Train [16/40]. 25.91 samples/sec. 463.102 ms/step.
Train [24/40]. 25.91 samples/sec. 463.115 ms/step.
Train [32/40]. 25.91 samples/sec. 463.124 ms/step.
Train [40/40]. 25.91 samples/sec. 463.180 ms/step.
Train benchmark of resnetv2_101x3_bit.goog_in21k_ft_in1k done. 25.81 samples/sec, 463.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running inference benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.08 GiB is free. Including non-PyTorch memory, this process has 20.56 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running inference benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.90 GiB is free. Including non-PyTorch memory, this process has 20.74 GiB memory in use. Of the allocated memory 16.26 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running inference benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
Infer [8/40]. 97.63 samples/sec. 1311.084 ms/step.
Infer [16/40]. 97.63 samples/sec. 1311.115 ms/step.
Infer [24/40]. 97.62 samples/sec. 1311.179 ms/step.
Infer [32/40]. 97.61 samples/sec. 1311.346 ms/step.
Infer [40/40]. 97.60 samples/sec. 1311.450 ms/step.
Inference benchmark of resnetv2_152x2_bit.goog_in21k_ft_in1k done. 97.60 samples/sec, 1311.45 ms/step
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 107.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.81 GiB is free. Including non-PyTorch memory, this process has 20.83 GiB memory in use. Of the allocated memory 19.79 GiB is allocated by PyTorch, and 553.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 417.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 744.06 MiB is free. Including non-PyTorch memory, this process has 22.91 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 596.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 714.06 MiB is free. Including non-PyTorch memory, this process has 22.94 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 517.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 514.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 228.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 250.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model resnetv2_152x2_bit.goog_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 448, 448) and batch size 12.
Train [8/40]. 34.55 samples/sec. 347.347 ms/step.
Train [16/40]. 34.55 samples/sec. 347.327 ms/step.
Train [24/40]. 34.55 samples/sec. 347.336 ms/step.
Train [32/40]. 34.55 samples/sec. 347.341 ms/step.
Train [40/40]. 34.55 samples/sec. 347.341 ms/step.
Train benchmark of resnetv2_152x2_bit.goog_in21k_ft_in1k done. 34.34 samples/sec, 347.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k created, param count: 236335208
Running inference benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 384.78 samples/sec. 665.322 ms/step.
Infer [16/40]. 384.78 samples/sec. 665.315 ms/step.
Infer [24/40]. 384.78 samples/sec. 665.316 ms/step.
Infer [32/40]. 384.77 samples/sec. 665.338 ms/step.
Infer [40/40]. 384.77 samples/sec. 665.339 ms/step.
Inference benchmark of resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k done. 384.73 samples/sec, 665.34 ms/step
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 268.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 732.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 359.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 420.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 759.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 129.64 samples/sec. 370.248 ms/step.
Train [16/40]. 129.64 samples/sec. 370.262 ms/step.
Train [24/40]. 129.63 samples/sec. 370.291 ms/step.
Train [32/40]. 129.62 samples/sec. 370.319 ms/step.
Train [40/40]. 129.62 samples/sec. 370.315 ms/step.
Train benchmark of resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k done. 128.92 samples/sec, 370.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running inference benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.72 GiB is free. Including non-PyTorch memory, this process has 19.92 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running inference benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 134.04 samples/sec. 1432.421 ms/step.
Infer [16/40]. 134.05 samples/sec. 1432.308 ms/step.
Infer [24/40]. 134.04 samples/sec. 1432.362 ms/step.
Infer [32/40]. 134.03 samples/sec. 1432.545 ms/step.
Infer [40/40]. 134.01 samples/sec. 1432.727 ms/step.
Inference benchmark of resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 done. 134.01 samples/sec, 1432.73 ms/step
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.62 GiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.41 GiB is allocated by PyTorch, and 109.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 22.54 GiB memory in use. Of the allocated memory 21.54 GiB is allocated by PyTorch, and 512.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.36 GiB is free. Including non-PyTorch memory, this process has 22.29 GiB memory in use. Of the allocated memory 21.42 GiB is allocated by PyTorch, and 381.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 556.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 100.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 333.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 164.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 500.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 557.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 76.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 created, param count: 236335208
Running train benchmark on resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 45.36 samples/sec. 352.758 ms/step.
Train [16/40]. 45.36 samples/sec. 352.720 ms/step.
Train [24/40]. 45.37 samples/sec. 352.690 ms/step.
Train [32/40]. 45.37 samples/sec. 352.682 ms/step.
Train [40/40]. 45.37 samples/sec. 352.686 ms/step.
Train benchmark of resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384 done. 45.11 samples/sec, 352.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running inference benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 14.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.90 GiB is free. Including non-PyTorch memory, this process has 18.74 GiB memory in use. Of the allocated memory 18.23 GiB is allocated by PyTorch, and 15.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running inference benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.24 GiB is free. Including non-PyTorch memory, this process has 15.40 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 366.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running inference benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 7.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process has 20.55 GiB memory in use. Of the allocated memory 17.90 GiB is allocated by PyTorch, and 2.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running inference benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 5.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.06 GiB is free. Including non-PyTorch memory, this process has 20.58 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running inference benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 64.
Infer [8/40]. 30.11 samples/sec. 2125.641 ms/step.
Infer [16/40]. 30.09 samples/sec. 2127.063 ms/step.
Infer [24/40]. 30.08 samples/sec. 2127.633 ms/step.
Infer [32/40]. 30.08 samples/sec. 2127.922 ms/step.
Infer [40/40]. 30.07 samples/sec. 2128.106 ms/step.
Inference benchmark of resnetv2_152x4_bit.goog_in21k_ft_in1k done. 30.07 samples/sec, 2128.11 ms/step
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 14.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.90 GiB is free. Including non-PyTorch memory, this process has 18.74 GiB memory in use. Of the allocated memory 18.23 GiB is allocated by PyTorch, and 15.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.24 GiB is free. Including non-PyTorch memory, this process has 15.40 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 366.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 7.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.84 GiB is free. Including non-PyTorch memory, this process has 18.80 GiB memory in use. Of the allocated memory 18.02 GiB is allocated by PyTorch, and 287.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 438.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 421.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.52 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.45 GiB is free. Including non-PyTorch memory, this process has 22.19 GiB memory in use. Of the allocated memory 21.32 GiB is allocated by PyTorch, and 389.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 2.64 GiB. GPU 0 has a total capacty of 23.65 GiB of which 436.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.15 GiB is allocated by PyTorch, and 585.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.21 GiB is allocated by PyTorch, and 430.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 386.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 335.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 450.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 244.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 192.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 402.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 394.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 21.88 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model resnetv2_152x4_bit.goog_in21k_ft_in1k created, param count: 936533224
Running train benchmark on resnetv2_152x4_bit.goog_in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 3.
Train [8/40]. 8.03 samples/sec. 373.611 ms/step.
Train [16/40]. 8.03 samples/sec. 373.670 ms/step.
Train [24/40]. 8.03 samples/sec. 373.691 ms/step.
Train [32/40]. 8.03 samples/sec. 373.689 ms/step.
Train [40/40]. 8.03 samples/sec. 373.698 ms/step.
Train benchmark of resnetv2_152x4_bit.goog_in21k_ft_in1k done. 7.98 samples/sec, 373.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext26ts.ra2_in1k created, param count: 10297952
Running inference benchmark on resnext26ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2247.10 samples/sec. 113.925 ms/step.
Infer [16/40]. 2247.22 samples/sec. 113.918 ms/step.
Infer [24/40]. 2247.08 samples/sec. 113.925 ms/step.
Infer [32/40]. 2247.03 samples/sec. 113.928 ms/step.
Infer [40/40]. 2246.92 samples/sec. 113.934 ms/step.
Inference benchmark of resnext26ts.ra2_in1k done. 2246.33 samples/sec, 113.93 ms/step
Model resnext26ts.ra2_in1k created, param count: 10297952
Running train benchmark on resnext26ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 102.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext26ts.ra2_in1k created, param count: 10297952
Running train benchmark on resnext26ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 57.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext26ts.ra2_in1k created, param count: 10297952
Running train benchmark on resnext26ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 612.23 samples/sec. 209.071 ms/step.
Train [16/40]. 612.28 samples/sec. 209.053 ms/step.
Train [24/40]. 612.17 samples/sec. 209.094 ms/step.
Train [32/40]. 612.20 samples/sec. 209.082 ms/step.
Train [40/40]. 612.20 samples/sec. 209.083 ms/step.
Train benchmark of resnext26ts.ra2_in1k done. 610.31 samples/sec, 209.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.a1_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1156.20 samples/sec. 221.416 ms/step.
Infer [16/40]. 1156.09 samples/sec. 221.436 ms/step.
Infer [24/40]. 1156.10 samples/sec. 221.434 ms/step.
Infer [32/40]. 1156.08 samples/sec. 221.438 ms/step.
Infer [40/40]. 1156.08 samples/sec. 221.438 ms/step.
Inference benchmark of resnext50_32x4d.a1_in1k done. 1155.87 samples/sec, 221.44 ms/step
Model resnext50_32x4d.a1_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 45.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.a1_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 171.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext50_32x4d.a1_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 343.95 samples/sec. 372.144 ms/step.
Train [16/40]. 343.92 samples/sec. 372.178 ms/step.
Train [24/40]. 343.90 samples/sec. 372.200 ms/step.
Train [32/40]. 343.82 samples/sec. 372.287 ms/step.
Train [40/40]. 343.81 samples/sec. 372.302 ms/step.
Train benchmark of resnext50_32x4d.a1_in1k done. 342.94 samples/sec, 372.30 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.a1h_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1156.89 samples/sec. 221.282 ms/step.
Infer [16/40]. 1156.83 samples/sec. 221.294 ms/step.
Infer [24/40]. 1156.80 samples/sec. 221.299 ms/step.
Infer [32/40]. 1156.73 samples/sec. 221.313 ms/step.
Infer [40/40]. 1156.58 samples/sec. 221.342 ms/step.
Inference benchmark of resnext50_32x4d.a1h_in1k done. 1156.39 samples/sec, 221.34 ms/step
Model resnext50_32x4d.a1h_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 45.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.a1h_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 171.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext50_32x4d.a1h_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a1h_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 343.67 samples/sec. 372.456 ms/step.
Train [16/40]. 343.62 samples/sec. 372.510 ms/step.
Train [24/40]. 343.62 samples/sec. 372.502 ms/step.
Train [32/40]. 343.62 samples/sec. 372.504 ms/step.
Train [40/40]. 343.64 samples/sec. 372.487 ms/step.
Train benchmark of resnext50_32x4d.a1h_in1k done. 342.76 samples/sec, 372.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.a2_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1156.62 samples/sec. 221.334 ms/step.
Infer [16/40]. 1156.61 samples/sec. 221.337 ms/step.
Infer [24/40]. 1156.54 samples/sec. 221.350 ms/step.
Infer [32/40]. 1156.38 samples/sec. 221.381 ms/step.
Infer [40/40]. 1156.31 samples/sec. 221.393 ms/step.
Inference benchmark of resnext50_32x4d.a2_in1k done. 1156.11 samples/sec, 221.39 ms/step
Model resnext50_32x4d.a2_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 45.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.a2_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 171.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext50_32x4d.a2_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 343.70 samples/sec. 372.421 ms/step.
Train [16/40]. 343.67 samples/sec. 372.447 ms/step.
Train [24/40]. 343.65 samples/sec. 372.471 ms/step.
Train [32/40]. 343.63 samples/sec. 372.491 ms/step.
Train [40/40]. 343.63 samples/sec. 372.498 ms/step.
Train benchmark of resnext50_32x4d.a2_in1k done. 342.74 samples/sec, 372.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.a3_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1907.41 samples/sec. 134.214 ms/step.
Infer [16/40]. 1907.30 samples/sec. 134.221 ms/step.
Infer [24/40]. 1907.18 samples/sec. 134.230 ms/step.
Infer [32/40]. 1907.12 samples/sec. 134.234 ms/step.
Infer [40/40]. 1907.10 samples/sec. 134.235 ms/step.
Inference benchmark of resnext50_32x4d.a3_in1k done. 1906.67 samples/sec, 134.24 ms/step
Model resnext50_32x4d.a3_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 135.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.a3_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 575.18 samples/sec. 333.807 ms/step.
Train [16/40]. 575.20 samples/sec. 333.797 ms/step.
Train [24/40]. 575.18 samples/sec. 333.809 ms/step.
Train [32/40]. 575.16 samples/sec. 333.822 ms/step.
Train [40/40]. 575.13 samples/sec. 333.839 ms/step.
Train benchmark of resnext50_32x4d.a3_in1k done. 573.47 samples/sec, 333.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1906.90 samples/sec. 134.250 ms/step.
Infer [16/40]. 1906.89 samples/sec. 134.250 ms/step.
Infer [24/40]. 1906.81 samples/sec. 134.255 ms/step.
Infer [32/40]. 1906.73 samples/sec. 134.261 ms/step.
Infer [40/40]. 1906.79 samples/sec. 134.257 ms/step.
Inference benchmark of resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k done. 1906.36 samples/sec, 134.26 ms/step
Model resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 135.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 575.33 samples/sec. 333.722 ms/step.
Train [16/40]. 575.32 samples/sec. 333.728 ms/step.
Train [24/40]. 575.36 samples/sec. 333.704 ms/step.
Train [32/40]. 575.38 samples/sec. 333.694 ms/step.
Train [40/40]. 575.37 samples/sec. 333.696 ms/step.
Train benchmark of resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k done. 573.71 samples/sec, 333.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.fb_swsl_ig1b_ft_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1907.36 samples/sec. 134.217 ms/step.
Infer [16/40]. 1907.42 samples/sec. 134.212 ms/step.
Infer [24/40]. 1907.33 samples/sec. 134.219 ms/step.
Infer [32/40]. 1907.19 samples/sec. 134.229 ms/step.
Infer [40/40]. 1907.28 samples/sec. 134.223 ms/step.
Inference benchmark of resnext50_32x4d.fb_swsl_ig1b_ft_in1k done. 1906.84 samples/sec, 134.22 ms/step
Model resnext50_32x4d.fb_swsl_ig1b_ft_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 135.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.fb_swsl_ig1b_ft_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 575.34 samples/sec. 333.714 ms/step.
Train [16/40]. 575.33 samples/sec. 333.722 ms/step.
Train [24/40]. 575.30 samples/sec. 333.739 ms/step.
Train [32/40]. 575.24 samples/sec. 333.772 ms/step.
Train [40/40]. 575.22 samples/sec. 333.786 ms/step.
Train benchmark of resnext50_32x4d.fb_swsl_ig1b_ft_in1k done. 573.57 samples/sec, 333.79 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.gluon_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1907.40 samples/sec. 134.214 ms/step.
Infer [16/40]. 1907.34 samples/sec. 134.218 ms/step.
Infer [24/40]. 1907.32 samples/sec. 134.219 ms/step.
Infer [32/40]. 1907.19 samples/sec. 134.229 ms/step.
Infer [40/40]. 1907.13 samples/sec. 134.233 ms/step.
Inference benchmark of resnext50_32x4d.gluon_in1k done. 1906.70 samples/sec, 134.23 ms/step
Model resnext50_32x4d.gluon_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 135.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.gluon_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 575.53 samples/sec. 333.603 ms/step.
Train [16/40]. 575.50 samples/sec. 333.623 ms/step.
Train [24/40]. 575.46 samples/sec. 333.644 ms/step.
Train [32/40]. 575.44 samples/sec. 333.658 ms/step.
Train [40/40]. 575.40 samples/sec. 333.682 ms/step.
Train benchmark of resnext50_32x4d.gluon_in1k done. 573.76 samples/sec, 333.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.ra_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1155.93 samples/sec. 221.467 ms/step.
Infer [16/40]. 1155.86 samples/sec. 221.480 ms/step.
Infer [24/40]. 1155.84 samples/sec. 221.485 ms/step.
Infer [32/40]. 1155.82 samples/sec. 221.487 ms/step.
Infer [40/40]. 1155.82 samples/sec. 221.488 ms/step.
Inference benchmark of resnext50_32x4d.ra_in1k done. 1155.62 samples/sec, 221.49 ms/step
Model resnext50_32x4d.ra_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 45.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.ra_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 171.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext50_32x4d.ra_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 343.68 samples/sec. 372.440 ms/step.
Train [16/40]. 343.72 samples/sec. 372.394 ms/step.
Train [24/40]. 343.70 samples/sec. 372.418 ms/step.
Train [32/40]. 343.71 samples/sec. 372.411 ms/step.
Train [40/40]. 343.67 samples/sec. 372.453 ms/step.
Train benchmark of resnext50_32x4d.ra_in1k done. 342.78 samples/sec, 372.45 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.tv2_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1907.02 samples/sec. 134.241 ms/step.
Infer [16/40]. 1906.92 samples/sec. 134.248 ms/step.
Infer [24/40]. 1906.80 samples/sec. 134.256 ms/step.
Infer [32/40]. 1906.84 samples/sec. 134.253 ms/step.
Infer [40/40]. 1906.88 samples/sec. 134.251 ms/step.
Inference benchmark of resnext50_32x4d.tv2_in1k done. 1906.45 samples/sec, 134.25 ms/step
Model resnext50_32x4d.tv2_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 135.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.tv2_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 575.45 samples/sec. 333.654 ms/step.
Train [16/40]. 575.45 samples/sec. 333.651 ms/step.
Train [24/40]. 575.45 samples/sec. 333.651 ms/step.
Train [32/40]. 575.44 samples/sec. 333.659 ms/step.
Train [40/40]. 575.39 samples/sec. 333.684 ms/step.
Train benchmark of resnext50_32x4d.tv2_in1k done. 573.74 samples/sec, 333.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50_32x4d.tv_in1k created, param count: 25028904
Running inference benchmark on resnext50_32x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1907.18 samples/sec. 134.229 ms/step.
Infer [16/40]. 1907.10 samples/sec. 134.235 ms/step.
Infer [24/40]. 1907.06 samples/sec. 134.238 ms/step.
Infer [32/40]. 1907.00 samples/sec. 134.242 ms/step.
Infer [40/40]. 1906.98 samples/sec. 134.244 ms/step.
Inference benchmark of resnext50_32x4d.tv_in1k done. 1906.53 samples/sec, 134.24 ms/step
Model resnext50_32x4d.tv_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 135.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50_32x4d.tv_in1k created, param count: 25028904
Running train benchmark on resnext50_32x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 575.20 samples/sec. 333.798 ms/step.
Train [16/40]. 575.26 samples/sec. 333.763 ms/step.
Train [24/40]. 575.27 samples/sec. 333.759 ms/step.
Train [32/40]. 575.22 samples/sec. 333.787 ms/step.
Train [40/40]. 575.20 samples/sec. 333.796 ms/step.
Train benchmark of resnext50_32x4d.tv_in1k done. 573.55 samples/sec, 333.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext50d_32x4d.bt_in1k created, param count: 25048136
Running inference benchmark on resnext50d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1098.96 samples/sec. 232.947 ms/step.
Infer [16/40]. 1098.95 samples/sec. 232.950 ms/step.
Infer [24/40]. 1098.92 samples/sec. 232.956 ms/step.
Infer [32/40]. 1098.91 samples/sec. 232.959 ms/step.
Infer [40/40]. 1098.90 samples/sec. 232.959 ms/step.
Inference benchmark of resnext50d_32x4d.bt_in1k done. 1098.71 samples/sec, 232.96 ms/step
Model resnext50d_32x4d.bt_in1k created, param count: 25048136
Running train benchmark on resnext50d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.23 GiB is free. Including non-PyTorch memory, this process has 22.41 GiB memory in use. Of the allocated memory 21.55 GiB is allocated by PyTorch, and 371.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext50d_32x4d.bt_in1k created, param count: 25048136
Running train benchmark on resnext50d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 388.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 171.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext50d_32x4d.bt_in1k created, param count: 25048136
Running train benchmark on resnext50d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 175.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext50d_32x4d.bt_in1k created, param count: 25048136
Running train benchmark on resnext50d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 327.13 samples/sec. 293.463 ms/step.
Train [16/40]. 327.09 samples/sec. 293.496 ms/step.
Train [24/40]. 327.09 samples/sec. 293.493 ms/step.
Train [32/40]. 327.13 samples/sec. 293.463 ms/step.
Train [40/40]. 327.13 samples/sec. 293.464 ms/step.
Train benchmark of resnext50d_32x4d.bt_in1k done. 326.07 samples/sec, 293.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k created, param count: 44177704
Running inference benchmark on resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1211.53 samples/sec. 211.302 ms/step.
Infer [16/40]. 1211.66 samples/sec. 211.281 ms/step.
Infer [24/40]. 1211.64 samples/sec. 211.285 ms/step.
Infer [32/40]. 1211.61 samples/sec. 211.288 ms/step.
Infer [40/40]. 1211.61 samples/sec. 211.289 ms/step.
Inference benchmark of resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k done. 1211.40 samples/sec, 211.29 ms/step
Model resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 107.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 152.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 377.48 samples/sec. 339.090 ms/step.
Train [16/40]. 377.41 samples/sec. 339.151 ms/step.
Train [24/40]. 377.41 samples/sec. 339.155 ms/step.
Train [32/40]. 377.41 samples/sec. 339.151 ms/step.
Train [40/40]. 377.40 samples/sec. 339.159 ms/step.
Train benchmark of resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k done. 375.93 samples/sec, 339.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x4d.fb_swsl_ig1b_ft_in1k created, param count: 44177704
Running inference benchmark on resnext101_32x4d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1211.54 samples/sec. 211.301 ms/step.
Infer [16/40]. 1211.66 samples/sec. 211.281 ms/step.
Infer [24/40]. 1211.69 samples/sec. 211.276 ms/step.
Infer [32/40]. 1211.67 samples/sec. 211.279 ms/step.
Infer [40/40]. 1211.66 samples/sec. 211.281 ms/step.
Inference benchmark of resnext101_32x4d.fb_swsl_ig1b_ft_in1k done. 1211.45 samples/sec, 211.28 ms/step
Model resnext101_32x4d.fb_swsl_ig1b_ft_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 107.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x4d.fb_swsl_ig1b_ft_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 152.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x4d.fb_swsl_ig1b_ft_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 377.39 samples/sec. 339.174 ms/step.
Train [16/40]. 377.38 samples/sec. 339.182 ms/step.
Train [24/40]. 377.38 samples/sec. 339.185 ms/step.
Train [32/40]. 377.37 samples/sec. 339.192 ms/step.
Train [40/40]. 377.37 samples/sec. 339.185 ms/step.
Train benchmark of resnext101_32x4d.fb_swsl_ig1b_ft_in1k done. 375.93 samples/sec, 339.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x4d.gluon_in1k created, param count: 44177704
Running inference benchmark on resnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1211.51 samples/sec. 211.307 ms/step.
Infer [16/40]. 1211.39 samples/sec. 211.327 ms/step.
Infer [24/40]. 1211.28 samples/sec. 211.347 ms/step.
Infer [32/40]. 1211.25 samples/sec. 211.353 ms/step.
Infer [40/40]. 1211.22 samples/sec. 211.357 ms/step.
Inference benchmark of resnext101_32x4d.gluon_in1k done. 1211.01 samples/sec, 211.36 ms/step
Model resnext101_32x4d.gluon_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 107.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x4d.gluon_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 152.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x4d.gluon_in1k created, param count: 44177704
Running train benchmark on resnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 377.46 samples/sec. 339.106 ms/step.
Train [16/40]. 377.45 samples/sec. 339.122 ms/step.
Train [24/40]. 377.40 samples/sec. 339.162 ms/step.
Train [32/40]. 377.41 samples/sec. 339.155 ms/step.
Train [40/40]. 377.40 samples/sec. 339.163 ms/step.
Train benchmark of resnext101_32x4d.gluon_in1k done. 375.93 samples/sec, 339.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k created, param count: 88791336
Running inference benchmark on resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 781.57 samples/sec. 327.547 ms/step.
Infer [16/40]. 781.38 samples/sec. 327.624 ms/step.
Infer [24/40]. 781.31 samples/sec. 327.654 ms/step.
Infer [32/40]. 781.26 samples/sec. 327.674 ms/step.
Infer [40/40]. 781.22 samples/sec. 327.691 ms/step.
Inference benchmark of resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k done. 781.12 samples/sec, 327.69 ms/step
Model resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 24.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 69.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 285.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 585.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 242.72 samples/sec. 263.677 ms/step.
Train [16/40]. 242.74 samples/sec. 263.657 ms/step.
Train [24/40]. 242.72 samples/sec. 263.681 ms/step.
Train [32/40]. 242.72 samples/sec. 263.683 ms/step.
Train [40/40]. 242.71 samples/sec. 263.688 ms/step.
Train benchmark of resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k done. 241.59 samples/sec, 263.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x8d.fb_swsl_ig1b_ft_in1k created, param count: 88791336
Running inference benchmark on resnext101_32x8d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 781.81 samples/sec. 327.445 ms/step.
Infer [16/40]. 781.74 samples/sec. 327.473 ms/step.
Infer [24/40]. 781.77 samples/sec. 327.464 ms/step.
Infer [32/40]. 781.77 samples/sec. 327.461 ms/step.
Infer [40/40]. 781.69 samples/sec. 327.497 ms/step.
Inference benchmark of resnext101_32x8d.fb_swsl_ig1b_ft_in1k done. 781.58 samples/sec, 327.50 ms/step
Model resnext101_32x8d.fb_swsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 24.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x8d.fb_swsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 69.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x8d.fb_swsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 315.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x8d.fb_swsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 534.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x8d.fb_swsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 242.92 samples/sec. 263.461 ms/step.
Train [16/40]. 242.91 samples/sec. 263.471 ms/step.
Train [24/40]. 242.91 samples/sec. 263.474 ms/step.
Train [32/40]. 242.89 samples/sec. 263.493 ms/step.
Train [40/40]. 242.89 samples/sec. 263.493 ms/step.
Train benchmark of resnext101_32x8d.fb_swsl_ig1b_ft_in1k done. 241.75 samples/sec, 263.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x8d.fb_wsl_ig1b_ft_in1k created, param count: 88791336
Running inference benchmark on resnext101_32x8d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 782.00 samples/sec. 327.365 ms/step.
Infer [16/40]. 781.97 samples/sec. 327.378 ms/step.
Infer [24/40]. 781.92 samples/sec. 327.401 ms/step.
Infer [32/40]. 781.89 samples/sec. 327.413 ms/step.
Infer [40/40]. 781.86 samples/sec. 327.426 ms/step.
Inference benchmark of resnext101_32x8d.fb_wsl_ig1b_ft_in1k done. 781.75 samples/sec, 327.43 ms/step
Model resnext101_32x8d.fb_wsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 24.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x8d.fb_wsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 69.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x8d.fb_wsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 315.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x8d.fb_wsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 534.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x8d.fb_wsl_ig1b_ft_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 242.84 samples/sec. 263.550 ms/step.
Train [16/40]. 242.83 samples/sec. 263.560 ms/step.
Train [24/40]. 242.83 samples/sec. 263.561 ms/step.
Train [32/40]. 242.81 samples/sec. 263.585 ms/step.
Train [40/40]. 242.80 samples/sec. 263.594 ms/step.
Train benchmark of resnext101_32x8d.fb_wsl_ig1b_ft_in1k done. 241.65 samples/sec, 263.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x8d.tv2_in1k created, param count: 88791336
Running inference benchmark on resnext101_32x8d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 781.42 samples/sec. 327.610 ms/step.
Infer [16/40]. 781.46 samples/sec. 327.590 ms/step.
Infer [24/40]. 781.43 samples/sec. 327.605 ms/step.
Infer [32/40]. 781.42 samples/sec. 327.607 ms/step.
Infer [40/40]. 781.42 samples/sec. 327.608 ms/step.
Inference benchmark of resnext101_32x8d.tv2_in1k done. 781.32 samples/sec, 327.61 ms/step
Model resnext101_32x8d.tv2_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 24.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x8d.tv2_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 69.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x8d.tv2_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 315.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x8d.tv2_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 534.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x8d.tv2_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv2_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 242.92 samples/sec. 263.459 ms/step.
Train [16/40]. 242.90 samples/sec. 263.484 ms/step.
Train [24/40]. 242.90 samples/sec. 263.483 ms/step.
Train [32/40]. 242.89 samples/sec. 263.495 ms/step.
Train [40/40]. 242.88 samples/sec. 263.506 ms/step.
Train benchmark of resnext101_32x8d.tv2_in1k done. 241.77 samples/sec, 263.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x8d.tv_in1k created, param count: 88791336
Running inference benchmark on resnext101_32x8d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 781.44 samples/sec. 327.599 ms/step.
Infer [16/40]. 781.44 samples/sec. 327.601 ms/step.
Infer [24/40]. 781.43 samples/sec. 327.605 ms/step.
Infer [32/40]. 781.44 samples/sec. 327.599 ms/step.
Infer [40/40]. 781.39 samples/sec. 327.620 ms/step.
Inference benchmark of resnext101_32x8d.tv_in1k done. 781.29 samples/sec, 327.62 ms/step
Model resnext101_32x8d.tv_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 24.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x8d.tv_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 69.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x8d.tv_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 315.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x8d.tv_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 534.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x8d.tv_in1k created, param count: 88791336
Running train benchmark on resnext101_32x8d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 242.83 samples/sec. 263.556 ms/step.
Train [16/40]. 242.84 samples/sec. 263.544 ms/step.
Train [24/40]. 242.83 samples/sec. 263.554 ms/step.
Train [32/40]. 242.82 samples/sec. 263.566 ms/step.
Train [40/40]. 242.82 samples/sec. 263.575 ms/step.
Train benchmark of resnext101_32x8d.tv_in1k done. 241.69 samples/sec, 263.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k created, param count: 194026792
Running inference benchmark on resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 434.75 samples/sec. 588.843 ms/step.
Infer [16/40]. 434.75 samples/sec. 588.850 ms/step.
Infer [24/40]. 434.74 samples/sec. 588.855 ms/step.
Infer [32/40]. 434.72 samples/sec. 588.878 ms/step.
Infer [40/40]. 434.72 samples/sec. 588.888 ms/step.
Inference benchmark of resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k done. 434.68 samples/sec, 588.89 ms/step
Model resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 950.06 MiB is free. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 87.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 331.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 345.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 477.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 964.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 138.38 samples/sec. 346.865 ms/step.
Train [16/40]. 138.36 samples/sec. 346.918 ms/step.
Train [24/40]. 138.36 samples/sec. 346.921 ms/step.
Train [32/40]. 138.36 samples/sec. 346.928 ms/step.
Train [40/40]. 138.35 samples/sec. 346.945 ms/step.
Train benchmark of resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k done. 137.83 samples/sec, 346.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x16d.fb_swsl_ig1b_ft_in1k created, param count: 194026792
Running inference benchmark on resnext101_32x16d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 434.77 samples/sec. 588.812 ms/step.
Infer [16/40]. 434.73 samples/sec. 588.872 ms/step.
Infer [24/40]. 434.72 samples/sec. 588.882 ms/step.
Infer [32/40]. 434.70 samples/sec. 588.908 ms/step.
Infer [40/40]. 434.68 samples/sec. 588.938 ms/step.
Inference benchmark of resnext101_32x16d.fb_swsl_ig1b_ft_in1k done. 434.65 samples/sec, 588.94 ms/step
Model resnext101_32x16d.fb_swsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 950.06 MiB is free. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 87.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x16d.fb_swsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 331.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x16d.fb_swsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 349.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x16d.fb_swsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 458.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x16d.fb_swsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 1000.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnext101_32x16d.fb_swsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_swsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 138.21 samples/sec. 347.295 ms/step.
Train [16/40]. 138.23 samples/sec. 347.252 ms/step.
Train [24/40]. 138.23 samples/sec. 347.257 ms/step.
Train [32/40]. 138.22 samples/sec. 347.285 ms/step.
Train [40/40]. 138.21 samples/sec. 347.308 ms/step.
Train benchmark of resnext101_32x16d.fb_swsl_ig1b_ft_in1k done. 137.70 samples/sec, 347.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x16d.fb_wsl_ig1b_ft_in1k created, param count: 194026792
Running inference benchmark on resnext101_32x16d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 434.68 samples/sec. 588.937 ms/step.
Infer [16/40]. 434.60 samples/sec. 589.047 ms/step.
Infer [24/40]. 434.55 samples/sec. 589.119 ms/step.
Infer [32/40]. 434.51 samples/sec. 589.175 ms/step.
Infer [40/40]. 434.48 samples/sec. 589.205 ms/step.
Inference benchmark of resnext101_32x16d.fb_wsl_ig1b_ft_in1k done. 434.45 samples/sec, 589.21 ms/step
Model resnext101_32x16d.fb_wsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 950.06 MiB is free. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 87.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x16d.fb_wsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 331.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x16d.fb_wsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 349.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x16d.fb_wsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 448.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x16d.fb_wsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 1000.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnext101_32x16d.fb_wsl_ig1b_ft_in1k created, param count: 194026792
Running train benchmark on resnext101_32x16d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 138.24 samples/sec. 347.217 ms/step.
Train [16/40]. 138.22 samples/sec. 347.274 ms/step.
Train [24/40]. 138.19 samples/sec. 347.356 ms/step.
Train [32/40]. 138.18 samples/sec. 347.384 ms/step.
Train [40/40]. 138.17 samples/sec. 347.389 ms/step.
Train benchmark of resnext101_32x16d.fb_wsl_ig1b_ft_in1k done. 137.66 samples/sec, 347.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running inference benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 218.86 samples/sec. 1169.717 ms/step.
Infer [16/40]. 218.85 samples/sec. 1169.728 ms/step.
Infer [24/40]. 218.84 samples/sec. 1169.824 ms/step.
Infer [32/40]. 218.82 samples/sec. 1169.904 ms/step.
Infer [40/40]. 218.80 samples/sec. 1170.004 ms/step.
Inference benchmark of resnext101_32x32d.fb_wsl_ig1b_ft_in1k done. 218.79 samples/sec, 1170.00 ms/step
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.62 GiB is allocated by PyTorch, and 7.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 21.81 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 65.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.38 GiB is free. Including non-PyTorch memory, this process has 22.26 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, and 121.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 100.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 584.06 MiB is free. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 444.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 309.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 480.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model resnext101_32x32d.fb_wsl_ig1b_ft_in1k created, param count: 468530472
Running train benchmark on resnext101_32x32d.fb_wsl_ig1b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 24.
Train [8/40]. 67.61 samples/sec. 354.963 ms/step.
Train [16/40]. 67.63 samples/sec. 354.878 ms/step.
Train [24/40]. 67.62 samples/sec. 354.911 ms/step.
Train [32/40]. 67.62 samples/sec. 354.914 ms/step.
Train [40/40]. 67.62 samples/sec. 354.920 ms/step.
Train benchmark of resnext101_32x32d.fb_wsl_ig1b_ft_in1k done. 67.37 samples/sec, 354.92 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_64x4d.c1_in1k created, param count: 83455272
Running inference benchmark on resnext101_64x4d.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 474.29 samples/sec. 539.749 ms/step.
Infer [16/40]. 474.30 samples/sec. 539.741 ms/step.
Infer [24/40]. 474.29 samples/sec. 539.755 ms/step.
Infer [32/40]. 474.26 samples/sec. 539.787 ms/step.
Infer [40/40]. 474.25 samples/sec. 539.796 ms/step.
Inference benchmark of resnext101_64x4d.c1_in1k done. 474.21 samples/sec, 539.80 ms/step
Model resnext101_64x4d.c1_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 18.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_64x4d.c1_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.76 GiB is free. Including non-PyTorch memory, this process has 21.88 GiB memory in use. Of the allocated memory 21.15 GiB is allocated by PyTorch, and 236.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_64x4d.c1_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 282.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 118.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_64x4d.c1_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 216.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_64x4d.c1_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 298.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model resnext101_64x4d.c1_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.c1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 142.94 samples/sec. 335.804 ms/step.
Train [16/40]. 142.93 samples/sec. 335.823 ms/step.
Train [24/40]. 142.93 samples/sec. 335.820 ms/step.
Train [32/40]. 142.93 samples/sec. 335.821 ms/step.
Train [40/40]. 142.92 samples/sec. 335.857 ms/step.
Train benchmark of resnext101_64x4d.c1_in1k done. 142.37 samples/sec, 335.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_64x4d.gluon_in1k created, param count: 83455272
Running inference benchmark on resnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 780.14 samples/sec. 328.144 ms/step.
Infer [16/40]. 780.12 samples/sec. 328.155 ms/step.
Infer [24/40]. 780.14 samples/sec. 328.147 ms/step.
Infer [32/40]. 780.10 samples/sec. 328.162 ms/step.
Infer [40/40]. 780.12 samples/sec. 328.155 ms/step.
Inference benchmark of resnext101_64x4d.gluon_in1k done. 780.01 samples/sec, 328.15 ms/step
Model resnext101_64x4d.gluon_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_64x4d.gluon_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 63.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_64x4d.gluon_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 292.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_64x4d.gluon_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 512.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_64x4d.gluon_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 238.87 samples/sec. 267.924 ms/step.
Train [16/40]. 238.85 samples/sec. 267.946 ms/step.
Train [24/40]. 238.86 samples/sec. 267.938 ms/step.
Train [32/40]. 238.85 samples/sec. 267.947 ms/step.
Train [40/40]. 238.85 samples/sec. 267.949 ms/step.
Train benchmark of resnext101_64x4d.gluon_in1k done. 237.78 samples/sec, 267.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model resnext101_64x4d.tv_in1k created, param count: 83455272
Running inference benchmark on resnext101_64x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 779.98 samples/sec. 328.213 ms/step.
Infer [16/40]. 779.77 samples/sec. 328.304 ms/step.
Infer [24/40]. 779.74 samples/sec. 328.315 ms/step.
Infer [32/40]. 779.71 samples/sec. 328.329 ms/step.
Infer [40/40]. 779.70 samples/sec. 328.333 ms/step.
Inference benchmark of resnext101_64x4d.tv_in1k done. 779.58 samples/sec, 328.33 ms/step
Model resnext101_64x4d.tv_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model resnext101_64x4d.tv_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 63.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model resnext101_64x4d.tv_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 292.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model resnext101_64x4d.tv_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 498.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model resnext101_64x4d.tv_in1k created, param count: 83455272
Running train benchmark on resnext101_64x4d.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 239.16 samples/sec. 267.607 ms/step.
Train [16/40]. 239.09 samples/sec. 267.684 ms/step.
Train [24/40]. 239.08 samples/sec. 267.696 ms/step.
Train [32/40]. 239.07 samples/sec. 267.709 ms/step.
Train [40/40]. 239.05 samples/sec. 267.726 ms/step.
Train benchmark of resnext101_64x4d.tv_in1k done. 237.99 samples/sec, 267.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnet_100.nav_in1k created, param count: 4796873
Running inference benchmark on rexnet_100.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4657.29 samples/sec. 54.968 ms/step.
Infer [16/40]. 4657.18 samples/sec. 54.969 ms/step.
Infer [24/40]. 4657.35 samples/sec. 54.967 ms/step.
Infer [32/40]. 4657.25 samples/sec. 54.968 ms/step.
Infer [40/40]. 4657.14 samples/sec. 54.969 ms/step.
Inference benchmark of rexnet_100.nav_in1k done. 4654.90 samples/sec, 54.97 ms/step
Model rexnet_100.nav_in1k created, param count: 4796873
Running train benchmark on rexnet_100.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1225.55 samples/sec. 208.886 ms/step.
Train [16/40]. 1225.73 samples/sec. 208.855 ms/step.
Train [24/40]. 1225.69 samples/sec. 208.861 ms/step.
Train [32/40]. 1225.72 samples/sec. 208.857 ms/step.
Train [40/40]. 1225.73 samples/sec. 208.855 ms/step.
Train benchmark of rexnet_100.nav_in1k done. 1219.59 samples/sec, 208.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnet_130.nav_in1k created, param count: 7557091
Running inference benchmark on rexnet_130.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3476.56 samples/sec. 73.636 ms/step.
Infer [16/40]. 3475.95 samples/sec. 73.649 ms/step.
Infer [24/40]. 3475.73 samples/sec. 73.654 ms/step.
Infer [32/40]. 3475.59 samples/sec. 73.657 ms/step.
Infer [40/40]. 3475.47 samples/sec. 73.659 ms/step.
Inference benchmark of rexnet_130.nav_in1k done. 3474.22 samples/sec, 73.66 ms/step
Model rexnet_130.nav_in1k created, param count: 7557091
Running train benchmark on rexnet_130.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 175.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnet_130.nav_in1k created, param count: 7557091
Running train benchmark on rexnet_130.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 941.41 samples/sec. 203.950 ms/step.
Train [16/40]. 941.33 samples/sec. 203.967 ms/step.
Train [24/40]. 941.42 samples/sec. 203.948 ms/step.
Train [32/40]. 941.49 samples/sec. 203.933 ms/step.
Train [40/40]. 941.64 samples/sec. 203.900 ms/step.
Train benchmark of rexnet_130.nav_in1k done. 936.88 samples/sec, 203.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnet_150.nav_in1k created, param count: 9728593
Running inference benchmark on rexnet_150.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2995.47 samples/sec. 85.462 ms/step.
Infer [16/40]. 2994.90 samples/sec. 85.479 ms/step.
Infer [24/40]. 2994.62 samples/sec. 85.487 ms/step.
Infer [32/40]. 2994.51 samples/sec. 85.490 ms/step.
Infer [40/40]. 2994.32 samples/sec. 85.495 ms/step.
Inference benchmark of rexnet_150.nav_in1k done. 2993.35 samples/sec, 85.50 ms/step
Model rexnet_150.nav_in1k created, param count: 9728593
Running train benchmark on rexnet_150.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 424.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 253.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnet_150.nav_in1k created, param count: 9728593
Running train benchmark on rexnet_150.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 136.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 123.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model rexnet_150.nav_in1k created, param count: 9728593
Running train benchmark on rexnet_150.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 825.77 samples/sec. 155.007 ms/step.
Train [16/40]. 825.76 samples/sec. 155.009 ms/step.
Train [24/40]. 825.77 samples/sec. 155.007 ms/step.
Train [32/40]. 825.73 samples/sec. 155.014 ms/step.
Train [40/40]. 825.76 samples/sec. 155.009 ms/step.
Train benchmark of rexnet_150.nav_in1k done. 820.80 samples/sec, 155.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnet_200.nav_in1k created, param count: 16366620
Running inference benchmark on rexnet_200.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2215.04 samples/sec. 115.573 ms/step.
Infer [16/40]. 2215.04 samples/sec. 115.573 ms/step.
Infer [24/40]. 2215.01 samples/sec. 115.575 ms/step.
Infer [32/40]. 2214.92 samples/sec. 115.580 ms/step.
Infer [40/40]. 2214.91 samples/sec. 115.580 ms/step.
Inference benchmark of rexnet_200.nav_in1k done. 2214.34 samples/sec, 115.58 ms/step
Model rexnet_200.nav_in1k created, param count: 16366620
Running train benchmark on rexnet_200.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 896.06 MiB is free. Including non-PyTorch memory, this process has 22.77 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 96.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnet_200.nav_in1k created, param count: 16366620
Running train benchmark on rexnet_200.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 155.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model rexnet_200.nav_in1k created, param count: 16366620
Running train benchmark on rexnet_200.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 606.77 samples/sec. 210.952 ms/step.
Train [16/40]. 606.79 samples/sec. 210.945 ms/step.
Train [24/40]. 606.82 samples/sec. 210.934 ms/step.
Train [32/40]. 606.79 samples/sec. 210.946 ms/step.
Train [40/40]. 606.80 samples/sec. 210.943 ms/step.
Train benchmark of rexnet_200.nav_in1k done. 603.68 samples/sec, 210.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnet_300.nav_in1k created, param count: 34708792
Running inference benchmark on rexnet_300.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1423.77 samples/sec. 179.804 ms/step.
Infer [16/40]. 1423.87 samples/sec. 179.792 ms/step.
Infer [24/40]. 1423.87 samples/sec. 179.792 ms/step.
Infer [32/40]. 1423.84 samples/sec. 179.795 ms/step.
Infer [40/40]. 1423.82 samples/sec. 179.798 ms/step.
Inference benchmark of rexnet_300.nav_in1k done. 1423.53 samples/sec, 179.80 ms/step
Model rexnet_300.nav_in1k created, param count: 34708792
Running train benchmark on rexnet_300.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.39 GiB is free. Including non-PyTorch memory, this process has 22.25 GiB memory in use. Of the allocated memory 21.74 GiB is allocated by PyTorch, and 12.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnet_300.nav_in1k created, param count: 34708792
Running train benchmark on rexnet_300.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 21.86 GiB is allocated by PyTorch, and 201.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model rexnet_300.nav_in1k created, param count: 34708792
Running train benchmark on rexnet_300.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 150.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model rexnet_300.nav_in1k created, param count: 34708792
Running train benchmark on rexnet_300.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 227.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model rexnet_300.nav_in1k created, param count: 34708792
Running train benchmark on rexnet_300.nav_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 396.52 samples/sec. 161.404 ms/step.
Train [16/40]. 396.51 samples/sec. 161.410 ms/step.
Train [24/40]. 396.48 samples/sec. 161.421 ms/step.
Train [32/40]. 396.47 samples/sec. 161.423 ms/step.
Train [40/40]. 396.47 samples/sec. 161.424 ms/step.
Train benchmark of rexnet_300.nav_in1k done. 394.07 samples/sec, 161.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnetr_200.sw_in12k created, param count: 44235013
Running inference benchmark on rexnetr_200.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1338.20 samples/sec. 191.301 ms/step.
Infer [16/40]. 1338.04 samples/sec. 191.324 ms/step.
Infer [24/40]. 1337.90 samples/sec. 191.344 ms/step.
Infer [32/40]. 1337.81 samples/sec. 191.357 ms/step.
Infer [40/40]. 1337.78 samples/sec. 191.362 ms/step.
Inference benchmark of rexnetr_200.sw_in12k done. 1337.50 samples/sec, 191.36 ms/step
Model rexnetr_200.sw_in12k created, param count: 44235013
Running train benchmark on rexnetr_200.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 494.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 95.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnetr_200.sw_in12k created, param count: 44235013
Running train benchmark on rexnetr_200.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 22.50 GiB memory in use. Of the allocated memory 21.84 GiB is allocated by PyTorch, and 166.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model rexnetr_200.sw_in12k created, param count: 44235013
Running train benchmark on rexnetr_200.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 276.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 107.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model rexnetr_200.sw_in12k created, param count: 44235013
Running train benchmark on rexnetr_200.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 110.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model rexnetr_200.sw_in12k created, param count: 44235013
Running train benchmark on rexnetr_200.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 372.50 samples/sec. 171.814 ms/step.
Train [16/40]. 372.39 samples/sec. 171.864 ms/step.
Train [24/40]. 372.35 samples/sec. 171.883 ms/step.
Train [32/40]. 372.32 samples/sec. 171.893 ms/step.
Train [40/40]. 372.31 samples/sec. 171.901 ms/step.
Train benchmark of rexnetr_200.sw_in12k done. 370.12 samples/sec, 171.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnetr_200.sw_in12k_ft_in1k created, param count: 16522432
Running inference benchmark on rexnetr_200.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1339.73 samples/sec. 191.083 ms/step.
Infer [16/40]. 1339.77 samples/sec. 191.078 ms/step.
Infer [24/40]. 1339.75 samples/sec. 191.080 ms/step.
Infer [32/40]. 1339.73 samples/sec. 191.083 ms/step.
Infer [40/40]. 1339.73 samples/sec. 191.084 ms/step.
Inference benchmark of rexnetr_200.sw_in12k_ft_in1k done. 1339.45 samples/sec, 191.08 ms/step
Model rexnetr_200.sw_in12k_ft_in1k created, param count: 16522432
Running train benchmark on rexnetr_200.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 610.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 86.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnetr_200.sw_in12k_ft_in1k created, param count: 16522432
Running train benchmark on rexnetr_200.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 156.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model rexnetr_200.sw_in12k_ft_in1k created, param count: 16522432
Running train benchmark on rexnetr_200.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 392.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 97.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model rexnetr_200.sw_in12k_ft_in1k created, param count: 16522432
Running train benchmark on rexnetr_200.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 185.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model rexnetr_200.sw_in12k_ft_in1k created, param count: 16522432
Running train benchmark on rexnetr_200.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
Train [8/40]. 376.36 samples/sec. 170.050 ms/step.
Train [16/40]. 376.35 samples/sec. 170.054 ms/step.
Train [24/40]. 376.34 samples/sec. 170.058 ms/step.
Train [32/40]. 376.32 samples/sec. 170.067 ms/step.
Train [40/40]. 376.32 samples/sec. 170.067 ms/step.
Train benchmark of rexnetr_200.sw_in12k_ft_in1k done. 374.14 samples/sec, 170.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnetr_300.sw_in12k created, param count: 76373469
Running inference benchmark on rexnetr_300.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 887.88 samples/sec. 288.326 ms/step.
Infer [16/40]. 887.89 samples/sec. 288.324 ms/step.
Infer [24/40]. 887.90 samples/sec. 288.320 ms/step.
Infer [32/40]. 887.90 samples/sec. 288.320 ms/step.
Infer [40/40]. 887.89 samples/sec. 288.324 ms/step.
Inference benchmark of rexnetr_300.sw_in12k done. 887.76 samples/sec, 288.32 ms/step
Model rexnetr_300.sw_in12k created, param count: 76373469
Running train benchmark on rexnetr_300.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.59 GiB is free. Including non-PyTorch memory, this process has 20.05 GiB memory in use. Of the allocated memory 19.53 GiB is allocated by PyTorch, and 25.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnetr_300.sw_in12k created, param count: 76373469
Running train benchmark on rexnetr_300.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.97 GiB is free. Including non-PyTorch memory, this process has 19.67 GiB memory in use. Of the allocated memory 18.99 GiB is allocated by PyTorch, and 189.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model rexnetr_300.sw_in12k created, param count: 76373469
Running train benchmark on rexnetr_300.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the allocated memory 21.71 GiB is allocated by PyTorch, and 387.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model rexnetr_300.sw_in12k created, param count: 76373469
Running train benchmark on rexnetr_300.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 980.06 MiB is free. Including non-PyTorch memory, this process has 22.68 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 253.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model rexnetr_300.sw_in12k created, param count: 76373469
Running train benchmark on rexnetr_300.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 111.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model rexnetr_300.sw_in12k created, param count: 76373469
Running train benchmark on rexnetr_300.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 242.59 samples/sec. 197.865 ms/step.
Train [16/40]. 242.57 samples/sec. 197.879 ms/step.
Train [24/40]. 242.55 samples/sec. 197.894 ms/step.
Train [32/40]. 242.53 samples/sec. 197.911 ms/step.
Train [40/40]. 242.53 samples/sec. 197.910 ms/step.
Train benchmark of rexnetr_300.sw_in12k done. 241.24 samples/sec, 197.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model rexnetr_300.sw_in12k_ft_in1k created, param count: 34810008
Running inference benchmark on rexnetr_300.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 888.68 samples/sec. 288.066 ms/step.
Infer [16/40]. 888.69 samples/sec. 288.063 ms/step.
Infer [24/40]. 888.71 samples/sec. 288.057 ms/step.
Infer [32/40]. 888.71 samples/sec. 288.059 ms/step.
Infer [40/40]. 888.71 samples/sec. 288.058 ms/step.
Inference benchmark of rexnetr_300.sw_in12k_ft_in1k done. 888.57 samples/sec, 288.06 ms/step
Model rexnetr_300.sw_in12k_ft_in1k created, param count: 34810008
Running train benchmark on rexnetr_300.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.76 GiB is free. Including non-PyTorch memory, this process has 19.88 GiB memory in use. Of the allocated memory 19.37 GiB is allocated by PyTorch, and 11.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model rexnetr_300.sw_in12k_ft_in1k created, param count: 34810008
Running train benchmark on rexnetr_300.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.10 GiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 211.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model rexnetr_300.sw_in12k_ft_in1k created, param count: 34810008
Running train benchmark on rexnetr_300.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 254.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model rexnetr_300.sw_in12k_ft_in1k created, param count: 34810008
Running train benchmark on rexnetr_300.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.07 GiB is free. Including non-PyTorch memory, this process has 22.57 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 293.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model rexnetr_300.sw_in12k_ft_in1k created, param count: 34810008
Running train benchmark on rexnetr_300.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 293.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model rexnetr_300.sw_in12k_ft_in1k created, param count: 34810008
Running train benchmark on rexnetr_300.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 245.79 samples/sec. 195.285 ms/step.
Train [16/40]. 245.77 samples/sec. 195.306 ms/step.
Train [24/40]. 245.80 samples/sec. 195.284 ms/step.
Train [32/40]. 245.80 samples/sec. 195.284 ms/step.
Train [40/40]. 245.80 samples/sec. 195.283 ms/step.
Train benchmark of rexnetr_300.sw_in12k_ft_in1k done. 244.45 samples/sec, 195.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 10.77 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.41 GiB is free. Including non-PyTorch memory, this process has 21.23 GiB memory in use. Of the allocated memory 20.71 GiB is allocated by PyTorch, and 22.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 8.08 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.59 GiB is free. Including non-PyTorch memory, this process has 17.05 GiB memory in use. Of the allocated memory 15.62 GiB is allocated by PyTorch, and 956.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.10 GiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 17.71 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.81 GiB is free. Including non-PyTorch memory, this process has 20.83 GiB memory in use. Of the allocated memory 18.08 GiB is allocated by PyTorch, and 2.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 11.02 GiB is free. Including non-PyTorch memory, this process has 12.62 GiB memory in use. Of the allocated memory 8.60 GiB is allocated by PyTorch, and 3.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 36.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 15.24 GiB is free. Including non-PyTorch memory, this process has 8.40 GiB memory in use. Of the allocated memory 6.54 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 17.26 GiB is free. Including non-PyTorch memory, this process has 6.38 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 16.91 GiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 3.44 GiB is allocated by PyTorch, and 2.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.21 GiB is free. Including non-PyTorch memory, this process has 18.44 GiB memory in use. Of the allocated memory 14.79 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 418.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 20.18 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running inference benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 8.
Infer [8/40]. 18.85 samples/sec. 424.405 ms/step.
Infer [16/40]. 18.85 samples/sec. 424.412 ms/step.
Infer [24/40]. 18.85 samples/sec. 424.419 ms/step.
Infer [32/40]. 18.85 samples/sec. 424.416 ms/step.
Infer [40/40]. 18.85 samples/sec. 424.414 ms/step.
Inference benchmark of samvit_base_patch16.sa1b done. 18.85 samples/sec, 424.41 ms/step
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 10.77 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.72 GiB is allocated by PyTorch, and 34.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 8.08 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.59 GiB is free. Including non-PyTorch memory, this process has 17.05 GiB memory in use. Of the allocated memory 15.62 GiB is allocated by PyTorch, and 950.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.10 GiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 17.71 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 22.18 GiB memory in use. Of the allocated memory 19.43 GiB is allocated by PyTorch, and 2.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 920.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 684.06 MiB is free. Including non-PyTorch memory, this process has 22.97 GiB memory in use. Of the allocated memory 20.78 GiB is allocated by PyTorch, and 1.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.86 GiB is free. Including non-PyTorch memory, this process has 21.78 GiB memory in use. Of the allocated memory 17.13 GiB is allocated by PyTorch, and 4.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 372.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 21.39 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.06 GiB is free. Including non-PyTorch memory, this process has 18.58 GiB memory in use. Of the allocated memory 16.13 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 11.48 GiB is free. Including non-PyTorch memory, this process has 12.16 GiB memory in use. Of the allocated memory 10.87 GiB is allocated by PyTorch, and 811.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.89 GiB is free. Including non-PyTorch memory, this process has 18.75 GiB memory in use. Of the allocated memory 17.66 GiB is allocated by PyTorch, and 608.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.92 GiB is free. Including non-PyTorch memory, this process has 18.72 GiB memory in use. Of the allocated memory 17.89 GiB is allocated by PyTorch, and 343.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 198.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 446.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 21.93 GiB memory in use. Of the allocated memory 21.14 GiB is allocated by PyTorch, and 300.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.69 GiB memory in use. Of the allocated memory 20.45 GiB is allocated by PyTorch, and 769.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model samvit_base_patch16.sa1b created, param count: 89670912
Running train benchmark on samvit_base_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.98 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.64 GiB is free. Including non-PyTorch memory, this process has 22.00 GiB memory in use. Of the allocated memory 21.43 GiB is allocated by PyTorch, and 70.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.46 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.24 GiB is free. Including non-PyTorch memory, this process has 14.40 GiB memory in use. Of the allocated memory 12.94 GiB is allocated by PyTorch, and 993.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.97 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.93 GiB is free. Including non-PyTorch memory, this process has 19.71 GiB memory in use. Of the allocated memory 18.39 GiB is allocated by PyTorch, and 845.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 668.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 21.13 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.89 GiB is free. Including non-PyTorch memory, this process has 21.75 GiB memory in use. Of the allocated memory 20.57 GiB is allocated by PyTorch, and 700.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 5.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 12.47 GiB is free. Including non-PyTorch memory, this process has 11.17 GiB memory in use. Of the allocated memory 9.04 GiB is allocated by PyTorch, and 1.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 14.42 GiB is free. Including non-PyTorch memory, this process has 9.22 GiB memory in use. Of the allocated memory 7.39 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 803.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.24 GiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 17.27 GiB is allocated by PyTorch, and 1.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.27 GiB is free. Including non-PyTorch memory, this process has 22.38 GiB memory in use. Of the allocated memory 20.32 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running inference benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 6.
Infer [8/40]. 5.72 samples/sec. 1048.551 ms/step.
Infer [16/40]. 5.72 samples/sec. 1048.578 ms/step.
Infer [24/40]. 5.72 samples/sec. 1048.592 ms/step.
Infer [32/40]. 5.72 samples/sec. 1048.631 ms/step.
Infer [40/40]. 5.72 samples/sec. 1048.698 ms/step.
Inference benchmark of samvit_huge_patch16.sa1b done. 5.72 samples/sec, 1048.70 ms/step
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.98 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.64 GiB is free. Including non-PyTorch memory, this process has 22.00 GiB memory in use. Of the allocated memory 21.44 GiB is allocated by PyTorch, and 62.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 13.46 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.24 GiB is free. Including non-PyTorch memory, this process has 14.40 GiB memory in use. Of the allocated memory 12.94 GiB is allocated by PyTorch, and 987.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.97 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.93 GiB is free. Including non-PyTorch memory, this process has 19.71 GiB memory in use. Of the allocated memory 18.40 GiB is allocated by PyTorch, and 840.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 668.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 21.14 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 23.65 GiB of which 404.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 698.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 21.56 GiB memory in use. Of the allocated memory 19.91 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.56 GiB is free. Including non-PyTorch memory, this process has 22.08 GiB memory in use. Of the allocated memory 20.35 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 22.50 GiB memory in use. Of the allocated memory 20.24 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 938.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 21.27 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 20.72 GiB is allocated by PyTorch, and 2.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 470.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 188.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 21.59 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 21.37 GiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.40 GiB is free. Including non-PyTorch memory, this process has 21.24 GiB memory in use. Of the allocated memory 19.57 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 2.
ERROR: "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 458.06 MiB is free. Including non-PyTorch memory, this process has 23.19 GiB memory in use. Of the allocated memory 21.81 GiB is allocated by PyTorch, and 913.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model samvit_huge_patch16.sa1b created, param count: 637026048
Running train benchmark on samvit_huge_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 14.36 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.19 GiB is free. Including non-PyTorch memory, this process has 13.45 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 2.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.77 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 22.15 GiB memory in use. Of the allocated memory 20.77 GiB is allocated by PyTorch, and 904.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1000.06 MiB is free. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 21.41 GiB is allocated by PyTorch, and 772.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.74 GiB is free. Including non-PyTorch memory, this process has 19.90 GiB memory in use. Of the allocated memory 18.15 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 20.34 GiB is allocated by PyTorch, and 1.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 12.01 GiB is free. Including non-PyTorch memory, this process has 11.63 GiB memory in use. Of the allocated memory 9.23 GiB is allocated by PyTorch, and 1.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 15.21 GiB is free. Including non-PyTorch memory, this process has 8.44 GiB memory in use. Of the allocated memory 6.54 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 16.40 GiB is free. Including non-PyTorch memory, this process has 7.24 GiB memory in use. Of the allocated memory 5.20 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.28 GiB is free. Including non-PyTorch memory, this process has 22.36 GiB memory in use. Of the allocated memory 20.35 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.72 GiB is free. Including non-PyTorch memory, this process has 17.92 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.16 GiB is free. Including non-PyTorch memory, this process has 21.48 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 2.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running inference benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 6.
Infer [8/40]. 8.75 samples/sec. 685.995 ms/step.
Infer [16/40]. 8.75 samples/sec. 685.986 ms/step.
Infer [24/40]. 8.75 samples/sec. 685.984 ms/step.
Infer [32/40]. 8.75 samples/sec. 685.978 ms/step.
Infer [40/40]. 8.75 samples/sec. 685.976 ms/step.
Inference benchmark of samvit_large_patch16.sa1b done. 8.75 samples/sec, 685.98 ms/step
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 14.36 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.17 GiB is free. Including non-PyTorch memory, this process has 13.47 GiB memory in use. Of the allocated memory 12.96 GiB is allocated by PyTorch, and 14.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 10.77 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 22.15 GiB memory in use. Of the allocated memory 20.78 GiB is allocated by PyTorch, and 898.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 23.65 GiB of which 988.06 MiB is free. Including non-PyTorch memory, this process has 22.68 GiB memory in use. Of the allocated memory 21.42 GiB is allocated by PyTorch, and 780.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.74 GiB is free. Including non-PyTorch memory, this process has 19.90 GiB memory in use. Of the allocated memory 18.15 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.56 GiB is free. Including non-PyTorch memory, this process has 20.08 GiB memory in use. Of the allocated memory 17.88 GiB is allocated by PyTorch, and 1.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 920.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 876.06 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 21.41 GiB is allocated by PyTorch, and 902.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacty of 23.65 GiB of which 292.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 21.04 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 1.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 416.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 20.90 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 938.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 670.06 MiB is free. Including non-PyTorch memory, this process has 22.99 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 576.06 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 21.59 GiB is allocated by PyTorch, and 1018.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.48 GiB is free. Including non-PyTorch memory, this process has 18.16 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 890.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.40 GiB is free. Including non-PyTorch memory, this process has 20.24 GiB memory in use. Of the allocated memory 19.17 GiB is allocated by PyTorch, and 592.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.25 GiB is free. Including non-PyTorch memory, this process has 22.39 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 605.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 200.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 547.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 2.
ERROR: "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.21 GiB is free. Including non-PyTorch memory, this process has 22.43 GiB memory in use. Of the allocated memory 21.50 GiB is allocated by PyTorch, and 448.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model samvit_large_patch16.sa1b created, param count: 308278272
Running train benchmark on samvit_large_patch16.sa1b for 40 steps w/ input size (3, 1024, 1024) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model sebotnet33ts_256.a1h_in1k created, param count: 13701984
Running inference benchmark on sebotnet33ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1441.99 samples/sec. 177.533 ms/step.
Infer [16/40]. 1442.03 samples/sec. 177.527 ms/step.
Infer [24/40]. 1442.08 samples/sec. 177.522 ms/step.
Infer [32/40]. 1442.10 samples/sec. 177.519 ms/step.
Infer [40/40]. 1442.06 samples/sec. 177.523 ms/step.
Inference benchmark of sebotnet33ts_256.a1h_in1k done. 1441.76 samples/sec, 177.52 ms/step
Model sebotnet33ts_256.a1h_in1k created, param count: 13701984
Running train benchmark on sebotnet33ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 21.63 GiB is allocated by PyTorch, and 92.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model sebotnet33ts_256.a1h_in1k created, param count: 13701984
Running train benchmark on sebotnet33ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 654.06 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 19.81 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model sebotnet33ts_256.a1h_in1k created, param count: 13701984
Running train benchmark on sebotnet33ts_256.a1h_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 485.90 samples/sec. 263.431 ms/step.
Train [16/40]. 485.84 samples/sec. 263.459 ms/step.
Train [24/40]. 485.80 samples/sec. 263.484 ms/step.
Train [32/40]. 485.78 samples/sec. 263.492 ms/step.
Train [40/40]. 485.79 samples/sec. 263.489 ms/step.
Train benchmark of sebotnet33ts_256.a1h_in1k done. 483.93 samples/sec, 263.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model sehalonet33ts.ra2_in1k created, param count: 13691712
Running inference benchmark on sehalonet33ts.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1664.78 samples/sec. 153.774 ms/step.
Infer [16/40]. 1664.67 samples/sec. 153.784 ms/step.
Infer [24/40]. 1664.71 samples/sec. 153.780 ms/step.
Infer [32/40]. 1664.71 samples/sec. 153.780 ms/step.
Infer [40/40]. 1664.70 samples/sec. 153.782 ms/step.
Inference benchmark of sehalonet33ts.ra2_in1k done. 1664.33 samples/sec, 153.78 ms/step
Model sehalonet33ts.ra2_in1k created, param count: 13691712
Running train benchmark on sehalonet33ts.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 792.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 94.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model sehalonet33ts.ra2_in1k created, param count: 13691712
Running train benchmark on sehalonet33ts.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 477.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model sehalonet33ts.ra2_in1k created, param count: 13691712
Running train benchmark on sehalonet33ts.ra2_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 522.53 samples/sec. 244.963 ms/step.
Train [16/40]. 522.53 samples/sec. 244.963 ms/step.
Train [24/40]. 522.57 samples/sec. 244.946 ms/step.
Train [32/40]. 522.59 samples/sec. 244.934 ms/step.
Train [40/40]. 522.55 samples/sec. 244.952 ms/step.
Train benchmark of sehalonet33ts.ra2_in1k done. 520.35 samples/sec, 244.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model SelecSls42b.in1k created, param count: 32458248
Running inference benchmark on SelecSls42b.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4600.71 samples/sec. 55.644 ms/step.
Infer [16/40]. 4601.06 samples/sec. 55.639 ms/step.
Infer [24/40]. 4600.91 samples/sec. 55.641 ms/step.
Infer [32/40]. 4601.03 samples/sec. 55.640 ms/step.
Infer [40/40]. 4600.93 samples/sec. 55.641 ms/step.
Inference benchmark of SelecSls42b.in1k done. 4598.81 samples/sec, 55.64 ms/step
Model SelecSls42b.in1k created, param count: 32458248
Running train benchmark on SelecSls42b.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1348.98 samples/sec. 189.773 ms/step.
Train [16/40]. 1349.04 samples/sec. 189.765 ms/step.
Train [24/40]. 1348.94 samples/sec. 189.779 ms/step.
Train [32/40]. 1348.65 samples/sec. 189.820 ms/step.
Train [40/40]. 1348.54 samples/sec. 189.835 ms/step.
Train benchmark of SelecSls42b.in1k done. 1343.48 samples/sec, 189.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model SelecSls60.in1k created, param count: 30670768
Running inference benchmark on SelecSls60.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3914.47 samples/sec. 65.398 ms/step.
Infer [16/40]. 3914.47 samples/sec. 65.398 ms/step.
Infer [24/40]. 3914.34 samples/sec. 65.401 ms/step.
Infer [32/40]. 3914.20 samples/sec. 65.403 ms/step.
Infer [40/40]. 3914.13 samples/sec. 65.404 ms/step.
Inference benchmark of SelecSls60.in1k done. 3912.58 samples/sec, 65.40 ms/step
Model SelecSls60.in1k created, param count: 30670768
Running train benchmark on SelecSls60.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1143.79 samples/sec. 223.817 ms/step.
Train [16/40]. 1143.79 samples/sec. 223.817 ms/step.
Train [24/40]. 1143.80 samples/sec. 223.816 ms/step.
Train [32/40]. 1143.79 samples/sec. 223.817 ms/step.
Train [40/40]. 1143.79 samples/sec. 223.818 ms/step.
Train benchmark of SelecSls60.in1k done. 1139.18 samples/sec, 223.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model SelecSls60b.in1k created, param count: 32774064
Running inference benchmark on SelecSls60b.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3901.12 samples/sec. 65.622 ms/step.
Infer [16/40]. 3900.22 samples/sec. 65.637 ms/step.
Infer [24/40]. 3899.80 samples/sec. 65.644 ms/step.
Infer [32/40]. 3899.66 samples/sec. 65.647 ms/step.
Infer [40/40]. 3899.52 samples/sec. 65.649 ms/step.
Inference benchmark of SelecSls60b.in1k done. 3897.97 samples/sec, 65.65 ms/step
Model SelecSls60b.in1k created, param count: 32774064
Running train benchmark on SelecSls60b.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1140.06 samples/sec. 224.550 ms/step.
Train [16/40]. 1140.13 samples/sec. 224.536 ms/step.
Train [24/40]. 1140.13 samples/sec. 224.535 ms/step.
Train [32/40]. 1140.14 samples/sec. 224.534 ms/step.
Train [40/40]. 1140.13 samples/sec. 224.536 ms/step.
Train benchmark of SelecSls60b.in1k done. 1135.66 samples/sec, 224.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model semnasnet_075.rmsp_in1k created, param count: 2912278
Running inference benchmark on semnasnet_075.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6677.18 samples/sec. 38.340 ms/step.
Infer [16/40]. 6676.79 samples/sec. 38.342 ms/step.
Infer [24/40]. 6676.77 samples/sec. 38.342 ms/step.
Infer [32/40]. 6676.88 samples/sec. 38.341 ms/step.
Infer [40/40]. 6676.79 samples/sec. 38.342 ms/step.
Inference benchmark of semnasnet_075.rmsp_in1k done. 6672.58 samples/sec, 38.34 ms/step
Model semnasnet_075.rmsp_in1k created, param count: 2912278
Running train benchmark on semnasnet_075.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1791.06 samples/sec. 142.932 ms/step.
Train [16/40]. 1791.72 samples/sec. 142.879 ms/step.
Train [24/40]. 1791.84 samples/sec. 142.870 ms/step.
Train [32/40]. 1791.99 samples/sec. 142.858 ms/step.
Train [40/40]. 1792.20 samples/sec. 142.841 ms/step.
Train benchmark of semnasnet_075.rmsp_in1k done. 1783.34 samples/sec, 142.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model semnasnet_100.rmsp_in1k created, param count: 3887038
Running inference benchmark on semnasnet_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5790.31 samples/sec. 44.212 ms/step.
Infer [16/40]. 5790.48 samples/sec. 44.210 ms/step.
Infer [24/40]. 5790.17 samples/sec. 44.213 ms/step.
Infer [32/40]. 5790.01 samples/sec. 44.214 ms/step.
Infer [40/40]. 5790.07 samples/sec. 44.214 ms/step.
Inference benchmark of semnasnet_100.rmsp_in1k done. 5786.86 samples/sec, 44.21 ms/step
Model semnasnet_100.rmsp_in1k created, param count: 3887038
Running train benchmark on semnasnet_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1577.50 samples/sec. 162.282 ms/step.
Train [16/40]. 1576.62 samples/sec. 162.372 ms/step.
Train [24/40]. 1576.45 samples/sec. 162.390 ms/step.
Train [32/40]. 1576.51 samples/sec. 162.384 ms/step.
Train [40/40]. 1576.52 samples/sec. 162.383 ms/step.
Train benchmark of semnasnet_100.rmsp_in1k done. 1569.43 samples/sec, 162.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model senet154.gluon_in1k created, param count: 115088984
Running inference benchmark on senet154.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 559.44 samples/sec. 457.600 ms/step.
Infer [16/40]. 559.37 samples/sec. 457.659 ms/step.
Infer [24/40]. 559.34 samples/sec. 457.679 ms/step.
Infer [32/40]. 559.33 samples/sec. 457.691 ms/step.
Infer [40/40]. 559.32 samples/sec. 457.699 ms/step.
Inference benchmark of senet154.gluon_in1k done. 559.27 samples/sec, 457.70 ms/step
Model senet154.gluon_in1k created, param count: 115088984
Running train benchmark on senet154.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 740.06 MiB is free. Including non-PyTorch memory, this process has 22.92 GiB memory in use. Of the allocated memory 22.41 GiB is allocated by PyTorch, and 9.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model senet154.gluon_in1k created, param count: 115088984
Running train benchmark on senet154.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 76.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model senet154.gluon_in1k created, param count: 115088984
Running train benchmark on senet154.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 235.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model senet154.gluon_in1k created, param count: 115088984
Running train benchmark on senet154.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 691.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model senet154.gluon_in1k created, param count: 115088984
Running train benchmark on senet154.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 556.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model senet154.gluon_in1k created, param count: 115088984
Running train benchmark on senet154.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 171.02 samples/sec. 280.666 ms/step.
Train [16/40]. 171.02 samples/sec. 280.673 ms/step.
Train [24/40]. 171.01 samples/sec. 280.684 ms/step.
Train [32/40]. 171.01 samples/sec. 280.691 ms/step.
Train [40/40]. 171.00 samples/sec. 280.694 ms/step.
Train benchmark of senet154.gluon_in1k done. 169.67 samples/sec, 280.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model sequencer2d_l.in1k created, param count: 54298216
Running inference benchmark on sequencer2d_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 626.79 samples/sec. 408.429 ms/step.
Infer [16/40]. 626.65 samples/sec. 408.519 ms/step.
Infer [24/40]. 626.49 samples/sec. 408.629 ms/step.
Infer [32/40]. 626.40 samples/sec. 408.682 ms/step.
Infer [40/40]. 626.36 samples/sec. 408.711 ms/step.
Inference benchmark of sequencer2d_l.in1k done. 626.29 samples/sec, 408.71 ms/step
Model sequencer2d_l.in1k created, param count: 54298216
Running train benchmark on sequencer2d_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 22.51 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 463.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model sequencer2d_l.in1k created, param count: 54298216
Running train benchmark on sequencer2d_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 570.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 366.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 380.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model sequencer2d_l.in1k created, param count: 54298216
Running train benchmark on sequencer2d_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 286.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 134.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model sequencer2d_l.in1k created, param count: 54298216
Running train benchmark on sequencer2d_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 197.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model sequencer2d_l.in1k created, param count: 54298216
Running train benchmark on sequencer2d_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 227.78 samples/sec. 280.973 ms/step.
Train [16/40]. 227.80 samples/sec. 280.946 ms/step.
Train [24/40]. 227.85 samples/sec. 280.883 ms/step.
Train [32/40]. 227.86 samples/sec. 280.876 ms/step.
Train [40/40]. 227.90 samples/sec. 280.831 ms/step.
Train benchmark of sequencer2d_l.in1k done. 225.87 samples/sec, 280.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model sequencer2d_m.in1k created, param count: 38307688
Running inference benchmark on sequencer2d_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 959.17 samples/sec. 266.899 ms/step.
Infer [16/40]. 959.21 samples/sec. 266.886 ms/step.
Infer [24/40]. 959.22 samples/sec. 266.883 ms/step.
Infer [32/40]. 959.22 samples/sec. 266.885 ms/step.
Infer [40/40]. 959.20 samples/sec. 266.888 ms/step.
Inference benchmark of sequencer2d_m.in1k done. 959.05 samples/sec, 266.89 ms/step
Model sequencer2d_m.in1k created, param count: 38307688
Running train benchmark on sequencer2d_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 618.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model sequencer2d_m.in1k created, param count: 38307688
Running train benchmark on sequencer2d_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 570.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 567.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model sequencer2d_m.in1k created, param count: 38307688
Running train benchmark on sequencer2d_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 320.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 83.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model sequencer2d_m.in1k created, param count: 38307688
Running train benchmark on sequencer2d_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 346.02 samples/sec. 277.444 ms/step.
Train [16/40]. 345.97 samples/sec. 277.480 ms/step.
Train [24/40]. 345.86 samples/sec. 277.573 ms/step.
Train [32/40]. 345.89 samples/sec. 277.545 ms/step.
Train [40/40]. 345.86 samples/sec. 277.566 ms/step.
Train benchmark of sequencer2d_m.in1k done. 343.44 samples/sec, 277.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model sequencer2d_s.in1k created, param count: 27651688
Running inference benchmark on sequencer2d_s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1240.45 samples/sec. 206.377 ms/step.
Infer [16/40]. 1240.50 samples/sec. 206.369 ms/step.
Infer [24/40]. 1240.55 samples/sec. 206.360 ms/step.
Infer [32/40]. 1240.63 samples/sec. 206.347 ms/step.
Infer [40/40]. 1240.67 samples/sec. 206.341 ms/step.
Inference benchmark of sequencer2d_s.in1k done. 1240.44 samples/sec, 206.34 ms/step
Model sequencer2d_s.in1k created, param count: 27651688
Running train benchmark on sequencer2d_s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 202.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 634.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model sequencer2d_s.in1k created, param count: 27651688
Running train benchmark on sequencer2d_s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 570.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 206.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 540.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model sequencer2d_s.in1k created, param count: 27651688
Running train benchmark on sequencer2d_s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 435.44 samples/sec. 293.958 ms/step.
Train [16/40]. 435.60 samples/sec. 293.847 ms/step.
Train [24/40]. 435.69 samples/sec. 293.786 ms/step.
Train [32/40]. 435.67 samples/sec. 293.803 ms/step.
Train [40/40]. 435.63 samples/sec. 293.828 ms/step.
Train benchmark of sequencer2d_s.in1k done. 433.14 samples/sec, 293.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnet33ts.ra2_in1k created, param count: 19779200
Running inference benchmark on seresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1719.61 samples/sec. 148.871 ms/step.
Infer [16/40]. 1719.64 samples/sec. 148.868 ms/step.
Infer [24/40]. 1719.63 samples/sec. 148.869 ms/step.
Infer [32/40]. 1719.62 samples/sec. 148.870 ms/step.
Infer [40/40]. 1719.62 samples/sec. 148.870 ms/step.
Inference benchmark of seresnet33ts.ra2_in1k done. 1719.24 samples/sec, 148.87 ms/step
Model seresnet33ts.ra2_in1k created, param count: 19779200
Running train benchmark on seresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 614.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.32 GiB is allocated by PyTorch, and 231.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnet33ts.ra2_in1k created, param count: 19779200
Running train benchmark on seresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 214.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnet33ts.ra2_in1k created, param count: 19779200
Running train benchmark on seresnet33ts.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 481.08 samples/sec. 266.067 ms/step.
Train [16/40]. 481.09 samples/sec. 266.060 ms/step.
Train [24/40]. 481.06 samples/sec. 266.078 ms/step.
Train [32/40]. 481.05 samples/sec. 266.086 ms/step.
Train [40/40]. 481.05 samples/sec. 266.083 ms/step.
Train benchmark of seresnet33ts.ra2_in1k done. 479.38 samples/sec, 266.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnet50.a1_in1k created, param count: 28088024
Running inference benchmark on seresnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1199.37 samples/sec. 213.445 ms/step.
Infer [16/40]. 1199.34 samples/sec. 213.451 ms/step.
Infer [24/40]. 1199.35 samples/sec. 213.449 ms/step.
Infer [32/40]. 1199.35 samples/sec. 213.449 ms/step.
Infer [40/40]. 1199.34 samples/sec. 213.450 ms/step.
Inference benchmark of seresnet50.a1_in1k done. 1199.12 samples/sec, 213.45 ms/step
Model seresnet50.a1_in1k created, param count: 28088024
Running train benchmark on seresnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 545.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnet50.a1_in1k created, param count: 28088024
Running train benchmark on seresnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 372.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 164.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnet50.a1_in1k created, param count: 28088024
Running train benchmark on seresnet50.a1_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 358.14 samples/sec. 357.400 ms/step.
Train [16/40]. 358.06 samples/sec. 357.483 ms/step.
Train [24/40]. 358.05 samples/sec. 357.494 ms/step.
Train [32/40]. 358.04 samples/sec. 357.507 ms/step.
Train [40/40]. 358.02 samples/sec. 357.521 ms/step.
Train benchmark of seresnet50.a1_in1k done. 356.83 samples/sec, 357.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnet50.a2_in1k created, param count: 28088024
Running inference benchmark on seresnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1199.42 samples/sec. 213.436 ms/step.
Infer [16/40]. 1199.33 samples/sec. 213.452 ms/step.
Infer [24/40]. 1199.25 samples/sec. 213.467 ms/step.
Infer [32/40]. 1199.20 samples/sec. 213.476 ms/step.
Infer [40/40]. 1199.18 samples/sec. 213.480 ms/step.
Inference benchmark of seresnet50.a2_in1k done. 1198.95 samples/sec, 213.48 ms/step
Model seresnet50.a2_in1k created, param count: 28088024
Running train benchmark on seresnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 545.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnet50.a2_in1k created, param count: 28088024
Running train benchmark on seresnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 372.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 164.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnet50.a2_in1k created, param count: 28088024
Running train benchmark on seresnet50.a2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 357.95 samples/sec. 357.597 ms/step.
Train [16/40]. 357.95 samples/sec. 357.594 ms/step.
Train [24/40]. 357.96 samples/sec. 357.581 ms/step.
Train [32/40]. 357.96 samples/sec. 357.586 ms/step.
Train [40/40]. 357.95 samples/sec. 357.595 ms/step.
Train benchmark of seresnet50.a2_in1k done. 356.75 samples/sec, 357.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnet50.a3_in1k created, param count: 28088024
Running inference benchmark on seresnet50.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1899.53 samples/sec. 134.770 ms/step.
Infer [16/40]. 1899.28 samples/sec. 134.788 ms/step.
Infer [24/40]. 1898.82 samples/sec. 134.821 ms/step.
Infer [32/40]. 1898.72 samples/sec. 134.828 ms/step.
Infer [40/40]. 1898.67 samples/sec. 134.831 ms/step.
Inference benchmark of seresnet50.a3_in1k done. 1898.24 samples/sec, 134.83 ms/step
Model seresnet50.a3_in1k created, param count: 28088024
Running train benchmark on seresnet50.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.11 GiB is allocated by PyTorch, and 28.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnet50.a3_in1k created, param count: 28088024
Running train benchmark on seresnet50.a3_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 592.79 samples/sec. 323.895 ms/step.
Train [16/40]. 592.75 samples/sec. 323.912 ms/step.
Train [24/40]. 592.80 samples/sec. 323.885 ms/step.
Train [32/40]. 592.79 samples/sec. 323.894 ms/step.
Train [40/40]. 592.80 samples/sec. 323.885 ms/step.
Train benchmark of seresnet50.a3_in1k done. 590.62 samples/sec, 323.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnet50.ra2_in1k created, param count: 28088024
Running inference benchmark on seresnet50.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1199.39 samples/sec. 213.443 ms/step.
Infer [16/40]. 1199.38 samples/sec. 213.444 ms/step.
Infer [24/40]. 1199.23 samples/sec. 213.470 ms/step.
Infer [32/40]. 1199.18 samples/sec. 213.478 ms/step.
Infer [40/40]. 1199.14 samples/sec. 213.487 ms/step.
Inference benchmark of seresnet50.ra2_in1k done. 1198.92 samples/sec, 213.49 ms/step
Model seresnet50.ra2_in1k created, param count: 28088024
Running train benchmark on seresnet50.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 545.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnet50.ra2_in1k created, param count: 28088024
Running train benchmark on seresnet50.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 372.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 164.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnet50.ra2_in1k created, param count: 28088024
Running train benchmark on seresnet50.ra2_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 357.82 samples/sec. 357.722 ms/step.
Train [16/40]. 357.86 samples/sec. 357.685 ms/step.
Train [24/40]. 357.90 samples/sec. 357.644 ms/step.
Train [32/40]. 357.89 samples/sec. 357.650 ms/step.
Train [40/40]. 357.88 samples/sec. 357.658 ms/step.
Train benchmark of seresnet50.ra2_in1k done. 356.69 samples/sec, 357.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnet152d.ra2_in1k created, param count: 66841080
Running inference benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 429.47 samples/sec. 596.090 ms/step.
Infer [16/40]. 429.46 samples/sec. 596.103 ms/step.
Infer [24/40]. 429.40 samples/sec. 596.184 ms/step.
Infer [32/40]. 429.37 samples/sec. 596.228 ms/step.
Infer [40/40]. 429.35 samples/sec. 596.254 ms/step.
Inference benchmark of seresnet152d.ra2_in1k done. 429.31 samples/sec, 596.25 ms/step
Model seresnet152d.ra2_in1k created, param count: 66841080
Running train benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 300.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 26.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnet152d.ra2_in1k created, param count: 66841080
Running train benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 600.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 246.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnet152d.ra2_in1k created, param count: 66841080
Running train benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 376.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 296.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnet152d.ra2_in1k created, param count: 66841080
Running train benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 591.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnet152d.ra2_in1k created, param count: 66841080
Running train benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 686.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model seresnet152d.ra2_in1k created, param count: 66841080
Running train benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 808.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model seresnet152d.ra2_in1k created, param count: 66841080
Running train benchmark on seresnet152d.ra2_in1k for 40 steps w/ input size (3, 320, 320) and batch size 32.
Train [8/40]. 141.91 samples/sec. 225.497 ms/step.
Train [16/40]. 141.92 samples/sec. 225.476 ms/step.
Train [24/40]. 141.92 samples/sec. 225.478 ms/step.
Train [32/40]. 141.92 samples/sec. 225.477 ms/step.
Train [40/40]. 141.92 samples/sec. 225.480 ms/step.
Train benchmark of seresnet152d.ra2_in1k done. 140.58 samples/sec, 225.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext26d_32x4d.bt_in1k created, param count: 16809512
Running inference benchmark on seresnext26d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1558.52 samples/sec. 164.258 ms/step.
Infer [16/40]. 1558.43 samples/sec. 164.268 ms/step.
Infer [24/40]. 1558.42 samples/sec. 164.268 ms/step.
Infer [32/40]. 1558.36 samples/sec. 164.275 ms/step.
Infer [40/40]. 1558.38 samples/sec. 164.273 ms/step.
Inference benchmark of seresnext26d_32x4d.bt_in1k done. 1558.06 samples/sec, 164.27 ms/step
Model seresnext26d_32x4d.bt_in1k created, param count: 16809512
Running train benchmark on seresnext26d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.23 GiB is free. Including non-PyTorch memory, this process has 22.41 GiB memory in use. Of the allocated memory 21.52 GiB is allocated by PyTorch, and 404.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext26d_32x4d.bt_in1k created, param count: 16809512
Running train benchmark on seresnext26d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 442.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 146.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext26d_32x4d.bt_in1k created, param count: 16809512
Running train benchmark on seresnext26d_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 439.34 samples/sec. 291.349 ms/step.
Train [16/40]. 439.36 samples/sec. 291.330 ms/step.
Train [24/40]. 439.36 samples/sec. 291.330 ms/step.
Train [32/40]. 439.35 samples/sec. 291.342 ms/step.
Train [40/40]. 439.34 samples/sec. 291.348 ms/step.
Train benchmark of seresnext26d_32x4d.bt_in1k done. 438.03 samples/sec, 291.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext26t_32x4d.bt_in1k created, param count: 16806976
Running inference benchmark on seresnext26t_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1573.52 samples/sec. 162.692 ms/step.
Infer [16/40]. 1573.51 samples/sec. 162.694 ms/step.
Infer [24/40]. 1573.50 samples/sec. 162.695 ms/step.
Infer [32/40]. 1573.56 samples/sec. 162.689 ms/step.
Infer [40/40]. 1573.54 samples/sec. 162.690 ms/step.
Inference benchmark of seresnext26t_32x4d.bt_in1k done. 1573.18 samples/sec, 162.69 ms/step
Model seresnext26t_32x4d.bt_in1k created, param count: 16806976
Running train benchmark on seresnext26t_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 290.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 80.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext26t_32x4d.bt_in1k created, param count: 16806976
Running train benchmark on seresnext26t_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 155.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext26t_32x4d.bt_in1k created, param count: 16806976
Running train benchmark on seresnext26t_32x4d.bt_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 442.59 samples/sec. 289.210 ms/step.
Train [16/40]. 442.51 samples/sec. 289.257 ms/step.
Train [24/40]. 442.54 samples/sec. 289.242 ms/step.
Train [32/40]. 442.54 samples/sec. 289.238 ms/step.
Train [40/40]. 442.54 samples/sec. 289.239 ms/step.
Train benchmark of seresnext26t_32x4d.bt_in1k done. 441.23 samples/sec, 289.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext26ts.ch_in1k created, param count: 10388064
Running inference benchmark on seresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 2167.46 samples/sec. 118.110 ms/step.
Infer [16/40]. 2167.65 samples/sec. 118.100 ms/step.
Infer [24/40]. 2167.53 samples/sec. 118.107 ms/step.
Infer [32/40]. 2167.42 samples/sec. 118.113 ms/step.
Infer [40/40]. 2167.33 samples/sec. 118.118 ms/step.
Inference benchmark of seresnext26ts.ch_in1k done. 2166.80 samples/sec, 118.12 ms/step
Model seresnext26ts.ch_in1k created, param count: 10388064
Running train benchmark on seresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 103.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext26ts.ch_in1k created, param count: 10388064
Running train benchmark on seresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 168.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 195.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext26ts.ch_in1k created, param count: 10388064
Running train benchmark on seresnext26ts.ch_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
Train [8/40]. 587.56 samples/sec. 217.849 ms/step.
Train [16/40]. 587.41 samples/sec. 217.905 ms/step.
Train [24/40]. 587.41 samples/sec. 217.905 ms/step.
Train [32/40]. 587.46 samples/sec. 217.888 ms/step.
Train [40/40]. 587.48 samples/sec. 217.881 ms/step.
Train benchmark of seresnext26ts.ch_in1k done. 585.35 samples/sec, 217.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext50_32x4d.gluon_in1k created, param count: 27559896
Running inference benchmark on seresnext50_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1672.76 samples/sec. 153.041 ms/step.
Infer [16/40]. 1672.74 samples/sec. 153.042 ms/step.
Infer [24/40]. 1672.73 samples/sec. 153.043 ms/step.
Infer [32/40]. 1672.68 samples/sec. 153.048 ms/step.
Infer [40/40]. 1672.64 samples/sec. 153.052 ms/step.
Inference benchmark of seresnext50_32x4d.gluon_in1k done. 1672.28 samples/sec, 153.05 ms/step
Model seresnext50_32x4d.gluon_in1k created, param count: 27559896
Running train benchmark on seresnext50_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.05 GiB is allocated by PyTorch, and 44.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext50_32x4d.gluon_in1k created, param count: 27559896
Running train benchmark on seresnext50_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 143.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext50_32x4d.gluon_in1k created, param count: 27559896
Running train benchmark on seresnext50_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 493.57 samples/sec. 259.336 ms/step.
Train [16/40]. 493.58 samples/sec. 259.327 ms/step.
Train [24/40]. 493.56 samples/sec. 259.338 ms/step.
Train [32/40]. 493.59 samples/sec. 259.325 ms/step.
Train [40/40]. 493.58 samples/sec. 259.329 ms/step.
Train benchmark of seresnext50_32x4d.gluon_in1k done. 491.44 samples/sec, 259.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext50_32x4d.racm_in1k created, param count: 27559896
Running inference benchmark on seresnext50_32x4d.racm_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 1015.39 samples/sec. 252.121 ms/step.
Infer [16/40]. 1015.34 samples/sec. 252.133 ms/step.
Infer [24/40]. 1015.27 samples/sec. 252.149 ms/step.
Infer [32/40]. 1015.22 samples/sec. 252.163 ms/step.
Infer [40/40]. 1015.21 samples/sec. 252.163 ms/step.
Inference benchmark of seresnext50_32x4d.racm_in1k done. 1015.05 samples/sec, 252.16 ms/step
Model seresnext50_32x4d.racm_in1k created, param count: 27559896
Running train benchmark on seresnext50_32x4d.racm_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 282.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 45.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext50_32x4d.racm_in1k created, param count: 27559896
Running train benchmark on seresnext50_32x4d.racm_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 136.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 170.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext50_32x4d.racm_in1k created, param count: 27559896
Running train benchmark on seresnext50_32x4d.racm_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 205.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnext50_32x4d.racm_in1k created, param count: 27559896
Running train benchmark on seresnext50_32x4d.racm_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
Train [8/40]. 294.55 samples/sec. 325.922 ms/step.
Train [16/40]. 294.53 samples/sec. 325.947 ms/step.
Train [24/40]. 294.52 samples/sec. 325.949 ms/step.
Train [32/40]. 294.53 samples/sec. 325.941 ms/step.
Train [40/40]. 294.54 samples/sec. 325.937 ms/step.
Train benchmark of seresnext50_32x4d.racm_in1k done. 293.43 samples/sec, 325.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext101_32x4d.gluon_in1k created, param count: 48955416
Running inference benchmark on seresnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1058.39 samples/sec. 241.877 ms/step.
Infer [16/40]. 1058.41 samples/sec. 241.873 ms/step.
Infer [24/40]. 1058.36 samples/sec. 241.883 ms/step.
Infer [32/40]. 1058.35 samples/sec. 241.887 ms/step.
Infer [40/40]. 1058.30 samples/sec. 241.898 ms/step.
Inference benchmark of seresnext101_32x4d.gluon_in1k done. 1058.11 samples/sec, 241.90 ms/step
Model seresnext101_32x4d.gluon_in1k created, param count: 48955416
Running train benchmark on seresnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 392.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext101_32x4d.gluon_in1k created, param count: 48955416
Running train benchmark on seresnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 141.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext101_32x4d.gluon_in1k created, param count: 48955416
Running train benchmark on seresnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 159.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnext101_32x4d.gluon_in1k created, param count: 48955416
Running train benchmark on seresnext101_32x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 320.22 samples/sec. 299.796 ms/step.
Train [16/40]. 320.22 samples/sec. 299.797 ms/step.
Train [24/40]. 320.22 samples/sec. 299.796 ms/step.
Train [32/40]. 320.22 samples/sec. 299.798 ms/step.
Train [40/40]. 320.21 samples/sec. 299.801 ms/step.
Train benchmark of seresnext101_32x4d.gluon_in1k done. 318.32 samples/sec, 299.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext101_32x8d.ah_in1k created, param count: 93569048
Running inference benchmark on seresnext101_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 435.12 samples/sec. 588.343 ms/step.
Infer [16/40]. 435.09 samples/sec. 588.388 ms/step.
Infer [24/40]. 435.06 samples/sec. 588.419 ms/step.
Infer [32/40]. 435.04 samples/sec. 588.457 ms/step.
Infer [40/40]. 435.04 samples/sec. 588.452 ms/step.
Inference benchmark of seresnext101_32x8d.ah_in1k done. 435.00 samples/sec, 588.45 ms/step
Model seresnext101_32x8d.ah_in1k created, param count: 93569048
Running train benchmark on seresnext101_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 23.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext101_32x8d.ah_in1k created, param count: 93569048
Running train benchmark on seresnext101_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 780.06 MiB is free. Including non-PyTorch memory, this process has 22.88 GiB memory in use. Of the allocated memory 22.15 GiB is allocated by PyTorch, and 242.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext101_32x8d.ah_in1k created, param count: 93569048
Running train benchmark on seresnext101_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 210.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 147.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnext101_32x8d.ah_in1k created, param count: 93569048
Running train benchmark on seresnext101_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 196.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnext101_32x8d.ah_in1k created, param count: 93569048
Running train benchmark on seresnext101_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 333.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model seresnext101_32x8d.ah_in1k created, param count: 93569048
Running train benchmark on seresnext101_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 127.78 samples/sec. 375.651 ms/step.
Train [16/40]. 127.78 samples/sec. 375.645 ms/step.
Train [24/40]. 127.78 samples/sec. 375.651 ms/step.
Train [32/40]. 127.77 samples/sec. 375.675 ms/step.
Train [40/40]. 127.76 samples/sec. 375.704 ms/step.
Train benchmark of seresnext101_32x8d.ah_in1k done. 127.14 samples/sec, 375.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext101_64x4d.gluon_in1k created, param count: 88232984
Running inference benchmark on seresnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 713.08 samples/sec. 359.007 ms/step.
Infer [16/40]. 713.04 samples/sec. 359.028 ms/step.
Infer [24/40]. 712.95 samples/sec. 359.070 ms/step.
Infer [32/40]. 712.89 samples/sec. 359.100 ms/step.
Infer [40/40]. 712.85 samples/sec. 359.124 ms/step.
Inference benchmark of seresnext101_64x4d.gluon_in1k done. 712.76 samples/sec, 359.12 ms/step
Model seresnext101_64x4d.gluon_in1k created, param count: 88232984
Running train benchmark on seresnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 246.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 18.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext101_64x4d.gluon_in1k created, param count: 88232984
Running train benchmark on seresnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 56.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext101_64x4d.gluon_in1k created, param count: 88232984
Running train benchmark on seresnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 229.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnext101_64x4d.gluon_in1k created, param count: 88232984
Running train benchmark on seresnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 165.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnext101_64x4d.gluon_in1k created, param count: 88232984
Running train benchmark on seresnext101_64x4d.gluon_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 213.55 samples/sec. 299.690 ms/step.
Train [16/40]. 213.56 samples/sec. 299.679 ms/step.
Train [24/40]. 213.56 samples/sec. 299.680 ms/step.
Train [32/40]. 213.55 samples/sec. 299.693 ms/step.
Train [40/40]. 213.55 samples/sec. 299.695 ms/step.
Train benchmark of seresnext101_64x4d.gluon_in1k done. 212.38 samples/sec, 299.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnext101d_32x8d.ah_in1k created, param count: 93588280
Running inference benchmark on seresnext101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 426.72 samples/sec. 599.930 ms/step.
Infer [16/40]. 426.67 samples/sec. 599.990 ms/step.
Infer [24/40]. 426.67 samples/sec. 600.001 ms/step.
Infer [32/40]. 426.64 samples/sec. 600.036 ms/step.
Infer [40/40]. 426.62 samples/sec. 600.064 ms/step.
Inference benchmark of seresnext101d_32x8d.ah_in1k done. 426.59 samples/sec, 600.06 ms/step
Model seresnext101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnext101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1022.06 MiB is free. Including non-PyTorch memory, this process has 22.64 GiB memory in use. Of the allocated memory 21.81 GiB is allocated by PyTorch, and 349.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnext101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnext101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 536.06 MiB is free. Including non-PyTorch memory, this process has 23.12 GiB memory in use. Of the allocated memory 22.14 GiB is allocated by PyTorch, and 487.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnext101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnext101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 147.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnext101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnext101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 186.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnext101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnext101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 189.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model seresnext101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnext101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
Train [8/40]. 124.89 samples/sec. 384.330 ms/step.
Train [16/40]. 124.89 samples/sec. 384.345 ms/step.
Train [24/40]. 124.88 samples/sec. 384.354 ms/step.
Train [32/40]. 124.87 samples/sec. 384.385 ms/step.
Train [40/40]. 124.87 samples/sec. 384.385 ms/step.
Train benchmark of seresnext101d_32x8d.ah_in1k done. 124.27 samples/sec, 384.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running inference benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 403.32 samples/sec. 634.737 ms/step.
Infer [16/40]. 403.30 samples/sec. 634.759 ms/step.
Infer [24/40]. 403.27 samples/sec. 634.805 ms/step.
Infer [32/40]. 403.26 samples/sec. 634.821 ms/step.
Infer [40/40]. 403.25 samples/sec. 634.844 ms/step.
Inference benchmark of seresnextaa101d_32x8d.ah_in1k done. 403.22 samples/sec, 634.84 ms/step
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 374.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 349.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 487.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 309.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 179.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 142.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 725.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model seresnextaa101d_32x8d.ah_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.ah_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
Train [8/40]. 121.24 samples/sec. 263.943 ms/step.
Train [16/40]. 121.25 samples/sec. 263.927 ms/step.
Train [24/40]. 121.24 samples/sec. 263.936 ms/step.
Train [32/40]. 121.24 samples/sec. 263.947 ms/step.
Train [40/40]. 121.23 samples/sec. 263.951 ms/step.
Train benchmark of seresnextaa101d_32x8d.ah_in1k done. 120.46 samples/sec, 263.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running inference benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 403.14 samples/sec. 635.019 ms/step.
Infer [16/40]. 403.13 samples/sec. 635.027 ms/step.
Infer [24/40]. 403.12 samples/sec. 635.044 ms/step.
Infer [32/40]. 403.12 samples/sec. 635.047 ms/step.
Infer [40/40]. 403.12 samples/sec. 635.049 ms/step.
Inference benchmark of seresnextaa101d_32x8d.sw_in12k done. 403.09 samples/sec, 635.05 ms/step
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running train benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 300.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 338.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running train benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 854.06 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Of the allocated memory 21.75 GiB is allocated by PyTorch, and 570.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running train benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 382.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running train benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 332.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running train benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 160.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running train benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 708.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model seresnextaa101d_32x8d.sw_in12k created, param count: 115760509
Running train benchmark on seresnextaa101d_32x8d.sw_in12k for 40 steps w/ input size (3, 288, 288) and batch size 32.
Train [8/40]. 120.65 samples/sec. 265.236 ms/step.
Train [16/40]. 120.63 samples/sec. 265.267 ms/step.
Train [24/40]. 120.64 samples/sec. 265.246 ms/step.
Train [32/40]. 120.64 samples/sec. 265.260 ms/step.
Train [40/40]. 120.64 samples/sec. 265.256 ms/step.
Train benchmark of seresnextaa101d_32x8d.sw_in12k done. 119.86 samples/sec, 265.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running inference benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
Infer [8/40]. 403.43 samples/sec. 634.551 ms/step.
Infer [16/40]. 403.40 samples/sec. 634.600 ms/step.
Infer [24/40]. 403.37 samples/sec. 634.651 ms/step.
Infer [32/40]. 403.37 samples/sec. 634.660 ms/step.
Infer [40/40]. 403.35 samples/sec. 634.680 ms/step.
Inference benchmark of seresnextaa101d_32x8d.sw_in12k_ft_in1k done. 403.32 samples/sec, 634.68 ms/step
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 374.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 349.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 487.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 309.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 176.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 179.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 191.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 725.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k for 40 steps w/ input size (3, 288, 288) and batch size 32.
Train [8/40]. 121.22 samples/sec. 263.977 ms/step.
Train [16/40]. 121.24 samples/sec. 263.934 ms/step.
Train [24/40]. 121.22 samples/sec. 263.980 ms/step.
Train [32/40]. 121.22 samples/sec. 263.984 ms/step.
Train [40/40]. 121.22 samples/sec. 263.982 ms/step.
Train benchmark of seresnextaa101d_32x8d.sw_in12k_ft_in1k done. 120.43 samples/sec, 263.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running inference benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 256.
Infer [8/40]. 331.26 samples/sec. 772.805 ms/step.
Infer [16/40]. 331.27 samples/sec. 772.795 ms/step.
Infer [24/40]. 331.26 samples/sec. 772.812 ms/step.
Infer [32/40]. 331.25 samples/sec. 772.820 ms/step.
Infer [40/40]. 331.24 samples/sec. 772.850 ms/step.
Inference benchmark of seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 done. 331.22 samples/sec, 772.85 ms/step
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.37 GiB is free. Including non-PyTorch memory, this process has 22.28 GiB memory in use. Of the allocated memory 21.36 GiB is allocated by PyTorch, and 425.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacty of 23.65 GiB of which 636.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 557.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 212.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 359.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 181.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 90.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 202.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 925.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 created, param count: 93588280
Running train benchmark on seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 for 40 steps w/ input size (3, 320, 320) and batch size 32.
Train [8/40]. 98.20 samples/sec. 325.858 ms/step.
Train [16/40]. 98.21 samples/sec. 325.847 ms/step.
Train [24/40]. 98.21 samples/sec. 325.820 ms/step.
Train [32/40]. 98.21 samples/sec. 325.829 ms/step.
Train [40/40]. 98.21 samples/sec. 325.841 ms/step.
Train benchmark of seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 done. 97.68 samples/sec, 325.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model skresnet18.ra_in1k created, param count: 11958056
Running inference benchmark on skresnet18.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 5041.75 samples/sec. 50.776 ms/step.
Infer [16/40]. 5039.45 samples/sec. 50.799 ms/step.
Infer [24/40]. 5039.49 samples/sec. 50.799 ms/step.
Infer [32/40]. 5041.10 samples/sec. 50.783 ms/step.
Infer [40/40]. 5040.85 samples/sec. 50.785 ms/step.
Inference benchmark of skresnet18.ra_in1k done. 5038.38 samples/sec, 50.78 ms/step
Model skresnet18.ra_in1k created, param count: 11958056
Running train benchmark on skresnet18.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1608.52 samples/sec. 159.152 ms/step.
Train [16/40]. 1608.65 samples/sec. 159.140 ms/step.
Train [24/40]. 1608.65 samples/sec. 159.140 ms/step.
Train [32/40]. 1608.45 samples/sec. 159.160 ms/step.
Train [40/40]. 1608.33 samples/sec. 159.171 ms/step.
Train benchmark of skresnet18.ra_in1k done. 1601.53 samples/sec, 159.17 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model skresnet34.ra_in1k created, param count: 22282376
Running inference benchmark on skresnet34.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2821.43 samples/sec. 90.734 ms/step.
Infer [16/40]. 2821.97 samples/sec. 90.717 ms/step.
Infer [24/40]. 2821.91 samples/sec. 90.719 ms/step.
Infer [32/40]. 2821.91 samples/sec. 90.719 ms/step.
Infer [40/40]. 2822.15 samples/sec. 90.711 ms/step.
Inference benchmark of skresnet34.ra_in1k done. 2821.33 samples/sec, 90.71 ms/step
Model skresnet34.ra_in1k created, param count: 22282376
Running train benchmark on skresnet34.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 931.29 samples/sec. 274.886 ms/step.
Train [16/40]. 931.24 samples/sec. 274.903 ms/step.
Train [24/40]. 931.32 samples/sec. 274.878 ms/step.
Train [32/40]. 931.26 samples/sec. 274.898 ms/step.
Train [40/40]. 931.25 samples/sec. 274.900 ms/step.
Train benchmark of skresnet34.ra_in1k done. 927.40 samples/sec, 274.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model skresnext50_32x4d.ra_in1k created, param count: 27479784
Running inference benchmark on skresnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1242.89 samples/sec. 205.971 ms/step.
Infer [16/40]. 1242.76 samples/sec. 205.993 ms/step.
Infer [24/40]. 1242.89 samples/sec. 205.972 ms/step.
Infer [32/40]. 1242.77 samples/sec. 205.992 ms/step.
Infer [40/40]. 1242.75 samples/sec. 205.994 ms/step.
Inference benchmark of skresnext50_32x4d.ra_in1k done. 1242.52 samples/sec, 205.99 ms/step
Model skresnext50_32x4d.ra_in1k created, param count: 27479784
Running train benchmark on skresnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 41.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model skresnext50_32x4d.ra_in1k created, param count: 27479784
Running train benchmark on skresnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 140.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model skresnext50_32x4d.ra_in1k created, param count: 27479784
Running train benchmark on skresnext50_32x4d.ra_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 390.45 samples/sec. 327.831 ms/step.
Train [16/40]. 390.40 samples/sec. 327.872 ms/step.
Train [24/40]. 390.38 samples/sec. 327.887 ms/step.
Train [32/40]. 390.34 samples/sec. 327.920 ms/step.
Train [40/40]. 390.33 samples/sec. 327.925 ms/step.
Train benchmark of skresnext50_32x4d.ra_in1k done. 388.77 samples/sec, 327.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model spnasnet_100.rmsp_in1k created, param count: 4421616
Running inference benchmark on spnasnet_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6265.94 samples/sec. 40.856 ms/step.
Infer [16/40]. 6266.05 samples/sec. 40.855 ms/step.
Infer [24/40]. 6265.95 samples/sec. 40.856 ms/step.
Infer [32/40]. 6266.06 samples/sec. 40.855 ms/step.
Infer [40/40]. 6266.25 samples/sec. 40.854 ms/step.
Inference benchmark of spnasnet_100.rmsp_in1k done. 6262.57 samples/sec, 40.85 ms/step
Model spnasnet_100.rmsp_in1k created, param count: 4421616
Running train benchmark on spnasnet_100.rmsp_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1660.54 samples/sec. 154.167 ms/step.
Train [16/40]. 1660.49 samples/sec. 154.171 ms/step.
Train [24/40]. 1660.44 samples/sec. 154.176 ms/step.
Train [32/40]. 1660.45 samples/sec. 154.175 ms/step.
Train [40/40]. 1660.46 samples/sec. 154.174 ms/step.
Train benchmark of spnasnet_100.rmsp_in1k done. 1652.12 samples/sec, 154.17 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_base_patch4_window7_224.ms_in1k created, param count: 87768224
Running inference benchmark on swin_base_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 854.58 samples/sec. 299.562 ms/step.
Infer [16/40]. 854.45 samples/sec. 299.608 ms/step.
Infer [24/40]. 854.38 samples/sec. 299.634 ms/step.
Infer [32/40]. 854.35 samples/sec. 299.645 ms/step.
Infer [40/40]. 854.33 samples/sec. 299.650 ms/step.
Inference benchmark of swin_base_patch4_window7_224.ms_in1k done. 854.21 samples/sec, 299.65 ms/step
Model swin_base_patch4_window7_224.ms_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 441.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window7_224.ms_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 303.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_base_patch4_window7_224.ms_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 470.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_base_patch4_window7_224.ms_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 291.95 samples/sec. 328.820 ms/step.
Train [16/40]. 291.89 samples/sec. 328.897 ms/step.
Train [24/40]. 291.86 samples/sec. 328.923 ms/step.
Train [32/40]. 291.84 samples/sec. 328.947 ms/step.
Train [40/40]. 291.83 samples/sec. 328.957 ms/step.
Train benchmark of swin_base_patch4_window7_224.ms_in1k done. 290.06 samples/sec, 328.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_base_patch4_window7_224.ms_in22k created, param count: 109130249
Running inference benchmark on swin_base_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 853.84 samples/sec. 299.823 ms/step.
Infer [16/40]. 853.77 samples/sec. 299.847 ms/step.
Infer [24/40]. 853.74 samples/sec. 299.857 ms/step.
Infer [32/40]. 853.72 samples/sec. 299.864 ms/step.
Infer [40/40]. 853.70 samples/sec. 299.871 ms/step.
Inference benchmark of swin_base_patch4_window7_224.ms_in22k done. 853.57 samples/sec, 299.87 ms/step
Model swin_base_patch4_window7_224.ms_in22k created, param count: 109130249
Running train benchmark on swin_base_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 250.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window7_224.ms_in22k created, param count: 109130249
Running train benchmark on swin_base_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 82.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 302.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_base_patch4_window7_224.ms_in22k created, param count: 109130249
Running train benchmark on swin_base_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 437.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_base_patch4_window7_224.ms_in22k created, param count: 109130249
Running train benchmark on swin_base_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 290.54 samples/sec. 330.423 ms/step.
Train [16/40]. 290.54 samples/sec. 330.417 ms/step.
Train [24/40]. 290.54 samples/sec. 330.417 ms/step.
Train [32/40]. 290.54 samples/sec. 330.418 ms/step.
Train [40/40]. 290.54 samples/sec. 330.418 ms/step.
Train benchmark of swin_base_patch4_window7_224.ms_in22k done. 288.77 samples/sec, 330.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_base_patch4_window7_224.ms_in22k_ft_in1k created, param count: 87768224
Running inference benchmark on swin_base_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 854.22 samples/sec. 299.688 ms/step.
Infer [16/40]. 854.22 samples/sec. 299.689 ms/step.
Infer [24/40]. 854.21 samples/sec. 299.691 ms/step.
Infer [32/40]. 854.21 samples/sec. 299.693 ms/step.
Infer [40/40]. 854.21 samples/sec. 299.692 ms/step.
Inference benchmark of swin_base_patch4_window7_224.ms_in22k_ft_in1k done. 854.09 samples/sec, 299.69 ms/step
Model swin_base_patch4_window7_224.ms_in22k_ft_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 441.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window7_224.ms_in22k_ft_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 303.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_base_patch4_window7_224.ms_in22k_ft_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 470.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_base_patch4_window7_224.ms_in22k_ft_in1k created, param count: 87768224
Running train benchmark on swin_base_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 291.84 samples/sec. 328.952 ms/step.
Train [16/40]. 291.81 samples/sec. 328.978 ms/step.
Train [24/40]. 291.82 samples/sec. 328.975 ms/step.
Train [32/40]. 291.80 samples/sec. 328.990 ms/step.
Train [40/40]. 291.80 samples/sec. 328.991 ms/step.
Train benchmark of swin_base_patch4_window7_224.ms_in22k_ft_in1k done. 289.92 samples/sec, 328.99 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running inference benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.21 GiB is free. Including non-PyTorch memory, this process has 20.43 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running inference benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 243.85 samples/sec. 787.368 ms/step.
Infer [16/40]. 243.84 samples/sec. 787.386 ms/step.
Infer [24/40]. 243.84 samples/sec. 787.387 ms/step.
Infer [32/40]. 243.84 samples/sec. 787.397 ms/step.
Infer [40/40]. 243.84 samples/sec. 787.399 ms/step.
Inference benchmark of swin_base_patch4_window12_384.ms_in1k done. 243.83 samples/sec, 787.40 ms/step
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.30 GiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 587.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 743.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process has 21.84 GiB memory in use. Of the allocated memory 20.85 GiB is allocated by PyTorch, and 503.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 412.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 362.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 221.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 295.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 514.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swin_base_patch4_window12_384.ms_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 85.47 samples/sec. 280.786 ms/step.
Train [16/40]. 85.47 samples/sec. 280.803 ms/step.
Train [24/40]. 85.47 samples/sec. 280.804 ms/step.
Train [32/40]. 85.47 samples/sec. 280.808 ms/step.
Train [40/40]. 85.47 samples/sec. 280.807 ms/step.
Train benchmark of swin_base_patch4_window12_384.ms_in1k done. 84.87 samples/sec, 280.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running inference benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.15 GiB is free. Including non-PyTorch memory, this process has 20.49 GiB memory in use. Of the allocated memory 13.23 GiB is allocated by PyTorch, and 6.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running inference benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 243.84 samples/sec. 787.389 ms/step.
Infer [16/40]. 243.84 samples/sec. 787.389 ms/step.
Infer [24/40]. 243.84 samples/sec. 787.391 ms/step.
Infer [32/40]. 243.84 samples/sec. 787.394 ms/step.
Infer [40/40]. 243.84 samples/sec. 787.393 ms/step.
Inference benchmark of swin_base_patch4_window12_384.ms_in22k done. 243.83 samples/sec, 787.39 ms/step
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.24 GiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.35 GiB is allocated by PyTorch, and 571.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.33 GiB is allocated by PyTorch, and 721.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.75 GiB is free. Including non-PyTorch memory, this process has 21.89 GiB memory in use. Of the allocated memory 20.93 GiB is allocated by PyTorch, and 467.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 386.06 MiB is free. Including non-PyTorch memory, this process has 23.26 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 307.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 163.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 335.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.55 GiB is allocated by PyTorch, and 489.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swin_base_patch4_window12_384.ms_in22k created, param count: 109265609
Running train benchmark on swin_base_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 85.07 samples/sec. 282.132 ms/step.
Train [16/40]. 85.07 samples/sec. 282.135 ms/step.
Train [24/40]. 85.06 samples/sec. 282.139 ms/step.
Train [32/40]. 85.06 samples/sec. 282.148 ms/step.
Train [40/40]. 85.06 samples/sec. 282.153 ms/step.
Train benchmark of swin_base_patch4_window12_384.ms_in22k done. 84.45 samples/sec, 282.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running inference benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.21 GiB is free. Including non-PyTorch memory, this process has 20.43 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running inference benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Infer [8/40]. 243.92 samples/sec. 787.142 ms/step.
Infer [16/40]. 243.92 samples/sec. 787.151 ms/step.
Infer [24/40]. 243.92 samples/sec. 787.154 ms/step.
Infer [32/40]. 243.92 samples/sec. 787.145 ms/step.
Infer [40/40]. 243.92 samples/sec. 787.146 ms/step.
Inference benchmark of swin_base_patch4_window12_384.ms_in22k_ft_in1k done. 243.90 samples/sec, 787.15 ms/step
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.30 GiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 587.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 743.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process has 21.84 GiB memory in use. Of the allocated memory 20.85 GiB is allocated by PyTorch, and 503.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 412.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 362.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 221.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 295.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 514.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swin_base_patch4_window12_384.ms_in22k_ft_in1k created, param count: 87903584
Running train benchmark on swin_base_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
Train [8/40]. 85.47 samples/sec. 280.804 ms/step.
Train [16/40]. 85.46 samples/sec. 280.826 ms/step.
Train [24/40]. 85.46 samples/sec. 280.832 ms/step.
Train [32/40]. 85.46 samples/sec. 280.829 ms/step.
Train [40/40]. 85.46 samples/sec. 280.833 ms/step.
Train benchmark of swin_base_patch4_window12_384.ms_in22k_ft_in1k done. 84.84 samples/sec, 280.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_large_patch4_window7_224.ms_in22k created, param count: 228565093
Running inference benchmark on swin_large_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 502.64 samples/sec. 509.308 ms/step.
Infer [16/40]. 502.63 samples/sec. 509.317 ms/step.
Infer [24/40]. 502.62 samples/sec. 509.326 ms/step.
Infer [32/40]. 502.63 samples/sec. 509.324 ms/step.
Infer [40/40]. 502.63 samples/sec. 509.325 ms/step.
Inference benchmark of swin_large_patch4_window7_224.ms_in22k done. 502.58 samples/sec, 509.32 ms/step
Model swin_large_patch4_window7_224.ms_in22k created, param count: 228565093
Running train benchmark on swin_large_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.88 GiB is free. Including non-PyTorch memory, this process has 21.76 GiB memory in use. Of the allocated memory 20.61 GiB is allocated by PyTorch, and 669.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_large_patch4_window7_224.ms_in22k created, param count: 228565093
Running train benchmark on swin_large_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 364.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 312.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_large_patch4_window7_224.ms_in22k created, param count: 228565093
Running train benchmark on swin_large_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 76.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 450.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_large_patch4_window7_224.ms_in22k created, param count: 228565093
Running train benchmark on swin_large_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 613.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_large_patch4_window7_224.ms_in22k created, param count: 228565093
Running train benchmark on swin_large_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.02 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swin_large_patch4_window7_224.ms_in22k created, param count: 228565093
Running train benchmark on swin_large_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 159.00 samples/sec. 301.887 ms/step.
Train [16/40]. 158.99 samples/sec. 301.898 ms/step.
Train [24/40]. 158.99 samples/sec. 301.911 ms/step.
Train [32/40]. 158.99 samples/sec. 301.905 ms/step.
Train [40/40]. 158.99 samples/sec. 301.903 ms/step.
Train benchmark of swin_large_patch4_window7_224.ms_in22k done. 157.90 samples/sec, 301.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_large_patch4_window7_224.ms_in22k_ft_in1k created, param count: 196532476
Running inference benchmark on swin_large_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 502.89 samples/sec. 509.062 ms/step.
Infer [16/40]. 502.88 samples/sec. 509.065 ms/step.
Infer [24/40]. 502.88 samples/sec. 509.067 ms/step.
Infer [32/40]. 502.87 samples/sec. 509.073 ms/step.
Infer [40/40]. 502.87 samples/sec. 509.073 ms/step.
Inference benchmark of swin_large_patch4_window7_224.ms_in22k_ft_in1k done. 502.83 samples/sec, 509.07 ms/step
Model swin_large_patch4_window7_224.ms_in22k_ft_in1k created, param count: 196532476
Running train benchmark on swin_large_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.01 GiB is free. Including non-PyTorch memory, this process has 21.63 GiB memory in use. Of the allocated memory 20.49 GiB is allocated by PyTorch, and 663.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_large_patch4_window7_224.ms_in22k_ft_in1k created, param count: 196532476
Running train benchmark on swin_large_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 472.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 326.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_large_patch4_window7_224.ms_in22k_ft_in1k created, param count: 196532476
Running train benchmark on swin_large_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 84.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 564.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_large_patch4_window7_224.ms_in22k_ft_in1k created, param count: 196532476
Running train benchmark on swin_large_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 611.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_large_patch4_window7_224.ms_in22k_ft_in1k created, param count: 196532476
Running train benchmark on swin_large_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 166.61 samples/sec. 384.137 ms/step.
Train [16/40]. 166.61 samples/sec. 384.141 ms/step.
Train [24/40]. 166.61 samples/sec. 384.139 ms/step.
Train [32/40]. 166.60 samples/sec. 384.150 ms/step.
Train [40/40]. 166.59 samples/sec. 384.188 ms/step.
Train benchmark of swin_large_patch4_window7_224.ms_in22k_ft_in1k done. 165.64 samples/sec, 384.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running inference benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.59 GiB is free. Including non-PyTorch memory, this process has 17.05 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 64.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running inference benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 54.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 18.29 GiB is allocated by PyTorch, and 4.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running inference benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 145.52 samples/sec. 879.596 ms/step.
Infer [16/40]. 145.52 samples/sec. 879.577 ms/step.
Infer [24/40]. 145.52 samples/sec. 879.582 ms/step.
Infer [32/40]. 145.52 samples/sec. 879.590 ms/step.
Infer [40/40]. 145.52 samples/sec. 879.580 ms/step.
Inference benchmark of swin_large_patch4_window12_384.ms_in22k done. 145.52 samples/sec, 879.58 ms/step
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.86 GiB is free. Including non-PyTorch memory, this process has 18.78 GiB memory in use. Of the allocated memory 18.21 GiB is allocated by PyTorch, and 68.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.22 GiB is free. Including non-PyTorch memory, this process has 20.42 GiB memory in use. Of the allocated memory 19.58 GiB is allocated by PyTorch, and 357.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 726.06 MiB is free. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 656.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 21.00 GiB is allocated by PyTorch, and 740.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 962.06 MiB is free. Including non-PyTorch memory, this process has 22.70 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 314.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 198.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 443.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 639.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model swin_large_patch4_window12_384.ms_in22k created, param count: 228768133
Running train benchmark on swin_large_patch4_window12_384.ms_in22k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 47.12 samples/sec. 339.564 ms/step.
Train [16/40]. 47.12 samples/sec. 339.575 ms/step.
Train [24/40]. 47.12 samples/sec. 339.578 ms/step.
Train [32/40]. 47.12 samples/sec. 339.586 ms/step.
Train [40/40]. 47.12 samples/sec. 339.585 ms/step.
Train benchmark of swin_large_patch4_window12_384.ms_in22k done. 46.82 samples/sec, 339.58 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running inference benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.71 GiB is free. Including non-PyTorch memory, this process has 16.93 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 58.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running inference benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 182.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 18.17 GiB is allocated by PyTorch, and 4.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running inference benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
Infer [8/40]. 145.62 samples/sec. 879.007 ms/step.
Infer [16/40]. 145.62 samples/sec. 879.008 ms/step.
Infer [24/40]. 145.61 samples/sec. 879.072 ms/step.
Infer [32/40]. 145.60 samples/sec. 879.125 ms/step.
Infer [40/40]. 145.59 samples/sec. 879.152 ms/step.
Inference benchmark of swin_large_patch4_window12_384.ms_in22k_ft_in1k done. 145.59 samples/sec, 879.15 ms/step
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.99 GiB is free. Including non-PyTorch memory, this process has 18.65 GiB memory in use. Of the allocated memory 18.10 GiB is allocated by PyTorch, and 62.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.34 GiB is free. Including non-PyTorch memory, this process has 20.30 GiB memory in use. Of the allocated memory 19.46 GiB is allocated by PyTorch, and 350.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 818.06 MiB is free. Including non-PyTorch memory, this process has 22.84 GiB memory in use. Of the allocated memory 21.68 GiB is allocated by PyTorch, and 686.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.50 GiB is free. Including non-PyTorch memory, this process has 22.14 GiB memory in use. Of the allocated memory 20.89 GiB is allocated by PyTorch, and 775.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 287.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 250.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 356.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 667.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model swin_large_patch4_window12_384.ms_in22k_ft_in1k created, param count: 196735516
Running train benchmark on swin_large_patch4_window12_384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
Train [8/40]. 47.43 samples/sec. 337.356 ms/step.
Train [16/40]. 47.43 samples/sec. 337.357 ms/step.
Train [24/40]. 47.43 samples/sec. 337.362 ms/step.
Train [32/40]. 47.42 samples/sec. 337.419 ms/step.
Train [40/40]. 47.41 samples/sec. 337.457 ms/step.
Train benchmark of swin_large_patch4_window12_384.ms_in22k_ft_in1k done. 47.12 samples/sec, 337.46 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_s3_base_224.ms_in1k created, param count: 71125762
Running inference benchmark on swin_s3_base_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 768.95 samples/sec. 332.921 ms/step.
Infer [16/40]. 768.95 samples/sec. 332.923 ms/step.
Infer [24/40]. 768.95 samples/sec. 332.921 ms/step.
Infer [32/40]. 768.95 samples/sec. 332.924 ms/step.
Infer [40/40]. 768.94 samples/sec. 332.926 ms/step.
Inference benchmark of swin_s3_base_224.ms_in1k done. 768.84 samples/sec, 332.93 ms/step
Model swin_s3_base_224.ms_in1k created, param count: 71125762
Running train benchmark on swin_s3_base_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 144.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_s3_base_224.ms_in1k created, param count: 71125762
Running train benchmark on swin_s3_base_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 154.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_s3_base_224.ms_in1k created, param count: 71125762
Running train benchmark on swin_s3_base_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 226.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 265.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_s3_base_224.ms_in1k created, param count: 71125762
Running train benchmark on swin_s3_base_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 625.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swin_s3_base_224.ms_in1k created, param count: 71125762
Running train benchmark on swin_s3_base_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
Train [8/40]. 258.50 samples/sec. 247.582 ms/step.
Train [16/40]. 258.51 samples/sec. 247.571 ms/step.
Train [24/40]. 258.47 samples/sec. 247.608 ms/step.
Train [32/40]. 258.44 samples/sec. 247.639 ms/step.
Train [40/40]. 258.42 samples/sec. 247.657 ms/step.
Train benchmark of swin_s3_base_224.ms_in1k done. 255.64 samples/sec, 247.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_s3_small_224.ms_in1k created, param count: 49737298
Running inference benchmark on swin_s3_small_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 967.68 samples/sec. 264.551 ms/step.
Infer [16/40]. 967.69 samples/sec. 264.547 ms/step.
Infer [24/40]. 967.70 samples/sec. 264.545 ms/step.
Infer [32/40]. 967.70 samples/sec. 264.545 ms/step.
Infer [40/40]. 967.72 samples/sec. 264.538 ms/step.
Inference benchmark of swin_s3_small_224.ms_in1k done. 967.57 samples/sec, 264.54 ms/step
Model swin_s3_small_224.ms_in1k created, param count: 49737298
Running train benchmark on swin_s3_small_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 130.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_s3_small_224.ms_in1k created, param count: 49737298
Running train benchmark on swin_s3_small_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 541.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_s3_small_224.ms_in1k created, param count: 49737298
Running train benchmark on swin_s3_small_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 136.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 283.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swin_s3_small_224.ms_in1k created, param count: 49737298
Running train benchmark on swin_s3_small_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 330.01 samples/sec. 290.900 ms/step.
Train [16/40]. 330.00 samples/sec. 290.908 ms/step.
Train [24/40]. 330.02 samples/sec. 290.895 ms/step.
Train [32/40]. 330.02 samples/sec. 290.888 ms/step.
Train [40/40]. 330.03 samples/sec. 290.882 ms/step.
Train benchmark of swin_s3_small_224.ms_in1k done. 327.73 samples/sec, 290.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_s3_tiny_224.ms_in1k created, param count: 28328674
Running inference benchmark on swin_s3_tiny_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1874.23 samples/sec. 136.590 ms/step.
Infer [16/40]. 1874.27 samples/sec. 136.586 ms/step.
Infer [24/40]. 1874.27 samples/sec. 136.587 ms/step.
Infer [32/40]. 1874.23 samples/sec. 136.590 ms/step.
Infer [40/40]. 1874.26 samples/sec. 136.587 ms/step.
Inference benchmark of swin_s3_tiny_224.ms_in1k done. 1873.85 samples/sec, 136.59 ms/step
Model swin_s3_tiny_224.ms_in1k created, param count: 28328674
Running train benchmark on swin_s3_tiny_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 458.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_s3_tiny_224.ms_in1k created, param count: 28328674
Running train benchmark on swin_s3_tiny_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 603.88 samples/sec. 317.945 ms/step.
Train [16/40]. 603.87 samples/sec. 317.947 ms/step.
Train [24/40]. 603.88 samples/sec. 317.944 ms/step.
Train [32/40]. 603.87 samples/sec. 317.948 ms/step.
Train [40/40]. 603.86 samples/sec. 317.953 ms/step.
Train benchmark of swin_s3_tiny_224.ms_in1k done. 601.46 samples/sec, 317.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_small_patch4_window7_224.ms_in1k created, param count: 49606258
Running inference benchmark on swin_small_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1211.34 samples/sec. 211.336 ms/step.
Infer [16/40]. 1211.28 samples/sec. 211.347 ms/step.
Infer [24/40]. 1211.29 samples/sec. 211.345 ms/step.
Infer [32/40]. 1211.25 samples/sec. 211.352 ms/step.
Infer [40/40]. 1211.24 samples/sec. 211.354 ms/step.
Inference benchmark of swin_small_patch4_window7_224.ms_in1k done. 1211.03 samples/sec, 211.35 ms/step
Model swin_small_patch4_window7_224.ms_in1k created, param count: 49606258
Running train benchmark on swin_small_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 407.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_small_patch4_window7_224.ms_in1k created, param count: 49606258
Running train benchmark on swin_small_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 524.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_small_patch4_window7_224.ms_in1k created, param count: 49606258
Running train benchmark on swin_small_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 412.68 samples/sec. 310.167 ms/step.
Train [16/40]. 412.68 samples/sec. 310.170 ms/step.
Train [24/40]. 412.68 samples/sec. 310.165 ms/step.
Train [32/40]. 412.67 samples/sec. 310.173 ms/step.
Train [40/40]. 412.67 samples/sec. 310.175 ms/step.
Train benchmark of swin_small_patch4_window7_224.ms_in1k done. 410.04 samples/sec, 310.18 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_small_patch4_window7_224.ms_in22k created, param count: 65632987
Running inference benchmark on swin_small_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1210.36 samples/sec. 211.507 ms/step.
Infer [16/40]. 1210.24 samples/sec. 211.529 ms/step.
Infer [24/40]. 1210.20 samples/sec. 211.535 ms/step.
Infer [32/40]. 1210.15 samples/sec. 211.545 ms/step.
Infer [40/40]. 1210.13 samples/sec. 211.548 ms/step.
Inference benchmark of swin_small_patch4_window7_224.ms_in22k done. 1209.90 samples/sec, 211.55 ms/step
Model swin_small_patch4_window7_224.ms_in22k created, param count: 65632987
Running train benchmark on swin_small_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 350.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_small_patch4_window7_224.ms_in22k created, param count: 65632987
Running train benchmark on swin_small_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.34 GiB is allocated by PyTorch, and 671.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_small_patch4_window7_224.ms_in22k created, param count: 65632987
Running train benchmark on swin_small_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 411.05 samples/sec. 311.396 ms/step.
Train [16/40]. 411.05 samples/sec. 311.395 ms/step.
Train [24/40]. 411.04 samples/sec. 311.404 ms/step.
Train [32/40]. 411.04 samples/sec. 311.403 ms/step.
Train [40/40]. 411.05 samples/sec. 311.400 ms/step.
Train benchmark of swin_small_patch4_window7_224.ms_in22k done. 408.38 samples/sec, 311.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_small_patch4_window7_224.ms_in22k_ft_in1k created, param count: 49606258
Running inference benchmark on swin_small_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1211.12 samples/sec. 211.375 ms/step.
Infer [16/40]. 1211.05 samples/sec. 211.387 ms/step.
Infer [24/40]. 1211.04 samples/sec. 211.388 ms/step.
Infer [32/40]. 1211.03 samples/sec. 211.390 ms/step.
Infer [40/40]. 1211.05 samples/sec. 211.386 ms/step.
Inference benchmark of swin_small_patch4_window7_224.ms_in22k_ft_in1k done. 1210.82 samples/sec, 211.39 ms/step
Model swin_small_patch4_window7_224.ms_in22k_ft_in1k created, param count: 49606258
Running train benchmark on swin_small_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 407.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_small_patch4_window7_224.ms_in22k_ft_in1k created, param count: 49606258
Running train benchmark on swin_small_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 524.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swin_small_patch4_window7_224.ms_in22k_ft_in1k created, param count: 49606258
Running train benchmark on swin_small_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 412.62 samples/sec. 310.209 ms/step.
Train [16/40]. 412.57 samples/sec. 310.254 ms/step.
Train [24/40]. 412.53 samples/sec. 310.284 ms/step.
Train [32/40]. 412.50 samples/sec. 310.303 ms/step.
Train [40/40]. 412.49 samples/sec. 310.314 ms/step.
Train benchmark of swin_small_patch4_window7_224.ms_in22k_ft_in1k done. 409.70 samples/sec, 310.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_tiny_patch4_window7_224.ms_in1k created, param count: 28288354
Running inference benchmark on swin_tiny_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1987.44 samples/sec. 128.809 ms/step.
Infer [16/40]. 1987.45 samples/sec. 128.808 ms/step.
Infer [24/40]. 1987.50 samples/sec. 128.805 ms/step.
Infer [32/40]. 1987.42 samples/sec. 128.810 ms/step.
Infer [40/40]. 1987.43 samples/sec. 128.809 ms/step.
Inference benchmark of swin_tiny_patch4_window7_224.ms_in1k done. 1986.94 samples/sec, 128.81 ms/step
Model swin_tiny_patch4_window7_224.ms_in1k created, param count: 28288354
Running train benchmark on swin_tiny_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 400.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_tiny_patch4_window7_224.ms_in1k created, param count: 28288354
Running train benchmark on swin_tiny_patch4_window7_224.ms_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 642.72 samples/sec. 298.732 ms/step.
Train [16/40]. 642.70 samples/sec. 298.739 ms/step.
Train [24/40]. 642.69 samples/sec. 298.744 ms/step.
Train [32/40]. 642.70 samples/sec. 298.739 ms/step.
Train [40/40]. 642.70 samples/sec. 298.741 ms/step.
Train benchmark of swin_tiny_patch4_window7_224.ms_in1k done. 639.90 samples/sec, 298.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_tiny_patch4_window7_224.ms_in22k created, param count: 44315083
Running inference benchmark on swin_tiny_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1985.72 samples/sec. 128.921 ms/step.
Infer [16/40]. 1985.52 samples/sec. 128.934 ms/step.
Infer [24/40]. 1985.42 samples/sec. 128.940 ms/step.
Infer [32/40]. 1985.41 samples/sec. 128.941 ms/step.
Infer [40/40]. 1985.40 samples/sec. 128.941 ms/step.
Inference benchmark of swin_tiny_patch4_window7_224.ms_in22k done. 1984.91 samples/sec, 128.94 ms/step
Model swin_tiny_patch4_window7_224.ms_in22k created, param count: 44315083
Running train benchmark on swin_tiny_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 403.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_tiny_patch4_window7_224.ms_in22k created, param count: 44315083
Running train benchmark on swin_tiny_patch4_window7_224.ms_in22k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 640.06 samples/sec. 299.970 ms/step.
Train [16/40]. 640.04 samples/sec. 299.982 ms/step.
Train [24/40]. 640.03 samples/sec. 299.984 ms/step.
Train [32/40]. 640.03 samples/sec. 299.986 ms/step.
Train [40/40]. 640.03 samples/sec. 299.984 ms/step.
Train benchmark of swin_tiny_patch4_window7_224.ms_in22k done. 637.22 samples/sec, 299.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swin_tiny_patch4_window7_224.ms_in22k_ft_in1k created, param count: 28288354
Running inference benchmark on swin_tiny_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1987.88 samples/sec. 128.780 ms/step.
Infer [16/40]. 1987.86 samples/sec. 128.782 ms/step.
Infer [24/40]. 1987.88 samples/sec. 128.780 ms/step.
Infer [32/40]. 1987.85 samples/sec. 128.782 ms/step.
Infer [40/40]. 1987.76 samples/sec. 128.788 ms/step.
Inference benchmark of swin_tiny_patch4_window7_224.ms_in22k_ft_in1k done. 1987.28 samples/sec, 128.79 ms/step
Model swin_tiny_patch4_window7_224.ms_in22k_ft_in1k created, param count: 28288354
Running train benchmark on swin_tiny_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 174.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 400.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swin_tiny_patch4_window7_224.ms_in22k_ft_in1k created, param count: 28288354
Running train benchmark on swin_tiny_patch4_window7_224.ms_in22k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 642.73 samples/sec. 298.728 ms/step.
Train [16/40]. 642.74 samples/sec. 298.720 ms/step.
Train [24/40]. 642.74 samples/sec. 298.720 ms/step.
Train [32/40]. 642.74 samples/sec. 298.723 ms/step.
Train [40/40]. 642.73 samples/sec. 298.726 ms/step.
Train benchmark of swin_tiny_patch4_window7_224.ms_in22k_ft_in1k done. 639.97 samples/sec, 298.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_base_window8_256.ms_in1k created, param count: 87918816
Running inference benchmark on swinv2_base_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 604.35 samples/sec. 423.599 ms/step.
Infer [16/40]. 604.36 samples/sec. 423.588 ms/step.
Infer [24/40]. 604.36 samples/sec. 423.588 ms/step.
Infer [32/40]. 604.32 samples/sec. 423.614 ms/step.
Infer [40/40]. 604.29 samples/sec. 423.637 ms/step.
Inference benchmark of swinv2_base_window8_256.ms_in1k done. 604.23 samples/sec, 423.64 ms/step
Model swinv2_base_window8_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 448.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 14.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_base_window8_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 564.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 204.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_base_window8_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 242.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 70.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_base_window8_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 190.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 124.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_base_window8_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.10 GiB is allocated by PyTorch, and 20.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_base_window8_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
Train [8/40]. 195.67 samples/sec. 245.317 ms/step.
Train [16/40]. 195.66 samples/sec. 245.324 ms/step.
Train [24/40]. 195.65 samples/sec. 245.330 ms/step.
Train [32/40]. 195.65 samples/sec. 245.336 ms/step.
Train [40/40]. 195.65 samples/sec. 245.342 ms/step.
Train benchmark of swinv2_base_window8_256.ms_in1k done. 193.80 samples/sec, 245.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_base_window12_192.ms_in22k created, param count: 109280841
Running inference benchmark on swinv2_base_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 256.
Infer [8/40]. 917.92 samples/sec. 278.892 ms/step.
Infer [16/40]. 917.93 samples/sec. 278.887 ms/step.
Infer [24/40]. 917.94 samples/sec. 278.886 ms/step.
Infer [32/40]. 917.92 samples/sec. 278.891 ms/step.
Infer [40/40]. 917.90 samples/sec. 278.897 ms/step.
Inference benchmark of swinv2_base_window12_192.ms_in22k done. 917.76 samples/sec, 278.90 ms/step
Model swinv2_base_window12_192.ms_in22k created, param count: 109280841
Running train benchmark on swinv2_base_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 149.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_base_window12_192.ms_in22k created, param count: 109280841
Running train benchmark on swinv2_base_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 92.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_base_window12_192.ms_in22k created, param count: 109280841
Running train benchmark on swinv2_base_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 116.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 258.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_base_window12_192.ms_in22k created, param count: 109280841
Running train benchmark on swinv2_base_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 227.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_base_window12_192.ms_in22k created, param count: 109280841
Running train benchmark on swinv2_base_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 64.
Train [8/40]. 277.61 samples/sec. 230.541 ms/step.
Train [16/40]. 277.62 samples/sec. 230.533 ms/step.
Train [24/40]. 277.62 samples/sec. 230.533 ms/step.
Train [32/40]. 277.57 samples/sec. 230.569 ms/step.
Train [40/40]. 277.55 samples/sec. 230.592 ms/step.
Train benchmark of swinv2_base_window12_192.ms_in22k done. 274.84 samples/sec, 230.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running inference benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 412.13 samples/sec. 621.161 ms/step.
Infer [16/40]. 412.14 samples/sec. 621.154 ms/step.
Infer [24/40]. 412.14 samples/sec. 621.153 ms/step.
Infer [32/40]. 412.14 samples/sec. 621.153 ms/step.
Infer [40/40]. 412.14 samples/sec. 621.152 ms/step.
Inference benchmark of swinv2_base_window12to16_192to256.ms_in22k_ft_in1k done. 412.11 samples/sec, 621.15 ms/step
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 434.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 21.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.45 GiB is free. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 20.50 GiB is allocated by PyTorch, and 205.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 1018.06 MiB is free. Including non-PyTorch memory, this process has 22.65 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 86.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 79.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 38.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 17.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swinv2_base_window12to16_192to256.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 32.
Train [8/40]. 128.87 samples/sec. 248.312 ms/step.
Train [16/40]. 128.87 samples/sec. 248.314 ms/step.
Train [24/40]. 128.85 samples/sec. 248.359 ms/step.
Train [32/40]. 128.83 samples/sec. 248.385 ms/step.
Train [40/40]. 128.82 samples/sec. 248.400 ms/step.
Train benchmark of swinv2_base_window12to16_192to256.ms_in22k_ft_in1k done. 127.63 samples/sec, 248.40 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running inference benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 20.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 12.14 GiB is free. Including non-PyTorch memory, this process has 11.50 GiB memory in use. Of the allocated memory 10.97 GiB is allocated by PyTorch, and 33.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running inference benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 15.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 14.51 GiB is free. Including non-PyTorch memory, this process has 9.13 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 302.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running inference benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.40 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.57 GiB is allocated by PyTorch, and 172.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running inference benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
Infer [8/40]. 111.92 samples/sec. 857.766 ms/step.
Infer [16/40]. 111.91 samples/sec. 857.847 ms/step.
Infer [24/40]. 111.91 samples/sec. 857.869 ms/step.
Infer [32/40]. 111.90 samples/sec. 857.874 ms/step.
Infer [40/40]. 111.91 samples/sec. 857.870 ms/step.
Inference benchmark of swinv2_base_window12to24_192to384.ms_in22k_ft_in1k done. 111.90 samples/sec, 857.87 ms/step
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 20.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.85 GiB is free. Including non-PyTorch memory, this process has 12.79 GiB memory in use. Of the allocated memory 12.26 GiB is allocated by PyTorch, and 35.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 15.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 13.65 GiB is free. Including non-PyTorch memory, this process has 9.99 GiB memory in use. Of the allocated memory 9.30 GiB is allocated by PyTorch, and 192.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 10.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.63 GiB is free. Including non-PyTorch memory, this process has 16.02 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 183.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 7.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.59 GiB is free. Including non-PyTorch memory, this process has 20.05 GiB memory in use. Of the allocated memory 19.22 GiB is allocated by PyTorch, and 343.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.46 GiB is free. Including non-PyTorch memory, this process has 20.19 GiB memory in use. Of the allocated memory 19.47 GiB is allocated by PyTorch, and 225.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 916.06 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 357.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 372.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 413.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 384.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 318.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 273.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model swinv2_base_window12to24_192to384.ms_in22k_ft_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
Train [8/40]. 35.00 samples/sec. 228.582 ms/step.
Train [16/40]. 35.00 samples/sec. 228.593 ms/step.
Train [24/40]. 35.00 samples/sec. 228.591 ms/step.
Train [32/40]. 35.00 samples/sec. 228.591 ms/step.
Train [40/40]. 35.00 samples/sec. 228.593 ms/step.
Train benchmark of swinv2_base_window12to24_192to384.ms_in22k_ft_in1k done. 34.65 samples/sec, 228.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running inference benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 412.27 samples/sec. 620.948 ms/step.
Infer [16/40]. 412.19 samples/sec. 621.067 ms/step.
Infer [24/40]. 412.17 samples/sec. 621.104 ms/step.
Infer [32/40]. 412.16 samples/sec. 621.124 ms/step.
Infer [40/40]. 412.15 samples/sec. 621.135 ms/step.
Inference benchmark of swinv2_base_window16_256.ms_in1k done. 412.11 samples/sec, 621.13 ms/step
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 434.06 MiB is free. Including non-PyTorch memory, this process has 23.22 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 21.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.45 GiB is free. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 20.50 GiB is allocated by PyTorch, and 205.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 1018.06 MiB is free. Including non-PyTorch memory, this process has 22.65 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 86.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 79.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 38.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 17.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swinv2_base_window16_256.ms_in1k created, param count: 87918816
Running train benchmark on swinv2_base_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 32.
Train [8/40]. 128.99 samples/sec. 248.087 ms/step.
Train [16/40]. 128.98 samples/sec. 248.106 ms/step.
Train [24/40]. 128.97 samples/sec. 248.115 ms/step.
Train [32/40]. 128.96 samples/sec. 248.132 ms/step.
Train [40/40]. 128.95 samples/sec. 248.158 ms/step.
Train benchmark of swinv2_base_window16_256.ms_in1k done. 127.73 samples/sec, 248.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_cr_small_224.sw_in1k created, param count: 49695100
Running inference benchmark on swinv2_cr_small_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1103.82 samples/sec. 231.923 ms/step.
Infer [16/40]. 1103.82 samples/sec. 231.922 ms/step.
Infer [24/40]. 1103.82 samples/sec. 231.921 ms/step.
Infer [32/40]. 1103.81 samples/sec. 231.924 ms/step.
Infer [40/40]. 1103.80 samples/sec. 231.926 ms/step.
Inference benchmark of swinv2_cr_small_224.sw_in1k done. 1103.61 samples/sec, 231.93 ms/step
Model swinv2_cr_small_224.sw_in1k created, param count: 49695100
Running train benchmark on swinv2_cr_small_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 135.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_cr_small_224.sw_in1k created, param count: 49695100
Running train benchmark on swinv2_cr_small_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 200.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 234.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_cr_small_224.sw_in1k created, param count: 49695100
Running train benchmark on swinv2_cr_small_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 469.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_cr_small_224.sw_in1k created, param count: 49695100
Running train benchmark on swinv2_cr_small_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 351.81 samples/sec. 272.873 ms/step.
Train [16/40]. 351.80 samples/sec. 272.885 ms/step.
Train [24/40]. 351.81 samples/sec. 272.878 ms/step.
Train [32/40]. 351.81 samples/sec. 272.877 ms/step.
Train [40/40]. 351.80 samples/sec. 272.883 ms/step.
Train benchmark of swinv2_cr_small_224.sw_in1k done. 348.78 samples/sec, 272.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_cr_small_ns_224.sw_in1k created, param count: 49696444
Running inference benchmark on swinv2_cr_small_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1096.35 samples/sec. 233.502 ms/step.
Infer [16/40]. 1096.34 samples/sec. 233.504 ms/step.
Infer [24/40]. 1096.31 samples/sec. 233.512 ms/step.
Infer [32/40]. 1096.29 samples/sec. 233.516 ms/step.
Infer [40/40]. 1096.25 samples/sec. 233.523 ms/step.
Inference benchmark of swinv2_cr_small_ns_224.sw_in1k done. 1096.07 samples/sec, 233.52 ms/step
Model swinv2_cr_small_ns_224.sw_in1k created, param count: 49696444
Running train benchmark on swinv2_cr_small_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 91.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_cr_small_ns_224.sw_in1k created, param count: 49696444
Running train benchmark on swinv2_cr_small_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 66.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 198.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_cr_small_ns_224.sw_in1k created, param count: 49696444
Running train benchmark on swinv2_cr_small_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 464.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_cr_small_ns_224.sw_in1k created, param count: 49696444
Running train benchmark on swinv2_cr_small_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 348.67 samples/sec. 275.334 ms/step.
Train [16/40]. 348.62 samples/sec. 275.372 ms/step.
Train [24/40]. 348.62 samples/sec. 275.374 ms/step.
Train [32/40]. 348.61 samples/sec. 275.377 ms/step.
Train [40/40]. 348.61 samples/sec. 275.376 ms/step.
Train benchmark of swinv2_cr_small_ns_224.sw_in1k done. 345.53 samples/sec, 275.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_cr_tiny_ns_224.sw_in1k created, param count: 28333468
Running inference benchmark on swinv2_cr_tiny_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1789.94 samples/sec. 143.022 ms/step.
Infer [16/40]. 1789.95 samples/sec. 143.021 ms/step.
Infer [24/40]. 1789.97 samples/sec. 143.019 ms/step.
Infer [32/40]. 1789.98 samples/sec. 143.018 ms/step.
Infer [40/40]. 1789.99 samples/sec. 143.018 ms/step.
Inference benchmark of swinv2_cr_tiny_ns_224.sw_in1k done. 1789.59 samples/sec, 143.02 ms/step
Model swinv2_cr_tiny_ns_224.sw_in1k created, param count: 28333468
Running train benchmark on swinv2_cr_tiny_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 264.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 86.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_cr_tiny_ns_224.sw_in1k created, param count: 28333468
Running train benchmark on swinv2_cr_tiny_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 257.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_cr_tiny_ns_224.sw_in1k created, param count: 28333468
Running train benchmark on swinv2_cr_tiny_ns_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 541.25 samples/sec. 236.490 ms/step.
Train [16/40]. 541.24 samples/sec. 236.496 ms/step.
Train [24/40]. 541.24 samples/sec. 236.493 ms/step.
Train [32/40]. 541.24 samples/sec. 236.496 ms/step.
Train [40/40]. 541.24 samples/sec. 236.493 ms/step.
Train benchmark of swinv2_cr_tiny_ns_224.sw_in1k done. 537.96 samples/sec, 236.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_large_window12_192.ms_in22k created, param count: 228772549
Running inference benchmark on swinv2_large_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 256.
Infer [8/40]. 552.89 samples/sec. 463.017 ms/step.
Infer [16/40]. 552.87 samples/sec. 463.036 ms/step.
Infer [24/40]. 552.86 samples/sec. 463.044 ms/step.
Infer [32/40]. 552.86 samples/sec. 463.045 ms/step.
Infer [40/40]. 552.86 samples/sec. 463.048 ms/step.
Inference benchmark of swinv2_large_window12_192.ms_in22k done. 552.80 samples/sec, 463.05 ms/step
Model swinv2_large_window12_192.ms_in22k created, param count: 228772549
Running train benchmark on swinv2_large_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 120.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 415.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_large_window12_192.ms_in22k created, param count: 228772549
Running train benchmark on swinv2_large_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 730.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 329.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_large_window12_192.ms_in22k created, param count: 228772549
Running train benchmark on swinv2_large_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 78.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_large_window12_192.ms_in22k created, param count: 228772549
Running train benchmark on swinv2_large_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 420.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_large_window12_192.ms_in22k created, param count: 228772549
Running train benchmark on swinv2_large_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 341.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_large_window12_192.ms_in22k created, param count: 228772549
Running train benchmark on swinv2_large_window12_192.ms_in22k for 40 steps w/ input size (3, 192, 192) and batch size 48.
Train [8/40]. 162.61 samples/sec. 295.180 ms/step.
Train [16/40]. 162.62 samples/sec. 295.167 ms/step.
Train [24/40]. 162.62 samples/sec. 295.174 ms/step.
Train [32/40]. 162.61 samples/sec. 295.176 ms/step.
Train [40/40]. 162.62 samples/sec. 295.169 ms/step.
Train benchmark of swinv2_large_window12_192.ms_in22k done. 161.27 samples/sec, 295.17 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running inference benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 252.83 samples/sec. 1012.525 ms/step.
Infer [16/40]. 252.83 samples/sec. 1012.525 ms/step.
Infer [24/40]. 252.83 samples/sec. 1012.527 ms/step.
Infer [32/40]. 252.83 samples/sec. 1012.528 ms/step.
Infer [40/40]. 252.83 samples/sec. 1012.523 ms/step.
Inference benchmark of swinv2_large_window12to16_192to256.ms_in22k_ft_in1k done. 252.82 samples/sec, 1012.52 ms/step
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.04 GiB is free. Including non-PyTorch memory, this process has 19.60 GiB memory in use. Of the allocated memory 19.06 GiB is allocated by PyTorch, and 46.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 556.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 232.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 21.46 GiB memory in use. Of the allocated memory 20.85 GiB is allocated by PyTorch, and 122.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 236.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 182.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 224.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 94.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 41.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swinv2_large_window12to16_192to256.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to16_192to256.ms_in22k_ft_in1k for 40 steps w/ input size (3, 256, 256) and batch size 24.
Train [8/40]. 74.99 samples/sec. 320.050 ms/step.
Train [16/40]. 74.99 samples/sec. 320.063 ms/step.
Train [24/40]. 74.99 samples/sec. 320.058 ms/step.
Train [32/40]. 74.99 samples/sec. 320.058 ms/step.
Train [40/40]. 74.99 samples/sec. 320.057 ms/step.
Train benchmark of swinv2_large_window12to16_192to256.ms_in22k_ft_in1k done. 74.42 samples/sec, 320.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running inference benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 30.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.64 GiB is free. Including non-PyTorch memory, this process has 17.00 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 63.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running inference benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 22.78 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.24 GiB is free. Including non-PyTorch memory, this process has 13.40 GiB memory in use. Of the allocated memory 12.54 GiB is allocated by PyTorch, and 374.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running inference benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 15.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 14.27 GiB is free. Including non-PyTorch memory, this process has 9.37 GiB memory in use. Of the allocated memory 8.64 GiB is allocated by PyTorch, and 240.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running inference benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 11.39 GiB. GPU 0 has a total capacty of 23.65 GiB of which 7.15 GiB is free. Including non-PyTorch memory, this process has 16.49 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 456.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running inference benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Infer [8/40]. 68.74 samples/sec. 931.040 ms/step.
Infer [16/40]. 68.74 samples/sec. 931.036 ms/step.
Infer [24/40]. 68.74 samples/sec. 931.084 ms/step.
Infer [32/40]. 68.73 samples/sec. 931.175 ms/step.
Infer [40/40]. 68.73 samples/sec. 931.219 ms/step.
Inference benchmark of swinv2_large_window12to24_192to384.ms_in22k_ft_in1k done. 68.72 samples/sec, 931.22 ms/step
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 30.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.72 GiB is free. Including non-PyTorch memory, this process has 18.92 GiB memory in use. Of the allocated memory 18.36 GiB is allocated by PyTorch, and 65.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 22.78 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.97 GiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 199.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 15.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 13.30 GiB is free. Including non-PyTorch memory, this process has 10.34 GiB memory in use. Of the allocated memory 9.60 GiB is allocated by PyTorch, and 249.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 11.39 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.13 GiB is free. Including non-PyTorch memory, this process has 18.51 GiB memory in use. Of the allocated memory 17.53 GiB is allocated by PyTorch, and 494.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 7.59 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.29 GiB is free. Including non-PyTorch memory, this process has 20.36 GiB memory in use. Of the allocated memory 19.58 GiB is allocated by PyTorch, and 288.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 5.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 522.06 MiB is free. Including non-PyTorch memory, this process has 23.13 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 431.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 23.65 GiB of which 376.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.29 GiB is allocated by PyTorch, and 503.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.37 GiB is free. Including non-PyTorch memory, this process has 22.27 GiB memory in use. Of the allocated memory 21.05 GiB is allocated by PyTorch, and 741.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 442.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 230.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 358.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 379.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 122.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 310.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model swinv2_large_window12to24_192to384.ms_in22k_ft_in1k created, param count: 196739932
Running train benchmark on swinv2_large_window12to24_192to384.ms_in22k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 6.
Train [8/40]. 21.15 samples/sec. 283.726 ms/step.
Train [16/40]. 21.14 samples/sec. 283.849 ms/step.
Train [24/40]. 21.13 samples/sec. 283.892 ms/step.
Train [32/40]. 21.13 samples/sec. 283.918 ms/step.
Train [40/40]. 21.13 samples/sec. 283.929 ms/step.
Train benchmark of swinv2_large_window12to24_192to384.ms_in22k_ft_in1k done. 20.96 samples/sec, 283.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_small_window8_256.ms_in1k created, param count: 49728418
Running inference benchmark on swinv2_small_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 845.31 samples/sec. 302.846 ms/step.
Infer [16/40]. 845.32 samples/sec. 302.844 ms/step.
Infer [24/40]. 845.32 samples/sec. 302.844 ms/step.
Infer [32/40]. 845.32 samples/sec. 302.845 ms/step.
Infer [40/40]. 845.31 samples/sec. 302.847 ms/step.
Inference benchmark of swinv2_small_window8_256.ms_in1k done. 845.19 samples/sec, 302.85 ms/step
Model swinv2_small_window8_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 696.06 MiB is free. Including non-PyTorch memory, this process has 22.96 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 165.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_small_window8_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 25.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_small_window8_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 104.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 41.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_small_window8_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 7.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_small_window8_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 273.11 samples/sec. 234.338 ms/step.
Train [16/40]. 273.12 samples/sec. 234.327 ms/step.
Train [24/40]. 273.12 samples/sec. 234.330 ms/step.
Train [32/40]. 273.12 samples/sec. 234.333 ms/step.
Train [40/40]. 273.12 samples/sec. 234.331 ms/step.
Train benchmark of swinv2_small_window8_256.ms_in1k done. 270.31 samples/sec, 234.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_small_window16_256.ms_in1k created, param count: 49728418
Running inference benchmark on swinv2_small_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 567.73 samples/sec. 450.921 ms/step.
Infer [16/40]. 567.72 samples/sec. 450.923 ms/step.
Infer [24/40]. 567.72 samples/sec. 450.926 ms/step.
Infer [32/40]. 567.72 samples/sec. 450.928 ms/step.
Infer [40/40]. 567.72 samples/sec. 450.926 ms/step.
Inference benchmark of swinv2_small_window16_256.ms_in1k done. 567.66 samples/sec, 450.93 ms/step
Model swinv2_small_window16_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.42 GiB is free. Including non-PyTorch memory, this process has 21.22 GiB memory in use. Of the allocated memory 20.40 GiB is allocated by PyTorch, and 328.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_small_window16_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 320.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 131.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_small_window16_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 22.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_small_window16_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 50.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_small_window16_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 37.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model swinv2_small_window16_256.ms_in1k created, param count: 49728418
Running train benchmark on swinv2_small_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 48.
Train [8/40]. 176.13 samples/sec. 272.529 ms/step.
Train [16/40]. 176.12 samples/sec. 272.536 ms/step.
Train [24/40]. 176.12 samples/sec. 272.540 ms/step.
Train [32/40]. 176.13 samples/sec. 272.531 ms/step.
Train [40/40]. 176.13 samples/sec. 272.529 ms/step.
Train benchmark of swinv2_small_window16_256.ms_in1k done. 174.51 samples/sec, 272.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_tiny_window8_256.ms_in1k created, param count: 28347154
Running inference benchmark on swinv2_tiny_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 1384.52 samples/sec. 184.901 ms/step.
Infer [16/40]. 1384.49 samples/sec. 184.906 ms/step.
Infer [24/40]. 1384.59 samples/sec. 184.892 ms/step.
Infer [32/40]. 1384.72 samples/sec. 184.874 ms/step.
Infer [40/40]. 1384.80 samples/sec. 184.865 ms/step.
Inference benchmark of swinv2_tiny_window8_256.ms_in1k done. 1384.53 samples/sec, 184.87 ms/step
Model swinv2_tiny_window8_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 155.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_tiny_window8_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 13.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_tiny_window8_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window8_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
Train [8/40]. 415.11 samples/sec. 308.352 ms/step.
Train [16/40]. 415.10 samples/sec. 308.362 ms/step.
Train [24/40]. 415.11 samples/sec. 308.356 ms/step.
Train [32/40]. 415.11 samples/sec. 308.354 ms/step.
Train [40/40]. 415.11 samples/sec. 308.351 ms/step.
Train benchmark of swinv2_tiny_window8_256.ms_in1k done. 413.06 samples/sec, 308.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model swinv2_tiny_window16_256.ms_in1k created, param count: 28347154
Running inference benchmark on swinv2_tiny_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
Infer [8/40]. 907.82 samples/sec. 281.996 ms/step.
Infer [16/40]. 907.77 samples/sec. 282.008 ms/step.
Infer [24/40]. 907.78 samples/sec. 282.008 ms/step.
Infer [32/40]. 907.77 samples/sec. 282.009 ms/step.
Infer [40/40]. 907.78 samples/sec. 282.008 ms/step.
Inference benchmark of swinv2_tiny_window16_256.ms_in1k done. 907.64 samples/sec, 282.01 ms/step
Model swinv2_tiny_window16_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.51 GiB is free. Including non-PyTorch memory, this process has 21.13 GiB memory in use. Of the allocated memory 20.31 GiB is allocated by PyTorch, and 328.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model swinv2_tiny_window16_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 484.06 MiB is free. Including non-PyTorch memory, this process has 23.17 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 57.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model swinv2_tiny_window16_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 58.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model swinv2_tiny_window16_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 96.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model swinv2_tiny_window16_256.ms_in1k created, param count: 28347154
Running train benchmark on swinv2_tiny_window16_256.ms_in1k for 40 steps w/ input size (3, 256, 256) and batch size 64.
Train [8/40]. 283.07 samples/sec. 226.096 ms/step.
Train [16/40]. 283.08 samples/sec. 226.088 ms/step.
Train [24/40]. 283.08 samples/sec. 226.085 ms/step.
Train [32/40]. 283.08 samples/sec. 226.085 ms/step.
Train [40/40]. 283.08 samples/sec. 226.085 ms/step.
Train benchmark of swinv2_tiny_window16_256.ms_in1k done. 281.35 samples/sec, 226.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b0.aa_in1k created, param count: 5288548
Running inference benchmark on tf_efficientnet_b0.aa_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4088.16 samples/sec. 62.620 ms/step.
Infer [16/40]. 4087.90 samples/sec. 62.624 ms/step.
Infer [24/40]. 4087.06 samples/sec. 62.637 ms/step.
Infer [32/40]. 4086.66 samples/sec. 62.643 ms/step.
Infer [40/40]. 4086.45 samples/sec. 62.646 ms/step.
Inference benchmark of tf_efficientnet_b0.aa_in1k done. 4084.70 samples/sec, 62.65 ms/step
Model tf_efficientnet_b0.aa_in1k created, param count: 5288548
Running train benchmark on tf_efficientnet_b0.aa_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1096.36 samples/sec. 233.499 ms/step.
Train [16/40]. 1096.32 samples/sec. 233.507 ms/step.
Train [24/40]. 1096.34 samples/sec. 233.505 ms/step.
Train [32/40]. 1096.29 samples/sec. 233.515 ms/step.
Train [40/40]. 1096.26 samples/sec. 233.522 ms/step.
Train benchmark of tf_efficientnet_b0.aa_in1k done. 1091.27 samples/sec, 233.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b0.ap_in1k created, param count: 5288548
Running inference benchmark on tf_efficientnet_b0.ap_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4088.14 samples/sec. 62.620 ms/step.
Infer [16/40]. 4088.05 samples/sec. 62.621 ms/step.
Infer [24/40]. 4088.03 samples/sec. 62.622 ms/step.
Infer [32/40]. 4088.01 samples/sec. 62.622 ms/step.
Infer [40/40]. 4087.97 samples/sec. 62.623 ms/step.
Inference benchmark of tf_efficientnet_b0.ap_in1k done. 4086.25 samples/sec, 62.62 ms/step
Model tf_efficientnet_b0.ap_in1k created, param count: 5288548
Running train benchmark on tf_efficientnet_b0.ap_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1096.54 samples/sec. 233.461 ms/step.
Train [16/40]. 1096.41 samples/sec. 233.490 ms/step.
Train [24/40]. 1096.37 samples/sec. 233.497 ms/step.
Train [32/40]. 1096.40 samples/sec. 233.492 ms/step.
Train [40/40]. 1096.39 samples/sec. 233.494 ms/step.
Train benchmark of tf_efficientnet_b0.ap_in1k done. 1091.43 samples/sec, 233.49 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b0.in1k created, param count: 5288548
Running inference benchmark on tf_efficientnet_b0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4088.82 samples/sec. 62.610 ms/step.
Infer [16/40]. 4088.80 samples/sec. 62.610 ms/step.
Infer [24/40]. 4088.88 samples/sec. 62.609 ms/step.
Infer [32/40]. 4088.80 samples/sec. 62.610 ms/step.
Infer [40/40]. 4088.83 samples/sec. 62.610 ms/step.
Inference benchmark of tf_efficientnet_b0.in1k done. 4087.10 samples/sec, 62.61 ms/step
Model tf_efficientnet_b0.in1k created, param count: 5288548
Running train benchmark on tf_efficientnet_b0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1096.29 samples/sec. 233.514 ms/step.
Train [16/40]. 1096.28 samples/sec. 233.518 ms/step.
Train [24/40]. 1096.27 samples/sec. 233.519 ms/step.
Train [32/40]. 1096.27 samples/sec. 233.518 ms/step.
Train [40/40]. 1096.28 samples/sec. 233.517 ms/step.
Train benchmark of tf_efficientnet_b0.in1k done. 1091.28 samples/sec, 233.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b0.ns_jft_in1k created, param count: 5288548
Running inference benchmark on tf_efficientnet_b0.ns_jft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4089.07 samples/sec. 62.606 ms/step.
Infer [16/40]. 4089.11 samples/sec. 62.605 ms/step.
Infer [24/40]. 4088.95 samples/sec. 62.608 ms/step.
Infer [32/40]. 4088.60 samples/sec. 62.613 ms/step.
Infer [40/40]. 4088.23 samples/sec. 62.619 ms/step.
Inference benchmark of tf_efficientnet_b0.ns_jft_in1k done. 4086.51 samples/sec, 62.62 ms/step
Model tf_efficientnet_b0.ns_jft_in1k created, param count: 5288548
Running train benchmark on tf_efficientnet_b0.ns_jft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1095.98 samples/sec. 233.582 ms/step.
Train [16/40]. 1095.94 samples/sec. 233.589 ms/step.
Train [24/40]. 1096.05 samples/sec. 233.567 ms/step.
Train [32/40]. 1096.03 samples/sec. 233.570 ms/step.
Train [40/40]. 1095.96 samples/sec. 233.585 ms/step.
Train benchmark of tf_efficientnet_b0.ns_jft_in1k done. 1090.87 samples/sec, 233.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b1.aa_in1k created, param count: 7794184
Running inference benchmark on tf_efficientnet_b1.aa_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2550.40 samples/sec. 100.377 ms/step.
Infer [16/40]. 2549.98 samples/sec. 100.393 ms/step.
Infer [24/40]. 2549.92 samples/sec. 100.395 ms/step.
Infer [32/40]. 2549.90 samples/sec. 100.396 ms/step.
Infer [40/40]. 2549.89 samples/sec. 100.396 ms/step.
Inference benchmark of tf_efficientnet_b1.aa_in1k done. 2549.17 samples/sec, 100.40 ms/step
Model tf_efficientnet_b1.aa_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.aa_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 215.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b1.aa_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.aa_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 112.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 176.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b1.aa_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.aa_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 692.43 samples/sec. 184.856 ms/step.
Train [16/40]. 692.47 samples/sec. 184.845 ms/step.
Train [24/40]. 692.45 samples/sec. 184.851 ms/step.
Train [32/40]. 692.45 samples/sec. 184.850 ms/step.
Train [40/40]. 692.45 samples/sec. 184.852 ms/step.
Train benchmark of tf_efficientnet_b1.aa_in1k done. 688.00 samples/sec, 184.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b1.ap_in1k created, param count: 7794184
Running inference benchmark on tf_efficientnet_b1.ap_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2551.46 samples/sec. 100.335 ms/step.
Infer [16/40]. 2550.93 samples/sec. 100.355 ms/step.
Infer [24/40]. 2550.81 samples/sec. 100.360 ms/step.
Infer [32/40]. 2550.73 samples/sec. 100.363 ms/step.
Infer [40/40]. 2550.69 samples/sec. 100.365 ms/step.
Inference benchmark of tf_efficientnet_b1.ap_in1k done. 2549.96 samples/sec, 100.36 ms/step
Model tf_efficientnet_b1.ap_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.ap_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 215.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b1.ap_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.ap_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 202.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b1.ap_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.ap_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 692.28 samples/sec. 184.895 ms/step.
Train [16/40]. 692.26 samples/sec. 184.903 ms/step.
Train [24/40]. 692.20 samples/sec. 184.918 ms/step.
Train [32/40]. 692.09 samples/sec. 184.947 ms/step.
Train [40/40]. 692.04 samples/sec. 184.961 ms/step.
Train benchmark of tf_efficientnet_b1.ap_in1k done. 687.73 samples/sec, 184.96 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b1.in1k created, param count: 7794184
Running inference benchmark on tf_efficientnet_b1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2551.89 samples/sec. 100.318 ms/step.
Infer [16/40]. 2551.65 samples/sec. 100.327 ms/step.
Infer [24/40]. 2551.22 samples/sec. 100.344 ms/step.
Infer [32/40]. 2551.06 samples/sec. 100.351 ms/step.
Infer [40/40]. 2550.98 samples/sec. 100.353 ms/step.
Inference benchmark of tf_efficientnet_b1.in1k done. 2550.30 samples/sec, 100.35 ms/step
Model tf_efficientnet_b1.in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 215.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b1.in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 202.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b1.in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 692.18 samples/sec. 184.923 ms/step.
Train [16/40]. 692.10 samples/sec. 184.944 ms/step.
Train [24/40]. 692.15 samples/sec. 184.932 ms/step.
Train [32/40]. 692.06 samples/sec. 184.954 ms/step.
Train [40/40]. 692.08 samples/sec. 184.949 ms/step.
Train benchmark of tf_efficientnet_b1.in1k done. 687.86 samples/sec, 184.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b1.ns_jft_in1k created, param count: 7794184
Running inference benchmark on tf_efficientnet_b1.ns_jft_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2551.93 samples/sec. 100.316 ms/step.
Infer [16/40]. 2551.85 samples/sec. 100.319 ms/step.
Infer [24/40]. 2551.85 samples/sec. 100.319 ms/step.
Infer [32/40]. 2551.81 samples/sec. 100.321 ms/step.
Infer [40/40]. 2551.58 samples/sec. 100.330 ms/step.
Inference benchmark of tf_efficientnet_b1.ns_jft_in1k done. 2550.91 samples/sec, 100.33 ms/step
Model tf_efficientnet_b1.ns_jft_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.ns_jft_in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 162.06 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 215.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b1.ns_jft_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.ns_jft_in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 202.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b1.ns_jft_in1k created, param count: 7794184
Running train benchmark on tf_efficientnet_b1.ns_jft_in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 692.16 samples/sec. 184.930 ms/step.
Train [16/40]. 692.19 samples/sec. 184.920 ms/step.
Train [24/40]. 692.16 samples/sec. 184.929 ms/step.
Train [32/40]. 692.14 samples/sec. 184.934 ms/step.
Train [40/40]. 692.11 samples/sec. 184.942 ms/step.
Train benchmark of tf_efficientnet_b1.ns_jft_in1k done. 687.91 samples/sec, 184.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b2.aa_in1k created, param count: 9109994
Running inference benchmark on tf_efficientnet_b2.aa_in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
Infer [8/40]. 1951.25 samples/sec. 131.198 ms/step.
Infer [16/40]. 1951.25 samples/sec. 131.198 ms/step.
Infer [24/40]. 1951.22 samples/sec. 131.200 ms/step.
Infer [32/40]. 1951.20 samples/sec. 131.201 ms/step.
Infer [40/40]. 1951.21 samples/sec. 131.201 ms/step.
Inference benchmark of tf_efficientnet_b2.aa_in1k done. 1950.79 samples/sec, 131.20 ms/step
Model tf_efficientnet_b2.aa_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.aa_in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 670.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 255.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b2.aa_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.aa_in1k for 40 steps w/ input size (3, 260, 260) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 134.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b2.aa_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.aa_in1k for 40 steps w/ input size (3, 260, 260) and batch size 128.
Train [8/40]. 514.29 samples/sec. 248.888 ms/step.
Train [16/40]. 514.30 samples/sec. 248.880 ms/step.
Train [24/40]. 514.31 samples/sec. 248.878 ms/step.
Train [32/40]. 514.30 samples/sec. 248.882 ms/step.
Train [40/40]. 514.31 samples/sec. 248.877 ms/step.
Train benchmark of tf_efficientnet_b2.aa_in1k done. 511.67 samples/sec, 248.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b2.ap_in1k created, param count: 9109994
Running inference benchmark on tf_efficientnet_b2.ap_in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
Infer [8/40]. 1950.72 samples/sec. 131.234 ms/step.
Infer [16/40]. 1950.76 samples/sec. 131.231 ms/step.
Infer [24/40]. 1950.79 samples/sec. 131.229 ms/step.
Infer [32/40]. 1950.79 samples/sec. 131.229 ms/step.
Infer [40/40]. 1950.77 samples/sec. 131.230 ms/step.
Inference benchmark of tf_efficientnet_b2.ap_in1k done. 1950.35 samples/sec, 131.23 ms/step
Model tf_efficientnet_b2.ap_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.ap_in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 670.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 255.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b2.ap_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.ap_in1k for 40 steps w/ input size (3, 260, 260) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 198.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b2.ap_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.ap_in1k for 40 steps w/ input size (3, 260, 260) and batch size 128.
Train [8/40]. 514.35 samples/sec. 248.860 ms/step.
Train [16/40]. 514.34 samples/sec. 248.865 ms/step.
Train [24/40]. 514.33 samples/sec. 248.870 ms/step.
Train [32/40]. 514.32 samples/sec. 248.873 ms/step.
Train [40/40]. 514.31 samples/sec. 248.879 ms/step.
Train benchmark of tf_efficientnet_b2.ap_in1k done. 511.66 samples/sec, 248.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b2.in1k created, param count: 9109994
Running inference benchmark on tf_efficientnet_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
Infer [8/40]. 1950.85 samples/sec. 131.225 ms/step.
Infer [16/40]. 1950.81 samples/sec. 131.227 ms/step.
Infer [24/40]. 1950.78 samples/sec. 131.229 ms/step.
Infer [32/40]. 1950.72 samples/sec. 131.234 ms/step.
Infer [40/40]. 1950.71 samples/sec. 131.234 ms/step.
Inference benchmark of tf_efficientnet_b2.in1k done. 1950.28 samples/sec, 131.23 ms/step
Model tf_efficientnet_b2.in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 670.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 255.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b2.in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 198.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b2.in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 128.
Train [8/40]. 514.43 samples/sec. 248.817 ms/step.
Train [16/40]. 514.42 samples/sec. 248.826 ms/step.
Train [24/40]. 514.40 samples/sec. 248.835 ms/step.
Train [32/40]. 514.36 samples/sec. 248.851 ms/step.
Train [40/40]. 514.35 samples/sec. 248.860 ms/step.
Train benchmark of tf_efficientnet_b2.in1k done. 511.66 samples/sec, 248.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b2.ns_jft_in1k created, param count: 9109994
Running inference benchmark on tf_efficientnet_b2.ns_jft_in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
Infer [8/40]. 1950.60 samples/sec. 131.241 ms/step.
Infer [16/40]. 1950.57 samples/sec. 131.244 ms/step.
Infer [24/40]. 1950.58 samples/sec. 131.243 ms/step.
Infer [32/40]. 1950.59 samples/sec. 131.242 ms/step.
Infer [40/40]. 1950.61 samples/sec. 131.241 ms/step.
Inference benchmark of tf_efficientnet_b2.ns_jft_in1k done. 1950.14 samples/sec, 131.24 ms/step
Model tf_efficientnet_b2.ns_jft_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.ns_jft_in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 670.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 128.06 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 255.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b2.ns_jft_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.ns_jft_in1k for 40 steps w/ input size (3, 260, 260) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 198.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b2.ns_jft_in1k created, param count: 9109994
Running train benchmark on tf_efficientnet_b2.ns_jft_in1k for 40 steps w/ input size (3, 260, 260) and batch size 128.
Train [8/40]. 514.23 samples/sec. 248.914 ms/step.
Train [16/40]. 514.26 samples/sec. 248.902 ms/step.
Train [24/40]. 514.25 samples/sec. 248.908 ms/step.
Train [32/40]. 514.26 samples/sec. 248.900 ms/step.
Train [40/40]. 514.27 samples/sec. 248.894 ms/step.
Train benchmark of tf_efficientnet_b2.ns_jft_in1k done. 511.55 samples/sec, 248.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b3.aa_in1k created, param count: 12233232
Running inference benchmark on tf_efficientnet_b3.aa_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1139.04 samples/sec. 224.750 ms/step.
Infer [16/40]. 1139.06 samples/sec. 224.747 ms/step.
Infer [24/40]. 1139.07 samples/sec. 224.744 ms/step.
Infer [32/40]. 1139.07 samples/sec. 224.745 ms/step.
Infer [40/40]. 1139.07 samples/sec. 224.745 ms/step.
Inference benchmark of tf_efficientnet_b3.aa_in1k done. 1138.85 samples/sec, 224.75 ms/step
Model tf_efficientnet_b3.aa_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.aa_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 20.59 GiB memory in use. Of the allocated memory 19.98 GiB is allocated by PyTorch, and 115.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b3.aa_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.aa_in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 406.06 MiB is free. Including non-PyTorch memory, this process has 23.24 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 501.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b3.aa_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.aa_in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 254.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b3.aa_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.aa_in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 307.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b3.aa_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.aa_in1k for 40 steps w/ input size (3, 300, 300) and batch size 64.
Train [8/40]. 312.53 samples/sec. 204.779 ms/step.
Train [16/40]. 312.56 samples/sec. 204.759 ms/step.
Train [24/40]. 312.57 samples/sec. 204.751 ms/step.
Train [32/40]. 312.58 samples/sec. 204.748 ms/step.
Train [40/40]. 312.58 samples/sec. 204.751 ms/step.
Train benchmark of tf_efficientnet_b3.aa_in1k done. 310.45 samples/sec, 204.75 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b3.ap_in1k created, param count: 12233232
Running inference benchmark on tf_efficientnet_b3.ap_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1139.15 samples/sec. 224.730 ms/step.
Infer [16/40]. 1139.13 samples/sec. 224.734 ms/step.
Infer [24/40]. 1139.07 samples/sec. 224.746 ms/step.
Infer [32/40]. 1138.99 samples/sec. 224.761 ms/step.
Infer [40/40]. 1138.93 samples/sec. 224.772 ms/step.
Inference benchmark of tf_efficientnet_b3.ap_in1k done. 1138.72 samples/sec, 224.77 ms/step
Model tf_efficientnet_b3.ap_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ap_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 20.59 GiB memory in use. Of the allocated memory 19.98 GiB is allocated by PyTorch, and 115.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b3.ap_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ap_in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 897.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b3.ap_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ap_in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 294.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b3.ap_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ap_in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 253.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b3.ap_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ap_in1k for 40 steps w/ input size (3, 300, 300) and batch size 64.
Train [8/40]. 312.84 samples/sec. 204.577 ms/step.
Train [16/40]. 312.77 samples/sec. 204.622 ms/step.
Train [24/40]. 312.74 samples/sec. 204.644 ms/step.
Train [32/40]. 312.72 samples/sec. 204.656 ms/step.
Train [40/40]. 312.69 samples/sec. 204.675 ms/step.
Train benchmark of tf_efficientnet_b3.ap_in1k done. 310.60 samples/sec, 204.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b3.in1k created, param count: 12233232
Running inference benchmark on tf_efficientnet_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1139.13 samples/sec. 224.733 ms/step.
Infer [16/40]. 1139.15 samples/sec. 224.729 ms/step.
Infer [24/40]. 1139.15 samples/sec. 224.730 ms/step.
Infer [32/40]. 1139.12 samples/sec. 224.735 ms/step.
Infer [40/40]. 1139.12 samples/sec. 224.735 ms/step.
Inference benchmark of tf_efficientnet_b3.in1k done. 1138.91 samples/sec, 224.74 ms/step
Model tf_efficientnet_b3.in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 20.59 GiB memory in use. Of the allocated memory 19.98 GiB is allocated by PyTorch, and 115.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b3.in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 897.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b3.in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 294.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b3.in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 253.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b3.in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 64.
Train [8/40]. 312.68 samples/sec. 204.685 ms/step.
Train [16/40]. 312.69 samples/sec. 204.678 ms/step.
Train [24/40]. 312.66 samples/sec. 204.692 ms/step.
Train [32/40]. 312.67 samples/sec. 204.691 ms/step.
Train [40/40]. 312.66 samples/sec. 204.698 ms/step.
Train benchmark of tf_efficientnet_b3.in1k done. 310.64 samples/sec, 204.70 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b3.ns_jft_in1k created, param count: 12233232
Running inference benchmark on tf_efficientnet_b3.ns_jft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1138.94 samples/sec. 224.771 ms/step.
Infer [16/40]. 1138.88 samples/sec. 224.782 ms/step.
Infer [24/40]. 1138.85 samples/sec. 224.788 ms/step.
Infer [32/40]. 1138.84 samples/sec. 224.791 ms/step.
Infer [40/40]. 1138.84 samples/sec. 224.791 ms/step.
Inference benchmark of tf_efficientnet_b3.ns_jft_in1k done. 1138.63 samples/sec, 224.79 ms/step
Model tf_efficientnet_b3.ns_jft_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ns_jft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 20.59 GiB memory in use. Of the allocated memory 19.98 GiB is allocated by PyTorch, and 115.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b3.ns_jft_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ns_jft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 897.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b3.ns_jft_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ns_jft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 138.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 294.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b3.ns_jft_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ns_jft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 253.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b3.ns_jft_in1k created, param count: 12233232
Running train benchmark on tf_efficientnet_b3.ns_jft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 64.
Train [8/40]. 312.67 samples/sec. 204.687 ms/step.
Train [16/40]. 312.68 samples/sec. 204.685 ms/step.
Train [24/40]. 312.65 samples/sec. 204.704 ms/step.
Train [32/40]. 312.65 samples/sec. 204.703 ms/step.
Train [40/40]. 312.64 samples/sec. 204.708 ms/step.
Train benchmark of tf_efficientnet_b3.ns_jft_in1k done. 310.62 samples/sec, 204.71 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running inference benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
Infer [8/40]. 549.36 samples/sec. 465.999 ms/step.
Infer [16/40]. 549.37 samples/sec. 465.992 ms/step.
Infer [24/40]. 549.37 samples/sec. 465.987 ms/step.
Infer [32/40]. 549.37 samples/sec. 465.990 ms/step.
Infer [40/40]. 549.37 samples/sec. 465.990 ms/step.
Inference benchmark of tf_efficientnet_b4.aa_in1k done. 549.31 samples/sec, 465.99 ms/step
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.94 GiB is free. Including non-PyTorch memory, this process has 19.70 GiB memory in use. Of the allocated memory 19.10 GiB is allocated by PyTorch, and 110.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 204.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 848.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 190.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 677.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 636.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 356.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 275.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 179.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 326.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b4.aa_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.aa_in1k for 40 steps w/ input size (3, 380, 380) and batch size 32.
Train [8/40]. 156.25 samples/sec. 204.798 ms/step.
Train [16/40]. 156.26 samples/sec. 204.791 ms/step.
Train [24/40]. 156.26 samples/sec. 204.792 ms/step.
Train [32/40]. 156.25 samples/sec. 204.803 ms/step.
Train [40/40]. 156.25 samples/sec. 204.801 ms/step.
Train benchmark of tf_efficientnet_b4.aa_in1k done. 155.07 samples/sec, 204.80 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running inference benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
Infer [8/40]. 549.36 samples/sec. 466.000 ms/step.
Infer [16/40]. 549.35 samples/sec. 466.005 ms/step.
Infer [24/40]. 549.35 samples/sec. 466.008 ms/step.
Infer [32/40]. 549.35 samples/sec. 466.008 ms/step.
Infer [40/40]. 549.35 samples/sec. 466.004 ms/step.
Inference benchmark of tf_efficientnet_b4.ap_in1k done. 549.29 samples/sec, 466.00 ms/step
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.94 GiB is free. Including non-PyTorch memory, this process has 19.70 GiB memory in use. Of the allocated memory 19.10 GiB is allocated by PyTorch, and 110.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 204.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 848.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 614.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 636.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 546.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 718.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 174.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 358.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b4.ap_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ap_in1k for 40 steps w/ input size (3, 380, 380) and batch size 32.
Train [8/40]. 156.20 samples/sec. 204.864 ms/step.
Train [16/40]. 156.22 samples/sec. 204.839 ms/step.
Train [24/40]. 156.21 samples/sec. 204.850 ms/step.
Train [32/40]. 156.21 samples/sec. 204.853 ms/step.
Train [40/40]. 156.21 samples/sec. 204.858 ms/step.
Train benchmark of tf_efficientnet_b4.ap_in1k done. 155.03 samples/sec, 204.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running inference benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
Infer [8/40]. 549.54 samples/sec. 465.844 ms/step.
Infer [16/40]. 549.46 samples/sec. 465.914 ms/step.
Infer [24/40]. 549.43 samples/sec. 465.936 ms/step.
Infer [32/40]. 549.42 samples/sec. 465.950 ms/step.
Infer [40/40]. 549.41 samples/sec. 465.956 ms/step.
Inference benchmark of tf_efficientnet_b4.in1k done. 549.36 samples/sec, 465.96 ms/step
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.94 GiB is free. Including non-PyTorch memory, this process has 19.70 GiB memory in use. Of the allocated memory 19.10 GiB is allocated by PyTorch, and 110.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 204.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 848.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 614.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 636.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 546.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 718.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 174.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 358.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b4.in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 32.
Train [8/40]. 156.17 samples/sec. 204.906 ms/step.
Train [16/40]. 156.20 samples/sec. 204.871 ms/step.
Train [24/40]. 156.20 samples/sec. 204.865 ms/step.
Train [32/40]. 156.20 samples/sec. 204.863 ms/step.
Train [40/40]. 156.21 samples/sec. 204.857 ms/step.
Train benchmark of tf_efficientnet_b4.in1k done. 155.07 samples/sec, 204.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running inference benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
Infer [8/40]. 549.43 samples/sec. 465.938 ms/step.
Infer [16/40]. 549.40 samples/sec. 465.965 ms/step.
Infer [24/40]. 549.39 samples/sec. 465.975 ms/step.
Infer [32/40]. 549.38 samples/sec. 465.981 ms/step.
Infer [40/40]. 549.37 samples/sec. 465.985 ms/step.
Inference benchmark of tf_efficientnet_b4.ns_jft_in1k done. 549.32 samples/sec, 465.99 ms/step
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.94 GiB is free. Including non-PyTorch memory, this process has 19.70 GiB memory in use. Of the allocated memory 19.10 GiB is allocated by PyTorch, and 110.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 204.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 848.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 614.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 636.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 546.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 718.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 174.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 358.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b4.ns_jft_in1k created, param count: 19341616
Running train benchmark on tf_efficientnet_b4.ns_jft_in1k for 40 steps w/ input size (3, 380, 380) and batch size 32.
Train [8/40]. 156.20 samples/sec. 204.868 ms/step.
Train [16/40]. 156.20 samples/sec. 204.862 ms/step.
Train [24/40]. 156.20 samples/sec. 204.861 ms/step.
Train [32/40]. 156.19 samples/sec. 204.875 ms/step.
Train [40/40]. 156.19 samples/sec. 204.874 ms/step.
Train benchmark of tf_efficientnet_b4.ns_jft_in1k done. 155.03 samples/sec, 204.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running inference benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
Infer [8/40]. 275.00 samples/sec. 930.924 ms/step.
Infer [16/40]. 275.00 samples/sec. 930.920 ms/step.
Infer [24/40]. 274.98 samples/sec. 930.971 ms/step.
Infer [32/40]. 274.97 samples/sec. 931.013 ms/step.
Infer [40/40]. 274.96 samples/sec. 931.041 ms/step.
Inference benchmark of tf_efficientnet_b5.aa_in1k done. 274.95 samples/sec, 931.04 ms/step
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 66.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 914.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 468.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 246.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 20.97 GiB is allocated by PyTorch, and 410.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 21.11 GiB is allocated by PyTorch, and 263.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 23.05 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 194.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 572.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 328.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 248.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 244.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 364.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b5.aa_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.aa_in1k for 40 steps w/ input size (3, 456, 456) and batch size 16.
Train [8/40]. 78.10 samples/sec. 204.853 ms/step.
Train [16/40]. 78.10 samples/sec. 204.876 ms/step.
Train [24/40]. 78.09 samples/sec. 204.884 ms/step.
Train [32/40]. 78.09 samples/sec. 204.886 ms/step.
Train [40/40]. 78.09 samples/sec. 204.879 ms/step.
Train benchmark of tf_efficientnet_b5.aa_in1k done. 77.42 samples/sec, 204.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running inference benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
Infer [8/40]. 275.01 samples/sec. 930.879 ms/step.
Infer [16/40]. 275.01 samples/sec. 930.871 ms/step.
Infer [24/40]. 275.01 samples/sec. 930.864 ms/step.
Infer [32/40]. 275.01 samples/sec. 930.871 ms/step.
Infer [40/40]. 275.01 samples/sec. 930.885 ms/step.
Inference benchmark of tf_efficientnet_b5.ap_in1k done. 274.99 samples/sec, 930.88 ms/step
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 66.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 914.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 468.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 246.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 20.97 GiB is allocated by PyTorch, and 410.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 21.11 GiB is allocated by PyTorch, and 263.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 422.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 372.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 572.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 383.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 271.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 340.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b5.ap_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ap_in1k for 40 steps w/ input size (3, 456, 456) and batch size 16.
Train [8/40]. 78.09 samples/sec. 204.883 ms/step.
Train [16/40]. 78.10 samples/sec. 204.871 ms/step.
Train [24/40]. 78.10 samples/sec. 204.864 ms/step.
Train [32/40]. 78.10 samples/sec. 204.876 ms/step.
Train [40/40]. 78.09 samples/sec. 204.886 ms/step.
Train benchmark of tf_efficientnet_b5.ap_in1k done. 77.42 samples/sec, 204.89 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running inference benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
Infer [8/40]. 275.02 samples/sec. 930.857 ms/step.
Infer [16/40]. 275.01 samples/sec. 930.869 ms/step.
Infer [24/40]. 275.01 samples/sec. 930.867 ms/step.
Infer [32/40]. 275.01 samples/sec. 930.874 ms/step.
Infer [40/40]. 275.01 samples/sec. 930.870 ms/step.
Inference benchmark of tf_efficientnet_b5.in1k done. 275.00 samples/sec, 930.87 ms/step
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 66.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 914.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 468.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 246.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 20.97 GiB is allocated by PyTorch, and 410.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 21.11 GiB is allocated by PyTorch, and 263.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 422.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 372.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 572.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 383.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 271.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 340.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b5.in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.in1k for 40 steps w/ input size (3, 456, 456) and batch size 16.
Train [8/40]. 78.10 samples/sec. 204.862 ms/step.
Train [16/40]. 78.10 samples/sec. 204.877 ms/step.
Train [24/40]. 78.09 samples/sec. 204.888 ms/step.
Train [32/40]. 78.09 samples/sec. 204.885 ms/step.
Train [40/40]. 78.09 samples/sec. 204.884 ms/step.
Train benchmark of tf_efficientnet_b5.in1k done. 77.45 samples/sec, 204.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running inference benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
Infer [8/40]. 275.01 samples/sec. 930.877 ms/step.
Infer [16/40]. 275.01 samples/sec. 930.884 ms/step.
Infer [24/40]. 275.00 samples/sec. 930.893 ms/step.
Infer [32/40]. 275.00 samples/sec. 930.895 ms/step.
Infer [40/40]. 275.00 samples/sec. 930.899 ms/step.
Inference benchmark of tf_efficientnet_b5.ns_jft_in1k done. 274.99 samples/sec, 930.90 ms/step
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 66.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 914.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 468.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 246.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 20.97 GiB is allocated by PyTorch, and 410.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 21.11 GiB is allocated by PyTorch, and 263.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 422.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 372.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 572.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 383.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 271.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 340.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b5.ns_jft_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ns_jft_in1k for 40 steps w/ input size (3, 456, 456) and batch size 16.
Train [8/40]. 78.09 samples/sec. 204.881 ms/step.
Train [16/40]. 78.09 samples/sec. 204.896 ms/step.
Train [24/40]. 78.09 samples/sec. 204.891 ms/step.
Train [32/40]. 78.09 samples/sec. 204.889 ms/step.
Train [40/40]. 78.09 samples/sec. 204.883 ms/step.
Train benchmark of tf_efficientnet_b5.ns_jft_in1k done. 77.44 samples/sec, 204.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running inference benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
Infer [8/40]. 275.02 samples/sec. 930.837 ms/step.
Infer [16/40]. 275.01 samples/sec. 930.864 ms/step.
Infer [24/40]. 275.01 samples/sec. 930.869 ms/step.
Infer [32/40]. 275.01 samples/sec. 930.866 ms/step.
Infer [40/40]. 275.01 samples/sec. 930.869 ms/step.
Inference benchmark of tf_efficientnet_b5.ra_in1k done. 275.00 samples/sec, 930.87 ms/step
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 348.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 66.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 914.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 468.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 246.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 20.97 GiB is allocated by PyTorch, and 410.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 2.70 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 21.11 GiB is allocated by PyTorch, and 263.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 422.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 372.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 572.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 383.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 88.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 271.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 340.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b5.ra_in1k created, param count: 30389784
Running train benchmark on tf_efficientnet_b5.ra_in1k for 40 steps w/ input size (3, 456, 456) and batch size 16.
Train [8/40]. 78.11 samples/sec. 204.848 ms/step.
Train [16/40]. 78.11 samples/sec. 204.848 ms/step.
Train [24/40]. 78.11 samples/sec. 204.844 ms/step.
Train [32/40]. 78.10 samples/sec. 204.854 ms/step.
Train [40/40]. 78.10 samples/sec. 204.855 ms/step.
Train benchmark of tf_efficientnet_b5.ra_in1k done. 77.46 samples/sec, 204.85 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.94 GiB is free. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 9.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.86 GiB is free. Including non-PyTorch memory, this process has 16.78 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 128.
Infer [8/40]. 159.95 samples/sec. 800.242 ms/step.
Infer [16/40]. 159.94 samples/sec. 800.301 ms/step.
Infer [24/40]. 159.93 samples/sec. 800.345 ms/step.
Infer [32/40]. 159.93 samples/sec. 800.365 ms/step.
Infer [40/40]. 159.92 samples/sec. 800.379 ms/step.
Inference benchmark of tf_efficientnet_b6.aa_in1k done. 159.91 samples/sec, 800.38 ms/step
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 20.91 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 23.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 23.65 GiB of which 278.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 367.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 484.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.79 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 22.52 GiB memory in use. Of the allocated memory 21.72 GiB is allocated by PyTorch, and 310.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 21.93 GiB memory in use. Of the allocated memory 20.92 GiB is allocated by PyTorch, and 528.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 766.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 282.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 601.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 369.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 451.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 32.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 272.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 363.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b6.aa_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.aa_in1k for 40 steps w/ input size (3, 528, 528) and batch size 8.
Train [8/40]. 47.15 samples/sec. 169.658 ms/step.
Train [16/40]. 47.15 samples/sec. 169.685 ms/step.
Train [24/40]. 47.15 samples/sec. 169.678 ms/step.
Train [32/40]. 47.15 samples/sec. 169.672 ms/step.
Train [40/40]. 47.15 samples/sec. 169.668 ms/step.
Train benchmark of tf_efficientnet_b6.aa_in1k done. 46.67 samples/sec, 169.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.94 GiB is free. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 9.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.86 GiB is free. Including non-PyTorch memory, this process has 16.78 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 128.
Infer [8/40]. 159.96 samples/sec. 800.215 ms/step.
Infer [16/40]. 159.94 samples/sec. 800.306 ms/step.
Infer [24/40]. 159.93 samples/sec. 800.337 ms/step.
Infer [32/40]. 159.93 samples/sec. 800.359 ms/step.
Infer [40/40]. 159.93 samples/sec. 800.373 ms/step.
Inference benchmark of tf_efficientnet_b6.ap_in1k done. 159.92 samples/sec, 800.37 ms/step
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 20.91 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 23.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 23.65 GiB of which 278.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 367.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 484.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.79 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 22.52 GiB memory in use. Of the allocated memory 21.72 GiB is allocated by PyTorch, and 310.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 21.93 GiB memory in use. Of the allocated memory 20.92 GiB is allocated by PyTorch, and 528.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 766.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 510.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 340.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 599.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 401.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 306.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 413.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b6.ap_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ap_in1k for 40 steps w/ input size (3, 528, 528) and batch size 8.
Train [8/40]. 47.04 samples/sec. 170.084 ms/step.
Train [16/40]. 47.04 samples/sec. 170.062 ms/step.
Train [24/40]. 47.03 samples/sec. 170.096 ms/step.
Train [32/40]. 47.03 samples/sec. 170.092 ms/step.
Train [40/40]. 47.04 samples/sec. 170.086 ms/step.
Train benchmark of tf_efficientnet_b6.ap_in1k done. 46.54 samples/sec, 170.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.94 GiB is free. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 9.57 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.86 GiB is free. Including non-PyTorch memory, this process has 16.78 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running inference benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 128.
Infer [8/40]. 159.94 samples/sec. 800.292 ms/step.
Infer [16/40]. 159.94 samples/sec. 800.282 ms/step.
Infer [24/40]. 159.94 samples/sec. 800.290 ms/step.
Infer [32/40]. 159.94 samples/sec. 800.295 ms/step.
Infer [40/40]. 159.94 samples/sec. 800.296 ms/step.
Inference benchmark of tf_efficientnet_b6.ns_jft_in1k done. 159.93 samples/sec, 800.30 ms/step
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 20.91 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 23.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 23.65 GiB of which 278.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 367.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 484.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 4.79 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 22.52 GiB memory in use. Of the allocated memory 21.72 GiB is allocated by PyTorch, and 310.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 21.93 GiB memory in use. Of the allocated memory 20.92 GiB is allocated by PyTorch, and 528.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 766.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 510.06 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 21.53 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 340.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 599.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 180.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 401.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 306.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 413.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b6.ns_jft_in1k created, param count: 43040704
Running train benchmark on tf_efficientnet_b6.ns_jft_in1k for 40 steps w/ input size (3, 528, 528) and batch size 8.
Train [8/40]. 47.02 samples/sec. 170.152 ms/step.
Train [16/40]. 47.03 samples/sec. 170.112 ms/step.
Train [24/40]. 47.03 samples/sec. 170.094 ms/step.
Train [32/40]. 47.03 samples/sec. 170.090 ms/step.
Train [40/40]. 47.04 samples/sec. 170.077 ms/step.
Train benchmark of tf_efficientnet_b6.ns_jft_in1k done. 46.54 samples/sec, 170.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.85 GiB is free. Including non-PyTorch memory, this process has 12.79 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.36 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.04 GiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 19.58 GiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.02 GiB is free. Including non-PyTorch memory, this process has 15.62 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 1.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
Infer [8/40]. 92.93 samples/sec. 1033.052 ms/step.
Infer [16/40]. 92.93 samples/sec. 1033.056 ms/step.
Infer [24/40]. 92.93 samples/sec. 1033.059 ms/step.
Infer [32/40]. 92.93 samples/sec. 1033.068 ms/step.
Infer [40/40]. 92.92 samples/sec. 1033.097 ms/step.
Inference benchmark of tf_efficientnet_b7.aa_in1k done. 92.92 samples/sec, 1033.10 ms/step
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.49 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.32 GiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 15.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 478.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 640.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 635.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 366.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 448.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 636.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 22.51 GiB memory in use. Of the allocated memory 21.27 GiB is allocated by PyTorch, and 769.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 438.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 452.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 544.06 MiB is free. Including non-PyTorch memory, this process has 23.11 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 439.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 320.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 289.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 316.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_b7.aa_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.aa_in1k for 40 steps w/ input size (3, 600, 600) and batch size 6.
Train [8/40]. 26.86 samples/sec. 223.365 ms/step.
Train [16/40]. 26.86 samples/sec. 223.343 ms/step.
Train [24/40]. 26.86 samples/sec. 223.344 ms/step.
Train [32/40]. 26.86 samples/sec. 223.343 ms/step.
Train [40/40]. 26.86 samples/sec. 223.346 ms/step.
Train benchmark of tf_efficientnet_b7.aa_in1k done. 26.59 samples/sec, 223.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.85 GiB is free. Including non-PyTorch memory, this process has 12.79 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.36 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.04 GiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 19.58 GiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.02 GiB is free. Including non-PyTorch memory, this process has 15.62 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 1.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
Infer [8/40]. 92.93 samples/sec. 1033.028 ms/step.
Infer [16/40]. 92.93 samples/sec. 1033.073 ms/step.
Infer [24/40]. 92.92 samples/sec. 1033.150 ms/step.
Infer [32/40]. 92.92 samples/sec. 1033.199 ms/step.
Infer [40/40]. 92.91 samples/sec. 1033.227 ms/step.
Inference benchmark of tf_efficientnet_b7.ap_in1k done. 92.91 samples/sec, 1033.23 ms/step
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.49 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.32 GiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 15.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 478.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 640.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 635.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 366.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 448.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 636.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 22.51 GiB memory in use. Of the allocated memory 21.27 GiB is allocated by PyTorch, and 769.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 804.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 280.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 703.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 302.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 355.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 275.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_b7.ap_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ap_in1k for 40 steps w/ input size (3, 600, 600) and batch size 6.
Train [8/40]. 26.84 samples/sec. 223.536 ms/step.
Train [16/40]. 26.84 samples/sec. 223.552 ms/step.
Train [24/40]. 26.84 samples/sec. 223.557 ms/step.
Train [32/40]. 26.84 samples/sec. 223.555 ms/step.
Train [40/40]. 26.84 samples/sec. 223.554 ms/step.
Train benchmark of tf_efficientnet_b7.ap_in1k done. 26.56 samples/sec, 223.55 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.85 GiB is free. Including non-PyTorch memory, this process has 12.79 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.36 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.04 GiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 19.58 GiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.02 GiB is free. Including non-PyTorch memory, this process has 15.62 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 1.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
Infer [8/40]. 92.91 samples/sec. 1033.208 ms/step.
Infer [16/40]. 92.91 samples/sec. 1033.213 ms/step.
Infer [24/40]. 92.91 samples/sec. 1033.217 ms/step.
Infer [32/40]. 92.91 samples/sec. 1033.225 ms/step.
Infer [40/40]. 92.91 samples/sec. 1033.227 ms/step.
Inference benchmark of tf_efficientnet_b7.ns_jft_in1k done. 92.91 samples/sec, 1033.23 ms/step
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.49 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.32 GiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 15.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 478.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 640.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 635.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 366.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 448.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 636.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 22.51 GiB memory in use. Of the allocated memory 21.27 GiB is allocated by PyTorch, and 769.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 804.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 280.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 703.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 302.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 355.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 275.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_b7.ns_jft_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ns_jft_in1k for 40 steps w/ input size (3, 600, 600) and batch size 6.
Train [8/40]. 26.84 samples/sec. 223.507 ms/step.
Train [16/40]. 26.84 samples/sec. 223.525 ms/step.
Train [24/40]. 26.84 samples/sec. 223.515 ms/step.
Train [32/40]. 26.84 samples/sec. 223.521 ms/step.
Train [40/40]. 26.84 samples/sec. 223.522 ms/step.
Train benchmark of tf_efficientnet_b7.ns_jft_in1k done. 26.57 samples/sec, 223.52 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.85 GiB is free. Including non-PyTorch memory, this process has 12.79 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 12.36 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.04 GiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 19.58 GiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.02 GiB is free. Including non-PyTorch memory, this process has 15.62 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 1.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running inference benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
Infer [8/40]. 92.92 samples/sec. 1033.147 ms/step.
Infer [16/40]. 92.91 samples/sec. 1033.204 ms/step.
Infer [24/40]. 92.91 samples/sec. 1033.218 ms/step.
Infer [32/40]. 92.91 samples/sec. 1033.230 ms/step.
Infer [40/40]. 92.91 samples/sec. 1033.234 ms/step.
Inference benchmark of tf_efficientnet_b7.ra_in1k done. 92.91 samples/sec, 1033.23 ms/step
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.49 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.32 GiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 15.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.12 GiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 478.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 640.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 635.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 366.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 448.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.09 GiB is allocated by PyTorch, and 636.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 22.51 GiB memory in use. Of the allocated memory 21.27 GiB is allocated by PyTorch, and 769.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 792.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.28 GiB is allocated by PyTorch, and 804.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 280.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.18 GiB is allocated by PyTorch, and 703.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 240.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 302.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 355.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 275.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_b7.ra_in1k created, param count: 66347960
Running train benchmark on tf_efficientnet_b7.ra_in1k for 40 steps w/ input size (3, 600, 600) and batch size 6.
Train [8/40]. 26.84 samples/sec. 223.545 ms/step.
Train [16/40]. 26.84 samples/sec. 223.555 ms/step.
Train [24/40]. 26.84 samples/sec. 223.567 ms/step.
Train [32/40]. 26.84 samples/sec. 223.569 ms/step.
Train [40/40]. 26.84 samples/sec. 223.570 ms/step.
Train benchmark of tf_efficientnet_b7.ra_in1k done. 26.55 samples/sec, 223.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.00 GiB is free. Including non-PyTorch memory, this process has 17.64 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 2.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 15.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.71 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 9.72 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 10.34 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.49 GiB is free. Including non-PyTorch memory, this process has 20.15 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 2.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 20.58 GiB is allocated by PyTorch, and 2.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 64.
Infer [8/40]. 61.04 samples/sec. 1048.450 ms/step.
Infer [16/40]. 61.04 samples/sec. 1048.461 ms/step.
Infer [24/40]. 61.04 samples/sec. 1048.466 ms/step.
Infer [32/40]. 61.04 samples/sec. 1048.488 ms/step.
Infer [40/40]. 61.04 samples/sec. 1048.536 ms/step.
Inference benchmark of tf_efficientnet_b8.ap_in1k done. 61.03 samples/sec, 1048.54 ms/step
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.70 GiB is free. Including non-PyTorch memory, this process has 18.94 GiB memory in use. Of the allocated memory 18.44 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.81 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.93 GiB is free. Including non-PyTorch memory, this process has 20.71 GiB memory in use. Of the allocated memory 19.74 GiB is allocated by PyTorch, and 492.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 22.09 GiB memory in use. Of the allocated memory 21.03 GiB is allocated by PyTorch, and 581.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacty of 23.65 GiB of which 758.06 MiB is free. Including non-PyTorch memory, this process has 22.90 GiB memory in use. Of the allocated memory 21.66 GiB is allocated by PyTorch, and 757.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 260.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 593.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 416.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 21.99 GiB is allocated by PyTorch, and 761.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 2.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 487.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 870.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 706.06 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 21.88 GiB is allocated by PyTorch, and 591.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 456.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 277.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 381.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 356.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 137.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 500.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model tf_efficientnet_b8.ap_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ap_in1k for 40 steps w/ input size (3, 672, 672) and batch size 3.
Train [8/40]. 15.50 samples/sec. 193.601 ms/step.
Train [16/40]. 15.49 samples/sec. 193.628 ms/step.
Train [24/40]. 15.50 samples/sec. 193.611 ms/step.
Train [32/40]. 15.49 samples/sec. 193.618 ms/step.
Train [40/40]. 15.49 samples/sec. 193.629 ms/step.
Train benchmark of tf_efficientnet_b8.ap_in1k done. 15.31 samples/sec, 193.63 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.00 GiB is free. Including non-PyTorch memory, this process has 17.64 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 2.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 15.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.71 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 9.72 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 10.34 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.49 GiB is free. Including non-PyTorch memory, this process has 20.15 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 2.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 23.65 GiB of which 222.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 20.58 GiB is allocated by PyTorch, and 2.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running inference benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 64.
Infer [8/40]. 61.05 samples/sec. 1048.277 ms/step.
Infer [16/40]. 61.05 samples/sec. 1048.295 ms/step.
Infer [24/40]. 61.04 samples/sec. 1048.443 ms/step.
Infer [32/40]. 61.04 samples/sec. 1048.533 ms/step.
Infer [40/40]. 61.03 samples/sec. 1048.588 ms/step.
Inference benchmark of tf_efficientnet_b8.ra_in1k done. 61.03 samples/sec, 1048.59 ms/step
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.70 GiB is free. Including non-PyTorch memory, this process has 18.94 GiB memory in use. Of the allocated memory 18.44 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.81 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.93 GiB is free. Including non-PyTorch memory, this process has 20.71 GiB memory in use. Of the allocated memory 19.74 GiB is allocated by PyTorch, and 492.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 22.09 GiB memory in use. Of the allocated memory 21.03 GiB is allocated by PyTorch, and 581.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacty of 23.65 GiB of which 758.06 MiB is free. Including non-PyTorch memory, this process has 22.90 GiB memory in use. Of the allocated memory 21.66 GiB is allocated by PyTorch, and 757.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 260.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 593.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 662.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 416.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 21.99 GiB is allocated by PyTorch, and 761.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 2.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 22.22 GiB memory in use. Of the allocated memory 21.25 GiB is allocated by PyTorch, and 487.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 870.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 374.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 21.88 GiB is allocated by PyTorch, and 923.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 332.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 401.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 399.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 356.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 137.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 882.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model tf_efficientnet_b8.ra_in1k created, param count: 87413142
Running train benchmark on tf_efficientnet_b8.ra_in1k for 40 steps w/ input size (3, 672, 672) and batch size 3.
Train [8/40]. 15.48 samples/sec. 193.809 ms/step.
Train [16/40]. 15.48 samples/sec. 193.813 ms/step.
Train [24/40]. 15.48 samples/sec. 193.751 ms/step.
Train [32/40]. 15.49 samples/sec. 193.731 ms/step.
Train [40/40]. 15.46 samples/sec. 194.036 ms/step.
Train benchmark of tf_efficientnet_b8.ra_in1k done. 15.27 samples/sec, 194.04 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_cc_b0_4e.in1k created, param count: 13314116
Running inference benchmark on tf_efficientnet_cc_b0_4e.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3072.61 samples/sec. 83.317 ms/step.
Infer [16/40]. 3072.52 samples/sec. 83.319 ms/step.
Infer [24/40]. 3072.48 samples/sec. 83.320 ms/step.
Infer [32/40]. 3071.96 samples/sec. 83.335 ms/step.
Infer [40/40]. 3071.32 samples/sec. 83.352 ms/step.
Inference benchmark of tf_efficientnet_cc_b0_4e.in1k done. 3070.40 samples/sec, 83.35 ms/step
Model tf_efficientnet_cc_b0_4e.in1k created, param count: 13314116
Running train benchmark on tf_efficientnet_cc_b0_4e.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 194.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 86.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_cc_b0_4e.in1k created, param count: 13314116
Running train benchmark on tf_efficientnet_cc_b0_4e.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 862.15 samples/sec. 222.699 ms/step.
Train [16/40]. 862.05 samples/sec. 222.726 ms/step.
Train [24/40]. 862.25 samples/sec. 222.673 ms/step.
Train [32/40]. 862.26 samples/sec. 222.670 ms/step.
Train [40/40]. 862.30 samples/sec. 222.660 ms/step.
Train benchmark of tf_efficientnet_cc_b0_4e.in1k done. 858.07 samples/sec, 222.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_cc_b0_8e.in1k created, param count: 24013284
Running inference benchmark on tf_efficientnet_cc_b0_8e.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3066.29 samples/sec. 83.489 ms/step.
Infer [16/40]. 3066.05 samples/sec. 83.495 ms/step.
Infer [24/40]. 3066.03 samples/sec. 83.496 ms/step.
Infer [32/40]. 3064.98 samples/sec. 83.524 ms/step.
Infer [40/40]. 3064.68 samples/sec. 83.532 ms/step.
Inference benchmark of tf_efficientnet_cc_b0_8e.in1k done. 3063.73 samples/sec, 83.53 ms/step
Model tf_efficientnet_cc_b0_8e.in1k created, param count: 24013284
Running train benchmark on tf_efficientnet_cc_b0_8e.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 99.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_cc_b0_8e.in1k created, param count: 24013284
Running train benchmark on tf_efficientnet_cc_b0_8e.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 859.84 samples/sec. 223.297 ms/step.
Train [16/40]. 859.96 samples/sec. 223.266 ms/step.
Train [24/40]. 859.90 samples/sec. 223.283 ms/step.
Train [32/40]. 859.84 samples/sec. 223.297 ms/step.
Train [40/40]. 859.85 samples/sec. 223.295 ms/step.
Train benchmark of tf_efficientnet_cc_b0_8e.in1k done. 855.64 samples/sec, 223.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_cc_b1_8e.in1k created, param count: 39715968
Running inference benchmark on tf_efficientnet_cc_b1_8e.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 1939.29 samples/sec. 132.007 ms/step.
Infer [16/40]. 1939.07 samples/sec. 132.022 ms/step.
Infer [24/40]. 1939.18 samples/sec. 132.015 ms/step.
Infer [32/40]. 1939.21 samples/sec. 132.013 ms/step.
Infer [40/40]. 1939.16 samples/sec. 132.016 ms/step.
Inference benchmark of tf_efficientnet_cc_b1_8e.in1k done. 1938.77 samples/sec, 132.02 ms/step
Model tf_efficientnet_cc_b1_8e.in1k created, param count: 39715968
Running train benchmark on tf_efficientnet_cc_b1_8e.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 62.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 193.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_cc_b1_8e.in1k created, param count: 39715968
Running train benchmark on tf_efficientnet_cc_b1_8e.in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 159.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_cc_b1_8e.in1k created, param count: 39715968
Running train benchmark on tf_efficientnet_cc_b1_8e.in1k for 40 steps w/ input size (3, 240, 240) and batch size 128.
Train [8/40]. 535.91 samples/sec. 238.845 ms/step.
Train [16/40]. 535.82 samples/sec. 238.884 ms/step.
Train [24/40]. 535.83 samples/sec. 238.882 ms/step.
Train [32/40]. 535.79 samples/sec. 238.900 ms/step.
Train [40/40]. 535.78 samples/sec. 238.902 ms/step.
Train benchmark of tf_efficientnet_cc_b1_8e.in1k done. 532.65 samples/sec, 238.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_el.in1k created, param count: 10589712
Running inference benchmark on tf_efficientnet_el.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 976.41 samples/sec. 262.184 ms/step.
Infer [16/40]. 976.38 samples/sec. 262.194 ms/step.
Infer [24/40]. 976.37 samples/sec. 262.196 ms/step.
Infer [32/40]. 976.35 samples/sec. 262.201 ms/step.
Infer [40/40]. 976.35 samples/sec. 262.202 ms/step.
Inference benchmark of tf_efficientnet_el.in1k done. 976.20 samples/sec, 262.20 ms/step
Model tf_efficientnet_el.in1k created, param count: 10589712
Running train benchmark on tf_efficientnet_el.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacty of 23.65 GiB of which 986.06 MiB is free. Including non-PyTorch memory, this process has 22.68 GiB memory in use. Of the allocated memory 21.61 GiB is allocated by PyTorch, and 581.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_el.in1k created, param count: 10589712
Running train benchmark on tf_efficientnet_el.in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 474.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 334.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_el.in1k created, param count: 10589712
Running train benchmark on tf_efficientnet_el.in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 143.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_el.in1k created, param count: 10589712
Running train benchmark on tf_efficientnet_el.in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 245.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_el.in1k created, param count: 10589712
Running train benchmark on tf_efficientnet_el.in1k for 40 steps w/ input size (3, 300, 300) and batch size 64.
Train [8/40]. 268.66 samples/sec. 238.217 ms/step.
Train [16/40]. 268.71 samples/sec. 238.176 ms/step.
Train [24/40]. 268.59 samples/sec. 238.277 ms/step.
Train [32/40]. 268.59 samples/sec. 238.283 ms/step.
Train [40/40]. 268.60 samples/sec. 238.271 ms/step.
Train benchmark of tf_efficientnet_el.in1k done. 267.34 samples/sec, 238.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_em.in1k created, param count: 6899496
Running inference benchmark on tf_efficientnet_em.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 2184.11 samples/sec. 117.210 ms/step.
Infer [16/40]. 2184.18 samples/sec. 117.207 ms/step.
Infer [24/40]. 2184.21 samples/sec. 117.205 ms/step.
Infer [32/40]. 2184.23 samples/sec. 117.204 ms/step.
Infer [40/40]. 2184.23 samples/sec. 117.204 ms/step.
Inference benchmark of tf_efficientnet_em.in1k done. 2183.71 samples/sec, 117.20 ms/step
Model tf_efficientnet_em.in1k created, param count: 6899496
Running train benchmark on tf_efficientnet_em.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 198.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 126.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_em.in1k created, param count: 6899496
Running train benchmark on tf_efficientnet_em.in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
Train [8/40]. 569.98 samples/sec. 336.856 ms/step.
Train [16/40]. 570.11 samples/sec. 336.777 ms/step.
Train [24/40]. 570.16 samples/sec. 336.748 ms/step.
Train [32/40]. 570.15 samples/sec. 336.753 ms/step.
Train [40/40]. 570.06 samples/sec. 336.809 ms/step.
Train benchmark of tf_efficientnet_em.in1k done. 568.14 samples/sec, 336.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_es.in1k created, param count: 5438392
Running inference benchmark on tf_efficientnet_es.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3529.90 samples/sec. 72.523 ms/step.
Infer [16/40]. 3529.67 samples/sec. 72.528 ms/step.
Infer [24/40]. 3529.70 samples/sec. 72.527 ms/step.
Infer [32/40]. 3529.66 samples/sec. 72.528 ms/step.
Infer [40/40]. 3529.67 samples/sec. 72.528 ms/step.
Inference benchmark of tf_efficientnet_es.in1k done. 3528.44 samples/sec, 72.53 ms/step
Model tf_efficientnet_es.in1k created, param count: 5438392
Running train benchmark on tf_efficientnet_es.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 946.62 samples/sec. 270.436 ms/step.
Train [16/40]. 946.73 samples/sec. 270.403 ms/step.
Train [24/40]. 946.73 samples/sec. 270.405 ms/step.
Train [32/40]. 946.70 samples/sec. 270.412 ms/step.
Train [40/40]. 946.70 samples/sec. 270.412 ms/step.
Train benchmark of tf_efficientnet_es.in1k done. 943.40 samples/sec, 270.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 20.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 17.61 GiB is free. Including non-PyTorch memory, this process has 6.03 GiB memory in use. Of the allocated memory 5.51 GiB is allocated by PyTorch, and 19.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 15.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.73 GiB is free. Including non-PyTorch memory, this process has 19.91 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 649.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 10.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.48 GiB is free. Including non-PyTorch memory, this process has 14.16 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 549.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 7.78 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.17 GiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.09 GiB is allocated by PyTorch, and 905.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.69 GiB is free. Including non-PyTorch memory, this process has 13.95 GiB memory in use. Of the allocated memory 10.22 GiB is allocated by PyTorch, and 3.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 12.36 GiB. GPU 0 has a total capacty of 23.65 GiB of which 12.17 GiB is free. Including non-PyTorch memory, this process has 11.47 GiB memory in use. Of the allocated memory 8.12 GiB is allocated by PyTorch, and 2.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.73 GiB is free. Including non-PyTorch memory, this process has 16.91 GiB memory in use. Of the allocated memory 14.26 GiB is allocated by PyTorch, and 2.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 6.18 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.70 GiB is free. Including non-PyTorch memory, this process has 17.94 GiB memory in use. Of the allocated memory 11.15 GiB is allocated by PyTorch, and 6.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 16.
Infer [8/40]. 14.61 samples/sec. 1095.128 ms/step.
Infer [16/40]. 14.61 samples/sec. 1095.297 ms/step.
Infer [24/40]. 14.61 samples/sec. 1095.490 ms/step.
Infer [32/40]. 14.60 samples/sec. 1095.589 ms/step.
Infer [40/40]. 14.60 samples/sec. 1095.662 ms/step.
Inference benchmark of tf_efficientnet_l2.ns_jft_in1k done. 14.60 samples/sec, 1095.66 ms/step
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 20.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 17.61 GiB is free. Including non-PyTorch memory, this process has 6.03 GiB memory in use. Of the allocated memory 5.51 GiB is allocated by PyTorch, and 19.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 15.56 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.35 GiB is free. Including non-PyTorch memory, this process has 21.29 GiB memory in use. Of the allocated memory 20.16 GiB is allocated by PyTorch, and 649.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 10.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.56 GiB is free. Including non-PyTorch memory, this process has 15.08 GiB memory in use. Of the allocated memory 14.04 GiB is allocated by PyTorch, and 549.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 7.78 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.48 GiB is free. Including non-PyTorch memory, this process has 20.16 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 906.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 5.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.50 GiB is free. Including non-PyTorch memory, this process has 19.14 GiB memory in use. Of the allocated memory 18.31 GiB is allocated by PyTorch, and 343.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 3.89 GiB. GPU 0 has a total capacty of 23.65 GiB of which 500.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 702.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacty of 23.65 GiB of which 634.06 MiB is free. Including non-PyTorch memory, this process has 23.02 GiB memory in use. Of the allocated memory 21.81 GiB is allocated by PyTorch, and 730.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 228.06 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 978.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 114.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 926.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 528.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 372.06 MiB is free. Including non-PyTorch memory, this process has 23.28 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 585.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 22.45 GiB memory in use. Of the allocated memory 21.60 GiB is allocated by PyTorch, and 366.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 572.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 320.06 MiB is free. Including non-PyTorch memory, this process has 23.33 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 675.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 338.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 372.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 232.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 406.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 2.
ERROR: "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 462.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model tf_efficientnet_l2.ns_jft_in1k created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k for 40 steps w/ input size (3, 800, 800) and batch size 1.
ERROR: "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 367.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.94 GiB is free. Including non-PyTorch memory, this process has 17.70 GiB memory in use. Of the allocated memory 17.19 GiB is allocated by PyTorch, and 19.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 17.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 9.46 GiB is free. Including non-PyTorch memory, this process has 14.18 GiB memory in use. Of the allocated memory 10.75 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 11.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.72 GiB is free. Including non-PyTorch memory, this process has 21.92 GiB memory in use. Of the allocated memory 19.45 GiB is allocated by PyTorch, and 1.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 8.75 GiB. GPU 0 has a total capacty of 23.65 GiB of which 6.35 GiB is free. Including non-PyTorch memory, this process has 17.29 GiB memory in use. Of the allocated memory 15.05 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running inference benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 64.
Infer [8/40]. 40.92 samples/sec. 1564.176 ms/step.
Infer [16/40]. 40.91 samples/sec. 1564.238 ms/step.
Infer [24/40]. 40.91 samples/sec. 1564.277 ms/step.
Infer [32/40]. 40.91 samples/sec. 1564.325 ms/step.
Infer [40/40]. 40.91 samples/sec. 1564.389 ms/step.
Inference benchmark of tf_efficientnet_l2.ns_jft_in1k_475 done. 40.91 samples/sec, 1564.39 ms/step
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 7.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 5.29 GiB is free. Including non-PyTorch memory, this process has 18.35 GiB memory in use. Of the allocated memory 17.84 GiB is allocated by PyTorch, and 21.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 5.51 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.46 GiB is free. Including non-PyTorch memory, this process has 20.18 GiB memory in use. Of the allocated memory 19.34 GiB is allocated by PyTorch, and 350.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 3.67 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 21.60 GiB memory in use. Of the allocated memory 20.86 GiB is allocated by PyTorch, and 250.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.46 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 22.56 GiB memory in use. Of the allocated memory 21.62 GiB is allocated by PyTorch, and 453.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 948.06 MiB is free. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 21.83 GiB is allocated by PyTorch, and 397.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 748.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 419.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 498.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 238.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 387.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 2.19 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.00 GiB is free. Including non-PyTorch memory, this process has 21.64 GiB memory in use. Of the allocated memory 20.66 GiB is allocated by PyTorch, and 496.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 540.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 278.06 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 789.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 518.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 608.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 6.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 612.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 4.
ERROR: "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.61 GiB is allocated by PyTorch, and 541.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 3.
ERROR: "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 4.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 306.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model tf_efficientnet_l2.ns_jft_in1k_475 created, param count: 480309308
Running train benchmark on tf_efficientnet_l2.ns_jft_in1k_475 for 40 steps w/ input size (3, 475, 475) and batch size 2.
Train [8/40]. 7.56 samples/sec. 264.572 ms/step.
Train [16/40]. 7.56 samples/sec. 264.504 ms/step.
Train [24/40]. 7.56 samples/sec. 264.532 ms/step.
Train [32/40]. 7.56 samples/sec. 264.551 ms/step.
Train [40/40]. 7.56 samples/sec. 264.559 ms/step.
Train benchmark of tf_efficientnet_l2.ns_jft_in1k_475 done. 7.46 samples/sec, 264.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_lite0.in1k created, param count: 4652008
Running inference benchmark on tf_efficientnet_lite0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 4646.99 samples/sec. 55.089 ms/step.
Infer [16/40]. 4647.21 samples/sec. 55.087 ms/step.
Infer [24/40]. 4647.40 samples/sec. 55.085 ms/step.
Infer [32/40]. 4647.40 samples/sec. 55.085 ms/step.
Infer [40/40]. 4646.85 samples/sec. 55.091 ms/step.
Inference benchmark of tf_efficientnet_lite0.in1k done. 4644.69 samples/sec, 55.09 ms/step
Model tf_efficientnet_lite0.in1k created, param count: 4652008
Running train benchmark on tf_efficientnet_lite0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1281.31 samples/sec. 199.796 ms/step.
Train [16/40]. 1281.24 samples/sec. 199.806 ms/step.
Train [24/40]. 1281.14 samples/sec. 199.823 ms/step.
Train [32/40]. 1281.07 samples/sec. 199.832 ms/step.
Train [40/40]. 1281.06 samples/sec. 199.834 ms/step.
Train benchmark of tf_efficientnet_lite0.in1k done. 1275.49 samples/sec, 199.83 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_lite1.in1k created, param count: 5416680
Running inference benchmark on tf_efficientnet_lite1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 3148.92 samples/sec. 81.298 ms/step.
Infer [16/40]. 3148.44 samples/sec. 81.310 ms/step.
Infer [24/40]. 3148.11 samples/sec. 81.319 ms/step.
Infer [32/40]. 3147.91 samples/sec. 81.324 ms/step.
Infer [40/40]. 3147.77 samples/sec. 81.327 ms/step.
Inference benchmark of tf_efficientnet_lite1.in1k done. 3146.75 samples/sec, 81.33 ms/step
Model tf_efficientnet_lite1.in1k created, param count: 5416680
Running train benchmark on tf_efficientnet_lite1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 83.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_lite1.in1k created, param count: 5416680
Running train benchmark on tf_efficientnet_lite1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 192.
Train [8/40]. 862.86 samples/sec. 222.515 ms/step.
Train [16/40]. 862.91 samples/sec. 222.503 ms/step.
Train [24/40]. 862.80 samples/sec. 222.532 ms/step.
Train [32/40]. 862.81 samples/sec. 222.528 ms/step.
Train [40/40]. 862.82 samples/sec. 222.527 ms/step.
Train benchmark of tf_efficientnet_lite1.in1k done. 858.71 samples/sec, 222.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_lite2.in1k created, param count: 6092072
Running inference benchmark on tf_efficientnet_lite2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
Infer [8/40]. 2416.63 samples/sec. 105.933 ms/step.
Infer [16/40]. 2416.21 samples/sec. 105.951 ms/step.
Infer [24/40]. 2416.10 samples/sec. 105.956 ms/step.
Infer [32/40]. 2416.10 samples/sec. 105.956 ms/step.
Infer [40/40]. 2415.98 samples/sec. 105.961 ms/step.
Inference benchmark of tf_efficientnet_lite2.in1k done. 2415.35 samples/sec, 105.96 ms/step
Model tf_efficientnet_lite2.in1k created, param count: 6092072
Running train benchmark on tf_efficientnet_lite2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 276.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_lite2.in1k created, param count: 6092072
Running train benchmark on tf_efficientnet_lite2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 171.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_lite2.in1k created, param count: 6092072
Running train benchmark on tf_efficientnet_lite2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 128.
Train [8/40]. 658.81 samples/sec. 194.289 ms/step.
Train [16/40]. 658.85 samples/sec. 194.278 ms/step.
Train [24/40]. 658.90 samples/sec. 194.264 ms/step.
Train [32/40]. 658.84 samples/sec. 194.282 ms/step.
Train [40/40]. 658.82 samples/sec. 194.285 ms/step.
Train benchmark of tf_efficientnet_lite2.in1k done. 655.60 samples/sec, 194.28 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_lite3.in1k created, param count: 8197096
Running inference benchmark on tf_efficientnet_lite3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1427.35 samples/sec. 179.353 ms/step.
Infer [16/40]. 1427.44 samples/sec. 179.343 ms/step.
Infer [24/40]. 1427.42 samples/sec. 179.345 ms/step.
Infer [32/40]. 1427.42 samples/sec. 179.345 ms/step.
Infer [40/40]. 1427.40 samples/sec. 179.347 ms/step.
Inference benchmark of tf_efficientnet_lite3.in1k done. 1427.13 samples/sec, 179.35 ms/step
Model tf_efficientnet_lite3.in1k created, param count: 8197096
Running train benchmark on tf_efficientnet_lite3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 297.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_lite3.in1k created, param count: 8197096
Running train benchmark on tf_efficientnet_lite3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 179.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_lite3.in1k created, param count: 8197096
Running train benchmark on tf_efficientnet_lite3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 107.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_lite3.in1k created, param count: 8197096
Running train benchmark on tf_efficientnet_lite3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 184.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_lite3.in1k created, param count: 8197096
Running train benchmark on tf_efficientnet_lite3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 64.
Train [8/40]. 403.88 samples/sec. 158.461 ms/step.
Train [16/40]. 403.85 samples/sec. 158.476 ms/step.
Train [24/40]. 403.82 samples/sec. 158.485 ms/step.
Train [32/40]. 403.80 samples/sec. 158.495 ms/step.
Train [40/40]. 403.79 samples/sec. 158.497 ms/step.
Train benchmark of tf_efficientnet_lite3.in1k done. 401.39 samples/sec, 158.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running inference benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
Infer [8/40]. 690.31 samples/sec. 370.846 ms/step.
Infer [16/40]. 690.30 samples/sec. 370.851 ms/step.
Infer [24/40]. 690.31 samples/sec. 370.848 ms/step.
Infer [32/40]. 690.23 samples/sec. 370.890 ms/step.
Infer [40/40]. 690.19 samples/sec. 370.914 ms/step.
Inference benchmark of tf_efficientnet_lite4.in1k done. 690.10 samples/sec, 370.91 ms/step
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running train benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 4.96 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.96 GiB is free. Including non-PyTorch memory, this process has 19.68 GiB memory in use. Of the allocated memory 19.07 GiB is allocated by PyTorch, and 115.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running train benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.24 GiB. GPU 0 has a total capacty of 23.65 GiB of which 208.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 431.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running train benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 848.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 56.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 348.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running train benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 636.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 560.06 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 146.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running train benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.95 GiB is allocated by PyTorch, and 131.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running train benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.99 GiB is allocated by PyTorch, and 119.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnet_lite4.in1k created, param count: 13006568
Running train benchmark on tf_efficientnet_lite4.in1k for 40 steps w/ input size (3, 380, 380) and batch size 32.
Train [8/40]. 203.52 samples/sec. 157.234 ms/step.
Train [16/40]. 203.50 samples/sec. 157.251 ms/step.
Train [24/40]. 203.50 samples/sec. 157.246 ms/step.
Train [32/40]. 203.49 samples/sec. 157.255 ms/step.
Train [40/40]. 203.49 samples/sec. 157.256 ms/step.
Train benchmark of tf_efficientnet_lite4.in1k done. 202.12 samples/sec, 157.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_b0.in1k created, param count: 7139704
Running inference benchmark on tf_efficientnetv2_b0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6360.09 samples/sec. 40.251 ms/step.
Infer [16/40]. 6360.43 samples/sec. 40.249 ms/step.
Infer [24/40]. 6360.45 samples/sec. 40.249 ms/step.
Infer [32/40]. 6360.40 samples/sec. 40.249 ms/step.
Infer [40/40]. 6360.56 samples/sec. 40.248 ms/step.
Inference benchmark of tf_efficientnetv2_b0.in1k done. 6356.55 samples/sec, 40.25 ms/step
Model tf_efficientnetv2_b0.in1k created, param count: 7139704
Running train benchmark on tf_efficientnetv2_b0.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1606.49 samples/sec. 159.354 ms/step.
Train [16/40]. 1606.02 samples/sec. 159.400 ms/step.
Train [24/40]. 1605.85 samples/sec. 159.417 ms/step.
Train [32/40]. 1605.76 samples/sec. 159.426 ms/step.
Train [40/40]. 1605.70 samples/sec. 159.432 ms/step.
Train benchmark of tf_efficientnetv2_b0.in1k done. 1595.50 samples/sec, 159.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_b1.in1k created, param count: 8141052
Running inference benchmark on tf_efficientnetv2_b1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Infer [8/40]. 4106.14 samples/sec. 62.346 ms/step.
Infer [16/40]. 4105.69 samples/sec. 62.353 ms/step.
Infer [24/40]. 4105.56 samples/sec. 62.354 ms/step.
Infer [32/40]. 4105.45 samples/sec. 62.356 ms/step.
Infer [40/40]. 4105.40 samples/sec. 62.357 ms/step.
Inference benchmark of tf_efficientnetv2_b1.in1k done. 4103.69 samples/sec, 62.36 ms/step
Model tf_efficientnetv2_b1.in1k created, param count: 8141052
Running train benchmark on tf_efficientnetv2_b1.in1k for 40 steps w/ input size (3, 240, 240) and batch size 256.
Train [8/40]. 1029.89 samples/sec. 248.569 ms/step.
Train [16/40]. 1030.43 samples/sec. 248.440 ms/step.
Train [24/40]. 1030.35 samples/sec. 248.460 ms/step.
Train [32/40]. 1030.59 samples/sec. 248.401 ms/step.
Train [40/40]. 1030.51 samples/sec. 248.420 ms/step.
Train benchmark of tf_efficientnetv2_b1.in1k done. 1024.86 samples/sec, 248.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_b2.in1k created, param count: 10096086
Running inference benchmark on tf_efficientnetv2_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
Infer [8/40]. 2900.68 samples/sec. 88.255 ms/step.
Infer [16/40]. 2900.90 samples/sec. 88.248 ms/step.
Infer [24/40]. 2900.98 samples/sec. 88.246 ms/step.
Infer [32/40]. 2900.91 samples/sec. 88.248 ms/step.
Infer [40/40]. 2900.85 samples/sec. 88.250 ms/step.
Inference benchmark of tf_efficientnetv2_b2.in1k done. 2899.97 samples/sec, 88.25 ms/step
Model tf_efficientnetv2_b2.in1k created, param count: 10096086
Running train benchmark on tf_efficientnetv2_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 259.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_b2.in1k created, param count: 10096086
Running train benchmark on tf_efficientnetv2_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 422.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_b2.in1k created, param count: 10096086
Running train benchmark on tf_efficientnetv2_b2.in1k for 40 steps w/ input size (3, 260, 260) and batch size 128.
Train [8/40]. 775.52 samples/sec. 165.051 ms/step.
Train [16/40]. 775.25 samples/sec. 165.108 ms/step.
Train [24/40]. 775.37 samples/sec. 165.083 ms/step.
Train [32/40]. 775.16 samples/sec. 165.127 ms/step.
Train [40/40]. 775.25 samples/sec. 165.108 ms/step.
Train benchmark of tf_efficientnetv2_b2.in1k done. 769.87 samples/sec, 165.11 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_b3.in1k created, param count: 14358406
Running inference benchmark on tf_efficientnetv2_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1747.15 samples/sec. 146.524 ms/step.
Infer [16/40]. 1747.20 samples/sec. 146.520 ms/step.
Infer [24/40]. 1747.17 samples/sec. 146.523 ms/step.
Infer [32/40]. 1747.16 samples/sec. 146.523 ms/step.
Infer [40/40]. 1747.17 samples/sec. 146.522 ms/step.
Inference benchmark of tf_efficientnetv2_b3.in1k done. 1746.80 samples/sec, 146.52 ms/step
Model tf_efficientnetv2_b3.in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 201.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_b3.in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 80.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 241.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_b3.in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.23 GiB is allocated by PyTorch, and 934.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_b3.in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
Train [8/40]. 478.91 samples/sec. 200.454 ms/step.
Train [16/40]. 478.87 samples/sec. 200.472 ms/step.
Train [24/40]. 478.96 samples/sec. 200.436 ms/step.
Train [32/40]. 479.00 samples/sec. 200.419 ms/step.
Train [40/40]. 479.07 samples/sec. 200.390 ms/step.
Train benchmark of tf_efficientnetv2_b3.in1k done. 475.77 samples/sec, 200.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_b3.in21k_ft_in1k created, param count: 14358406
Running inference benchmark on tf_efficientnetv2_b3.in21k_ft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
Infer [8/40]. 1746.79 samples/sec. 146.554 ms/step.
Infer [16/40]. 1746.70 samples/sec. 146.562 ms/step.
Infer [24/40]. 1746.62 samples/sec. 146.569 ms/step.
Infer [32/40]. 1746.57 samples/sec. 146.573 ms/step.
Infer [40/40]. 1746.55 samples/sec. 146.575 ms/step.
Inference benchmark of tf_efficientnetv2_b3.in21k_ft_in1k done. 1746.18 samples/sec, 146.57 ms/step
Model tf_efficientnetv2_b3.in21k_ft_in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in21k_ft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 201.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_b3.in21k_ft_in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in21k_ft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 285.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_b3.in21k_ft_in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in21k_ft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 957.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_b3.in21k_ft_in1k created, param count: 14358406
Running train benchmark on tf_efficientnetv2_b3.in21k_ft_in1k for 40 steps w/ input size (3, 300, 300) and batch size 96.
Train [8/40]. 478.88 samples/sec. 200.468 ms/step.
Train [16/40]. 478.83 samples/sec. 200.489 ms/step.
Train [24/40]. 478.79 samples/sec. 200.506 ms/step.
Train [32/40]. 478.66 samples/sec. 200.558 ms/step.
Train [40/40]. 478.67 samples/sec. 200.558 ms/step.
Train benchmark of tf_efficientnetv2_b3.in21k_ft_in1k done. 475.47 samples/sec, 200.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running inference benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
Infer [8/40]. 170.35 samples/sec. 1502.755 ms/step.
Infer [16/40]. 170.34 samples/sec. 1502.905 ms/step.
Infer [24/40]. 170.33 samples/sec. 1502.959 ms/step.
Infer [32/40]. 170.33 samples/sec. 1503.002 ms/step.
Infer [40/40]. 170.32 samples/sec. 1503.026 ms/step.
Inference benchmark of tf_efficientnetv2_l.in1k done. 170.32 samples/sec, 1503.03 ms/step
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 252.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 459.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 384.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.21 GiB is free. Including non-PyTorch memory, this process has 22.43 GiB memory in use. Of the allocated memory 21.42 GiB is allocated by PyTorch, and 525.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 844.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 428.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 46.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 360.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 72.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 667.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 443.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 21.42 GiB is allocated by PyTorch, and 1.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 221.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnetv2_l.in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in1k for 40 steps w/ input size (3, 480, 480) and batch size 8.
Train [8/40]. 38.80 samples/sec. 206.171 ms/step.
Train [16/40]. 38.80 samples/sec. 206.190 ms/step.
Train [24/40]. 38.79 samples/sec. 206.221 ms/step.
Train [32/40]. 38.80 samples/sec. 206.200 ms/step.
Train [40/40]. 38.80 samples/sec. 206.186 ms/step.
Train benchmark of tf_efficientnetv2_l.in1k done. 38.30 samples/sec, 206.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running inference benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
Infer [8/40]. 170.42 samples/sec. 1502.166 ms/step.
Infer [16/40]. 170.41 samples/sec. 1502.228 ms/step.
Infer [24/40]. 170.41 samples/sec. 1502.268 ms/step.
Infer [32/40]. 170.39 samples/sec. 1502.408 ms/step.
Infer [40/40]. 170.38 samples/sec. 1502.504 ms/step.
Inference benchmark of tf_efficientnetv2_l.in21k_ft_in1k done. 170.38 samples/sec, 1502.50 ms/step
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 252.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 459.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 23.65 GiB of which 558.06 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.22 GiB is allocated by PyTorch, and 384.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.21 GiB is free. Including non-PyTorch memory, this process has 22.43 GiB memory in use. Of the allocated memory 21.42 GiB is allocated by PyTorch, and 525.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 900.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 844.06 MiB is free. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 428.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 236.06 MiB is free. Including non-PyTorch memory, this process has 23.41 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 424.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 58.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 427.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 459.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.24 GiB is allocated by PyTorch, and 897.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 228.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnetv2_l.in21k_ft_in1k created, param count: 118515272
Running train benchmark on tf_efficientnetv2_l.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 8.
Train [8/40]. 38.85 samples/sec. 205.921 ms/step.
Train [16/40]. 38.86 samples/sec. 205.871 ms/step.
Train [24/40]. 38.86 samples/sec. 205.847 ms/step.
Train [32/40]. 38.87 samples/sec. 205.829 ms/step.
Train [40/40]. 38.87 samples/sec. 205.839 ms/step.
Train benchmark of tf_efficientnetv2_l.in21k_ft_in1k done. 38.37 samples/sec, 205.84 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running inference benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
Infer [8/40]. 306.90 samples/sec. 834.145 ms/step.
Infer [16/40]. 306.88 samples/sec. 834.189 ms/step.
Infer [24/40]. 306.88 samples/sec. 834.208 ms/step.
Infer [32/40]. 306.87 samples/sec. 834.225 ms/step.
Infer [40/40]. 306.87 samples/sec. 834.238 ms/step.
Inference benchmark of tf_efficientnetv2_m.in1k done. 306.85 samples/sec, 834.24 ms/step
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 502.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 7.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 23.65 GiB of which 814.06 MiB is free. Including non-PyTorch memory, this process has 22.85 GiB memory in use. Of the allocated memory 21.99 GiB is allocated by PyTorch, and 369.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 440.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 58.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 535.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 262.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 86.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 426.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 870.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 34.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 202.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnetv2_m.in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in1k for 40 steps w/ input size (3, 480, 480) and batch size 16.
Train [8/40]. 85.66 samples/sec. 186.792 ms/step.
Train [16/40]. 85.67 samples/sec. 186.768 ms/step.
Train [24/40]. 85.67 samples/sec. 186.772 ms/step.
Train [32/40]. 85.65 samples/sec. 186.811 ms/step.
Train [40/40]. 85.64 samples/sec. 186.825 ms/step.
Train benchmark of tf_efficientnetv2_m.in1k done. 84.71 samples/sec, 186.82 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running inference benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
Infer [8/40]. 306.87 samples/sec. 834.224 ms/step.
Infer [16/40]. 306.81 samples/sec. 834.385 ms/step.
Infer [24/40]. 306.79 samples/sec. 834.457 ms/step.
Infer [32/40]. 306.77 samples/sec. 834.499 ms/step.
Infer [40/40]. 306.76 samples/sec. 834.531 ms/step.
Inference benchmark of tf_efficientnetv2_m.in21k_ft_in1k done. 306.74 samples/sec, 834.53 ms/step
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 502.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 7.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 23.65 GiB of which 814.06 MiB is free. Including non-PyTorch memory, this process has 22.85 GiB memory in use. Of the allocated memory 21.99 GiB is allocated by PyTorch, and 369.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacty of 23.65 GiB of which 440.06 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 58.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 535.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 74.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 276.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 68.06 MiB is free. Including non-PyTorch memory, this process has 23.57 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 444.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 52.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 854.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 28.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 210.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnetv2_m.in21k_ft_in1k created, param count: 54139356
Running train benchmark on tf_efficientnetv2_m.in21k_ft_in1k for 40 steps w/ input size (3, 480, 480) and batch size 16.
Train [8/40]. 85.78 samples/sec. 186.529 ms/step.
Train [16/40]. 85.77 samples/sec. 186.551 ms/step.
Train [24/40]. 85.75 samples/sec. 186.595 ms/step.
Train [32/40]. 85.75 samples/sec. 186.598 ms/step.
Train [40/40]. 85.74 samples/sec. 186.606 ms/step.
Train benchmark of tf_efficientnetv2_m.in21k_ft_in1k done. 84.80 samples/sec, 186.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_s.in1k created, param count: 21458488
Running inference benchmark on tf_efficientnetv2_s.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 787.02 samples/sec. 325.278 ms/step.
Infer [16/40]. 787.00 samples/sec. 325.287 ms/step.
Infer [24/40]. 786.97 samples/sec. 325.297 ms/step.
Infer [32/40]. 786.97 samples/sec. 325.297 ms/step.
Infer [40/40]. 786.97 samples/sec. 325.298 ms/step.
Inference benchmark of tf_efficientnetv2_s.in1k done. 786.86 samples/sec, 325.30 ms/step
Model tf_efficientnetv2_s.in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 22.63 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 88.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_s.in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 200.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_s.in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 173.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_s.in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 277.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnetv2_s.in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 189.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnetv2_s.in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 224.81 samples/sec. 213.514 ms/step.
Train [16/40]. 224.82 samples/sec. 213.507 ms/step.
Train [24/40]. 224.81 samples/sec. 213.515 ms/step.
Train [32/40]. 224.81 samples/sec. 213.518 ms/step.
Train [40/40]. 224.81 samples/sec. 213.514 ms/step.
Train benchmark of tf_efficientnetv2_s.in1k done. 223.09 samples/sec, 213.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_s.in21k_ft_in1k created, param count: 21458488
Running inference benchmark on tf_efficientnetv2_s.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 787.79 samples/sec. 324.958 ms/step.
Infer [16/40]. 787.80 samples/sec. 324.957 ms/step.
Infer [24/40]. 787.79 samples/sec. 324.961 ms/step.
Infer [32/40]. 787.78 samples/sec. 324.963 ms/step.
Infer [40/40]. 787.78 samples/sec. 324.965 ms/step.
Inference benchmark of tf_efficientnetv2_s.in21k_ft_in1k done. 787.67 samples/sec, 324.96 ms/step
Model tf_efficientnetv2_s.in21k_ft_in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 22.63 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 88.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_s.in21k_ft_in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 200.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_s.in21k_ft_in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 173.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_s.in21k_ft_in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 277.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnetv2_s.in21k_ft_in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 189.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnetv2_s.in21k_ft_in1k created, param count: 21458488
Running train benchmark on tf_efficientnetv2_s.in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
Train [8/40]. 224.78 samples/sec. 213.543 ms/step.
Train [16/40]. 224.79 samples/sec. 213.532 ms/step.
Train [24/40]. 224.80 samples/sec. 213.524 ms/step.
Train [32/40]. 224.81 samples/sec. 213.514 ms/step.
Train [40/40]. 224.81 samples/sec. 213.513 ms/step.
Train benchmark of tf_efficientnetv2_s.in21k_ft_in1k done. 223.08 samples/sec, 213.51 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running inference benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
Infer [8/40]. 110.12 samples/sec. 2324.718 ms/step.
Infer [16/40]. 110.11 samples/sec. 2324.870 ms/step.
Infer [24/40]. 110.11 samples/sec. 2324.934 ms/step.
Infer [32/40]. 110.11 samples/sec. 2324.974 ms/step.
Infer [40/40]. 110.11 samples/sec. 2325.001 ms/step.
Inference benchmark of tf_efficientnetv2_xl.in21k_ft_in1k done. 110.11 samples/sec, 2325.00 ms/step
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 830.06 MiB is free. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 24.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.32 GiB is free. Including non-PyTorch memory, this process has 22.32 GiB memory in use. Of the allocated memory 21.44 GiB is allocated by PyTorch, and 396.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 22.34 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 290.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 23.65 GiB of which 992.06 MiB is free. Including non-PyTorch memory, this process has 22.67 GiB memory in use. Of the allocated memory 21.63 GiB is allocated by PyTorch, and 563.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 248.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 228.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 483.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 30.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 223.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 890.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 22.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 311.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 12.
ERROR: "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 42.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 21.54 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 8.
ERROR: "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 464.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model tf_efficientnetv2_xl.in21k_ft_in1k created, param count: 208119808
Running train benchmark on tf_efficientnetv2_xl.in21k_ft_in1k for 40 steps w/ input size (3, 512, 512) and batch size 6.
Train [8/40]. 25.18 samples/sec. 238.308 ms/step.
Train [16/40]. 25.18 samples/sec. 238.275 ms/step.
Train [24/40]. 25.18 samples/sec. 238.259 ms/step.
Train [32/40]. 25.18 samples/sec. 238.309 ms/step.
Train [40/40]. 25.18 samples/sec. 238.310 ms/step.
Train benchmark of tf_efficientnetv2_xl.in21k_ft_in1k done. 24.84 samples/sec, 238.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mixnet_l.in1k created, param count: 7329252
Running inference benchmark on tf_mixnet_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2006.10 samples/sec. 127.611 ms/step.
Infer [16/40]. 2005.90 samples/sec. 127.623 ms/step.
Infer [24/40]. 2005.93 samples/sec. 127.622 ms/step.
Infer [32/40]. 2005.94 samples/sec. 127.621 ms/step.
Infer [40/40]. 2005.91 samples/sec. 127.623 ms/step.
Inference benchmark of tf_mixnet_l.in1k done. 2005.46 samples/sec, 127.62 ms/step
Model tf_mixnet_l.in1k created, param count: 7329252
Running train benchmark on tf_mixnet_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 2.06 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 256.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_mixnet_l.in1k created, param count: 7329252
Running train benchmark on tf_mixnet_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 36.06 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 270.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tf_mixnet_l.in1k created, param count: 7329252
Running train benchmark on tf_mixnet_l.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 588.04 samples/sec. 217.671 ms/step.
Train [16/40]. 588.03 samples/sec. 217.674 ms/step.
Train [24/40]. 588.06 samples/sec. 217.665 ms/step.
Train [32/40]. 588.07 samples/sec. 217.660 ms/step.
Train [40/40]. 588.07 samples/sec. 217.659 ms/step.
Train benchmark of tf_mixnet_l.in1k done. 584.28 samples/sec, 217.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mixnet_m.in1k created, param count: 5014382
Running inference benchmark on tf_mixnet_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2711.13 samples/sec. 94.426 ms/step.
Infer [16/40]. 2711.13 samples/sec. 94.426 ms/step.
Infer [24/40]. 2711.15 samples/sec. 94.425 ms/step.
Infer [32/40]. 2711.13 samples/sec. 94.426 ms/step.
Infer [40/40]. 2711.17 samples/sec. 94.424 ms/step.
Inference benchmark of tf_mixnet_m.in1k done. 2710.40 samples/sec, 94.42 ms/step
Model tf_mixnet_m.in1k created, param count: 5014382
Running train benchmark on tf_mixnet_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.00 GiB is allocated by PyTorch, and 137.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tf_mixnet_m.in1k created, param count: 5014382
Running train benchmark on tf_mixnet_m.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 763.75 samples/sec. 251.392 ms/step.
Train [16/40]. 763.74 samples/sec. 251.393 ms/step.
Train [24/40]. 763.80 samples/sec. 251.374 ms/step.
Train [32/40]. 763.76 samples/sec. 251.387 ms/step.
Train [40/40]. 763.75 samples/sec. 251.392 ms/step.
Train benchmark of tf_mixnet_m.in1k done. 759.28 samples/sec, 251.39 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mixnet_s.in1k created, param count: 4134606
Running inference benchmark on tf_mixnet_s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 3601.84 samples/sec. 71.075 ms/step.
Infer [16/40]. 3602.32 samples/sec. 71.065 ms/step.
Infer [24/40]. 3602.44 samples/sec. 71.063 ms/step.
Infer [32/40]. 3602.40 samples/sec. 71.064 ms/step.
Infer [40/40]. 3601.98 samples/sec. 71.072 ms/step.
Inference benchmark of tf_mixnet_s.in1k done. 3600.67 samples/sec, 71.07 ms/step
Model tf_mixnet_s.in1k created, param count: 4134606
Running train benchmark on tf_mixnet_s.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1012.37 samples/sec. 252.871 ms/step.
Train [16/40]. 1012.50 samples/sec. 252.840 ms/step.
Train [24/40]. 1012.48 samples/sec. 252.843 ms/step.
Train [32/40]. 1012.45 samples/sec. 252.851 ms/step.
Train [40/40]. 1012.42 samples/sec. 252.858 ms/step.
Train benchmark of tf_mixnet_s.in1k done. 1007.18 samples/sec, 252.86 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mobilenetv3_large_075.in1k created, param count: 3993528
Running inference benchmark on tf_mobilenetv3_large_075.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7734.71 samples/sec. 33.098 ms/step.
Infer [16/40]. 7734.11 samples/sec. 33.100 ms/step.
Infer [24/40]. 7733.99 samples/sec. 33.101 ms/step.
Infer [32/40]. 7734.14 samples/sec. 33.100 ms/step.
Infer [40/40]. 7734.20 samples/sec. 33.100 ms/step.
Inference benchmark of tf_mobilenetv3_large_075.in1k done. 7728.31 samples/sec, 33.10 ms/step
Model tf_mobilenetv3_large_075.in1k created, param count: 3993528
Running train benchmark on tf_mobilenetv3_large_075.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2109.50 samples/sec. 121.356 ms/step.
Train [16/40]. 2109.24 samples/sec. 121.371 ms/step.
Train [24/40]. 2109.24 samples/sec. 121.371 ms/step.
Train [32/40]. 2109.22 samples/sec. 121.372 ms/step.
Train [40/40]. 2109.16 samples/sec. 121.375 ms/step.
Train benchmark of tf_mobilenetv3_large_075.in1k done. 2096.17 samples/sec, 121.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mobilenetv3_large_100.in1k created, param count: 5483032
Running inference benchmark on tf_mobilenetv3_large_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6918.40 samples/sec. 37.003 ms/step.
Infer [16/40]. 6918.09 samples/sec. 37.004 ms/step.
Infer [24/40]. 6918.20 samples/sec. 37.004 ms/step.
Infer [32/40]. 6918.35 samples/sec. 37.003 ms/step.
Infer [40/40]. 6918.33 samples/sec. 37.003 ms/step.
Inference benchmark of tf_mobilenetv3_large_100.in1k done. 6913.59 samples/sec, 37.00 ms/step
Model tf_mobilenetv3_large_100.in1k created, param count: 5483032
Running train benchmark on tf_mobilenetv3_large_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1877.61 samples/sec. 136.343 ms/step.
Train [16/40]. 1877.59 samples/sec. 136.345 ms/step.
Train [24/40]. 1877.72 samples/sec. 136.336 ms/step.
Train [32/40]. 1877.70 samples/sec. 136.337 ms/step.
Train [40/40]. 1877.74 samples/sec. 136.334 ms/step.
Train benchmark of tf_mobilenetv3_large_100.in1k done. 1866.86 samples/sec, 136.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mobilenetv3_large_minimal_100.in1k created, param count: 3924288
Running inference benchmark on tf_mobilenetv3_large_minimal_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7537.74 samples/sec. 33.962 ms/step.
Infer [16/40]. 7537.57 samples/sec. 33.963 ms/step.
Infer [24/40]. 7537.55 samples/sec. 33.963 ms/step.
Infer [32/40]. 7537.55 samples/sec. 33.963 ms/step.
Infer [40/40]. 7537.63 samples/sec. 33.963 ms/step.
Inference benchmark of tf_mobilenetv3_large_minimal_100.in1k done. 7532.23 samples/sec, 33.96 ms/step
Model tf_mobilenetv3_large_minimal_100.in1k created, param count: 3924288
Running train benchmark on tf_mobilenetv3_large_minimal_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2178.41 samples/sec. 117.517 ms/step.
Train [16/40]. 2178.28 samples/sec. 117.524 ms/step.
Train [24/40]. 2178.23 samples/sec. 117.526 ms/step.
Train [32/40]. 2178.22 samples/sec. 117.527 ms/step.
Train [40/40]. 2178.25 samples/sec. 117.525 ms/step.
Train benchmark of tf_mobilenetv3_large_minimal_100.in1k done. 2166.37 samples/sec, 117.53 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mobilenetv3_small_075.in1k created, param count: 2041872
Running inference benchmark on tf_mobilenetv3_small_075.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 23835.13 samples/sec. 10.740 ms/step.
Infer [16/40]. 23833.89 samples/sec. 10.741 ms/step.
Infer [24/40]. 23830.66 samples/sec. 10.742 ms/step.
Infer [32/40]. 23827.27 samples/sec. 10.744 ms/step.
Infer [40/40]. 23825.68 samples/sec. 10.745 ms/step.
Inference benchmark of tf_mobilenetv3_small_075.in1k done. 23778.63 samples/sec, 10.74 ms/step
Model tf_mobilenetv3_small_075.in1k created, param count: 2041872
Running train benchmark on tf_mobilenetv3_small_075.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 5872.48 samples/sec. 43.593 ms/step.
Train [16/40]. 5870.84 samples/sec. 43.605 ms/step.
Train [24/40]. 5870.06 samples/sec. 43.611 ms/step.
Train [32/40]. 5869.73 samples/sec. 43.614 ms/step.
Train [40/40]. 5869.93 samples/sec. 43.612 ms/step.
Train benchmark of tf_mobilenetv3_small_075.in1k done. 5793.17 samples/sec, 43.61 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mobilenetv3_small_100.in1k created, param count: 2542856
Running inference benchmark on tf_mobilenetv3_small_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 21800.83 samples/sec. 11.743 ms/step.
Infer [16/40]. 21791.91 samples/sec. 11.747 ms/step.
Infer [24/40]. 21793.88 samples/sec. 11.746 ms/step.
Infer [32/40]. 21793.28 samples/sec. 11.747 ms/step.
Infer [40/40]. 21793.24 samples/sec. 11.747 ms/step.
Inference benchmark of tf_mobilenetv3_small_100.in1k done. 21754.30 samples/sec, 11.75 ms/step
Model tf_mobilenetv3_small_100.in1k created, param count: 2542856
Running train benchmark on tf_mobilenetv3_small_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 5516.07 samples/sec. 46.410 ms/step.
Train [16/40]. 5516.33 samples/sec. 46.408 ms/step.
Train [24/40]. 5515.74 samples/sec. 46.413 ms/step.
Train [32/40]. 5516.02 samples/sec. 46.410 ms/step.
Train [40/40]. 5516.11 samples/sec. 46.410 ms/step.
Train benchmark of tf_mobilenetv3_small_100.in1k done. 5448.10 samples/sec, 46.41 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tf_mobilenetv3_small_minimal_100.in1k created, param count: 2044736
Running inference benchmark on tf_mobilenetv3_small_minimal_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 24722.36 samples/sec. 10.355 ms/step.
Infer [16/40]. 24723.05 samples/sec. 10.355 ms/step.
Infer [24/40]. 24721.16 samples/sec. 10.355 ms/step.
Infer [32/40]. 24723.03 samples/sec. 10.355 ms/step.
Infer [40/40]. 24722.68 samples/sec. 10.355 ms/step.
Inference benchmark of tf_mobilenetv3_small_minimal_100.in1k done. 24670.57 samples/sec, 10.36 ms/step
Model tf_mobilenetv3_small_minimal_100.in1k created, param count: 2044736
Running train benchmark on tf_mobilenetv3_small_minimal_100.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 6849.02 samples/sec. 37.378 ms/step.
Train [16/40]. 6848.76 samples/sec. 37.379 ms/step.
Train [24/40]. 6848.45 samples/sec. 37.381 ms/step.
Train [32/40]. 6848.07 samples/sec. 37.383 ms/step.
Train [40/40]. 6848.08 samples/sec. 37.383 ms/step.
Train benchmark of tf_mobilenetv3_small_minimal_100.in1k done. 6764.37 samples/sec, 37.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tinynet_a.in1k created, param count: 6187972
Running inference benchmark on tinynet_a.in1k for 40 steps w/ input size (3, 192, 192) and batch size 256.
Infer [8/40]. 5800.15 samples/sec. 44.137 ms/step.
Infer [16/40]. 5799.63 samples/sec. 44.141 ms/step.
Infer [24/40]. 5799.56 samples/sec. 44.141 ms/step.
Infer [32/40]. 5799.16 samples/sec. 44.144 ms/step.
Infer [40/40]. 5798.94 samples/sec. 44.146 ms/step.
Inference benchmark of tinynet_a.in1k done. 5795.60 samples/sec, 44.15 ms/step
Model tinynet_a.in1k created, param count: 6187972
Running train benchmark on tinynet_a.in1k for 40 steps w/ input size (3, 192, 192) and batch size 256.
Train [8/40]. 1436.54 samples/sec. 178.207 ms/step.
Train [16/40]. 1436.43 samples/sec. 178.219 ms/step.
Train [24/40]. 1436.34 samples/sec. 178.230 ms/step.
Train [32/40]. 1436.33 samples/sec. 178.232 ms/step.
Train [40/40]. 1436.31 samples/sec. 178.235 ms/step.
Train benchmark of tinynet_a.in1k done. 1427.85 samples/sec, 178.24 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tinynet_b.in1k created, param count: 3730562
Running inference benchmark on tinynet_b.in1k for 40 steps w/ input size (3, 188, 188) and batch size 256.
Infer [8/40]. 7305.33 samples/sec. 35.043 ms/step.
Infer [16/40]. 7304.94 samples/sec. 35.045 ms/step.
Infer [24/40]. 7305.11 samples/sec. 35.044 ms/step.
Infer [32/40]. 7304.88 samples/sec. 35.045 ms/step.
Infer [40/40]. 7304.40 samples/sec. 35.047 ms/step.
Inference benchmark of tinynet_b.in1k done. 7299.24 samples/sec, 35.05 ms/step
Model tinynet_b.in1k created, param count: 3730562
Running train benchmark on tinynet_b.in1k for 40 steps w/ input size (3, 188, 188) and batch size 256.
Train [8/40]. 1736.07 samples/sec. 147.460 ms/step.
Train [16/40]. 1736.10 samples/sec. 147.457 ms/step.
Train [24/40]. 1736.07 samples/sec. 147.460 ms/step.
Train [32/40]. 1735.84 samples/sec. 147.479 ms/step.
Train [40/40]. 1735.86 samples/sec. 147.477 ms/step.
Train benchmark of tinynet_b.in1k done. 1725.97 samples/sec, 147.48 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tinynet_c.in1k created, param count: 2457234
Running inference benchmark on tinynet_c.in1k for 40 steps w/ input size (3, 184, 184) and batch size 256.
Infer [8/40]. 11863.52 samples/sec. 21.579 ms/step.
Infer [16/40]. 11863.76 samples/sec. 21.578 ms/step.
Infer [24/40]. 11863.16 samples/sec. 21.579 ms/step.
Infer [32/40]. 11862.21 samples/sec. 21.581 ms/step.
Infer [40/40]. 11861.28 samples/sec. 21.583 ms/step.
Inference benchmark of tinynet_c.in1k done. 11848.27 samples/sec, 21.58 ms/step
Model tinynet_c.in1k created, param count: 2457234
Running train benchmark on tinynet_c.in1k for 40 steps w/ input size (3, 184, 184) and batch size 256.
Train [8/40]. 2706.53 samples/sec. 94.586 ms/step.
Train [16/40]. 2706.51 samples/sec. 94.587 ms/step.
Train [24/40]. 2706.25 samples/sec. 94.596 ms/step.
Train [32/40]. 2706.00 samples/sec. 94.605 ms/step.
Train [40/40]. 2706.02 samples/sec. 94.604 ms/step.
Train benchmark of tinynet_c.in1k done. 2685.78 samples/sec, 94.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tinynet_d.in1k created, param count: 2338446
Running inference benchmark on tinynet_d.in1k for 40 steps w/ input size (3, 152, 152) and batch size 256.
Infer [8/40]. 24641.44 samples/sec. 10.389 ms/step.
Infer [16/40]. 24642.05 samples/sec. 10.389 ms/step.
Infer [24/40]. 24640.94 samples/sec. 10.389 ms/step.
Infer [32/40]. 24640.49 samples/sec. 10.389 ms/step.
Infer [40/40]. 24640.56 samples/sec. 10.389 ms/step.
Inference benchmark of tinynet_d.in1k done. 24592.15 samples/sec, 10.39 ms/step
Model tinynet_d.in1k created, param count: 2338446
Running train benchmark on tinynet_d.in1k for 40 steps w/ input size (3, 152, 152) and batch size 256.
Train [8/40]. 5392.17 samples/sec. 47.476 ms/step.
Train [16/40]. 5390.61 samples/sec. 47.490 ms/step.
Train [24/40]. 5390.33 samples/sec. 47.492 ms/step.
Train [32/40]. 5389.84 samples/sec. 47.497 ms/step.
Train [40/40]. 5389.80 samples/sec. 47.497 ms/step.
Train benchmark of tinynet_d.in1k done. 5328.76 samples/sec, 47.50 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tinynet_e.in1k created, param count: 2042972
Running inference benchmark on tinynet_e.in1k for 40 steps w/ input size (3, 106, 106) and batch size 256.
Infer [8/40]. 31046.98 samples/sec. 8.246 ms/step.
Infer [16/40]. 31054.07 samples/sec. 8.244 ms/step.
Infer [24/40]. 31059.03 samples/sec. 8.242 ms/step.
Infer [32/40]. 31057.85 samples/sec. 8.243 ms/step.
Infer [40/40]. 31061.89 samples/sec. 8.242 ms/step.
Inference benchmark of tinynet_e.in1k done. 30988.95 samples/sec, 8.24 ms/step
Model tinynet_e.in1k created, param count: 2042972
Running train benchmark on tinynet_e.in1k for 40 steps w/ input size (3, 106, 106) and batch size 256.
Train [8/40]. 8310.74 samples/sec. 30.804 ms/step.
Train [16/40]. 8309.63 samples/sec. 30.808 ms/step.
Train [24/40]. 8310.17 samples/sec. 30.806 ms/step.
Train [32/40]. 8308.93 samples/sec. 30.810 ms/step.
Train [40/40]. 8309.28 samples/sec. 30.809 ms/step.
Train benchmark of tinynet_e.in1k done. 8174.85 samples/sec, 30.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tnt_s_patch16_224 created, param count: 23755336
Running inference benchmark on tnt_s_patch16_224 for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1166.41 samples/sec. 219.477 ms/step.
Infer [16/40]. 1166.45 samples/sec. 219.469 ms/step.
Infer [24/40]. 1166.45 samples/sec. 219.469 ms/step.
Infer [32/40]. 1166.45 samples/sec. 219.468 ms/step.
Infer [40/40]. 1166.45 samples/sec. 219.468 ms/step.
Inference benchmark of tnt_s_patch16_224 done. 1166.25 samples/sec, 219.47 ms/step
Model tnt_s_patch16_224 created, param count: 23755336
Running train benchmark on tnt_s_patch16_224 for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 268.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 357.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tnt_s_patch16_224 created, param count: 23755336
Running train benchmark on tnt_s_patch16_224 for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 583.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tnt_s_patch16_224 created, param count: 23755336
Running train benchmark on tnt_s_patch16_224 for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 383.07 samples/sec. 334.145 ms/step.
Train [16/40]. 383.06 samples/sec. 334.151 ms/step.
Train [24/40]. 383.06 samples/sec. 334.147 ms/step.
Train [32/40]. 383.06 samples/sec. 334.148 ms/step.
Train [40/40]. 383.06 samples/sec. 334.151 ms/step.
Train benchmark of tnt_s_patch16_224 done. 380.92 samples/sec, 334.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_l.miil_in1k created, param count: 55989256
Running inference benchmark on tresnet_l.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1424.96 samples/sec. 179.655 ms/step.
Infer [16/40]. 1425.06 samples/sec. 179.642 ms/step.
Infer [24/40]. 1425.10 samples/sec. 179.637 ms/step.
Infer [32/40]. 1425.11 samples/sec. 179.636 ms/step.
Infer [40/40]. 1425.10 samples/sec. 179.636 ms/step.
Inference benchmark of tresnet_l.miil_in1k done. 1424.82 samples/sec, 179.64 ms/step
Model tresnet_l.miil_in1k created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.67 GiB is allocated by PyTorch, and 330.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tresnet_l.miil_in1k created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 413.77 samples/sec. 464.023 ms/step.
Train [16/40]. 413.76 samples/sec. 464.037 ms/step.
Train [24/40]. 413.74 samples/sec. 464.060 ms/step.
Train [32/40]. 413.73 samples/sec. 464.076 ms/step.
Train [40/40]. 413.72 samples/sec. 464.080 ms/step.
Train benchmark of tresnet_l.miil_in1k done. 412.23 samples/sec, 464.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_l.miil_in1k_448 created, param count: 55989256
Running inference benchmark on tresnet_l.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 361.78 samples/sec. 707.607 ms/step.
Infer [16/40]. 361.78 samples/sec. 707.615 ms/step.
Infer [24/40]. 361.77 samples/sec. 707.631 ms/step.
Infer [32/40]. 361.76 samples/sec. 707.660 ms/step.
Infer [40/40]. 361.75 samples/sec. 707.671 ms/step.
Inference benchmark of tresnet_l.miil_in1k_448 done. 361.73 samples/sec, 707.67 ms/step
Model tresnet_l.miil_in1k_448 created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 23.65 GiB of which 242.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 381.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tresnet_l.miil_in1k_448 created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 148.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.45 GiB is allocated by PyTorch, and 559.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tresnet_l.miil_in1k_448 created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 466.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 211.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tresnet_l.miil_in1k_448 created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 158.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 565.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tresnet_l.miil_in1k_448 created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.12 GiB is allocated by PyTorch, and 922.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tresnet_l.miil_in1k_448 created, param count: 55989256
Running train benchmark on tresnet_l.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 48.
Train [8/40]. 110.08 samples/sec. 436.033 ms/step.
Train [16/40]. 110.08 samples/sec. 436.053 ms/step.
Train [24/40]. 110.08 samples/sec. 436.051 ms/step.
Train [32/40]. 110.08 samples/sec. 436.053 ms/step.
Train [40/40]. 110.07 samples/sec. 436.069 ms/step.
Train benchmark of tresnet_l.miil_in1k_448 done. 109.66 samples/sec, 436.07 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_m.miil_in1k created, param count: 31389032
Running inference benchmark on tresnet_m.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2371.21 samples/sec. 107.962 ms/step.
Infer [16/40]. 2371.04 samples/sec. 107.970 ms/step.
Infer [24/40]. 2370.59 samples/sec. 107.990 ms/step.
Infer [32/40]. 2371.44 samples/sec. 107.951 ms/step.
Infer [40/40]. 2371.01 samples/sec. 107.971 ms/step.
Inference benchmark of tresnet_m.miil_in1k done. 2370.41 samples/sec, 107.97 ms/step
Model tresnet_m.miil_in1k created, param count: 31389032
Running train benchmark on tresnet_m.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 743.95 samples/sec. 344.108 ms/step.
Train [16/40]. 743.93 samples/sec. 344.118 ms/step.
Train [24/40]. 743.93 samples/sec. 344.119 ms/step.
Train [32/40]. 743.96 samples/sec. 344.106 ms/step.
Train [40/40]. 743.93 samples/sec. 344.120 ms/step.
Train benchmark of tresnet_m.miil_in1k done. 741.13 samples/sec, 344.12 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_m.miil_in1k_448 created, param count: 31389032
Running inference benchmark on tresnet_m.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 672.54 samples/sec. 380.645 ms/step.
Infer [16/40]. 672.53 samples/sec. 380.653 ms/step.
Infer [24/40]. 672.52 samples/sec. 380.659 ms/step.
Infer [32/40]. 672.51 samples/sec. 380.664 ms/step.
Infer [40/40]. 672.49 samples/sec. 380.673 ms/step.
Inference benchmark of tresnet_m.miil_in1k_448 done. 672.41 samples/sec, 380.67 ms/step
Model tresnet_m.miil_in1k_448 created, param count: 31389032
Running train benchmark on tresnet_m.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 118.06 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 63.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tresnet_m.miil_in1k_448 created, param count: 31389032
Running train benchmark on tresnet_m.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 60.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tresnet_m.miil_in1k_448 created, param count: 31389032
Running train benchmark on tresnet_m.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 294.06 MiB is free. Including non-PyTorch memory, this process has 23.35 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 225.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tresnet_m.miil_in1k_448 created, param count: 31389032
Running train benchmark on tresnet_m.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 637.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tresnet_m.miil_in1k_448 created, param count: 31389032
Running train benchmark on tresnet_m.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 64.
Train [8/40]. 206.11 samples/sec. 310.521 ms/step.
Train [16/40]. 206.10 samples/sec. 310.530 ms/step.
Train [24/40]. 206.10 samples/sec. 310.532 ms/step.
Train [32/40]. 206.09 samples/sec. 310.545 ms/step.
Train [40/40]. 206.07 samples/sec. 310.568 ms/step.
Train benchmark of tresnet_m.miil_in1k_448 done. 205.22 samples/sec, 310.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_m.miil_in21k_ft_in1k created, param count: 31389032
Running inference benchmark on tresnet_m.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2371.29 samples/sec. 107.958 ms/step.
Infer [16/40]. 2370.90 samples/sec. 107.976 ms/step.
Infer [24/40]. 2371.15 samples/sec. 107.964 ms/step.
Infer [32/40]. 2371.40 samples/sec. 107.953 ms/step.
Infer [40/40]. 2371.26 samples/sec. 107.959 ms/step.
Inference benchmark of tresnet_m.miil_in21k_ft_in1k done. 2370.64 samples/sec, 107.96 ms/step
Model tresnet_m.miil_in21k_ft_in1k created, param count: 31389032
Running train benchmark on tresnet_m.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 743.52 samples/sec. 344.309 ms/step.
Train [16/40]. 743.42 samples/sec. 344.356 ms/step.
Train [24/40]. 743.43 samples/sec. 344.351 ms/step.
Train [32/40]. 743.45 samples/sec. 344.338 ms/step.
Train [40/40]. 743.44 samples/sec. 344.346 ms/step.
Train benchmark of tresnet_m.miil_in21k_ft_in1k done. 740.65 samples/sec, 344.35 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_v2_l.miil_in21k_ft_in1k created, param count: 46174824
Running inference benchmark on tresnet_v2_l.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1227.82 samples/sec. 208.500 ms/step.
Infer [16/40]. 1228.24 samples/sec. 208.428 ms/step.
Infer [24/40]. 1228.59 samples/sec. 208.370 ms/step.
Infer [32/40]. 1228.67 samples/sec. 208.355 ms/step.
Infer [40/40]. 1228.69 samples/sec. 208.352 ms/step.
Inference benchmark of tresnet_v2_l.miil_in21k_ft_in1k done. 1228.48 samples/sec, 208.35 ms/step
Model tresnet_v2_l.miil_in21k_ft_in1k created, param count: 46174824
Running train benchmark on tresnet_v2_l.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 246.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tresnet_v2_l.miil_in21k_ft_in1k created, param count: 46174824
Running train benchmark on tresnet_v2_l.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 173.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tresnet_v2_l.miil_in21k_ft_in1k created, param count: 46174824
Running train benchmark on tresnet_v2_l.miil_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 444.08 samples/sec. 288.236 ms/step.
Train [16/40]. 444.07 samples/sec. 288.245 ms/step.
Train [24/40]. 444.07 samples/sec. 288.246 ms/step.
Train [32/40]. 444.05 samples/sec. 288.253 ms/step.
Train [40/40]. 444.05 samples/sec. 288.256 ms/step.
Train benchmark of tresnet_v2_l.miil_in21k_ft_in1k done. 441.49 samples/sec, 288.26 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_xl.miil_in1k created, param count: 78436244
Running inference benchmark on tresnet_xl.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 999.88 samples/sec. 256.030 ms/step.
Infer [16/40]. 999.92 samples/sec. 256.021 ms/step.
Infer [24/40]. 999.94 samples/sec. 256.017 ms/step.
Infer [32/40]. 999.95 samples/sec. 256.014 ms/step.
Infer [40/40]. 999.95 samples/sec. 256.013 ms/step.
Inference benchmark of tresnet_xl.miil_in1k done. 999.80 samples/sec, 256.01 ms/step
Model tresnet_xl.miil_in1k created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 192.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 330.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tresnet_xl.miil_in1k created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 374.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tresnet_xl.miil_in1k created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 315.95 samples/sec. 405.130 ms/step.
Train [16/40]. 315.94 samples/sec. 405.138 ms/step.
Train [24/40]. 315.94 samples/sec. 405.140 ms/step.
Train [32/40]. 315.94 samples/sec. 405.143 ms/step.
Train [40/40]. 315.92 samples/sec. 405.163 ms/step.
Train benchmark of tresnet_xl.miil_in1k done. 314.51 samples/sec, 405.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running inference benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 256.13 samples/sec. 999.497 ms/step.
Infer [16/40]. 256.11 samples/sec. 999.572 ms/step.
Infer [24/40]. 256.11 samples/sec. 999.588 ms/step.
Infer [32/40]. 256.10 samples/sec. 999.609 ms/step.
Infer [40/40]. 256.10 samples/sec. 999.625 ms/step.
Inference benchmark of tresnet_xl.miil_in1k_448 done. 256.08 samples/sec, 999.62 ms/step
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1018.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 38.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 812.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 23.65 GiB of which 156.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 364.06 MiB is free. Including non-PyTorch memory, this process has 23.29 GiB memory in use. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 593.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 330.06 MiB is free. Including non-PyTorch memory, this process has 23.32 GiB memory in use. Of the allocated memory 22.46 GiB is allocated by PyTorch, and 374.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 140.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 432.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 21.86 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model tresnet_xl.miil_in1k_448 created, param count: 78436244
Running train benchmark on tresnet_xl.miil_in1k_448 for 40 steps w/ input size (3, 448, 448) and batch size 32.
Train [8/40]. 84.41 samples/sec. 379.081 ms/step.
Train [16/40]. 84.39 samples/sec. 379.175 ms/step.
Train [24/40]. 84.38 samples/sec. 379.218 ms/step.
Train [32/40]. 84.38 samples/sec. 379.246 ms/step.
Train [40/40]. 84.37 samples/sec. 379.269 ms/step.
Train benchmark of tresnet_xl.miil_in1k_448 done. 83.96 samples/sec, 379.27 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model twins_pcpvt_base.in1k created, param count: 43828456
Running inference benchmark on twins_pcpvt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1799.16 samples/sec. 142.288 ms/step.
Infer [16/40]. 1799.22 samples/sec. 142.284 ms/step.
Infer [24/40]. 1799.17 samples/sec. 142.288 ms/step.
Infer [32/40]. 1799.04 samples/sec. 142.298 ms/step.
Infer [40/40]. 1798.94 samples/sec. 142.306 ms/step.
Inference benchmark of twins_pcpvt_base.in1k done. 1798.55 samples/sec, 142.31 ms/step
Model twins_pcpvt_base.in1k created, param count: 43828456
Running train benchmark on twins_pcpvt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 134.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 88.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model twins_pcpvt_base.in1k created, param count: 43828456
Running train benchmark on twins_pcpvt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 182.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 72.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model twins_pcpvt_base.in1k created, param count: 43828456
Running train benchmark on twins_pcpvt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 522.03 samples/sec. 245.195 ms/step.
Train [16/40]. 522.03 samples/sec. 245.197 ms/step.
Train [24/40]. 522.02 samples/sec. 245.199 ms/step.
Train [32/40]. 521.98 samples/sec. 245.219 ms/step.
Train [40/40]. 521.95 samples/sec. 245.234 ms/step.
Train benchmark of twins_pcpvt_base.in1k done. 517.42 samples/sec, 245.23 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model twins_pcpvt_large.in1k created, param count: 60989672
Running inference benchmark on twins_pcpvt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1285.66 samples/sec. 199.120 ms/step.
Infer [16/40]. 1285.61 samples/sec. 199.127 ms/step.
Infer [24/40]. 1285.51 samples/sec. 199.142 ms/step.
Infer [32/40]. 1285.45 samples/sec. 199.152 ms/step.
Infer [40/40]. 1285.39 samples/sec. 199.162 ms/step.
Inference benchmark of twins_pcpvt_large.in1k done. 1285.15 samples/sec, 199.16 ms/step
Model twins_pcpvt_large.in1k created, param count: 60989672
Running train benchmark on twins_pcpvt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 64.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 23.01 GiB is allocated by PyTorch, and 69.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model twins_pcpvt_large.in1k created, param count: 60989672
Running train benchmark on twins_pcpvt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 380.06 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.74 GiB is allocated by PyTorch, and 33.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model twins_pcpvt_large.in1k created, param count: 60989672
Running train benchmark on twins_pcpvt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 20.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.82 GiB is allocated by PyTorch, and 311.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model twins_pcpvt_large.in1k created, param count: 60989672
Running train benchmark on twins_pcpvt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 376.20 samples/sec. 255.183 ms/step.
Train [16/40]. 376.21 samples/sec. 255.176 ms/step.
Train [24/40]. 376.21 samples/sec. 255.177 ms/step.
Train [32/40]. 376.19 samples/sec. 255.189 ms/step.
Train [40/40]. 376.19 samples/sec. 255.190 ms/step.
Train benchmark of twins_pcpvt_large.in1k done. 371.75 samples/sec, 255.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model twins_pcpvt_small.in1k created, param count: 24106216
Running inference benchmark on twins_pcpvt_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2555.15 samples/sec. 100.190 ms/step.
Infer [16/40]. 2555.09 samples/sec. 100.192 ms/step.
Infer [24/40]. 2555.09 samples/sec. 100.192 ms/step.
Infer [32/40]. 2555.12 samples/sec. 100.191 ms/step.
Infer [40/40]. 2555.11 samples/sec. 100.191 ms/step.
Inference benchmark of twins_pcpvt_small.in1k done. 2554.41 samples/sec, 100.19 ms/step
Model twins_pcpvt_small.in1k created, param count: 24106216
Running train benchmark on twins_pcpvt_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 6.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.09 GiB is allocated by PyTorch, and 44.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model twins_pcpvt_small.in1k created, param count: 24106216
Running train benchmark on twins_pcpvt_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 719.69 samples/sec. 266.782 ms/step.
Train [16/40]. 719.72 samples/sec. 266.769 ms/step.
Train [24/40]. 719.71 samples/sec. 266.776 ms/step.
Train [32/40]. 719.69 samples/sec. 266.780 ms/step.
Train [40/40]. 719.70 samples/sec. 266.779 ms/step.
Train benchmark of twins_pcpvt_small.in1k done. 715.35 samples/sec, 266.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model twins_svt_base.in1k created, param count: 56070952
Running inference benchmark on twins_svt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1399.47 samples/sec. 182.926 ms/step.
Infer [16/40]. 1399.40 samples/sec. 182.935 ms/step.
Infer [24/40]. 1399.37 samples/sec. 182.939 ms/step.
Infer [32/40]. 1399.35 samples/sec. 182.942 ms/step.
Infer [40/40]. 1399.31 samples/sec. 182.947 ms/step.
Inference benchmark of twins_svt_base.in1k done. 1399.05 samples/sec, 182.95 ms/step
Model twins_svt_base.in1k created, param count: 56070952
Running train benchmark on twins_svt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 97.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model twins_svt_base.in1k created, param count: 56070952
Running train benchmark on twins_svt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 12.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 192.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model twins_svt_base.in1k created, param count: 56070952
Running train benchmark on twins_svt_base.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 439.30 samples/sec. 291.374 ms/step.
Train [16/40]. 439.34 samples/sec. 291.349 ms/step.
Train [24/40]. 439.30 samples/sec. 291.376 ms/step.
Train [32/40]. 439.30 samples/sec. 291.371 ms/step.
Train [40/40]. 439.29 samples/sec. 291.382 ms/step.
Train benchmark of twins_svt_base.in1k done. 436.32 samples/sec, 291.38 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model twins_svt_large.in1k created, param count: 99271400
Running inference benchmark on twins_svt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 972.93 samples/sec. 263.124 ms/step.
Infer [16/40]. 972.94 samples/sec. 263.120 ms/step.
Infer [24/40]. 972.96 samples/sec. 263.116 ms/step.
Infer [32/40]. 972.94 samples/sec. 263.120 ms/step.
Infer [40/40]. 972.94 samples/sec. 263.120 ms/step.
Inference benchmark of twins_svt_large.in1k done. 972.77 samples/sec, 263.12 ms/step
Model twins_svt_large.in1k created, param count: 99271400
Running train benchmark on twins_svt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 14.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 23.03 GiB is allocated by PyTorch, and 99.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model twins_svt_large.in1k created, param count: 99271400
Running train benchmark on twins_svt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 98.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 111.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model twins_svt_large.in1k created, param count: 99271400
Running train benchmark on twins_svt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.91 GiB is allocated by PyTorch, and 86.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model twins_svt_large.in1k created, param count: 99271400
Running train benchmark on twins_svt_large.in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
Train [8/40]. 308.62 samples/sec. 311.059 ms/step.
Train [16/40]. 308.61 samples/sec. 311.076 ms/step.
Train [24/40]. 308.61 samples/sec. 311.070 ms/step.
Train [32/40]. 308.61 samples/sec. 311.070 ms/step.
Train [40/40]. 308.60 samples/sec. 311.077 ms/step.
Train benchmark of twins_svt_large.in1k done. 306.61 samples/sec, 311.08 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model twins_svt_small.in1k created, param count: 24060776
Running inference benchmark on twins_svt_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2812.99 samples/sec. 91.006 ms/step.
Infer [16/40]. 2812.91 samples/sec. 91.009 ms/step.
Infer [24/40]. 2812.82 samples/sec. 91.012 ms/step.
Infer [32/40]. 2812.88 samples/sec. 91.010 ms/step.
Infer [40/40]. 2812.86 samples/sec. 91.011 ms/step.
Inference benchmark of twins_svt_small.in1k done. 2812.02 samples/sec, 91.01 ms/step
Model twins_svt_small.in1k created, param count: 24060776
Running train benchmark on twins_svt_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 876.81 samples/sec. 291.967 ms/step.
Train [16/40]. 876.75 samples/sec. 291.987 ms/step.
Train [24/40]. 876.72 samples/sec. 291.996 ms/step.
Train [32/40]. 876.72 samples/sec. 291.997 ms/step.
Train [40/40]. 876.72 samples/sec. 291.998 ms/step.
Train benchmark of twins_svt_small.in1k done. 871.49 samples/sec, 292.00 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg11.tv_in1k created, param count: 132863336
Running inference benchmark on vgg11.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2598.43 samples/sec. 98.521 ms/step.
Infer [16/40]. 2598.25 samples/sec. 98.528 ms/step.
Infer [24/40]. 2598.23 samples/sec. 98.529 ms/step.
Infer [32/40]. 2598.22 samples/sec. 98.529 ms/step.
Infer [40/40]. 2598.27 samples/sec. 98.527 ms/step.
Inference benchmark of vgg11.tv_in1k done. 2597.47 samples/sec, 98.53 ms/step
Model vgg11.tv_in1k created, param count: 132863336
Running train benchmark on vgg11.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 804.34 samples/sec. 318.273 ms/step.
Train [16/40]. 804.31 samples/sec. 318.284 ms/step.
Train [24/40]. 804.29 samples/sec. 318.291 ms/step.
Train [32/40]. 804.24 samples/sec. 318.312 ms/step.
Train [40/40]. 804.20 samples/sec. 318.330 ms/step.
Train benchmark of vgg11.tv_in1k done. 803.06 samples/sec, 318.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg11_bn.tv_in1k created, param count: 132868840
Running inference benchmark on vgg11_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2220.92 samples/sec. 115.267 ms/step.
Infer [16/40]. 2220.87 samples/sec. 115.270 ms/step.
Infer [24/40]. 2220.85 samples/sec. 115.271 ms/step.
Infer [32/40]. 2220.46 samples/sec. 115.292 ms/step.
Infer [40/40]. 2220.41 samples/sec. 115.294 ms/step.
Inference benchmark of vgg11_bn.tv_in1k done. 2219.85 samples/sec, 115.29 ms/step
Model vgg11_bn.tv_in1k created, param count: 132868840
Running train benchmark on vgg11_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 651.86 samples/sec. 392.719 ms/step.
Train [16/40]. 651.82 samples/sec. 392.746 ms/step.
Train [24/40]. 651.78 samples/sec. 392.771 ms/step.
Train [32/40]. 651.67 samples/sec. 392.837 ms/step.
Train [40/40]. 651.62 samples/sec. 392.868 ms/step.
Train benchmark of vgg11_bn.tv_in1k done. 650.76 samples/sec, 392.87 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg13.tv_in1k created, param count: 133047848
Running inference benchmark on vgg13.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1673.60 samples/sec. 152.964 ms/step.
Infer [16/40]. 1674.03 samples/sec. 152.924 ms/step.
Infer [24/40]. 1674.15 samples/sec. 152.913 ms/step.
Infer [32/40]. 1674.22 samples/sec. 152.907 ms/step.
Infer [40/40]. 1674.18 samples/sec. 152.911 ms/step.
Inference benchmark of vgg13.tv_in1k done. 1673.84 samples/sec, 152.91 ms/step
Model vgg13.tv_in1k created, param count: 133047848
Running train benchmark on vgg13.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 527.65 samples/sec. 485.168 ms/step.
Train [16/40]. 526.95 samples/sec. 485.812 ms/step.
Train [24/40]. 526.86 samples/sec. 485.895 ms/step.
Train [32/40]. 526.99 samples/sec. 485.776 ms/step.
Train [40/40]. 526.82 samples/sec. 485.937 ms/step.
Train benchmark of vgg13.tv_in1k done. 526.31 samples/sec, 485.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg13_bn.tv_in1k created, param count: 133053736
Running inference benchmark on vgg13_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1416.59 samples/sec. 180.715 ms/step.
Infer [16/40]. 1416.68 samples/sec. 180.704 ms/step.
Infer [24/40]. 1416.63 samples/sec. 180.711 ms/step.
Infer [32/40]. 1416.63 samples/sec. 180.711 ms/step.
Infer [40/40]. 1416.49 samples/sec. 180.728 ms/step.
Inference benchmark of vgg13_bn.tv_in1k done. 1416.20 samples/sec, 180.73 ms/step
Model vgg13_bn.tv_in1k created, param count: 133053736
Running train benchmark on vgg13_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 268.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.48 GiB is allocated by PyTorch, and 416.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vgg13_bn.tv_in1k created, param count: 133053736
Running train benchmark on vgg13_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 94.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.12 GiB is allocated by PyTorch, and 951.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vgg13_bn.tv_in1k created, param count: 133053736
Running train benchmark on vgg13_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 411.74 samples/sec. 310.876 ms/step.
Train [16/40]. 411.74 samples/sec. 310.878 ms/step.
Train [24/40]. 411.73 samples/sec. 310.883 ms/step.
Train [32/40]. 411.74 samples/sec. 310.878 ms/step.
Train [40/40]. 411.74 samples/sec. 310.878 ms/step.
Train benchmark of vgg13_bn.tv_in1k done. 411.05 samples/sec, 310.88 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg16.tv_in1k created, param count: 138357544
Running inference benchmark on vgg16.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1386.35 samples/sec. 184.658 ms/step.
Infer [16/40]. 1386.27 samples/sec. 184.669 ms/step.
Infer [24/40]. 1386.44 samples/sec. 184.646 ms/step.
Infer [32/40]. 1386.48 samples/sec. 184.640 ms/step.
Infer [40/40]. 1386.52 samples/sec. 184.635 ms/step.
Inference benchmark of vgg16.tv_in1k done. 1386.23 samples/sec, 184.63 ms/step
Model vgg16.tv_in1k created, param count: 138357544
Running train benchmark on vgg16.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 433.84 samples/sec. 590.084 ms/step.
Train [16/40]. 433.20 samples/sec. 590.952 ms/step.
Train [24/40]. 433.07 samples/sec. 591.126 ms/step.
Train [32/40]. 433.06 samples/sec. 591.137 ms/step.
Train [40/40]. 432.63 samples/sec. 591.731 ms/step.
Train benchmark of vgg16.tv_in1k done. 432.26 samples/sec, 591.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg16_bn.tv_in1k created, param count: 138365992
Running inference benchmark on vgg16_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1188.58 samples/sec. 215.383 ms/step.
Infer [16/40]. 1188.12 samples/sec. 215.466 ms/step.
Infer [24/40]. 1188.16 samples/sec. 215.459 ms/step.
Infer [32/40]. 1188.00 samples/sec. 215.488 ms/step.
Infer [40/40]. 1187.88 samples/sec. 215.510 ms/step.
Inference benchmark of vgg16_bn.tv_in1k done. 1187.66 samples/sec, 215.51 ms/step
Model vgg16_bn.tv_in1k created, param count: 138365992
Running train benchmark on vgg16_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 252.06 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.50 GiB is allocated by PyTorch, and 411.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vgg16_bn.tv_in1k created, param count: 138365992
Running train benchmark on vgg16_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.32 GiB is allocated by PyTorch, and 703.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vgg16_bn.tv_in1k created, param count: 138365992
Running train benchmark on vgg16_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 351.45 samples/sec. 364.202 ms/step.
Train [16/40]. 351.45 samples/sec. 364.201 ms/step.
Train [24/40]. 351.46 samples/sec. 364.198 ms/step.
Train [32/40]. 351.46 samples/sec. 364.199 ms/step.
Train [40/40]. 351.46 samples/sec. 364.194 ms/step.
Train benchmark of vgg16_bn.tv_in1k done. 350.90 samples/sec, 364.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg19.tv_in1k created, param count: 143667240
Running inference benchmark on vgg19.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1182.77 samples/sec. 216.440 ms/step.
Infer [16/40]. 1182.45 samples/sec. 216.499 ms/step.
Infer [24/40]. 1182.36 samples/sec. 216.517 ms/step.
Infer [32/40]. 1182.11 samples/sec. 216.561 ms/step.
Infer [40/40]. 1182.01 samples/sec. 216.580 ms/step.
Inference benchmark of vgg19.tv_in1k done. 1181.80 samples/sec, 216.58 ms/step
Model vgg19.tv_in1k created, param count: 143667240
Running train benchmark on vgg19.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 502.06 MiB is free. Including non-PyTorch memory, this process has 23.15 GiB memory in use. Of the allocated memory 18.22 GiB is allocated by PyTorch, and 4.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vgg19.tv_in1k created, param count: 143667240
Running train benchmark on vgg19.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 337.12 samples/sec. 569.538 ms/step.
Train [16/40]. 337.66 samples/sec. 568.625 ms/step.
Train [24/40]. 337.73 samples/sec. 568.496 ms/step.
Train [32/40]. 337.87 samples/sec. 568.274 ms/step.
Train [40/40]. 338.27 samples/sec. 567.588 ms/step.
Train benchmark of vgg19.tv_in1k done. 337.96 samples/sec, 567.59 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vgg19_bn.tv_in1k created, param count: 143678248
Running inference benchmark on vgg19_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1023.83 samples/sec. 250.043 ms/step.
Infer [16/40]. 1023.62 samples/sec. 250.092 ms/step.
Infer [24/40]. 1023.57 samples/sec. 250.105 ms/step.
Infer [32/40]. 1023.61 samples/sec. 250.095 ms/step.
Infer [40/40]. 1023.44 samples/sec. 250.136 ms/step.
Inference benchmark of vgg19_bn.tv_in1k done. 1023.28 samples/sec, 250.14 ms/step
Model vgg19_bn.tv_in1k created, param count: 143678248
Running train benchmark on vgg19_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 204.06 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 439.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vgg19_bn.tv_in1k created, param count: 143678248
Running train benchmark on vgg19_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 144.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.62 GiB is allocated by PyTorch, and 388.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vgg19_bn.tv_in1k created, param count: 143678248
Running train benchmark on vgg19_bn.tv_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
Train [8/40]. 306.70 samples/sec. 417.349 ms/step.
Train [16/40]. 306.70 samples/sec. 417.352 ms/step.
Train [24/40]. 306.69 samples/sec. 417.364 ms/step.
Train [32/40]. 306.66 samples/sec. 417.397 ms/step.
Train [40/40]. 306.65 samples/sec. 417.418 ms/step.
Train benchmark of vgg19_bn.tv_in1k done. 306.18 samples/sec, 417.42 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model visformer_small.in1k created, param count: 40219592
Running inference benchmark on visformer_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 2769.97 samples/sec. 92.420 ms/step.
Infer [16/40]. 2769.80 samples/sec. 92.425 ms/step.
Infer [24/40]. 2769.74 samples/sec. 92.427 ms/step.
Infer [32/40]. 2769.51 samples/sec. 92.435 ms/step.
Infer [40/40]. 2769.29 samples/sec. 92.442 ms/step.
Inference benchmark of visformer_small.in1k done. 2768.48 samples/sec, 92.44 ms/step
Model visformer_small.in1k created, param count: 40219592
Running train benchmark on visformer_small.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 877.88 samples/sec. 291.610 ms/step.
Train [16/40]. 877.92 samples/sec. 291.599 ms/step.
Train [24/40]. 877.93 samples/sec. 291.594 ms/step.
Train [32/40]. 877.94 samples/sec. 291.592 ms/step.
Train [40/40]. 877.92 samples/sec. 291.597 ms/step.
Train benchmark of visformer_small.in1k done. 875.25 samples/sec, 291.60 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model visformer_tiny.in1k created, param count: 10321368
Running inference benchmark on visformer_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 7099.64 samples/sec. 36.058 ms/step.
Infer [16/40]. 7098.75 samples/sec. 36.063 ms/step.
Infer [24/40]. 7098.52 samples/sec. 36.064 ms/step.
Infer [32/40]. 7097.96 samples/sec. 36.067 ms/step.
Infer [40/40]. 7097.61 samples/sec. 36.068 ms/step.
Inference benchmark of visformer_tiny.in1k done. 7092.85 samples/sec, 36.07 ms/step
Model visformer_tiny.in1k created, param count: 10321368
Running train benchmark on visformer_tiny.in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 2106.14 samples/sec. 121.549 ms/step.
Train [16/40]. 2106.11 samples/sec. 121.551 ms/step.
Train [24/40]. 2106.22 samples/sec. 121.545 ms/step.
Train [32/40]. 2106.24 samples/sec. 121.544 ms/step.
Train [40/40]. 2106.24 samples/sec. 121.544 ms/step.
Train benchmark of visformer_tiny.in1k done. 2095.40 samples/sec, 121.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch8_224.augreg2_in21k_ft_in1k created, param count: 86576872
Running inference benchmark on vit_base_patch8_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 293.74 samples/sec. 871.526 ms/step.
Infer [16/40]. 293.32 samples/sec. 872.765 ms/step.
Infer [24/40]. 293.18 samples/sec. 873.177 ms/step.
Infer [32/40]. 293.21 samples/sec. 873.084 ms/step.
Infer [40/40]. 293.12 samples/sec. 873.348 ms/step.
Inference benchmark of vit_base_patch8_224.augreg2_in21k_ft_in1k done. 293.11 samples/sec, 873.35 ms/step
Model vit_base_patch8_224.augreg2_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 605.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch8_224.augreg2_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 68.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch8_224.augreg2_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 738.06 MiB is free. Including non-PyTorch memory, this process has 22.92 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 125.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch8_224.augreg2_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 884.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 138.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch8_224.augreg2_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 125.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_base_patch8_224.augreg2_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 78.62 samples/sec. 610.513 ms/step.
Train [16/40]. 78.62 samples/sec. 610.526 ms/step.
Train [24/40]. 78.62 samples/sec. 610.532 ms/step.
Train [32/40]. 78.62 samples/sec. 610.539 ms/step.
Train [40/40]. 78.62 samples/sec. 610.545 ms/step.
Train benchmark of vit_base_patch8_224.augreg2_in21k_ft_in1k done. 78.49 samples/sec, 610.54 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch8_224.augreg_in21k_ft_in1k created, param count: 86576872
Running inference benchmark on vit_base_patch8_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 293.31 samples/sec. 872.789 ms/step.
Infer [16/40]. 293.08 samples/sec. 873.475 ms/step.
Infer [24/40]. 292.93 samples/sec. 873.935 ms/step.
Infer [32/40]. 292.83 samples/sec. 874.226 ms/step.
Infer [40/40]. 292.73 samples/sec. 874.526 ms/step.
Inference benchmark of vit_base_patch8_224.augreg_in21k_ft_in1k done. 292.71 samples/sec, 874.53 ms/step
Model vit_base_patch8_224.augreg_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 605.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch8_224.augreg_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 68.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch8_224.augreg_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 738.06 MiB is free. Including non-PyTorch memory, this process has 22.92 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 125.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch8_224.augreg_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 884.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 138.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch8_224.augreg_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 125.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_base_patch8_224.augreg_in21k_ft_in1k created, param count: 86576872
Running train benchmark on vit_base_patch8_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 48.
Train [8/40]. 78.82 samples/sec. 608.989 ms/step.
Train [16/40]. 78.75 samples/sec. 609.542 ms/step.
Train [24/40]. 78.71 samples/sec. 609.841 ms/step.
Train [32/40]. 78.69 samples/sec. 609.999 ms/step.
Train [40/40]. 78.68 samples/sec. 610.094 ms/step.
Train benchmark of vit_base_patch8_224.augreg_in21k_ft_in1k done. 78.55 samples/sec, 610.09 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch8_224.dino created, param count: 85807872
Running inference benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 293.00 samples/sec. 873.714 ms/step.
Infer [16/40]. 292.88 samples/sec. 874.082 ms/step.
Infer [24/40]. 292.74 samples/sec. 874.500 ms/step.
Infer [32/40]. 292.66 samples/sec. 874.741 ms/step.
Infer [40/40]. 292.60 samples/sec. 874.910 ms/step.
Inference benchmark of vit_base_patch8_224.dino done. 292.58 samples/sec, 874.91 ms/step
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 184.06 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.37 GiB is allocated by PyTorch, and 608.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 22.04 GiB is allocated by PyTorch, and 71.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacty of 23.65 GiB of which 738.06 MiB is free. Including non-PyTorch memory, this process has 22.92 GiB memory in use. Of the allocated memory 22.30 GiB is allocated by PyTorch, and 129.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 884.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 142.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 150.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 128.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model vit_base_patch8_224.dino created, param count: 85807872
Running train benchmark on vit_base_patch8_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running inference benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 256.
Infer [8/40]. 131.97 samples/sec. 1939.884 ms/step.
Infer [16/40]. 131.85 samples/sec. 1941.632 ms/step.
Infer [24/40]. 131.81 samples/sec. 1942.202 ms/step.
Infer [32/40]. 131.75 samples/sec. 1943.019 ms/step.
Infer [40/40]. 131.69 samples/sec. 1943.978 ms/step.
Inference benchmark of vit_base_patch14_dinov2.lvd142m done. 131.69 samples/sec, 1943.98 ms/step
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.92 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 21.21 GiB is allocated by PyTorch, and 16.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.52 GiB is free. Including non-PyTorch memory, this process has 22.12 GiB memory in use. Of the allocated memory 21.27 GiB is allocated by PyTorch, and 367.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 96.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 213.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacty of 23.65 GiB of which 994.06 MiB is free. Including non-PyTorch memory, this process has 22.67 GiB memory in use. Of the allocated memory 21.74 GiB is allocated by PyTorch, and 437.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 18.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 240.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 772.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 389.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 468.06 MiB is free. Including non-PyTorch memory, this process has 23.18 GiB memory in use. Of the allocated memory 22.42 GiB is allocated by PyTorch, and 267.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model vit_base_patch14_dinov2.lvd142m created, param count: 86579712
Running train benchmark on vit_base_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224.augreg2_in21k_ft_in1k created, param count: 86567656
Running inference benchmark on vit_base_patch16_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.99 samples/sec. 172.624 ms/step.
Infer [16/40]. 1483.11 samples/sec. 172.610 ms/step.
Infer [24/40]. 1483.08 samples/sec. 172.614 ms/step.
Infer [32/40]. 1483.00 samples/sec. 172.623 ms/step.
Infer [40/40]. 1482.67 samples/sec. 172.661 ms/step.
Inference benchmark of vit_base_patch16_224.augreg2_in21k_ft_in1k done. 1482.37 samples/sec, 172.66 ms/step
Model vit_base_patch16_224.augreg2_in21k_ft_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224.augreg2_in21k_ft_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.augreg2_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.63 samples/sec. 468.714 ms/step.
Train [16/40]. 409.64 samples/sec. 468.705 ms/step.
Train [24/40]. 409.62 samples/sec. 468.729 ms/step.
Train [32/40]. 409.61 samples/sec. 468.739 ms/step.
Train [40/40]. 409.61 samples/sec. 468.739 ms/step.
Train benchmark of vit_base_patch16_224.augreg2_in21k_ft_in1k done. 408.75 samples/sec, 468.74 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224.augreg_in1k created, param count: 86567656
Running inference benchmark on vit_base_patch16_224.augreg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.90 samples/sec. 172.635 ms/step.
Infer [16/40]. 1482.53 samples/sec. 172.678 ms/step.
Infer [24/40]. 1481.65 samples/sec. 172.780 ms/step.
Infer [32/40]. 1481.27 samples/sec. 172.825 ms/step.
Infer [40/40]. 1481.04 samples/sec. 172.852 ms/step.
Inference benchmark of vit_base_patch16_224.augreg_in1k done. 1480.74 samples/sec, 172.85 ms/step
Model vit_base_patch16_224.augreg_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.augreg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224.augreg_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.augreg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.43 samples/sec. 468.948 ms/step.
Train [16/40]. 409.12 samples/sec. 469.295 ms/step.
Train [24/40]. 409.00 samples/sec. 469.439 ms/step.
Train [32/40]. 408.92 samples/sec. 469.525 ms/step.
Train [40/40]. 408.89 samples/sec. 469.570 ms/step.
Train benchmark of vit_base_patch16_224.augreg_in1k done. 408.02 samples/sec, 469.57 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224.augreg_in21k_ft_in1k created, param count: 86567656
Running inference benchmark on vit_base_patch16_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.84 samples/sec. 172.642 ms/step.
Infer [16/40]. 1482.78 samples/sec. 172.648 ms/step.
Infer [24/40]. 1482.84 samples/sec. 172.641 ms/step.
Infer [32/40]. 1482.81 samples/sec. 172.645 ms/step.
Infer [40/40]. 1482.57 samples/sec. 172.674 ms/step.
Inference benchmark of vit_base_patch16_224.augreg_in21k_ft_in1k done. 1482.28 samples/sec, 172.67 ms/step
Model vit_base_patch16_224.augreg_in21k_ft_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224.augreg_in21k_ft_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.01 samples/sec. 469.424 ms/step.
Train [16/40]. 408.90 samples/sec. 469.554 ms/step.
Train [24/40]. 408.83 samples/sec. 469.637 ms/step.
Train [32/40]. 408.82 samples/sec. 469.643 ms/step.
Train [40/40]. 408.80 samples/sec. 469.664 ms/step.
Train benchmark of vit_base_patch16_224.augreg_in21k_ft_in1k done. 407.94 samples/sec, 469.66 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224.dino created, param count: 85798656
Running inference benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1481.03 samples/sec. 172.853 ms/step.
Infer [16/40]. 1480.81 samples/sec. 172.878 ms/step.
Infer [24/40]. 1480.60 samples/sec. 172.903 ms/step.
Infer [32/40]. 1480.39 samples/sec. 172.927 ms/step.
Infer [40/40]. 1480.27 samples/sec. 172.942 ms/step.
Inference benchmark of vit_base_patch16_224.dino done. 1479.94 samples/sec, 172.94 ms/step
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 39.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model vit_base_patch16_224.dino created, param count: 85798656
Running train benchmark on vit_base_patch16_224.dino for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224.mae created, param count: 85798656
Running inference benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1484.26 samples/sec. 172.476 ms/step.
Infer [16/40]. 1484.14 samples/sec. 172.490 ms/step.
Infer [24/40]. 1484.05 samples/sec. 172.501 ms/step.
Infer [32/40]. 1484.00 samples/sec. 172.507 ms/step.
Infer [40/40]. 1484.03 samples/sec. 172.504 ms/step.
Inference benchmark of vit_base_patch16_224.mae done. 1483.69 samples/sec, 172.50 ms/step
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 39.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 12.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 8 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 8.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 6 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 6.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 4 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 4.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 3 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 3.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 2 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 2.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 1 for retry.
Model vit_base_patch16_224.mae created, param count: 85798656
Running train benchmark on vit_base_patch16_224.mae for 40 steps w/ input size (3, 224, 224) and batch size 1.
ERROR: "random_ expects 'from' to be less than 'to', but got from=0 >= to=0" while running benchmark.
WARNING: Reducing batch size to 0 for retry.
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656
Running inference benchmark on vit_base_patch16_224.orig_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1483.93 samples/sec. 172.515 ms/step.
Infer [16/40]. 1483.99 samples/sec. 172.508 ms/step.
Infer [24/40]. 1483.95 samples/sec. 172.512 ms/step.
Infer [32/40]. 1484.02 samples/sec. 172.504 ms/step.
Infer [40/40]. 1484.00 samples/sec. 172.506 ms/step.
Inference benchmark of vit_base_patch16_224.orig_in21k_ft_in1k done. 1483.69 samples/sec, 172.51 ms/step
Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.orig_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.orig_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.84 samples/sec. 468.472 ms/step.
Train [16/40]. 409.66 samples/sec. 468.678 ms/step.
Train [24/40]. 409.64 samples/sec. 468.701 ms/step.
Train [32/40]. 409.62 samples/sec. 468.729 ms/step.
Train [40/40]. 409.62 samples/sec. 468.727 ms/step.
Train benchmark of vit_base_patch16_224.orig_in21k_ft_in1k done. 408.74 samples/sec, 468.73 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224.sam_in1k created, param count: 86567656
Running inference benchmark on vit_base_patch16_224.sam_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.44 samples/sec. 172.688 ms/step.
Infer [16/40]. 1482.42 samples/sec. 172.691 ms/step.
Infer [24/40]. 1482.40 samples/sec. 172.693 ms/step.
Infer [32/40]. 1482.42 samples/sec. 172.690 ms/step.
Infer [40/40]. 1482.46 samples/sec. 172.686 ms/step.
Inference benchmark of vit_base_patch16_224.sam_in1k done. 1482.10 samples/sec, 172.69 ms/step
Model vit_base_patch16_224.sam_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.sam_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224.sam_in1k created, param count: 86567656
Running train benchmark on vit_base_patch16_224.sam_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.64 samples/sec. 468.702 ms/step.
Train [16/40]. 409.60 samples/sec. 468.751 ms/step.
Train [24/40]. 409.58 samples/sec. 468.771 ms/step.
Train [32/40]. 409.56 samples/sec. 468.791 ms/step.
Train [40/40]. 409.55 samples/sec. 468.807 ms/step.
Train benchmark of vit_base_patch16_224.sam_in1k done. 408.68 samples/sec, 468.81 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_224_miil.in21k_ft_in1k created, param count: 86540008
Running inference benchmark on vit_base_patch16_224_miil.in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1483.20 samples/sec. 172.599 ms/step.
Infer [16/40]. 1483.13 samples/sec. 172.608 ms/step.
Infer [24/40]. 1483.10 samples/sec. 172.612 ms/step.
Infer [32/40]. 1483.06 samples/sec. 172.616 ms/step.
Infer [40/40]. 1483.06 samples/sec. 172.616 ms/step.
Inference benchmark of vit_base_patch16_224_miil.in21k_ft_in1k done. 1482.69 samples/sec, 172.62 ms/step
Model vit_base_patch16_224_miil.in21k_ft_in1k created, param count: 86540008
Running train benchmark on vit_base_patch16_224_miil.in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 44.06 MiB is free. Including non-PyTorch memory, this process has 23.60 GiB memory in use. Of the allocated memory 23.06 GiB is allocated by PyTorch, and 36.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_224_miil.in21k_ft_in1k created, param count: 86540008
Running train benchmark on vit_base_patch16_224_miil.in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 412.56 samples/sec. 465.386 ms/step.
Train [16/40]. 412.57 samples/sec. 465.373 ms/step.
Train [24/40]. 412.55 samples/sec. 465.393 ms/step.
Train [32/40]. 412.54 samples/sec. 465.404 ms/step.
Train [40/40]. 412.52 samples/sec. 465.428 ms/step.
Train benchmark of vit_base_patch16_224_miil.in21k_ft_in1k done. 411.68 samples/sec, 465.43 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_384.augreg_in1k created, param count: 86859496
Running inference benchmark on vit_base_patch16_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 426.36 samples/sec. 600.434 ms/step.
Infer [16/40]. 426.30 samples/sec. 600.520 ms/step.
Infer [24/40]. 426.09 samples/sec. 600.809 ms/step.
Infer [32/40]. 425.98 samples/sec. 600.969 ms/step.
Infer [40/40]. 425.85 samples/sec. 601.148 ms/step.
Inference benchmark of vit_base_patch16_384.augreg_in1k done. 425.82 samples/sec, 601.15 ms/step
Model vit_base_patch16_384.augreg_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 786.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 458.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_384.augreg_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 333.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_384.augreg_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 396.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 188.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_384.augreg_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 616.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 453.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_384.augreg_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.76 samples/sec. 557.707 ms/step.
Train [16/40]. 114.76 samples/sec. 557.705 ms/step.
Train [24/40]. 114.76 samples/sec. 557.693 ms/step.
Train [32/40]. 114.76 samples/sec. 557.687 ms/step.
Train [40/40]. 114.76 samples/sec. 557.689 ms/step.
Train benchmark of vit_base_patch16_384.augreg_in1k done. 114.55 samples/sec, 557.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_384.augreg_in21k_ft_in1k created, param count: 86859496
Running inference benchmark on vit_base_patch16_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 426.60 samples/sec. 600.100 ms/step.
Infer [16/40]. 426.41 samples/sec. 600.367 ms/step.
Infer [24/40]. 426.42 samples/sec. 600.348 ms/step.
Infer [32/40]. 426.35 samples/sec. 600.445 ms/step.
Infer [40/40]. 426.08 samples/sec. 600.823 ms/step.
Inference benchmark of vit_base_patch16_384.augreg_in21k_ft_in1k done. 426.05 samples/sec, 600.82 ms/step
Model vit_base_patch16_384.augreg_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 786.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 458.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_384.augreg_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 333.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_384.augreg_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 396.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 188.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_384.augreg_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 616.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 453.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_384.augreg_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.77 samples/sec. 557.653 ms/step.
Train [16/40]. 114.76 samples/sec. 557.666 ms/step.
Train [24/40]. 114.76 samples/sec. 557.672 ms/step.
Train [32/40]. 114.76 samples/sec. 557.677 ms/step.
Train [40/40]. 114.76 samples/sec. 557.678 ms/step.
Train benchmark of vit_base_patch16_384.augreg_in21k_ft_in1k done. 114.56 samples/sec, 557.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_384.orig_in21k_ft_in1k created, param count: 86859496
Running inference benchmark on vit_base_patch16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 426.18 samples/sec. 600.685 ms/step.
Infer [16/40]. 425.99 samples/sec. 600.953 ms/step.
Infer [24/40]. 425.89 samples/sec. 601.090 ms/step.
Infer [32/40]. 425.77 samples/sec. 601.264 ms/step.
Infer [40/40]. 425.77 samples/sec. 601.267 ms/step.
Inference benchmark of vit_base_patch16_384.orig_in21k_ft_in1k done. 425.73 samples/sec, 601.27 ms/step
Model vit_base_patch16_384.orig_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 786.06 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 458.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_384.orig_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 266.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 333.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_384.orig_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 396.06 MiB is free. Including non-PyTorch memory, this process has 23.25 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 188.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_384.orig_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 616.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.10 GiB is allocated by PyTorch, and 453.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_384.orig_in21k_ft_in1k created, param count: 86859496
Running train benchmark on vit_base_patch16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.77 samples/sec. 557.660 ms/step.
Train [16/40]. 114.76 samples/sec. 557.671 ms/step.
Train [24/40]. 114.76 samples/sec. 557.683 ms/step.
Train [32/40]. 114.76 samples/sec. 557.685 ms/step.
Train [40/40]. 114.76 samples/sec. 557.691 ms/step.
Train benchmark of vit_base_patch16_384.orig_in21k_ft_in1k done. 114.55 samples/sec, 557.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.datacompxl created, param count: 86193152
Running inference benchmark on vit_base_patch16_clip_224.datacompxl for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.19 samples/sec. 172.717 ms/step.
Infer [16/40]. 1481.49 samples/sec. 172.799 ms/step.
Infer [24/40]. 1480.90 samples/sec. 172.868 ms/step.
Infer [32/40]. 1480.64 samples/sec. 172.898 ms/step.
Infer [40/40]. 1480.46 samples/sec. 172.919 ms/step.
Inference benchmark of vit_base_patch16_clip_224.datacompxl done. 1480.10 samples/sec, 172.92 ms/step
Model vit_base_patch16_clip_224.datacompxl created, param count: 86193152
Running train benchmark on vit_base_patch16_clip_224.datacompxl for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.datacompxl created, param count: 86193152
Running train benchmark on vit_base_patch16_clip_224.datacompxl for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 408.28 samples/sec. 470.271 ms/step.
Train [16/40]. 408.29 samples/sec. 470.254 ms/step.
Train [24/40]. 408.30 samples/sec. 470.243 ms/step.
Train [32/40]. 408.32 samples/sec. 470.223 ms/step.
Train [40/40]. 408.33 samples/sec. 470.207 ms/step.
Train benchmark of vit_base_patch16_clip_224.datacompxl done. 407.47 samples/sec, 470.21 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.laion2b created, param count: 86193152
Running inference benchmark on vit_base_patch16_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1479.73 samples/sec. 173.005 ms/step.
Infer [16/40]. 1479.58 samples/sec. 173.022 ms/step.
Infer [24/40]. 1479.48 samples/sec. 173.034 ms/step.
Infer [32/40]. 1479.36 samples/sec. 173.047 ms/step.
Infer [40/40]. 1479.31 samples/sec. 173.054 ms/step.
Inference benchmark of vit_base_patch16_clip_224.laion2b done. 1478.97 samples/sec, 173.05 ms/step
Model vit_base_patch16_clip_224.laion2b created, param count: 86193152
Running train benchmark on vit_base_patch16_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.laion2b created, param count: 86193152
Running train benchmark on vit_base_patch16_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.15 samples/sec. 469.264 ms/step.
Train [16/40]. 409.16 samples/sec. 469.255 ms/step.
Train [24/40]. 409.15 samples/sec. 469.260 ms/step.
Train [32/40]. 409.14 samples/sec. 469.273 ms/step.
Train [40/40]. 409.09 samples/sec. 469.329 ms/step.
Train benchmark of vit_base_patch16_clip_224.laion2b done. 408.23 samples/sec, 469.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.laion2b_ft_in1k created, param count: 86568424
Running inference benchmark on vit_base_patch16_clip_224.laion2b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.21 samples/sec. 172.715 ms/step.
Infer [16/40]. 1480.79 samples/sec. 172.880 ms/step.
Infer [24/40]. 1480.45 samples/sec. 172.920 ms/step.
Infer [32/40]. 1480.24 samples/sec. 172.945 ms/step.
Infer [40/40]. 1480.13 samples/sec. 172.957 ms/step.
Inference benchmark of vit_base_patch16_clip_224.laion2b_ft_in1k done. 1479.78 samples/sec, 172.96 ms/step
Model vit_base_patch16_clip_224.laion2b_ft_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.laion2b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 35.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.laion2b_ft_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.laion2b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.12 samples/sec. 469.305 ms/step.
Train [16/40]. 408.75 samples/sec. 469.722 ms/step.
Train [24/40]. 408.61 samples/sec. 469.887 ms/step.
Train [32/40]. 408.55 samples/sec. 469.960 ms/step.
Train [40/40]. 408.50 samples/sec. 470.007 ms/step.
Train benchmark of vit_base_patch16_clip_224.laion2b_ft_in1k done. 407.64 samples/sec, 470.01 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.laion2b_ft_in12k created, param count: 94889773
Running inference benchmark on vit_base_patch16_clip_224.laion2b_ft_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1481.47 samples/sec. 172.802 ms/step.
Infer [16/40]. 1481.41 samples/sec. 172.808 ms/step.
Infer [24/40]. 1480.54 samples/sec. 172.910 ms/step.
Infer [32/40]. 1480.07 samples/sec. 172.965 ms/step.
Infer [40/40]. 1479.79 samples/sec. 172.997 ms/step.
Inference benchmark of vit_base_patch16_clip_224.laion2b_ft_in12k done. 1479.42 samples/sec, 173.00 ms/step
Model vit_base_patch16_clip_224.laion2b_ft_in12k created, param count: 94889773
Running train benchmark on vit_base_patch16_clip_224.laion2b_ft_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 452.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 40.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.laion2b_ft_in12k created, param count: 94889773
Running train benchmark on vit_base_patch16_clip_224.laion2b_ft_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 408.50 samples/sec. 470.018 ms/step.
Train [16/40]. 408.40 samples/sec. 470.128 ms/step.
Train [24/40]. 408.19 samples/sec. 470.370 ms/step.
Train [32/40]. 408.09 samples/sec. 470.489 ms/step.
Train [40/40]. 408.02 samples/sec. 470.564 ms/step.
Train benchmark of vit_base_patch16_clip_224.laion2b_ft_in12k done. 407.17 samples/sec, 470.56 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.laion2b_ft_in12k_in1k created, param count: 86568424
Running inference benchmark on vit_base_patch16_clip_224.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.41 samples/sec. 172.692 ms/step.
Infer [16/40]. 1482.54 samples/sec. 172.677 ms/step.
Infer [24/40]. 1482.47 samples/sec. 172.685 ms/step.
Infer [32/40]. 1482.01 samples/sec. 172.738 ms/step.
Infer [40/40]. 1481.45 samples/sec. 172.804 ms/step.
Inference benchmark of vit_base_patch16_clip_224.laion2b_ft_in12k_in1k done. 1481.10 samples/sec, 172.80 ms/step
Model vit_base_patch16_clip_224.laion2b_ft_in12k_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 35.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.laion2b_ft_in12k_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.17 samples/sec. 469.242 ms/step.
Train [16/40]. 409.17 samples/sec. 469.246 ms/step.
Train [24/40]. 409.09 samples/sec. 469.335 ms/step.
Train [32/40]. 408.91 samples/sec. 469.538 ms/step.
Train [40/40]. 408.79 samples/sec. 469.676 ms/step.
Train benchmark of vit_base_patch16_clip_224.laion2b_ft_in12k_in1k done. 407.93 samples/sec, 469.68 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.openai created, param count: 86193152
Running inference benchmark on vit_base_patch16_clip_224.openai for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1481.55 samples/sec. 172.792 ms/step.
Infer [16/40]. 1480.83 samples/sec. 172.877 ms/step.
Infer [24/40]. 1480.48 samples/sec. 172.917 ms/step.
Infer [32/40]. 1480.39 samples/sec. 172.927 ms/step.
Infer [40/40]. 1480.17 samples/sec. 172.953 ms/step.
Inference benchmark of vit_base_patch16_clip_224.openai done. 1479.87 samples/sec, 172.95 ms/step
Model vit_base_patch16_clip_224.openai created, param count: 86193152
Running train benchmark on vit_base_patch16_clip_224.openai for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.openai created, param count: 86193152
Running train benchmark on vit_base_patch16_clip_224.openai for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 408.34 samples/sec. 470.198 ms/step.
Train [16/40]. 408.33 samples/sec. 470.203 ms/step.
Train [24/40]. 408.34 samples/sec. 470.193 ms/step.
Train [32/40]. 408.37 samples/sec. 470.166 ms/step.
Train [40/40]. 408.37 samples/sec. 470.167 ms/step.
Train benchmark of vit_base_patch16_clip_224.openai done. 407.51 samples/sec, 470.17 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.openai_ft_in1k created, param count: 86568424
Running inference benchmark on vit_base_patch16_clip_224.openai_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.62 samples/sec. 172.668 ms/step.
Infer [16/40]. 1481.27 samples/sec. 172.825 ms/step.
Infer [24/40]. 1480.75 samples/sec. 172.886 ms/step.
Infer [32/40]. 1480.48 samples/sec. 172.916 ms/step.
Infer [40/40]. 1480.37 samples/sec. 172.930 ms/step.
Inference benchmark of vit_base_patch16_clip_224.openai_ft_in1k done. 1480.06 samples/sec, 172.93 ms/step
Model vit_base_patch16_clip_224.openai_ft_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.openai_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 35.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.openai_ft_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.openai_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.11 samples/sec. 469.317 ms/step.
Train [16/40]. 409.10 samples/sec. 469.327 ms/step.
Train [24/40]. 409.07 samples/sec. 469.360 ms/step.
Train [32/40]. 409.08 samples/sec. 469.341 ms/step.
Train [40/40]. 409.08 samples/sec. 469.341 ms/step.
Train benchmark of vit_base_patch16_clip_224.openai_ft_in1k done. 408.20 samples/sec, 469.34 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.openai_ft_in12k created, param count: 94889773
Running inference benchmark on vit_base_patch16_clip_224.openai_ft_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1479.09 samples/sec. 173.079 ms/step.
Infer [16/40]. 1479.17 samples/sec. 173.070 ms/step.
Infer [24/40]. 1479.16 samples/sec. 173.071 ms/step.
Infer [32/40]. 1479.18 samples/sec. 173.069 ms/step.
Infer [40/40]. 1479.08 samples/sec. 173.080 ms/step.
Inference benchmark of vit_base_patch16_clip_224.openai_ft_in12k done. 1478.72 samples/sec, 173.08 ms/step
Model vit_base_patch16_clip_224.openai_ft_in12k created, param count: 94889773
Running train benchmark on vit_base_patch16_clip_224.openai_ft_in12k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 452.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.66 GiB is allocated by PyTorch, and 40.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.openai_ft_in12k created, param count: 94889773
Running train benchmark on vit_base_patch16_clip_224.openai_ft_in12k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 408.69 samples/sec. 469.793 ms/step.
Train [16/40]. 408.62 samples/sec. 469.870 ms/step.
Train [24/40]. 408.48 samples/sec. 470.032 ms/step.
Train [32/40]. 408.30 samples/sec. 470.240 ms/step.
Train [40/40]. 408.20 samples/sec. 470.362 ms/step.
Train benchmark of vit_base_patch16_clip_224.openai_ft_in12k done. 407.34 samples/sec, 470.36 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_224.openai_ft_in12k_in1k created, param count: 86568424
Running inference benchmark on vit_base_patch16_clip_224.openai_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1482.58 samples/sec. 172.672 ms/step.
Infer [16/40]. 1482.71 samples/sec. 172.657 ms/step.
Infer [24/40]. 1482.71 samples/sec. 172.657 ms/step.
Infer [32/40]. 1482.70 samples/sec. 172.658 ms/step.
Infer [40/40]. 1482.78 samples/sec. 172.648 ms/step.
Inference benchmark of vit_base_patch16_clip_224.openai_ft_in12k_in1k done. 1482.48 samples/sec, 172.65 ms/step
Model vit_base_patch16_clip_224.openai_ft_in12k_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.openai_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 488.06 MiB is free. Including non-PyTorch memory, this process has 23.16 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 35.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_224.openai_ft_in12k_in1k created, param count: 86568424
Running train benchmark on vit_base_patch16_clip_224.openai_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 409.09 samples/sec. 469.339 ms/step.
Train [16/40]. 409.10 samples/sec. 469.321 ms/step.
Train [24/40]. 409.10 samples/sec. 469.320 ms/step.
Train [32/40]. 409.10 samples/sec. 469.320 ms/step.
Train [40/40]. 409.09 samples/sec. 469.334 ms/step.
Train benchmark of vit_base_patch16_clip_224.openai_ft_in12k_in1k done. 408.21 samples/sec, 469.33 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_384.laion2b_ft_in1k created, param count: 86860264
Running inference benchmark on vit_base_patch16_clip_384.laion2b_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 425.40 samples/sec. 601.793 ms/step.
Infer [16/40]. 425.28 samples/sec. 601.954 ms/step.
Infer [24/40]. 425.25 samples/sec. 601.998 ms/step.
Infer [32/40]. 425.11 samples/sec. 602.199 ms/step.
Infer [40/40]. 425.05 samples/sec. 602.277 ms/step.
Inference benchmark of vit_base_patch16_clip_384.laion2b_ft_in1k done. 425.02 samples/sec, 602.28 ms/step
Model vit_base_patch16_clip_384.laion2b_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 460.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 974.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 912.06 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 336.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 189.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 452.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 454.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.67 samples/sec. 558.137 ms/step.
Train [16/40]. 114.67 samples/sec. 558.138 ms/step.
Train [24/40]. 114.66 samples/sec. 558.148 ms/step.
Train [32/40]. 114.66 samples/sec. 558.162 ms/step.
Train [40/40]. 114.66 samples/sec. 558.163 ms/step.
Train benchmark of vit_base_patch16_clip_384.laion2b_ft_in1k done. 114.46 samples/sec, 558.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_384.laion2b_ft_in12k_in1k created, param count: 86860264
Running inference benchmark on vit_base_patch16_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 425.24 samples/sec. 602.010 ms/step.
Infer [16/40]. 425.18 samples/sec. 602.102 ms/step.
Infer [24/40]. 425.13 samples/sec. 602.164 ms/step.
Infer [32/40]. 425.00 samples/sec. 602.348 ms/step.
Infer [40/40]. 424.88 samples/sec. 602.528 ms/step.
Inference benchmark of vit_base_patch16_clip_384.laion2b_ft_in12k_in1k done. 424.84 samples/sec, 602.53 ms/step
Model vit_base_patch16_clip_384.laion2b_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 460.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 974.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 912.06 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 336.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 189.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 452.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 454.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_clip_384.laion2b_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.67 samples/sec. 558.140 ms/step.
Train [16/40]. 114.66 samples/sec. 558.152 ms/step.
Train [24/40]. 114.66 samples/sec. 558.150 ms/step.
Train [32/40]. 114.66 samples/sec. 558.157 ms/step.
Train [40/40]. 114.66 samples/sec. 558.161 ms/step.
Train benchmark of vit_base_patch16_clip_384.laion2b_ft_in12k_in1k done. 114.46 samples/sec, 558.16 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_384.openai_ft_in1k created, param count: 86860264
Running inference benchmark on vit_base_patch16_clip_384.openai_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 425.37 samples/sec. 601.822 ms/step.
Infer [16/40]. 425.31 samples/sec. 601.920 ms/step.
Infer [24/40]. 425.17 samples/sec. 602.116 ms/step.
Infer [32/40]. 424.91 samples/sec. 602.486 ms/step.
Infer [40/40]. 424.78 samples/sec. 602.661 ms/step.
Inference benchmark of vit_base_patch16_clip_384.openai_ft_in1k done. 424.75 samples/sec, 602.66 ms/step
Model vit_base_patch16_clip_384.openai_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 460.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_384.openai_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 974.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 912.06 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 336.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_clip_384.openai_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 189.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_clip_384.openai_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 452.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 454.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_clip_384.openai_ft_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.66 samples/sec. 558.173 ms/step.
Train [16/40]. 114.66 samples/sec. 558.185 ms/step.
Train [24/40]. 114.66 samples/sec. 558.189 ms/step.
Train [32/40]. 114.66 samples/sec. 558.187 ms/step.
Train [40/40]. 114.66 samples/sec. 558.193 ms/step.
Train benchmark of vit_base_patch16_clip_384.openai_ft_in1k done. 114.45 samples/sec, 558.19 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_clip_384.openai_ft_in12k_in1k created, param count: 86860264
Running inference benchmark on vit_base_patch16_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 425.04 samples/sec. 602.292 ms/step.
Infer [16/40]. 424.98 samples/sec. 602.376 ms/step.
Infer [24/40]. 424.99 samples/sec. 602.370 ms/step.
Infer [32/40]. 424.91 samples/sec. 602.478 ms/step.
Infer [40/40]. 424.82 samples/sec. 602.608 ms/step.
Inference benchmark of vit_base_patch16_clip_384.openai_ft_in12k_in1k done. 424.79 samples/sec, 602.61 ms/step
Model vit_base_patch16_clip_384.openai_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacty of 23.65 GiB of which 350.06 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 460.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_clip_384.openai_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 974.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 912.06 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 336.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_patch16_clip_384.openai_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 178.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 189.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_patch16_clip_384.openai_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 650.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 452.06 MiB is free. Including non-PyTorch memory, this process has 23.20 GiB memory in use. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 454.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_patch16_clip_384.openai_ft_in12k_in1k created, param count: 86860264
Running train benchmark on vit_base_patch16_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
Train [8/40]. 114.66 samples/sec. 558.149 ms/step.
Train [16/40]. 114.66 samples/sec. 558.155 ms/step.
Train [24/40]. 114.66 samples/sec. 558.157 ms/step.
Train [32/40]. 114.66 samples/sec. 558.148 ms/step.
Train [40/40]. 114.67 samples/sec. 558.146 ms/step.
Train benchmark of vit_base_patch16_clip_384.openai_ft_in12k_in1k done. 114.46 samples/sec, 558.15 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch16_rpn_224.sw_in1k created, param count: 86538472
Running inference benchmark on vit_base_patch16_rpn_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 1284.03 samples/sec. 199.373 ms/step.
Infer [16/40]. 1284.04 samples/sec. 199.371 ms/step.
Infer [24/40]. 1284.10 samples/sec. 199.362 ms/step.
Infer [32/40]. 1284.12 samples/sec. 199.358 ms/step.
Infer [40/40]. 1284.11 samples/sec. 199.360 ms/step.
Inference benchmark of vit_base_patch16_rpn_224.sw_in1k done. 1283.84 samples/sec, 199.36 ms/step
Model vit_base_patch16_rpn_224.sw_in1k created, param count: 86538472
Running train benchmark on vit_base_patch16_rpn_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 588.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 304.06 MiB is free. Including non-PyTorch memory, this process has 23.34 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 164.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch16_rpn_224.sw_in1k created, param count: 86538472
Running train benchmark on vit_base_patch16_rpn_224.sw_in1k for 40 steps w/ input size (3, 224, 224) and batch size 192.
Train [8/40]. 394.83 samples/sec. 486.285 ms/step.
Train [16/40]. 394.84 samples/sec. 486.275 ms/step.
Train [24/40]. 394.82 samples/sec. 486.300 ms/step.
Train [32/40]. 394.82 samples/sec. 486.292 ms/step.
Train [40/40]. 394.82 samples/sec. 486.292 ms/step.
Train benchmark of vit_base_patch16_rpn_224.sw_in1k done. 394.04 samples/sec, 486.29 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_224.augreg_in1k created, param count: 88224232
Running inference benchmark on vit_base_patch32_224.augreg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6288.42 samples/sec. 40.710 ms/step.
Infer [16/40]. 6288.88 samples/sec. 40.707 ms/step.
Infer [24/40]. 6285.02 samples/sec. 40.732 ms/step.
Infer [32/40]. 6281.81 samples/sec. 40.753 ms/step.
Infer [40/40]. 6279.80 samples/sec. 40.766 ms/step.
Inference benchmark of vit_base_patch32_224.augreg_in1k done. 6276.11 samples/sec, 40.77 ms/step
Model vit_base_patch32_224.augreg_in1k created, param count: 88224232
Running train benchmark on vit_base_patch32_224.augreg_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1871.71 samples/sec. 136.774 ms/step.
Train [16/40]. 1871.63 samples/sec. 136.779 ms/step.
Train [24/40]. 1871.63 samples/sec. 136.779 ms/step.
Train [32/40]. 1871.64 samples/sec. 136.778 ms/step.
Train [40/40]. 1871.67 samples/sec. 136.776 ms/step.
Train benchmark of vit_base_patch32_224.augreg_in1k done. 1861.43 samples/sec, 136.78 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_224.augreg_in21k_ft_in1k created, param count: 88224232
Running inference benchmark on vit_base_patch32_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6297.30 samples/sec. 40.652 ms/step.
Infer [16/40]. 6296.94 samples/sec. 40.655 ms/step.
Infer [24/40]. 6295.84 samples/sec. 40.662 ms/step.
Infer [32/40]. 6295.05 samples/sec. 40.667 ms/step.
Infer [40/40]. 6294.43 samples/sec. 40.671 ms/step.
Inference benchmark of vit_base_patch32_224.augreg_in21k_ft_in1k done. 6290.71 samples/sec, 40.67 ms/step
Model vit_base_patch32_224.augreg_in21k_ft_in1k created, param count: 88224232
Running train benchmark on vit_base_patch32_224.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1873.15 samples/sec. 136.668 ms/step.
Train [16/40]. 1873.01 samples/sec. 136.678 ms/step.
Train [24/40]. 1872.97 samples/sec. 136.681 ms/step.
Train [32/40]. 1872.95 samples/sec. 136.683 ms/step.
Train [40/40]. 1872.92 samples/sec. 136.685 ms/step.
Train benchmark of vit_base_patch32_224.augreg_in21k_ft_in1k done. 1862.87 samples/sec, 136.69 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_224.sam_in1k created, param count: 88224232
Running inference benchmark on vit_base_patch32_224.sam_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6296.06 samples/sec. 40.660 ms/step.
Infer [16/40]. 6296.08 samples/sec. 40.660 ms/step.
Infer [24/40]. 6295.99 samples/sec. 40.661 ms/step.
Infer [32/40]. 6295.78 samples/sec. 40.662 ms/step.
Infer [40/40]. 6295.33 samples/sec. 40.665 ms/step.
Inference benchmark of vit_base_patch32_224.sam_in1k done. 6291.61 samples/sec, 40.66 ms/step
Model vit_base_patch32_224.sam_in1k created, param count: 88224232
Running train benchmark on vit_base_patch32_224.sam_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1873.16 samples/sec. 136.668 ms/step.
Train [16/40]. 1873.08 samples/sec. 136.673 ms/step.
Train [24/40]. 1873.07 samples/sec. 136.674 ms/step.
Train [32/40]. 1873.11 samples/sec. 136.671 ms/step.
Train [40/40]. 1873.16 samples/sec. 136.668 ms/step.
Train benchmark of vit_base_patch32_224.sam_in1k done. 1863.46 samples/sec, 136.67 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_384.augreg_in1k created, param count: 88297192
Running inference benchmark on vit_base_patch32_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 2049.92 samples/sec. 124.883 ms/step.
Infer [16/40]. 2049.39 samples/sec. 124.915 ms/step.
Infer [24/40]. 2049.14 samples/sec. 124.930 ms/step.
Infer [32/40]. 2048.91 samples/sec. 124.945 ms/step.
Infer [40/40]. 2048.76 samples/sec. 124.954 ms/step.
Inference benchmark of vit_base_patch32_384.augreg_in1k done. 2048.29 samples/sec, 124.95 ms/step
Model vit_base_patch32_384.augreg_in1k created, param count: 88297192
Running train benchmark on vit_base_patch32_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 436.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 340.06 MiB is free. Including non-PyTorch memory, this process has 23.31 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch32_384.augreg_in1k created, param count: 88297192
Running train benchmark on vit_base_patch32_384.augreg_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
Train [8/40]. 587.28 samples/sec. 326.931 ms/step.
Train [16/40]. 587.28 samples/sec. 326.928 ms/step.
Train [24/40]. 587.28 samples/sec. 326.931 ms/step.
Train [32/40]. 587.28 samples/sec. 326.931 ms/step.
Train [40/40]. 587.27 samples/sec. 326.935 ms/step.
Train benchmark of vit_base_patch32_384.augreg_in1k done. 585.55 samples/sec, 326.94 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_384.augreg_in21k_ft_in1k created, param count: 88297192
Running inference benchmark on vit_base_patch32_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 2050.36 samples/sec. 124.856 ms/step.
Infer [16/40]. 2049.82 samples/sec. 124.889 ms/step.
Infer [24/40]. 2049.61 samples/sec. 124.902 ms/step.
Infer [32/40]. 2049.39 samples/sec. 124.915 ms/step.
Infer [40/40]. 2049.28 samples/sec. 124.922 ms/step.
Inference benchmark of vit_base_patch32_384.augreg_in21k_ft_in1k done. 2048.81 samples/sec, 124.92 ms/step
Model vit_base_patch32_384.augreg_in21k_ft_in1k created, param count: 88297192
Running train benchmark on vit_base_patch32_384.augreg_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Train [8/40]. 569.57 samples/sec. 449.462 ms/step.
Train [16/40]. 569.57 samples/sec. 449.464 ms/step.
Train [24/40]. 569.58 samples/sec. 449.458 ms/step.
Train [32/40]. 569.56 samples/sec. 449.468 ms/step.
Train [40/40]. 569.56 samples/sec. 449.467 ms/step.
Train benchmark of vit_base_patch32_384.augreg_in21k_ft_in1k done. 568.33 samples/sec, 449.47 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_224.laion2b created, param count: 87849728
Running inference benchmark on vit_base_patch32_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6296.60 samples/sec. 40.657 ms/step.
Infer [16/40]. 6296.98 samples/sec. 40.654 ms/step.
Infer [24/40]. 6296.58 samples/sec. 40.657 ms/step.
Infer [32/40]. 6296.34 samples/sec. 40.659 ms/step.
Infer [40/40]. 6296.12 samples/sec. 40.660 ms/step.
Inference benchmark of vit_base_patch32_clip_224.laion2b done. 6292.25 samples/sec, 40.66 ms/step
Model vit_base_patch32_clip_224.laion2b created, param count: 87849728
Running train benchmark on vit_base_patch32_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1870.53 samples/sec. 136.860 ms/step.
Train [16/40]. 1870.14 samples/sec. 136.888 ms/step.
Train [24/40]. 1869.97 samples/sec. 136.901 ms/step.
Train [32/40]. 1869.91 samples/sec. 136.905 ms/step.
Train [40/40]. 1869.89 samples/sec. 136.907 ms/step.
Train benchmark of vit_base_patch32_clip_224.laion2b done. 1859.98 samples/sec, 136.91 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_224.laion2b_ft_in1k created, param count: 88225000
Running inference benchmark on vit_base_patch32_clip_224.laion2b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6297.33 samples/sec. 40.652 ms/step.
Infer [16/40]. 6297.11 samples/sec. 40.654 ms/step.
Infer [24/40]. 6296.77 samples/sec. 40.656 ms/step.
Infer [32/40]. 6296.90 samples/sec. 40.655 ms/step.
Infer [40/40]. 6296.76 samples/sec. 40.656 ms/step.
Inference benchmark of vit_base_patch32_clip_224.laion2b_ft_in1k done. 6293.02 samples/sec, 40.66 ms/step
Model vit_base_patch32_clip_224.laion2b_ft_in1k created, param count: 88225000
Running train benchmark on vit_base_patch32_clip_224.laion2b_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1868.88 samples/sec. 136.981 ms/step.
Train [16/40]. 1868.88 samples/sec. 136.981 ms/step.
Train [24/40]. 1868.87 samples/sec. 136.981 ms/step.
Train [32/40]. 1868.89 samples/sec. 136.980 ms/step.
Train [40/40]. 1868.91 samples/sec. 136.978 ms/step.
Train benchmark of vit_base_patch32_clip_224.laion2b_ft_in1k done. 1858.68 samples/sec, 136.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_224.laion2b_ft_in12k_in1k created, param count: 88225000
Running inference benchmark on vit_base_patch32_clip_224.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6292.68 samples/sec. 40.682 ms/step.
Infer [16/40]. 6291.04 samples/sec. 40.693 ms/step.
Infer [24/40]. 6290.64 samples/sec. 40.695 ms/step.
Infer [32/40]. 6290.56 samples/sec. 40.696 ms/step.
Infer [40/40]. 6290.49 samples/sec. 40.696 ms/step.
Inference benchmark of vit_base_patch32_clip_224.laion2b_ft_in12k_in1k done. 6286.37 samples/sec, 40.70 ms/step
Model vit_base_patch32_clip_224.laion2b_ft_in12k_in1k created, param count: 88225000
Running train benchmark on vit_base_patch32_clip_224.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1870.21 samples/sec. 136.883 ms/step.
Train [16/40]. 1869.87 samples/sec. 136.908 ms/step.
Train [24/40]. 1869.61 samples/sec. 136.927 ms/step.
Train [32/40]. 1869.48 samples/sec. 136.937 ms/step.
Train [40/40]. 1869.35 samples/sec. 136.946 ms/step.
Train benchmark of vit_base_patch32_clip_224.laion2b_ft_in12k_in1k done. 1859.40 samples/sec, 136.95 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_224.openai created, param count: 87849728
Running inference benchmark on vit_base_patch32_clip_224.openai for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6296.95 samples/sec. 40.655 ms/step.
Infer [16/40]. 6296.87 samples/sec. 40.655 ms/step.
Infer [24/40]. 6296.75 samples/sec. 40.656 ms/step.
Infer [32/40]. 6296.73 samples/sec. 40.656 ms/step.
Infer [40/40]. 6296.61 samples/sec. 40.657 ms/step.
Inference benchmark of vit_base_patch32_clip_224.openai done. 6292.91 samples/sec, 40.66 ms/step
Model vit_base_patch32_clip_224.openai created, param count: 87849728
Running train benchmark on vit_base_patch32_clip_224.openai for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1870.68 samples/sec. 136.849 ms/step.
Train [16/40]. 1870.56 samples/sec. 136.857 ms/step.
Train [24/40]. 1870.28 samples/sec. 136.878 ms/step.
Train [32/40]. 1870.13 samples/sec. 136.889 ms/step.
Train [40/40]. 1870.05 samples/sec. 136.895 ms/step.
Train benchmark of vit_base_patch32_clip_224.openai done. 1860.11 samples/sec, 136.90 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_224.openai_ft_in1k created, param count: 88225000
Running inference benchmark on vit_base_patch32_clip_224.openai_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 6294.36 samples/sec. 40.671 ms/step.
Infer [16/40]. 6292.19 samples/sec. 40.685 ms/step.
Infer [24/40]. 6292.19 samples/sec. 40.685 ms/step.
Infer [32/40]. 6292.32 samples/sec. 40.684 ms/step.
Infer [40/40]. 6292.53 samples/sec. 40.683 ms/step.
Inference benchmark of vit_base_patch32_clip_224.openai_ft_in1k done. 6288.79 samples/sec, 40.68 ms/step
Model vit_base_patch32_clip_224.openai_ft_in1k created, param count: 88225000
Running train benchmark on vit_base_patch32_clip_224.openai_ft_in1k for 40 steps w/ input size (3, 224, 224) and batch size 256.
Train [8/40]. 1870.05 samples/sec. 136.895 ms/step.
Train [16/40]. 1870.18 samples/sec. 136.886 ms/step.
Train [24/40]. 1869.83 samples/sec. 136.911 ms/step.
Train [32/40]. 1869.65 samples/sec. 136.924 ms/step.
Train [40/40]. 1869.56 samples/sec. 136.931 ms/step.
Train benchmark of vit_base_patch32_clip_224.openai_ft_in1k done. 1859.58 samples/sec, 136.93 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_384.laion2b_ft_in12k_in1k created, param count: 88297960
Running inference benchmark on vit_base_patch32_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 2049.93 samples/sec. 124.882 ms/step.
Infer [16/40]. 2049.69 samples/sec. 124.897 ms/step.
Infer [24/40]. 2049.48 samples/sec. 124.910 ms/step.
Infer [32/40]. 2049.32 samples/sec. 124.920 ms/step.
Infer [40/40]. 2049.20 samples/sec. 124.927 ms/step.
Inference benchmark of vit_base_patch32_clip_384.laion2b_ft_in12k_in1k done. 2048.72 samples/sec, 124.93 ms/step
Model vit_base_patch32_clip_384.laion2b_ft_in12k_in1k created, param count: 88297960
Running train benchmark on vit_base_patch32_clip_384.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Train [8/40]. 568.93 samples/sec. 449.969 ms/step.
Train [16/40]. 568.85 samples/sec. 450.028 ms/step.
Train [24/40]. 568.84 samples/sec. 450.039 ms/step.
Train [32/40]. 568.82 samples/sec. 450.052 ms/step.
Train [40/40]. 568.82 samples/sec. 450.056 ms/step.
Train benchmark of vit_base_patch32_clip_384.laion2b_ft_in12k_in1k done. 567.54 samples/sec, 450.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_384.openai_ft_in12k_in1k created, param count: 88297960
Running inference benchmark on vit_base_patch32_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 2049.43 samples/sec. 124.913 ms/step.
Infer [16/40]. 2049.04 samples/sec. 124.937 ms/step.
Infer [24/40]. 2048.72 samples/sec. 124.956 ms/step.
Infer [32/40]. 2048.61 samples/sec. 124.963 ms/step.
Infer [40/40]. 2048.29 samples/sec. 124.982 ms/step.
Inference benchmark of vit_base_patch32_clip_384.openai_ft_in12k_in1k done. 2047.81 samples/sec, 124.98 ms/step
Model vit_base_patch32_clip_384.openai_ft_in12k_in1k created, param count: 88297960
Running train benchmark on vit_base_patch32_clip_384.openai_ft_in12k_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Train [8/40]. 568.83 samples/sec. 450.045 ms/step.
Train [16/40]. 568.84 samples/sec. 450.037 ms/step.
Train [24/40]. 568.83 samples/sec. 450.048 ms/step.
Train [32/40]. 568.83 samples/sec. 450.049 ms/step.
Train [40/40]. 568.81 samples/sec. 450.061 ms/step.
Train benchmark of vit_base_patch32_clip_384.openai_ft_in12k_in1k done. 567.56 samples/sec, 450.06 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_patch32_clip_448.laion2b_ft_in12k_in1k created, param count: 88337896
Running inference benchmark on vit_base_patch32_clip_448.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
Infer [8/40]. 1441.12 samples/sec. 177.640 ms/step.
Infer [16/40]. 1441.09 samples/sec. 177.643 ms/step.
Infer [24/40]. 1441.10 samples/sec. 177.643 ms/step.
Infer [32/40]. 1440.94 samples/sec. 177.662 ms/step.
Infer [40/40]. 1440.75 samples/sec. 177.685 ms/step.
Inference benchmark of vit_base_patch32_clip_448.laion2b_ft_in12k_in1k done. 1440.47 samples/sec, 177.69 ms/step
Model vit_base_patch32_clip_448.laion2b_ft_in12k_in1k created, param count: 88337896
Running train benchmark on vit_base_patch32_clip_448.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 48.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 28.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_patch32_clip_448.laion2b_ft_in12k_in1k created, param count: 88337896
Running train benchmark on vit_base_patch32_clip_448.laion2b_ft_in12k_in1k for 40 steps w/ input size (3, 448, 448) and batch size 192.
Train [8/40]. 403.08 samples/sec. 476.327 ms/step.
Train [16/40]. 403.08 samples/sec. 476.335 ms/step.
Train [24/40]. 403.08 samples/sec. 476.327 ms/step.
Train [32/40]. 403.09 samples/sec. 476.315 ms/step.
Train [40/40]. 403.09 samples/sec. 476.315 ms/step.
Train benchmark of vit_base_patch32_clip_448.laion2b_ft_in12k_in1k done. 402.27 samples/sec, 476.31 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running inference benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
Infer [8/40]. 262.10 samples/sec. 976.735 ms/step.
Infer [16/40]. 262.08 samples/sec. 976.794 ms/step.
Infer [24/40]. 262.07 samples/sec. 976.840 ms/step.
Infer [32/40]. 261.96 samples/sec. 977.237 ms/step.
Infer [40/40]. 261.94 samples/sec. 977.318 ms/step.
Inference benchmark of vit_base_r50_s16_384.orig_in21k_ft_in1k done. 261.93 samples/sec, 977.32 ms/step
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running train benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacty of 23.65 GiB of which 2.15 GiB is free. Including non-PyTorch memory, this process has 21.49 GiB memory in use. Of the allocated memory 20.95 GiB is allocated by PyTorch, and 42.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running train benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 23.65 GiB of which 262.06 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 334.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running train benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 214.06 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 159.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running train benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 102.06 MiB is free. Including non-PyTorch memory, this process has 23.54 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 251.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running train benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 434.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 132.06 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 480.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running train benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.60 GiB is allocated by PyTorch, and 404.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model vit_base_r50_s16_384.orig_in21k_ft_in1k created, param count: 98950952
Running train benchmark on vit_base_r50_s16_384.orig_in21k_ft_in1k for 40 steps w/ input size (3, 384, 384) and batch size 32.
Train [8/40]. 79.65 samples/sec. 401.769 ms/step.
Train [16/40]. 79.65 samples/sec. 401.763 ms/step.
Train [24/40]. 79.65 samples/sec. 401.759 ms/step.
Train [32/40]. 79.63 samples/sec. 401.850 ms/step.
Train [40/40]. 79.61 samples/sec. 401.979 ms/step.
Train benchmark of vit_base_r50_s16_384.orig_in21k_ft_in1k done. 79.29 samples/sec, 401.98 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running inference benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
Infer [8/40]. 114.13 samples/sec. 2242.989 ms/step.
Infer [16/40]. 114.11 samples/sec. 2243.508 ms/step.
Infer [24/40]. 114.06 samples/sec. 2244.381 ms/step.
Infer [32/40]. 114.04 samples/sec. 2244.782 ms/step.
Infer [40/40]. 114.03 samples/sec. 2245.095 ms/step.
Inference benchmark of vit_giant_patch14_clip_224.laion2b done. 114.02 samples/sec, 2245.09 ms/step
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 1.04 GiB. GPU 0 has a total capacty of 23.65 GiB of which 620.06 MiB is free. Including non-PyTorch memory, this process has 23.04 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 148.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 60.06 MiB is free. Including non-PyTorch memory, this process has 23.58 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 200.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 128.
ERROR: "CUDA out of memory. Tried to allocate 772.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 26.06 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 283.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 96 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 96.
ERROR: "CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 420.06 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.43 GiB is allocated by PyTorch, and 312.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 64 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 64.
ERROR: "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 348.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 48 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 48.
ERROR: "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 198.06 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.53 GiB is allocated by PyTorch, and 425.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 32 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 32.
ERROR: "CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 78.06 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 22.52 GiB is allocated by PyTorch, and 561.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 24 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 24.
ERROR: "CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 92.06 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 301.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 16 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 16.
ERROR: "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 50.06 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 21.21 GiB is allocated by PyTorch, and 1.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 12 for retry.
Model vit_giant_patch14_clip_224.laion2b created, param count: 1012646656
Running train benchmark on vit_giant_patch14_clip_224.laion2b for 40 steps w/ input size (3, 224, 224) and batch size 12.
Train [8/40]. 27.70 samples/sec. 433.257 ms/step.
Train [16/40]. 27.69 samples/sec. 433.292 ms/step.
Train [24/40]. 27.69 samples/sec. 433.305 ms/step.
Train [32/40]. 27.69 samples/sec. 433.319 ms/step.
Train [40/40]. 27.69 samples/sec. 433.318 ms/step.
Train benchmark of vit_giant_patch14_clip_224.laion2b done. 27.54 samples/sec, 433.32 ms/sample
Benchmarking in float32 precision. NCHW layout. torchscript disabled
Model vit_giant_patch14_dinov2.lvd142m created, param count: 1136479232
Running inference benchmark on vit_giant_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 256.
ERROR: "CUDA out of memory. Tried to allocate 5.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.32 GiB is free. Including non-PyTorch memory, this process has 22.32 GiB memory in use. Of the allocated memory 21.78 GiB is allocated by PyTorch, and 42.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 192 for retry.
Model vit_giant_patch14_dinov2.lvd142m created, param count: 1136479232
Running inference benchmark on vit_giant_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 192.
ERROR: "CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 23.65 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 22.29 GiB memory in use. Of the allocated memory 21.42 GiB is allocated by PyTorch, and 380.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" while running benchmark.
WARNING: Reducing batch size to 128 for retry.
Model vit_giant_patch14_dinov2.lvd142m created, param count: 1136479232
Running inference benchmark on vit_giant_patch14_dinov2.lvd142m for 40 steps w/ input size (3, 518, 518) and batch size 128.
Infer [8/40]. 14.36 samples/sec. 8915.594 ms/step.
Infer [16/40]. 14.34 samples/sec. 8923.443 ms/step.
Infer [24/40]. 14.34 samples/sec. 8928.500 ms/step.
